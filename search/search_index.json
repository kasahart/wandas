{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Wandas: Waveform Analysis Data Structures","text":"<p>Wandas \u306f\u3001Python\u306b\u3088\u308b\u52b9\u7387\u7684\u306a\u4fe1\u53f7\u89e3\u6790\u306e\u305f\u3081\u306e\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002Wandas \u306f\u3001\u4fe1\u53f7\u51e6\u7406\u306e\u305f\u3081\u306e\u5305\u62ec\u7684\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u3001Matplotlib\u3068\u306e\u30b7\u30fc\u30e0\u30ec\u30b9\u306a\u7d71\u5408\u3092\u5b9f\u73fe\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"#_1","title":"\u6a5f\u80fd","text":"<ul> <li>\u5305\u62ec\u7684\u306a\u4fe1\u53f7\u51e6\u7406\u6a5f\u80fd: \u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3001\u30d5\u30fc\u30ea\u30a8\u5909\u63db\u3001STFT\u306a\u3069\u3001\u57fa\u672c\u7684\u306a\u4fe1\u53f7\u51e6\u7406\u64cd\u4f5c\u3092\u7c21\u5358\u306b\u5b9f\u884c\u53ef\u80fd</li> <li>\u53ef\u8996\u5316\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e\u7d71\u5408: Matplotlib\u3068\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u7d71\u5408\u3057\u3066\u30c7\u30fc\u30bf\u3092\u7c21\u5358\u306b\u53ef\u8996\u5316\u53ef\u80fd</li> <li>\u9045\u5ef6\u8a55\u4fa1: dask\u3092\u6d3b\u7528\u3057\u305f\u52b9\u7387\u7684\u306a\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u51e6\u7406</li> <li>\u591a\u69d8\u306a\u5206\u6790\u30c4\u30fc\u30eb: \u5468\u6ce2\u6570\u5206\u6790\u3001\u30aa\u30af\u30bf\u30fc\u30d6\u30d0\u30f3\u30c9\u5206\u6790\u3001\u6642\u9593-\u5468\u6ce2\u6570\u5206\u6790\u306a\u3069</li> </ul>"},{"location":"#_2","title":"\u4f7f\u7528\u4f8b","text":""},{"location":"#_3","title":"\u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f\u3068\u53ef\u8996\u5316","text":"<pre><code>import wandas as wd\n\n# docs/docs/ja/index.md \u304b\u3089\u306e\u76f8\u5bfe\u30d1\u30b9\u3067\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\n# \u5b9f\u969b\u306e\u4f7f\u7528\u6642\u306f\u9069\u5207\u306a\u30d1\u30b9\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\n# cf = wd.read_wav(\"../../examples/data/summer_streets1.wav\")\n# cf.describe()\n</code></pre>"},{"location":"#_4","title":"\u30d5\u30a3\u30eb\u30bf\u51e6\u7406","text":"<pre><code># import wandas as wd\n# import numpy as np\n# signal = wd.generate_sin(freqs=[5000, 1000], duration=1)\n# \u30ed\u30fc\u30d1\u30b9\u30d5\u30a3\u30eb\u30bf\u3092\u9069\u7528\n# filtered_signal = signal.low_pass_filter(cutoff=1000)\n# filtered_signal.fft().plot()\n</code></pre> <p>\u8a73\u7d30\u306a\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3084\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"#_5","title":"\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u69cb\u6210","text":"<ul> <li>\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb - 5\u5206\u3067\u59cb\u3081\u3089\u308c\u308b\u5165\u9580\u30ac\u30a4\u30c9\u3068\u4e00\u822c\u7684\u306a\u30bf\u30b9\u30af\u306e\u30ec\u30b7\u30d4\u96c6</li> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - \u8a73\u7d30\u306aAPI\u4ed5\u69d8</li> <li>\u7406\u8ad6\u80cc\u666f/\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3 - \u8a2d\u8a08\u601d\u60f3\u3068\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u89e3\u8aac</li> <li>\u8ca2\u732e\u30ac\u30a4\u30c9 - \u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30b7\u30e7\u30f3\u306e\u30eb\u30fc\u30eb\u3068\u65b9\u6cd5</li> </ul>"},{"location":"#_6","title":"\u30e9\u30a4\u30bb\u30f3\u30b9","text":"<p>\u3053\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f MIT\u30e9\u30a4\u30bb\u30f3\u30b9 \u306e\u4e0b\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"contributing/","title":"Wandas\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3078\u306e\u8ca2\u732e\\n\\n\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u3001Wandas\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3078\u306e\u8ca2\u732e\u65b9\u6cd5\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002","text":""},{"location":"api/","title":"API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9","text":"<p>Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u4e3b\u8981\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3068\u95a2\u6570\u306eAPI\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u3067\u3059\u3002</p>"},{"location":"api/#_1","title":"\u30b3\u30a2\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u30b3\u30a2\u30e2\u30b8\u30e5\u30fc\u30eb\u306fWandas\u306e\u57fa\u672c\u7684\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.core","title":"<code>wandas.core</code>","text":""},{"location":"api/#wandas.core-attributes","title":"Attributes","text":""},{"location":"api/#wandas.core.__all__","title":"<code>__all__ = ['BaseFrame']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.core-classes","title":"Classes","text":""},{"location":"api/#wandas.core.BaseFrame","title":"<code>BaseFrame</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>Abstract base class for all signal frame types.</p> <p>This class provides the common interface and functionality for all frame types used in signal processing. It implements basic operations like indexing, iteration, and data manipulation that are shared across all frame types.</p>"},{"location":"api/#wandas.core.BaseFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The signal data to process. Must be a dask array. sampling_rate : float     The sampling rate of the signal in Hz. label : str, optional     A label for the frame. If not provided, defaults to \"unnamed_frame\". metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata | dict], optional     Metadata for each channel in the frame. Can be ChannelMetadata objects     or dicts that will be validated by Pydantic. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/#wandas.core.BaseFrame--attributes","title":"Attributes","text":"<p>sampling_rate : float     The sampling rate of the signal in Hz. label : str     The label of the frame. metadata : dict     Additional metadata for the frame. operation_history : list[dict]     History of operations performed on this frame.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>class BaseFrame(ABC, Generic[T]):\n    \"\"\"\n    Abstract base class for all signal frame types.\n\n    This class provides the common interface and functionality for all frame types\n    used in signal processing. It implements basic operations like indexing, iteration,\n    and data manipulation that are shared across all frame types.\n\n    Parameters\n    ----------\n    data : DaArray\n        The signal data to process. Must be a dask array.\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str, optional\n        A label for the frame. If not provided, defaults to \"unnamed_frame\".\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata | dict], optional\n        Metadata for each channel in the frame. Can be ChannelMetadata objects\n        or dicts that will be validated by Pydantic.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str\n        The label of the frame.\n    metadata : dict\n        Additional metadata for the frame.\n    operation_history : list[dict]\n        History of operations performed on this frame.\n    \"\"\"\n\n    _data: DaArray\n    sampling_rate: float\n    label: str\n    metadata: dict[str, Any]\n    operation_history: list[dict[str, Any]]\n    _channel_metadata: list[ChannelMetadata]\n    _previous: Optional[\"BaseFrame[Any]\"]\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ):\n        self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n        if self._data.ndim == 1:\n            self._data = self._data.reshape((1, -1))\n        self.sampling_rate = sampling_rate\n        self.label = label or \"unnamed_frame\"\n        self.metadata = metadata or {}\n        self.operation_history = operation_history or []\n        self._previous = previous\n\n        if channel_metadata:\n            # Pydantic handles both ChannelMetadata objects and dicts\n            def _to_channel_metadata(\n                ch: ChannelMetadata | dict[str, Any], index: int\n            ) -&gt; ChannelMetadata:\n                if isinstance(ch, ChannelMetadata):\n                    return copy.deepcopy(ch)\n                elif isinstance(ch, dict):\n                    try:\n                        return ChannelMetadata(**ch)\n                    except ValidationError as e:\n                        raise ValueError(\n                            f\"Invalid channel_metadata at index {index}\\n\"\n                            f\"  Got: {ch}\\n\"\n                            f\"  Validation error: {e}\\n\"\n                            f\"Ensure all dict keys match ChannelMetadata fields \"\n                            f\"(label, unit, ref, extra) and have correct types.\"\n                        ) from e\n                else:\n                    raise TypeError(\n                        f\"Invalid type in channel_metadata at index {index}\\n\"\n                        f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                        f\"  Expected: ChannelMetadata or dict\\n\"\n                        f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                    )\n\n            self._channel_metadata = [\n                _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n                for i, ch in enumerate(channel_metadata)\n            ]\n        else:\n            self._channel_metadata = [\n                ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n                for i in range(self._n_channels)\n            ]\n\n        try:\n            # Display information for newer dask versions\n            logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n            logger.debug(\n                f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n            )\n        except Exception as e:\n            logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n\n    @property\n    @abstractmethod\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n\n    @property\n    def n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return self._n_channels\n\n    @property\n    def channels(self) -&gt; list[ChannelMetadata]:\n        \"\"\"Property to access channel metadata.\"\"\"\n        return self._channel_metadata\n\n    @property\n    def previous(self) -&gt; Optional[\"BaseFrame[Any]\"]:\n        \"\"\"\n        Returns the previous frame.\n        \"\"\"\n        return self._previous\n\n    def get_channel(\n        self: S,\n        channel_idx: int\n        | list[int]\n        | tuple[int, ...]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index.\n\n        Parameters\n        ----------\n        channel_idx : int or sequence of int\n            Single channel index or sequence of channel indices.\n            Supports negative indices (e.g., -1 for the last channel).\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n        &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n        &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n        &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n        \"\"\"\n        if isinstance(channel_idx, int):\n            # Convert single channel to a list.\n            channel_idx_list: list[int] = [channel_idx]\n        else:\n            channel_idx_list = list(channel_idx)\n\n        new_data = self._data[channel_idx_list]\n        new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Returns the number of channels.\n        \"\"\"\n        return len(self._channel_metadata)\n\n    def __iter__(self: S) -&gt; Iterator[S]:\n        for idx in range(len(self)):\n            yield self[idx]\n\n    def __getitem__(\n        self: S,\n        key: int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index, label, or advanced indexing.\n\n        This method supports multiple indexing patterns similar to NumPy and pandas:\n\n        - Single channel by index: `frame[0]`\n        - Single channel by label: `frame[\"ch0\"]`\n        - Slice of channels: `frame[0:3]`\n        - Multiple channels by indices: `frame[[0, 2, 5]]`\n        - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n        - NumPy integer array: `frame[np.array([0, 2])]`\n        - Boolean mask: `frame[mask]` where mask is a boolean array\n        - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n        Parameters\n        ----------\n        key : int, str, slice, list, tuple, or ndarray\n            - int: Single channel index (supports negative indexing)\n            - str: Single channel label\n            - slice: Range of channels\n            - list[int]: Multiple channel indices\n            - list[str]: Multiple channel labels\n            - tuple: Multidimensional indexing (channel_key, time_key, ...)\n            - ndarray[int]: NumPy array of channel indices\n            - ndarray[bool]: Boolean mask for channel selection\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Raises\n        ------\n        ValueError\n            If the key length is invalid for the shape or if boolean mask\n            length doesn't match number of channels.\n        IndexError\n            If the channel index is out of range.\n        TypeError\n            If the key type is invalid or list contains mixed types.\n        KeyError\n            If a channel label is not found.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Single channel selection\n        &gt;&gt;&gt; frame[0]  # First channel\n        &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n        &gt;&gt;&gt; frame[-1]  # Last channel\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Multiple channel selection\n        &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n        &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n        &gt;&gt;&gt; frame[0:3]  # Slice\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # NumPy array indexing\n        &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n        &gt;&gt;&gt; mask = np.array([True, False, True])\n        &gt;&gt;&gt; frame[mask]  # Boolean mask\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Time slicing (multidimensional)\n        &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n        &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n        \"\"\"\n\n        # Single index (int)\n        if isinstance(key, numbers.Integral):\n            # Ensure we pass a plain Python int to satisfy the type checker\n            return self.get_channel(int(key))\n\n        # Single label (str)\n        if isinstance(key, str):\n            index = self.label2index(key)\n            return self.get_channel(index)\n\n        # Phase 2: NumPy array support (bool mask and int array)\n        if isinstance(key, np.ndarray):\n            if key.dtype == bool or key.dtype == np.bool_:\n                # Boolean mask\n                if len(key) != self.n_channels:\n                    raise ValueError(\n                        f\"Boolean mask length {len(key)} does not match \"\n                        f\"number of channels {self.n_channels}\"\n                    )\n                indices = np.where(key)[0]\n                return self.get_channel(indices)\n            elif np.issubdtype(key.dtype, np.integer):\n                # Integer array\n                return self.get_channel(key)\n            else:\n                raise TypeError(\n                    f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n                )\n\n        # Phase 1: List support (int or str)\n        if isinstance(key, list):\n            if len(key) == 0:\n                raise ValueError(\"Cannot index with an empty list\")\n\n            # Check if all elements are strings\n            if all(isinstance(k, str) for k in key):\n                # Multiple labels - type narrowing for mypy\n                str_list = cast(list[str], key)\n                indices_from_labels = [self.label2index(label) for label in str_list]\n                return self.get_channel(indices_from_labels)\n\n            # Check if all elements are integers\n            elif all(isinstance(k, int | np.integer) for k in key):\n                # Multiple indices - convert to list[int] for type safety\n                int_list = [int(k) for k in key]\n                return self.get_channel(int_list)\n\n            else:\n                raise TypeError(\n                    f\"List must contain all str or all int, got mixed types: \"\n                    f\"{[type(k).__name__ for k in key]}\"\n                )\n\n        # Tuple: multidimensional indexing\n        if isinstance(key, tuple):\n            return self._handle_multidim_indexing(key)\n\n        # Slice\n        if isinstance(key, slice):\n            new_data = self._data[key]\n            new_channel_metadata = self._channel_metadata[key]\n            if isinstance(new_channel_metadata, ChannelMetadata):\n                new_channel_metadata = [new_channel_metadata]\n            return self._create_new_instance(\n                data=new_data,\n                operation_history=self.operation_history,\n                channel_metadata=new_channel_metadata,\n            )\n\n        raise TypeError(\n            f\"Invalid key type: {type(key).__name__}. \"\n            f\"Expected int, str, slice, list, tuple, or ndarray.\"\n        )\n\n    def _handle_multidim_indexing(\n        self: S,\n        key: tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ],\n    ) -&gt; S:\n        \"\"\"\n        Handle multidimensional indexing (channel + time axis).\n\n        Parameters\n        ----------\n        key : tuple\n            Tuple of indices where the first element selects channels\n            and subsequent elements select along other dimensions (e.g., time).\n\n        Returns\n        -------\n        S\n            New instance with selected channels and time range.\n\n        Raises\n        ------\n        ValueError\n            If the key length exceeds the data dimensions.\n        \"\"\"\n        if len(key) &gt; self._data.ndim:\n            raise ValueError(f\"Invalid key length: {len(key)} for shape {self.shape}\")\n\n        # First element: channel selection\n        channel_key = key[0]\n        time_keys = key[1:] if len(key) &gt; 1 else ()\n\n        # Select channels first (recursively call __getitem__)\n        if isinstance(channel_key, list | np.ndarray):\n            selected = self[channel_key]\n        elif isinstance(channel_key, int | str | slice):\n            selected = self[channel_key]\n        else:\n            raise TypeError(\n                f\"Invalid channel key type in tuple: {type(channel_key).__name__}\"\n            )\n\n        # Apply time indexing if present\n        if time_keys:\n            new_data = selected._data[(slice(None),) + time_keys]\n            return selected._create_new_instance(\n                data=new_data,\n                operation_history=selected.operation_history,\n                channel_metadata=selected._channel_metadata,\n            )\n\n        return selected\n\n    def label2index(self, label: str) -&gt; int:\n        \"\"\"\n        Get the index from a channel label.\n\n        Parameters\n        ----------\n        label : str\n            Channel label.\n\n        Returns\n        -------\n        int\n            Corresponding index.\n\n        Raises\n        ------\n        KeyError\n            If the channel label is not found.\n        \"\"\"\n        for idx, ch in enumerate(self._channel_metadata):\n            if ch.label == label:\n                return idx\n        raise KeyError(f\"Channel label '{label}' not found.\")\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        _shape: tuple[int, ...] = self._data.shape\n        if _shape[0] == 1:\n            return _shape[1:]\n        return _shape\n\n    @property\n    def data(self) -&gt; T:\n        \"\"\"\n        Returns the computed data.\n        Calculation is executed the first time this is accessed.\n        \"\"\"\n        data = self.compute()\n        if self.n_channels == 1:\n            return data.squeeze(axis=0)\n        return data\n\n    @property\n    def labels(self) -&gt; list[str]:\n        \"\"\"Get a list of all channel labels.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def compute(self) -&gt; T:\n        \"\"\"\n        Compute and return the data.\n        This method materializes lazily computed data into a concrete NumPy array.\n\n        Returns\n        -------\n        NDArrayReal\n            The computed data.\n\n        Raises\n        ------\n        ValueError\n            If the computed result is not a NumPy array.\n        \"\"\"\n        logger.debug(\n            \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n        )\n        result = self._data.compute()\n\n        if not isinstance(result, np.ndarray):\n            raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n        logger.debug(f\"Computation complete, result shape: {result.shape}\")\n        return cast(T, result)\n\n    @abstractmethod\n    def plot(\n        self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the data\"\"\"\n        pass\n\n    def persist(self: S) -&gt; S:\n        \"\"\"Persist the data in memory\"\"\"\n        persisted_data = self._data.persist()\n        return self._create_new_instance(data=persisted_data)\n\n    @abstractmethod\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Abstract method for derived classes to provide\n        additional initialization arguments.\n        \"\"\"\n        pass\n\n    def _create_new_instance(self: S, data: DaArray, **kwargs: Any) -&gt; S:\n        \"\"\"\n        Create a new channel instance based on an existing channel.\n        Keyword arguments can override or extend the original attributes.\n        \"\"\"\n\n        sampling_rate = kwargs.pop(\"sampling_rate\", self.sampling_rate)\n        # if not isinstance(sampling_rate, int):\n        #     raise TypeError(\"Sampling rate must be an integer\")\n\n        label = kwargs.pop(\"label\", self.label)\n        if not isinstance(label, str):\n            raise TypeError(\"Label must be a string\")\n\n        metadata = kwargs.pop(\"metadata\", copy.deepcopy(self.metadata))\n        if not isinstance(metadata, dict):\n            raise TypeError(\"Metadata must be a dictionary\")\n\n        channel_metadata = kwargs.pop(\n            \"channel_metadata\", copy.deepcopy(self._channel_metadata)\n        )\n        if not isinstance(channel_metadata, list):\n            raise TypeError(\"Channel metadata must be a list\")\n\n        # Get additional initialization arguments from derived classes\n        additional_kwargs = self._get_additional_init_kwargs()\n        kwargs.update(additional_kwargs)\n\n        return type(self)(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            channel_metadata=channel_metadata,\n            previous=self,\n            **kwargs,\n        )\n\n    def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n        \"\"\"Implicit conversion to NumPy array\"\"\"\n        result = self.compute()\n        if dtype is not None:\n            return result.astype(dtype)\n        return result\n\n    def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n        \"\"\"\n        Visualize the computation graph and save it to a file.\n\n        This method creates a visual representation of the Dask computation graph.\n        In Jupyter notebooks, it returns an IPython.display.Image object that\n        will be displayed inline. In other environments, it saves the graph to\n        a file and returns None.\n\n        Parameters\n        ----------\n        filename : str, optional\n            Output filename for the graph image. If None, a unique filename\n            is generated using UUID. The file is saved in the current working\n            directory.\n\n        Returns\n        -------\n        IPython.display.Image or None\n            In Jupyter environments: Returns an IPython.display.Image object\n            that can be displayed inline.\n            In other environments: Returns None after saving the graph to file.\n            Returns None if visualization fails.\n\n        Notes\n        -----\n        This method requires graphviz to be installed on your system:\n        - Ubuntu/Debian: `sudo apt-get install graphviz`\n        - macOS: `brew install graphviz`\n        - Windows: Download from https://graphviz.org/download/\n\n        The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n        making it easier to understand the processing pipeline.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n        &gt;&gt;&gt; # In Jupyter: displays graph inline\n        &gt;&gt;&gt; processed.visualize_graph()\n        &gt;&gt;&gt; # Save to specific file\n        &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n        See Also\n        --------\n        debug_info : Print detailed debug information about the frame\n        \"\"\"\n        try:\n            filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n            return self._data.visualize(filename=filename)\n        except Exception as e:\n            logger.warning(f\"Failed to visualize the graph: {e}\")\n            return None\n\n    @abstractmethod\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"Basic implementation of binary operations\"\"\"\n        # Basic logic\n        # Actual implementation is left to derived classes\n        pass\n\n    def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Addition operator\"\"\"\n        return self._binary_op(other, lambda x, y: x + y, \"+\")\n\n    def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Subtraction operator\"\"\"\n        return self._binary_op(other, lambda x, y: x - y, \"-\")\n\n    def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Multiplication operator\"\"\"\n        return self._binary_op(other, lambda x, y: x * y, \"*\")\n\n    def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Division operator\"\"\"\n        return self._binary_op(other, lambda x, y: x / y, \"/\")\n\n    def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Power operator\"\"\"\n        return self._binary_op(other, lambda x, y: x**y, \"**\")\n\n    def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply a named operation.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters to pass to the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        # Apply the operation through abstract method\n        return self._apply_operation_impl(operation_name, **params)\n\n    @abstractmethod\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"Implementation of operation application\"\"\"\n        pass\n\n    def _relabel_channels(\n        self,\n        operation_name: str,\n        display_name: str | None = None,\n    ) -&gt; list[ChannelMetadata]:\n        \"\"\"\n        Update channel labels to reflect applied operation.\n\n        This method creates new channel metadata with labels that include\n        the operation name, making it easier to track processing history\n        and distinguish frames in plots.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation (e.g., \"normalize\", \"lowpass_filter\")\n        display_name : str, optional\n            Display name for the operation. If None, uses operation_name.\n            This allows operations to provide custom, more readable labels.\n\n        Returns\n        -------\n        list[ChannelMetadata]\n            New channel metadata with updated labels.\n            Original metadata is deep-copied and only labels are modified.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Original label: \"ch0\"\n        &gt;&gt;&gt; # After normalize: \"normalize(ch0)\"\n        &gt;&gt;&gt; # After chained ops: \"lowpass_filter(normalize(ch0))\"\n\n        Notes\n        -----\n        Labels are nested for chained operations, allowing full\n        traceability of the processing pipeline.\n        \"\"\"\n        display = display_name or operation_name\n        new_metadata = []\n        for ch in self._channel_metadata:\n            # All channel metadata are ChannelMetadata objects at this point\n            new_ch = ch.model_copy(deep=True)\n            new_ch.label = f\"{display}({ch.label})\"\n            new_metadata.append(new_ch)\n        return new_metadata\n\n    def debug_info(self) -&gt; None:\n        \"\"\"Output detailed debug information\"\"\"\n        logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n        logger.debug(f\"Label: {self.label}\")\n        logger.debug(f\"Shape: {self.shape}\")\n        logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n        logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n        self._debug_info_impl()\n        logger.debug(\"=== End Debug Info ===\")\n\n    def print_operation_history(self) -&gt; None:\n        \"\"\"\n        Print the operation history to standard output in a readable format.\n\n        This method writes a human-friendly representation of the\n        `operation_history` list to stdout. Each operation is printed on its\n        own line with an index, the operation name (if available), and the\n        parameters used.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf.print_operation_history()\n        1: normalize {}\n        2: low_pass_filter {'cutoff': 1000}\n        \"\"\"\n        if not self.operation_history:\n            print(\"Operation history: &lt;empty&gt;\")\n            return\n\n        print(f\"Operation history ({len(self.operation_history)}):\")\n        for i, record in enumerate(self.operation_history, start=1):\n            # record is expected to be a dict with at least a 'operation' key\n            op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n            # Copy params for display - exclude the 'operation'/'name' keys\n            params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n            print(f\"{i}: {op_name} {params}\")\n\n    def to_numpy(self) -&gt; T:\n        \"\"\"Convert the frame data to a NumPy array.\n\n        This method computes the Dask array and returns it as a concrete NumPy array.\n        The returned array has the same shape as the frame's data.\n\n        Returns\n        -------\n        T\n            NumPy array containing the frame data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; data = cf.to_numpy()\n        &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n        \"\"\"\n        return self.data\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"Convert the frame data to a pandas DataFrame.\n\n        This method provides a common implementation for converting frame data\n        to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame with appropriate index and columns.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; df = cf.to_dataframe()\n        &gt;&gt;&gt; print(df.head())\n        \"\"\"\n        # Get data as numpy array\n        data = self.to_numpy()\n\n        # Get column names from subclass\n        columns = self._get_dataframe_columns()\n\n        # Get index from subclass\n        index = self._get_dataframe_index()\n\n        # Create DataFrame\n        if data.ndim == 1:\n            # Single channel case - reshape to 2D\n            df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n        else:\n            # Multi-channel case - transpose to (n_samples, n_channels)\n            df = pd.DataFrame(data.T, columns=columns, index=index)\n\n        return df\n\n    @abstractmethod\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get column names for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate column names for the DataFrame.\n\n        Returns\n        -------\n        list[str]\n            List of column names.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get index for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate index for the DataFrame based on the frame type.\n\n        Returns\n        -------\n        pd.Index\n            Index for the DataFrame.\n        \"\"\"\n        pass\n\n    def _debug_info_impl(self) -&gt; None:\n        \"\"\"Implement derived class-specific debug information\"\"\"\n        pass\n\n    def _print_operation_history(self) -&gt; None:\n        \"\"\"Print the operation history information.\n\n        This is a helper method for info() implementations to display\n        the number of operations applied to the frame in a consistent format.\n        \"\"\"\n        if self.operation_history:\n            print(f\"  Operations Applied: {len(self.operation_history)}\")\n        else:\n            print(\"  Operations Applied: None\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame-attributes","title":"Attributes","text":""},{"location":"api/#wandas.core.BaseFrame.sampling_rate","title":"<code>sampling_rate = sampling_rate</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.core.BaseFrame.label","title":"<code>label = label or 'unnamed_frame'</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.core.BaseFrame.metadata","title":"<code>metadata = metadata or {}</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.core.BaseFrame.operation_history","title":"<code>operation_history = operation_history or []</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.core.BaseFrame.n_channels","title":"<code>n_channels</code>  <code>property</code>","text":"<p>Returns the number of channels.</p>"},{"location":"api/#wandas.core.BaseFrame.channels","title":"<code>channels</code>  <code>property</code>","text":"<p>Property to access channel metadata.</p>"},{"location":"api/#wandas.core.BaseFrame.previous","title":"<code>previous</code>  <code>property</code>","text":"<p>Returns the previous frame.</p>"},{"location":"api/#wandas.core.BaseFrame.shape","title":"<code>shape</code>  <code>property</code>","text":""},{"location":"api/#wandas.core.BaseFrame.data","title":"<code>data</code>  <code>property</code>","text":"<p>Returns the computed data. Calculation is executed the first time this is accessed.</p>"},{"location":"api/#wandas.core.BaseFrame.labels","title":"<code>labels</code>  <code>property</code>","text":"<p>Get a list of all channel labels.</p>"},{"location":"api/#wandas.core.BaseFrame-functions","title":"Functions","text":""},{"location":"api/#wandas.core.BaseFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n):\n    self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n    if self._data.ndim == 1:\n        self._data = self._data.reshape((1, -1))\n    self.sampling_rate = sampling_rate\n    self.label = label or \"unnamed_frame\"\n    self.metadata = metadata or {}\n    self.operation_history = operation_history or []\n    self._previous = previous\n\n    if channel_metadata:\n        # Pydantic handles both ChannelMetadata objects and dicts\n        def _to_channel_metadata(\n            ch: ChannelMetadata | dict[str, Any], index: int\n        ) -&gt; ChannelMetadata:\n            if isinstance(ch, ChannelMetadata):\n                return copy.deepcopy(ch)\n            elif isinstance(ch, dict):\n                try:\n                    return ChannelMetadata(**ch)\n                except ValidationError as e:\n                    raise ValueError(\n                        f\"Invalid channel_metadata at index {index}\\n\"\n                        f\"  Got: {ch}\\n\"\n                        f\"  Validation error: {e}\\n\"\n                        f\"Ensure all dict keys match ChannelMetadata fields \"\n                        f\"(label, unit, ref, extra) and have correct types.\"\n                    ) from e\n            else:\n                raise TypeError(\n                    f\"Invalid type in channel_metadata at index {index}\\n\"\n                    f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                    f\"  Expected: ChannelMetadata or dict\\n\"\n                    f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                )\n\n        self._channel_metadata = [\n            _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n            for i, ch in enumerate(channel_metadata)\n        ]\n    else:\n        self._channel_metadata = [\n            ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n            for i in range(self._n_channels)\n        ]\n\n    try:\n        # Display information for newer dask versions\n        logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n        logger.debug(\n            f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n        )\n    except Exception as e:\n        logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.get_channel","title":"<code>get_channel(channel_idx)</code>","text":"<p>Get channel(s) by index.</p>"},{"location":"api/#wandas.core.BaseFrame.get_channel--parameters","title":"Parameters","text":"<p>channel_idx : int or sequence of int     Single channel index or sequence of channel indices.     Supports negative indices (e.g., -1 for the last channel).</p>"},{"location":"api/#wandas.core.BaseFrame.get_channel--returns","title":"Returns","text":"<p>S     New instance containing the selected channel(s).</p>"},{"location":"api/#wandas.core.BaseFrame.get_channel--examples","title":"Examples","text":"<p>frame.get_channel(0)  # Single channel frame.get_channel([0, 2, 3])  # Multiple channels frame.get_channel((-1, -2))  # Last two channels frame.get_channel(np.array([1, 2]))  # NumPy array of indices</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def get_channel(\n    self: S,\n    channel_idx: int\n    | list[int]\n    | tuple[int, ...]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index.\n\n    Parameters\n    ----------\n    channel_idx : int or sequence of int\n        Single channel index or sequence of channel indices.\n        Supports negative indices (e.g., -1 for the last channel).\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n    &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n    &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n    &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n    \"\"\"\n    if isinstance(channel_idx, int):\n        # Convert single channel to a list.\n        channel_idx_list: list[int] = [channel_idx]\n    else:\n        channel_idx_list = list(channel_idx)\n\n    new_data = self._data[channel_idx_list]\n    new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n    return self._create_new_instance(\n        data=new_data,\n        operation_history=self.operation_history,\n        channel_metadata=new_channel_metadata,\n    )\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of channels.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of channels.\n    \"\"\"\n    return len(self._channel_metadata)\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__iter__","title":"<code>__iter__()</code>","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __iter__(self: S) -&gt; Iterator[S]:\n    for idx in range(len(self)):\n        yield self[idx]\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get channel(s) by index, label, or advanced indexing.</p> <p>This method supports multiple indexing patterns similar to NumPy and pandas:</p> <ul> <li>Single channel by index: <code>frame[0]</code></li> <li>Single channel by label: <code>frame[\"ch0\"]</code></li> <li>Slice of channels: <code>frame[0:3]</code></li> <li>Multiple channels by indices: <code>frame[[0, 2, 5]]</code></li> <li>Multiple channels by labels: <code>frame[[\"ch0\", \"ch2\"]]</code></li> <li>NumPy integer array: <code>frame[np.array([0, 2])]</code></li> <li>Boolean mask: <code>frame[mask]</code> where mask is a boolean array</li> <li>Multidimensional indexing: <code>frame[0, 100:200]</code> (channel + time)</li> </ul>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--parameters","title":"Parameters","text":"<p>key : int, str, slice, list, tuple, or ndarray     - int: Single channel index (supports negative indexing)     - str: Single channel label     - slice: Range of channels     - list[int]: Multiple channel indices     - list[str]: Multiple channel labels     - tuple: Multidimensional indexing (channel_key, time_key, ...)     - ndarray[int]: NumPy array of channel indices     - ndarray[bool]: Boolean mask for channel selection</p>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--returns","title":"Returns","text":"<p>S     New instance containing the selected channel(s).</p>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--raises","title":"Raises","text":"<p>ValueError     If the key length is invalid for the shape or if boolean mask     length doesn't match number of channels. IndexError     If the channel index is out of range. TypeError     If the key type is invalid or list contains mixed types. KeyError     If a channel label is not found.</p>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--examples","title":"Examples","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __getitem__(\n    self: S,\n    key: int\n    | str\n    | slice\n    | list[int]\n    | list[str]\n    | tuple[\n        int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n        ...,\n    ]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index, label, or advanced indexing.\n\n    This method supports multiple indexing patterns similar to NumPy and pandas:\n\n    - Single channel by index: `frame[0]`\n    - Single channel by label: `frame[\"ch0\"]`\n    - Slice of channels: `frame[0:3]`\n    - Multiple channels by indices: `frame[[0, 2, 5]]`\n    - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n    - NumPy integer array: `frame[np.array([0, 2])]`\n    - Boolean mask: `frame[mask]` where mask is a boolean array\n    - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n    Parameters\n    ----------\n    key : int, str, slice, list, tuple, or ndarray\n        - int: Single channel index (supports negative indexing)\n        - str: Single channel label\n        - slice: Range of channels\n        - list[int]: Multiple channel indices\n        - list[str]: Multiple channel labels\n        - tuple: Multidimensional indexing (channel_key, time_key, ...)\n        - ndarray[int]: NumPy array of channel indices\n        - ndarray[bool]: Boolean mask for channel selection\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Raises\n    ------\n    ValueError\n        If the key length is invalid for the shape or if boolean mask\n        length doesn't match number of channels.\n    IndexError\n        If the channel index is out of range.\n    TypeError\n        If the key type is invalid or list contains mixed types.\n    KeyError\n        If a channel label is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Single channel selection\n    &gt;&gt;&gt; frame[0]  # First channel\n    &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n    &gt;&gt;&gt; frame[-1]  # Last channel\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Multiple channel selection\n    &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n    &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n    &gt;&gt;&gt; frame[0:3]  # Slice\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # NumPy array indexing\n    &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n    &gt;&gt;&gt; mask = np.array([True, False, True])\n    &gt;&gt;&gt; frame[mask]  # Boolean mask\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Time slicing (multidimensional)\n    &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n    &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n    \"\"\"\n\n    # Single index (int)\n    if isinstance(key, numbers.Integral):\n        # Ensure we pass a plain Python int to satisfy the type checker\n        return self.get_channel(int(key))\n\n    # Single label (str)\n    if isinstance(key, str):\n        index = self.label2index(key)\n        return self.get_channel(index)\n\n    # Phase 2: NumPy array support (bool mask and int array)\n    if isinstance(key, np.ndarray):\n        if key.dtype == bool or key.dtype == np.bool_:\n            # Boolean mask\n            if len(key) != self.n_channels:\n                raise ValueError(\n                    f\"Boolean mask length {len(key)} does not match \"\n                    f\"number of channels {self.n_channels}\"\n                )\n            indices = np.where(key)[0]\n            return self.get_channel(indices)\n        elif np.issubdtype(key.dtype, np.integer):\n            # Integer array\n            return self.get_channel(key)\n        else:\n            raise TypeError(\n                f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n            )\n\n    # Phase 1: List support (int or str)\n    if isinstance(key, list):\n        if len(key) == 0:\n            raise ValueError(\"Cannot index with an empty list\")\n\n        # Check if all elements are strings\n        if all(isinstance(k, str) for k in key):\n            # Multiple labels - type narrowing for mypy\n            str_list = cast(list[str], key)\n            indices_from_labels = [self.label2index(label) for label in str_list]\n            return self.get_channel(indices_from_labels)\n\n        # Check if all elements are integers\n        elif all(isinstance(k, int | np.integer) for k in key):\n            # Multiple indices - convert to list[int] for type safety\n            int_list = [int(k) for k in key]\n            return self.get_channel(int_list)\n\n        else:\n            raise TypeError(\n                f\"List must contain all str or all int, got mixed types: \"\n                f\"{[type(k).__name__ for k in key]}\"\n            )\n\n    # Tuple: multidimensional indexing\n    if isinstance(key, tuple):\n        return self._handle_multidim_indexing(key)\n\n    # Slice\n    if isinstance(key, slice):\n        new_data = self._data[key]\n        new_channel_metadata = self._channel_metadata[key]\n        if isinstance(new_channel_metadata, ChannelMetadata):\n            new_channel_metadata = [new_channel_metadata]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    raise TypeError(\n        f\"Invalid key type: {type(key).__name__}. \"\n        f\"Expected int, str, slice, list, tuple, or ndarray.\"\n    )\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--single-channel-selection","title":"Single channel selection","text":"<p>frame[0]  # First channel frame[\"acc_x\"]  # By label frame[-1]  # Last channel</p>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--multiple-channel-selection","title":"Multiple channel selection","text":"<p>frame[[0, 2, 5]]  # Multiple indices frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels frame[0:3]  # Slice</p>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--numpy-array-indexing","title":"NumPy array indexing","text":"<p>frame[np.array([0, 2, 4])]  # Integer array mask = np.array([True, False, True]) frame[mask]  # Boolean mask</p>"},{"location":"api/#wandas.core.BaseFrame.__getitem__--time-slicing-multidimensional","title":"Time slicing (multidimensional)","text":"<p>frame[0, 100:200]  # Channel 0, samples 100-200 frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample</p>"},{"location":"api/#wandas.core.BaseFrame.label2index","title":"<code>label2index(label)</code>","text":"<p>Get the index from a channel label.</p>"},{"location":"api/#wandas.core.BaseFrame.label2index--parameters","title":"Parameters","text":"<p>label : str     Channel label.</p>"},{"location":"api/#wandas.core.BaseFrame.label2index--returns","title":"Returns","text":"<p>int     Corresponding index.</p>"},{"location":"api/#wandas.core.BaseFrame.label2index--raises","title":"Raises","text":"<p>KeyError     If the channel label is not found.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n\n    Parameters\n    ----------\n    label : str\n        Channel label.\n\n    Returns\n    -------\n    int\n        Corresponding index.\n\n    Raises\n    ------\n    KeyError\n        If the channel label is not found.\n    \"\"\"\n    for idx, ch in enumerate(self._channel_metadata):\n        if ch.label == label:\n            return idx\n    raise KeyError(f\"Channel label '{label}' not found.\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.compute","title":"<code>compute()</code>","text":"<p>Compute and return the data. This method materializes lazily computed data into a concrete NumPy array.</p>"},{"location":"api/#wandas.core.BaseFrame.compute--returns","title":"Returns","text":"<p>NDArrayReal     The computed data.</p>"},{"location":"api/#wandas.core.BaseFrame.compute--raises","title":"Raises","text":"<p>ValueError     If the computed result is not a NumPy array.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def compute(self) -&gt; T:\n    \"\"\"\n    Compute and return the data.\n    This method materializes lazily computed data into a concrete NumPy array.\n\n    Returns\n    -------\n    NDArrayReal\n        The computed data.\n\n    Raises\n    ------\n    ValueError\n        If the computed result is not a NumPy array.\n    \"\"\"\n    logger.debug(\n        \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n    )\n    result = self._data.compute()\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n    logger.debug(f\"Computation complete, result shape: {result.shape}\")\n    return cast(T, result)\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.plot","title":"<code>plot(plot_type='default', ax=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Plot the data</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>@abstractmethod\ndef plot(\n    self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the data\"\"\"\n    pass\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.persist","title":"<code>persist()</code>","text":"<p>Persist the data in memory</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def persist(self: S) -&gt; S:\n    \"\"\"Persist the data in memory\"\"\"\n    persisted_data = self._data.persist()\n    return self._create_new_instance(data=persisted_data)\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__array__","title":"<code>__array__(dtype=None)</code>","text":"<p>Implicit conversion to NumPy array</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n    \"\"\"Implicit conversion to NumPy array\"\"\"\n    result = self.compute()\n    if dtype is not None:\n        return result.astype(dtype)\n    return result\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph","title":"<code>visualize_graph(filename=None)</code>","text":"<p>Visualize the computation graph and save it to a file.</p> <p>This method creates a visual representation of the Dask computation graph. In Jupyter notebooks, it returns an IPython.display.Image object that will be displayed inline. In other environments, it saves the graph to a file and returns None.</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--parameters","title":"Parameters","text":"<p>filename : str, optional     Output filename for the graph image. If None, a unique filename     is generated using UUID. The file is saved in the current working     directory.</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--returns","title":"Returns","text":"<p>IPython.display.Image or None     In Jupyter environments: Returns an IPython.display.Image object     that can be displayed inline.     In other environments: Returns None after saving the graph to file.     Returns None if visualization fails.</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--notes","title":"Notes","text":"<p>This method requires graphviz to be installed on your system: - Ubuntu/Debian: <code>sudo apt-get install graphviz</code> - macOS: <code>brew install graphviz</code> - Windows: Download from https://graphviz.org/download/</p> <p>The graph displays operation names (e.g., 'normalize', 'lowpass_filter') making it easier to understand the processing pipeline.</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"audio.wav\") processed = signal.normalize().low_pass_filter(cutoff=1000)</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--in-jupyter-displays-graph-inline","title":"In Jupyter: displays graph inline","text":"<p>processed.visualize_graph()</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--save-to-specific-file","title":"Save to specific file","text":"<p>processed.visualize_graph(\"my_graph.png\")</p>"},{"location":"api/#wandas.core.BaseFrame.visualize_graph--see-also","title":"See Also","text":"<p>debug_info : Print detailed debug information about the frame</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n    \"\"\"\n    Visualize the computation graph and save it to a file.\n\n    This method creates a visual representation of the Dask computation graph.\n    In Jupyter notebooks, it returns an IPython.display.Image object that\n    will be displayed inline. In other environments, it saves the graph to\n    a file and returns None.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Output filename for the graph image. If None, a unique filename\n        is generated using UUID. The file is saved in the current working\n        directory.\n\n    Returns\n    -------\n    IPython.display.Image or None\n        In Jupyter environments: Returns an IPython.display.Image object\n        that can be displayed inline.\n        In other environments: Returns None after saving the graph to file.\n        Returns None if visualization fails.\n\n    Notes\n    -----\n    This method requires graphviz to be installed on your system:\n    - Ubuntu/Debian: `sudo apt-get install graphviz`\n    - macOS: `brew install graphviz`\n    - Windows: Download from https://graphviz.org/download/\n\n    The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n    making it easier to understand the processing pipeline.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n    &gt;&gt;&gt; # In Jupyter: displays graph inline\n    &gt;&gt;&gt; processed.visualize_graph()\n    &gt;&gt;&gt; # Save to specific file\n    &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n    See Also\n    --------\n    debug_info : Print detailed debug information about the frame\n    \"\"\"\n    try:\n        filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n        return self._data.visualize(filename=filename)\n    except Exception as e:\n        logger.warning(f\"Failed to visualize the graph: {e}\")\n        return None\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__add__","title":"<code>__add__(other)</code>","text":"<p>Addition operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Addition operator\"\"\"\n    return self._binary_op(other, lambda x, y: x + y, \"+\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtraction operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Subtraction operator\"\"\"\n    return self._binary_op(other, lambda x, y: x - y, \"-\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiplication operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Multiplication operator\"\"\"\n    return self._binary_op(other, lambda x, y: x * y, \"*\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Division operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Division operator\"\"\"\n    return self._binary_op(other, lambda x, y: x / y, \"/\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.__pow__","title":"<code>__pow__(other)</code>","text":"<p>Power operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Power operator\"\"\"\n    return self._binary_op(other, lambda x, y: x**y, \"**\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.apply_operation","title":"<code>apply_operation(operation_name, **params)</code>","text":"<p>Apply a named operation.</p>"},{"location":"api/#wandas.core.BaseFrame.apply_operation--parameters","title":"Parameters","text":"<p>operation_name : str     Name of the operation to apply. **params : Any     Parameters to pass to the operation.</p>"},{"location":"api/#wandas.core.BaseFrame.apply_operation--returns","title":"Returns","text":"<p>S     A new instance with the operation applied.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n    \"\"\"\n    Apply a named operation.\n\n    Parameters\n    ----------\n    operation_name : str\n        Name of the operation to apply.\n    **params : Any\n        Parameters to pass to the operation.\n\n    Returns\n    -------\n    S\n        A new instance with the operation applied.\n    \"\"\"\n    # Apply the operation through abstract method\n    return self._apply_operation_impl(operation_name, **params)\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.debug_info","title":"<code>debug_info()</code>","text":"<p>Output detailed debug information</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def debug_info(self) -&gt; None:\n    \"\"\"Output detailed debug information\"\"\"\n    logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n    logger.debug(f\"Label: {self.label}\")\n    logger.debug(f\"Shape: {self.shape}\")\n    logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n    logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n    self._debug_info_impl()\n    logger.debug(\"=== End Debug Info ===\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.print_operation_history","title":"<code>print_operation_history()</code>","text":"<p>Print the operation history to standard output in a readable format.</p> <p>This method writes a human-friendly representation of the <code>operation_history</code> list to stdout. Each operation is printed on its own line with an index, the operation name (if available), and the parameters used.</p>"},{"location":"api/#wandas.core.BaseFrame.print_operation_history--examples","title":"Examples","text":"<p>cf.print_operation_history() 1: normalize {} 2: low_pass_filter {'cutoff': 1000}</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def print_operation_history(self) -&gt; None:\n    \"\"\"\n    Print the operation history to standard output in a readable format.\n\n    This method writes a human-friendly representation of the\n    `operation_history` list to stdout. Each operation is printed on its\n    own line with an index, the operation name (if available), and the\n    parameters used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf.print_operation_history()\n    1: normalize {}\n    2: low_pass_filter {'cutoff': 1000}\n    \"\"\"\n    if not self.operation_history:\n        print(\"Operation history: &lt;empty&gt;\")\n        return\n\n    print(f\"Operation history ({len(self.operation_history)}):\")\n    for i, record in enumerate(self.operation_history, start=1):\n        # record is expected to be a dict with at least a 'operation' key\n        op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n        # Copy params for display - exclude the 'operation'/'name' keys\n        params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n        print(f\"{i}: {op_name} {params}\")\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Convert the frame data to a NumPy array.</p> <p>This method computes the Dask array and returns it as a concrete NumPy array. The returned array has the same shape as the frame's data.</p>"},{"location":"api/#wandas.core.BaseFrame.to_numpy--returns","title":"Returns","text":"<p>T     NumPy array containing the frame data.</p>"},{"location":"api/#wandas.core.BaseFrame.to_numpy--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") data = cf.to_numpy() print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def to_numpy(self) -&gt; T:\n    \"\"\"Convert the frame data to a NumPy array.\n\n    This method computes the Dask array and returns it as a concrete NumPy array.\n    The returned array has the same shape as the frame's data.\n\n    Returns\n    -------\n    T\n        NumPy array containing the frame data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; data = cf.to_numpy()\n    &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n    \"\"\"\n    return self.data\n</code></pre>"},{"location":"api/#wandas.core.BaseFrame.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert the frame data to a pandas DataFrame.</p> <p>This method provides a common implementation for converting frame data to pandas DataFrame. Subclasses can override this method for custom behavior.</p>"},{"location":"api/#wandas.core.BaseFrame.to_dataframe--returns","title":"Returns","text":"<p>pd.DataFrame     DataFrame with appropriate index and columns.</p>"},{"location":"api/#wandas.core.BaseFrame.to_dataframe--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") df = cf.to_dataframe() print(df.head())</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"Convert the frame data to a pandas DataFrame.\n\n    This method provides a common implementation for converting frame data\n    to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with appropriate index and columns.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; df = cf.to_dataframe()\n    &gt;&gt;&gt; print(df.head())\n    \"\"\"\n    # Get data as numpy array\n    data = self.to_numpy()\n\n    # Get column names from subclass\n    columns = self._get_dataframe_columns()\n\n    # Get index from subclass\n    index = self._get_dataframe_index()\n\n    # Create DataFrame\n    if data.ndim == 1:\n        # Single channel case - reshape to 2D\n        df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n    else:\n        # Multi-channel case - transpose to (n_samples, n_channels)\n        df = pd.DataFrame(data.T, columns=columns, index=index)\n\n    return df\n</code></pre>"},{"location":"api/#wandas.core-modules","title":"Modules","text":""},{"location":"api/#wandas.core.base_frame","title":"<code>base_frame</code>","text":""},{"location":"api/#wandas.core.base_frame-attributes","title":"Attributes","text":""},{"location":"api/#wandas.core.base_frame.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.core.base_frame.T","title":"<code>T = TypeVar('T', NDArrayComplex, NDArrayReal)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.core.base_frame.S","title":"<code>S = TypeVar('S', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.core.base_frame-classes","title":"Classes","text":""},{"location":"api/#wandas.core.base_frame.BaseFrame","title":"<code>BaseFrame</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>Abstract base class for all signal frame types.</p> <p>This class provides the common interface and functionality for all frame types used in signal processing. It implements basic operations like indexing, iteration, and data manipulation that are shared across all frame types.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The signal data to process. Must be a dask array. sampling_rate : float     The sampling rate of the signal in Hz. label : str, optional     A label for the frame. If not provided, defaults to \"unnamed_frame\". metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata | dict], optional     Metadata for each channel in the frame. Can be ChannelMetadata objects     or dicts that will be validated by Pydantic. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame--attributes","title":"Attributes","text":"<p>sampling_rate : float     The sampling rate of the signal in Hz. label : str     The label of the frame. metadata : dict     Additional metadata for the frame. operation_history : list[dict]     History of operations performed on this frame.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>class BaseFrame(ABC, Generic[T]):\n    \"\"\"\n    Abstract base class for all signal frame types.\n\n    This class provides the common interface and functionality for all frame types\n    used in signal processing. It implements basic operations like indexing, iteration,\n    and data manipulation that are shared across all frame types.\n\n    Parameters\n    ----------\n    data : DaArray\n        The signal data to process. Must be a dask array.\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str, optional\n        A label for the frame. If not provided, defaults to \"unnamed_frame\".\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata | dict], optional\n        Metadata for each channel in the frame. Can be ChannelMetadata objects\n        or dicts that will be validated by Pydantic.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str\n        The label of the frame.\n    metadata : dict\n        Additional metadata for the frame.\n    operation_history : list[dict]\n        History of operations performed on this frame.\n    \"\"\"\n\n    _data: DaArray\n    sampling_rate: float\n    label: str\n    metadata: dict[str, Any]\n    operation_history: list[dict[str, Any]]\n    _channel_metadata: list[ChannelMetadata]\n    _previous: Optional[\"BaseFrame[Any]\"]\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ):\n        self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n        if self._data.ndim == 1:\n            self._data = self._data.reshape((1, -1))\n        self.sampling_rate = sampling_rate\n        self.label = label or \"unnamed_frame\"\n        self.metadata = metadata or {}\n        self.operation_history = operation_history or []\n        self._previous = previous\n\n        if channel_metadata:\n            # Pydantic handles both ChannelMetadata objects and dicts\n            def _to_channel_metadata(\n                ch: ChannelMetadata | dict[str, Any], index: int\n            ) -&gt; ChannelMetadata:\n                if isinstance(ch, ChannelMetadata):\n                    return copy.deepcopy(ch)\n                elif isinstance(ch, dict):\n                    try:\n                        return ChannelMetadata(**ch)\n                    except ValidationError as e:\n                        raise ValueError(\n                            f\"Invalid channel_metadata at index {index}\\n\"\n                            f\"  Got: {ch}\\n\"\n                            f\"  Validation error: {e}\\n\"\n                            f\"Ensure all dict keys match ChannelMetadata fields \"\n                            f\"(label, unit, ref, extra) and have correct types.\"\n                        ) from e\n                else:\n                    raise TypeError(\n                        f\"Invalid type in channel_metadata at index {index}\\n\"\n                        f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                        f\"  Expected: ChannelMetadata or dict\\n\"\n                        f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                    )\n\n            self._channel_metadata = [\n                _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n                for i, ch in enumerate(channel_metadata)\n            ]\n        else:\n            self._channel_metadata = [\n                ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n                for i in range(self._n_channels)\n            ]\n\n        try:\n            # Display information for newer dask versions\n            logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n            logger.debug(\n                f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n            )\n        except Exception as e:\n            logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n\n    @property\n    @abstractmethod\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n\n    @property\n    def n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return self._n_channels\n\n    @property\n    def channels(self) -&gt; list[ChannelMetadata]:\n        \"\"\"Property to access channel metadata.\"\"\"\n        return self._channel_metadata\n\n    @property\n    def previous(self) -&gt; Optional[\"BaseFrame[Any]\"]:\n        \"\"\"\n        Returns the previous frame.\n        \"\"\"\n        return self._previous\n\n    def get_channel(\n        self: S,\n        channel_idx: int\n        | list[int]\n        | tuple[int, ...]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index.\n\n        Parameters\n        ----------\n        channel_idx : int or sequence of int\n            Single channel index or sequence of channel indices.\n            Supports negative indices (e.g., -1 for the last channel).\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n        &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n        &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n        &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n        \"\"\"\n        if isinstance(channel_idx, int):\n            # Convert single channel to a list.\n            channel_idx_list: list[int] = [channel_idx]\n        else:\n            channel_idx_list = list(channel_idx)\n\n        new_data = self._data[channel_idx_list]\n        new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Returns the number of channels.\n        \"\"\"\n        return len(self._channel_metadata)\n\n    def __iter__(self: S) -&gt; Iterator[S]:\n        for idx in range(len(self)):\n            yield self[idx]\n\n    def __getitem__(\n        self: S,\n        key: int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index, label, or advanced indexing.\n\n        This method supports multiple indexing patterns similar to NumPy and pandas:\n\n        - Single channel by index: `frame[0]`\n        - Single channel by label: `frame[\"ch0\"]`\n        - Slice of channels: `frame[0:3]`\n        - Multiple channels by indices: `frame[[0, 2, 5]]`\n        - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n        - NumPy integer array: `frame[np.array([0, 2])]`\n        - Boolean mask: `frame[mask]` where mask is a boolean array\n        - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n        Parameters\n        ----------\n        key : int, str, slice, list, tuple, or ndarray\n            - int: Single channel index (supports negative indexing)\n            - str: Single channel label\n            - slice: Range of channels\n            - list[int]: Multiple channel indices\n            - list[str]: Multiple channel labels\n            - tuple: Multidimensional indexing (channel_key, time_key, ...)\n            - ndarray[int]: NumPy array of channel indices\n            - ndarray[bool]: Boolean mask for channel selection\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Raises\n        ------\n        ValueError\n            If the key length is invalid for the shape or if boolean mask\n            length doesn't match number of channels.\n        IndexError\n            If the channel index is out of range.\n        TypeError\n            If the key type is invalid or list contains mixed types.\n        KeyError\n            If a channel label is not found.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Single channel selection\n        &gt;&gt;&gt; frame[0]  # First channel\n        &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n        &gt;&gt;&gt; frame[-1]  # Last channel\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Multiple channel selection\n        &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n        &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n        &gt;&gt;&gt; frame[0:3]  # Slice\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # NumPy array indexing\n        &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n        &gt;&gt;&gt; mask = np.array([True, False, True])\n        &gt;&gt;&gt; frame[mask]  # Boolean mask\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Time slicing (multidimensional)\n        &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n        &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n        \"\"\"\n\n        # Single index (int)\n        if isinstance(key, numbers.Integral):\n            # Ensure we pass a plain Python int to satisfy the type checker\n            return self.get_channel(int(key))\n\n        # Single label (str)\n        if isinstance(key, str):\n            index = self.label2index(key)\n            return self.get_channel(index)\n\n        # Phase 2: NumPy array support (bool mask and int array)\n        if isinstance(key, np.ndarray):\n            if key.dtype == bool or key.dtype == np.bool_:\n                # Boolean mask\n                if len(key) != self.n_channels:\n                    raise ValueError(\n                        f\"Boolean mask length {len(key)} does not match \"\n                        f\"number of channels {self.n_channels}\"\n                    )\n                indices = np.where(key)[0]\n                return self.get_channel(indices)\n            elif np.issubdtype(key.dtype, np.integer):\n                # Integer array\n                return self.get_channel(key)\n            else:\n                raise TypeError(\n                    f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n                )\n\n        # Phase 1: List support (int or str)\n        if isinstance(key, list):\n            if len(key) == 0:\n                raise ValueError(\"Cannot index with an empty list\")\n\n            # Check if all elements are strings\n            if all(isinstance(k, str) for k in key):\n                # Multiple labels - type narrowing for mypy\n                str_list = cast(list[str], key)\n                indices_from_labels = [self.label2index(label) for label in str_list]\n                return self.get_channel(indices_from_labels)\n\n            # Check if all elements are integers\n            elif all(isinstance(k, int | np.integer) for k in key):\n                # Multiple indices - convert to list[int] for type safety\n                int_list = [int(k) for k in key]\n                return self.get_channel(int_list)\n\n            else:\n                raise TypeError(\n                    f\"List must contain all str or all int, got mixed types: \"\n                    f\"{[type(k).__name__ for k in key]}\"\n                )\n\n        # Tuple: multidimensional indexing\n        if isinstance(key, tuple):\n            return self._handle_multidim_indexing(key)\n\n        # Slice\n        if isinstance(key, slice):\n            new_data = self._data[key]\n            new_channel_metadata = self._channel_metadata[key]\n            if isinstance(new_channel_metadata, ChannelMetadata):\n                new_channel_metadata = [new_channel_metadata]\n            return self._create_new_instance(\n                data=new_data,\n                operation_history=self.operation_history,\n                channel_metadata=new_channel_metadata,\n            )\n\n        raise TypeError(\n            f\"Invalid key type: {type(key).__name__}. \"\n            f\"Expected int, str, slice, list, tuple, or ndarray.\"\n        )\n\n    def _handle_multidim_indexing(\n        self: S,\n        key: tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ],\n    ) -&gt; S:\n        \"\"\"\n        Handle multidimensional indexing (channel + time axis).\n\n        Parameters\n        ----------\n        key : tuple\n            Tuple of indices where the first element selects channels\n            and subsequent elements select along other dimensions (e.g., time).\n\n        Returns\n        -------\n        S\n            New instance with selected channels and time range.\n\n        Raises\n        ------\n        ValueError\n            If the key length exceeds the data dimensions.\n        \"\"\"\n        if len(key) &gt; self._data.ndim:\n            raise ValueError(f\"Invalid key length: {len(key)} for shape {self.shape}\")\n\n        # First element: channel selection\n        channel_key = key[0]\n        time_keys = key[1:] if len(key) &gt; 1 else ()\n\n        # Select channels first (recursively call __getitem__)\n        if isinstance(channel_key, list | np.ndarray):\n            selected = self[channel_key]\n        elif isinstance(channel_key, int | str | slice):\n            selected = self[channel_key]\n        else:\n            raise TypeError(\n                f\"Invalid channel key type in tuple: {type(channel_key).__name__}\"\n            )\n\n        # Apply time indexing if present\n        if time_keys:\n            new_data = selected._data[(slice(None),) + time_keys]\n            return selected._create_new_instance(\n                data=new_data,\n                operation_history=selected.operation_history,\n                channel_metadata=selected._channel_metadata,\n            )\n\n        return selected\n\n    def label2index(self, label: str) -&gt; int:\n        \"\"\"\n        Get the index from a channel label.\n\n        Parameters\n        ----------\n        label : str\n            Channel label.\n\n        Returns\n        -------\n        int\n            Corresponding index.\n\n        Raises\n        ------\n        KeyError\n            If the channel label is not found.\n        \"\"\"\n        for idx, ch in enumerate(self._channel_metadata):\n            if ch.label == label:\n                return idx\n        raise KeyError(f\"Channel label '{label}' not found.\")\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        _shape: tuple[int, ...] = self._data.shape\n        if _shape[0] == 1:\n            return _shape[1:]\n        return _shape\n\n    @property\n    def data(self) -&gt; T:\n        \"\"\"\n        Returns the computed data.\n        Calculation is executed the first time this is accessed.\n        \"\"\"\n        data = self.compute()\n        if self.n_channels == 1:\n            return data.squeeze(axis=0)\n        return data\n\n    @property\n    def labels(self) -&gt; list[str]:\n        \"\"\"Get a list of all channel labels.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def compute(self) -&gt; T:\n        \"\"\"\n        Compute and return the data.\n        This method materializes lazily computed data into a concrete NumPy array.\n\n        Returns\n        -------\n        NDArrayReal\n            The computed data.\n\n        Raises\n        ------\n        ValueError\n            If the computed result is not a NumPy array.\n        \"\"\"\n        logger.debug(\n            \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n        )\n        result = self._data.compute()\n\n        if not isinstance(result, np.ndarray):\n            raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n        logger.debug(f\"Computation complete, result shape: {result.shape}\")\n        return cast(T, result)\n\n    @abstractmethod\n    def plot(\n        self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the data\"\"\"\n        pass\n\n    def persist(self: S) -&gt; S:\n        \"\"\"Persist the data in memory\"\"\"\n        persisted_data = self._data.persist()\n        return self._create_new_instance(data=persisted_data)\n\n    @abstractmethod\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Abstract method for derived classes to provide\n        additional initialization arguments.\n        \"\"\"\n        pass\n\n    def _create_new_instance(self: S, data: DaArray, **kwargs: Any) -&gt; S:\n        \"\"\"\n        Create a new channel instance based on an existing channel.\n        Keyword arguments can override or extend the original attributes.\n        \"\"\"\n\n        sampling_rate = kwargs.pop(\"sampling_rate\", self.sampling_rate)\n        # if not isinstance(sampling_rate, int):\n        #     raise TypeError(\"Sampling rate must be an integer\")\n\n        label = kwargs.pop(\"label\", self.label)\n        if not isinstance(label, str):\n            raise TypeError(\"Label must be a string\")\n\n        metadata = kwargs.pop(\"metadata\", copy.deepcopy(self.metadata))\n        if not isinstance(metadata, dict):\n            raise TypeError(\"Metadata must be a dictionary\")\n\n        channel_metadata = kwargs.pop(\n            \"channel_metadata\", copy.deepcopy(self._channel_metadata)\n        )\n        if not isinstance(channel_metadata, list):\n            raise TypeError(\"Channel metadata must be a list\")\n\n        # Get additional initialization arguments from derived classes\n        additional_kwargs = self._get_additional_init_kwargs()\n        kwargs.update(additional_kwargs)\n\n        return type(self)(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            channel_metadata=channel_metadata,\n            previous=self,\n            **kwargs,\n        )\n\n    def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n        \"\"\"Implicit conversion to NumPy array\"\"\"\n        result = self.compute()\n        if dtype is not None:\n            return result.astype(dtype)\n        return result\n\n    def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n        \"\"\"\n        Visualize the computation graph and save it to a file.\n\n        This method creates a visual representation of the Dask computation graph.\n        In Jupyter notebooks, it returns an IPython.display.Image object that\n        will be displayed inline. In other environments, it saves the graph to\n        a file and returns None.\n\n        Parameters\n        ----------\n        filename : str, optional\n            Output filename for the graph image. If None, a unique filename\n            is generated using UUID. The file is saved in the current working\n            directory.\n\n        Returns\n        -------\n        IPython.display.Image or None\n            In Jupyter environments: Returns an IPython.display.Image object\n            that can be displayed inline.\n            In other environments: Returns None after saving the graph to file.\n            Returns None if visualization fails.\n\n        Notes\n        -----\n        This method requires graphviz to be installed on your system:\n        - Ubuntu/Debian: `sudo apt-get install graphviz`\n        - macOS: `brew install graphviz`\n        - Windows: Download from https://graphviz.org/download/\n\n        The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n        making it easier to understand the processing pipeline.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n        &gt;&gt;&gt; # In Jupyter: displays graph inline\n        &gt;&gt;&gt; processed.visualize_graph()\n        &gt;&gt;&gt; # Save to specific file\n        &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n        See Also\n        --------\n        debug_info : Print detailed debug information about the frame\n        \"\"\"\n        try:\n            filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n            return self._data.visualize(filename=filename)\n        except Exception as e:\n            logger.warning(f\"Failed to visualize the graph: {e}\")\n            return None\n\n    @abstractmethod\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"Basic implementation of binary operations\"\"\"\n        # Basic logic\n        # Actual implementation is left to derived classes\n        pass\n\n    def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Addition operator\"\"\"\n        return self._binary_op(other, lambda x, y: x + y, \"+\")\n\n    def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Subtraction operator\"\"\"\n        return self._binary_op(other, lambda x, y: x - y, \"-\")\n\n    def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Multiplication operator\"\"\"\n        return self._binary_op(other, lambda x, y: x * y, \"*\")\n\n    def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Division operator\"\"\"\n        return self._binary_op(other, lambda x, y: x / y, \"/\")\n\n    def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Power operator\"\"\"\n        return self._binary_op(other, lambda x, y: x**y, \"**\")\n\n    def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply a named operation.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters to pass to the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        # Apply the operation through abstract method\n        return self._apply_operation_impl(operation_name, **params)\n\n    @abstractmethod\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"Implementation of operation application\"\"\"\n        pass\n\n    def _relabel_channels(\n        self,\n        operation_name: str,\n        display_name: str | None = None,\n    ) -&gt; list[ChannelMetadata]:\n        \"\"\"\n        Update channel labels to reflect applied operation.\n\n        This method creates new channel metadata with labels that include\n        the operation name, making it easier to track processing history\n        and distinguish frames in plots.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation (e.g., \"normalize\", \"lowpass_filter\")\n        display_name : str, optional\n            Display name for the operation. If None, uses operation_name.\n            This allows operations to provide custom, more readable labels.\n\n        Returns\n        -------\n        list[ChannelMetadata]\n            New channel metadata with updated labels.\n            Original metadata is deep-copied and only labels are modified.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Original label: \"ch0\"\n        &gt;&gt;&gt; # After normalize: \"normalize(ch0)\"\n        &gt;&gt;&gt; # After chained ops: \"lowpass_filter(normalize(ch0))\"\n\n        Notes\n        -----\n        Labels are nested for chained operations, allowing full\n        traceability of the processing pipeline.\n        \"\"\"\n        display = display_name or operation_name\n        new_metadata = []\n        for ch in self._channel_metadata:\n            # All channel metadata are ChannelMetadata objects at this point\n            new_ch = ch.model_copy(deep=True)\n            new_ch.label = f\"{display}({ch.label})\"\n            new_metadata.append(new_ch)\n        return new_metadata\n\n    def debug_info(self) -&gt; None:\n        \"\"\"Output detailed debug information\"\"\"\n        logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n        logger.debug(f\"Label: {self.label}\")\n        logger.debug(f\"Shape: {self.shape}\")\n        logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n        logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n        self._debug_info_impl()\n        logger.debug(\"=== End Debug Info ===\")\n\n    def print_operation_history(self) -&gt; None:\n        \"\"\"\n        Print the operation history to standard output in a readable format.\n\n        This method writes a human-friendly representation of the\n        `operation_history` list to stdout. Each operation is printed on its\n        own line with an index, the operation name (if available), and the\n        parameters used.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf.print_operation_history()\n        1: normalize {}\n        2: low_pass_filter {'cutoff': 1000}\n        \"\"\"\n        if not self.operation_history:\n            print(\"Operation history: &lt;empty&gt;\")\n            return\n\n        print(f\"Operation history ({len(self.operation_history)}):\")\n        for i, record in enumerate(self.operation_history, start=1):\n            # record is expected to be a dict with at least a 'operation' key\n            op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n            # Copy params for display - exclude the 'operation'/'name' keys\n            params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n            print(f\"{i}: {op_name} {params}\")\n\n    def to_numpy(self) -&gt; T:\n        \"\"\"Convert the frame data to a NumPy array.\n\n        This method computes the Dask array and returns it as a concrete NumPy array.\n        The returned array has the same shape as the frame's data.\n\n        Returns\n        -------\n        T\n            NumPy array containing the frame data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; data = cf.to_numpy()\n        &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n        \"\"\"\n        return self.data\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"Convert the frame data to a pandas DataFrame.\n\n        This method provides a common implementation for converting frame data\n        to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame with appropriate index and columns.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; df = cf.to_dataframe()\n        &gt;&gt;&gt; print(df.head())\n        \"\"\"\n        # Get data as numpy array\n        data = self.to_numpy()\n\n        # Get column names from subclass\n        columns = self._get_dataframe_columns()\n\n        # Get index from subclass\n        index = self._get_dataframe_index()\n\n        # Create DataFrame\n        if data.ndim == 1:\n            # Single channel case - reshape to 2D\n            df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n        else:\n            # Multi-channel case - transpose to (n_samples, n_channels)\n            df = pd.DataFrame(data.T, columns=columns, index=index)\n\n        return df\n\n    @abstractmethod\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get column names for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate column names for the DataFrame.\n\n        Returns\n        -------\n        list[str]\n            List of column names.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get index for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate index for the DataFrame based on the frame type.\n\n        Returns\n        -------\n        pd.Index\n            Index for the DataFrame.\n        \"\"\"\n        pass\n\n    def _debug_info_impl(self) -&gt; None:\n        \"\"\"Implement derived class-specific debug information\"\"\"\n        pass\n\n    def _print_operation_history(self) -&gt; None:\n        \"\"\"Print the operation history information.\n\n        This is a helper method for info() implementations to display\n        the number of operations applied to the frame in a consistent format.\n        \"\"\"\n        if self.operation_history:\n            print(f\"  Operations Applied: {len(self.operation_history)}\")\n        else:\n            print(\"  Operations Applied: None\")\n</code></pre> Attributes\u00b6 <code></code> <code>sampling_rate = sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>label = label or 'unnamed_frame'</code> <code>instance-attribute</code> \u00b6 <code></code> <code>metadata = metadata or {}</code> <code>instance-attribute</code> \u00b6 <code></code> <code>operation_history = operation_history or []</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_channels</code> <code>property</code> \u00b6 <p>Returns the number of channels.</p> <code></code> <code>channels</code> <code>property</code> \u00b6 <p>Property to access channel metadata.</p> <code></code> <code>previous</code> <code>property</code> \u00b6 <p>Returns the previous frame.</p> <code></code> <code>shape</code> <code>property</code> \u00b6 <code></code> <code>data</code> <code>property</code> \u00b6 <p>Returns the computed data. Calculation is executed the first time this is accessed.</p> <code></code> <code>labels</code> <code>property</code> \u00b6 <p>Get a list of all channel labels.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n):\n    self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n    if self._data.ndim == 1:\n        self._data = self._data.reshape((1, -1))\n    self.sampling_rate = sampling_rate\n    self.label = label or \"unnamed_frame\"\n    self.metadata = metadata or {}\n    self.operation_history = operation_history or []\n    self._previous = previous\n\n    if channel_metadata:\n        # Pydantic handles both ChannelMetadata objects and dicts\n        def _to_channel_metadata(\n            ch: ChannelMetadata | dict[str, Any], index: int\n        ) -&gt; ChannelMetadata:\n            if isinstance(ch, ChannelMetadata):\n                return copy.deepcopy(ch)\n            elif isinstance(ch, dict):\n                try:\n                    return ChannelMetadata(**ch)\n                except ValidationError as e:\n                    raise ValueError(\n                        f\"Invalid channel_metadata at index {index}\\n\"\n                        f\"  Got: {ch}\\n\"\n                        f\"  Validation error: {e}\\n\"\n                        f\"Ensure all dict keys match ChannelMetadata fields \"\n                        f\"(label, unit, ref, extra) and have correct types.\"\n                    ) from e\n            else:\n                raise TypeError(\n                    f\"Invalid type in channel_metadata at index {index}\\n\"\n                    f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                    f\"  Expected: ChannelMetadata or dict\\n\"\n                    f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                )\n\n        self._channel_metadata = [\n            _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n            for i, ch in enumerate(channel_metadata)\n        ]\n    else:\n        self._channel_metadata = [\n            ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n            for i in range(self._n_channels)\n        ]\n\n    try:\n        # Display information for newer dask versions\n        logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n        logger.debug(\n            f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n        )\n    except Exception as e:\n        logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n</code></pre> <code></code> <code>get_channel(channel_idx)</code> \u00b6 <p>Get channel(s) by index.</p> <code></code> <code>__len__()</code> \u00b6 <p>Returns the number of channels.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of channels.\n    \"\"\"\n    return len(self._channel_metadata)\n</code></pre> <code></code> <code>__iter__()</code> \u00b6 Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __iter__(self: S) -&gt; Iterator[S]:\n    for idx in range(len(self)):\n        yield self[idx]\n</code></pre> <code></code> <code>__getitem__(key)</code> \u00b6 <p>Get channel(s) by index, label, or advanced indexing.</p> <p>This method supports multiple indexing patterns similar to NumPy and pandas:</p> <ul> <li>Single channel by index: <code>frame[0]</code></li> <li>Single channel by label: <code>frame[\"ch0\"]</code></li> <li>Slice of channels: <code>frame[0:3]</code></li> <li>Multiple channels by indices: <code>frame[[0, 2, 5]]</code></li> <li>Multiple channels by labels: <code>frame[[\"ch0\", \"ch2\"]]</code></li> <li>NumPy integer array: <code>frame[np.array([0, 2])]</code></li> <li>Boolean mask: <code>frame[mask]</code> where mask is a boolean array</li> <li>Multidimensional indexing: <code>frame[0, 100:200]</code> (channel + time)</li> </ul> <code></code> <code>label2index(label)</code> \u00b6 <p>Get the index from a channel label.</p> <code></code> <code>compute()</code> \u00b6 <p>Compute and return the data. This method materializes lazily computed data into a concrete NumPy array.</p> <code></code> <code>plot(plot_type='default', ax=None, **kwargs)</code> <code>abstractmethod</code> \u00b6 <p>Plot the data</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>@abstractmethod\ndef plot(\n    self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the data\"\"\"\n    pass\n</code></pre> <code></code> <code>persist()</code> \u00b6 <p>Persist the data in memory</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def persist(self: S) -&gt; S:\n    \"\"\"Persist the data in memory\"\"\"\n    persisted_data = self._data.persist()\n    return self._create_new_instance(data=persisted_data)\n</code></pre> <code></code> <code>__array__(dtype=None)</code> \u00b6 <p>Implicit conversion to NumPy array</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n    \"\"\"Implicit conversion to NumPy array\"\"\"\n    result = self.compute()\n    if dtype is not None:\n        return result.astype(dtype)\n    return result\n</code></pre> <code></code> <code>visualize_graph(filename=None)</code> \u00b6 <p>Visualize the computation graph and save it to a file.</p> <p>This method creates a visual representation of the Dask computation graph. In Jupyter notebooks, it returns an IPython.display.Image object that will be displayed inline. In other environments, it saves the graph to a file and returns None.</p> <code></code> <code>__add__(other)</code> \u00b6 <p>Addition operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Addition operator\"\"\"\n    return self._binary_op(other, lambda x, y: x + y, \"+\")\n</code></pre> <code></code> <code>__sub__(other)</code> \u00b6 <p>Subtraction operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Subtraction operator\"\"\"\n    return self._binary_op(other, lambda x, y: x - y, \"-\")\n</code></pre> <code></code> <code>__mul__(other)</code> \u00b6 <p>Multiplication operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Multiplication operator\"\"\"\n    return self._binary_op(other, lambda x, y: x * y, \"*\")\n</code></pre> <code></code> <code>__truediv__(other)</code> \u00b6 <p>Division operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Division operator\"\"\"\n    return self._binary_op(other, lambda x, y: x / y, \"/\")\n</code></pre> <code></code> <code>__pow__(other)</code> \u00b6 <p>Power operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Power operator\"\"\"\n    return self._binary_op(other, lambda x, y: x**y, \"**\")\n</code></pre> <code></code> <code>apply_operation(operation_name, **params)</code> \u00b6 <p>Apply a named operation.</p> <code></code> <code>debug_info()</code> \u00b6 <p>Output detailed debug information</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def debug_info(self) -&gt; None:\n    \"\"\"Output detailed debug information\"\"\"\n    logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n    logger.debug(f\"Label: {self.label}\")\n    logger.debug(f\"Shape: {self.shape}\")\n    logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n    logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n    self._debug_info_impl()\n    logger.debug(\"=== End Debug Info ===\")\n</code></pre> <code></code> <code>print_operation_history()</code> \u00b6 <p>Print the operation history to standard output in a readable format.</p> <p>This method writes a human-friendly representation of the <code>operation_history</code> list to stdout. Each operation is printed on its own line with an index, the operation name (if available), and the parameters used.</p> <code></code> <code>to_numpy()</code> \u00b6 <p>Convert the frame data to a NumPy array.</p> <p>This method computes the Dask array and returns it as a concrete NumPy array. The returned array has the same shape as the frame's data.</p> <code></code> <code>to_dataframe()</code> \u00b6 <p>Convert the frame data to a pandas DataFrame.</p> <p>This method provides a common implementation for converting frame data to pandas DataFrame. Subclasses can override this method for custom behavior.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.get_channel--parameters","title":"Parameters","text":"<p>channel_idx : int or sequence of int     Single channel index or sequence of channel indices.     Supports negative indices (e.g., -1 for the last channel).</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.get_channel--returns","title":"Returns","text":"<p>S     New instance containing the selected channel(s).</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.get_channel--examples","title":"Examples","text":"<p>frame.get_channel(0)  # Single channel frame.get_channel([0, 2, 3])  # Multiple channels frame.get_channel((-1, -2))  # Last two channels frame.get_channel(np.array([1, 2]))  # NumPy array of indices</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def get_channel(\n    self: S,\n    channel_idx: int\n    | list[int]\n    | tuple[int, ...]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index.\n\n    Parameters\n    ----------\n    channel_idx : int or sequence of int\n        Single channel index or sequence of channel indices.\n        Supports negative indices (e.g., -1 for the last channel).\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n    &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n    &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n    &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n    \"\"\"\n    if isinstance(channel_idx, int):\n        # Convert single channel to a list.\n        channel_idx_list: list[int] = [channel_idx]\n    else:\n        channel_idx_list = list(channel_idx)\n\n    new_data = self._data[channel_idx_list]\n    new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n    return self._create_new_instance(\n        data=new_data,\n        operation_history=self.operation_history,\n        channel_metadata=new_channel_metadata,\n    )\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--parameters","title":"Parameters","text":"<p>key : int, str, slice, list, tuple, or ndarray     - int: Single channel index (supports negative indexing)     - str: Single channel label     - slice: Range of channels     - list[int]: Multiple channel indices     - list[str]: Multiple channel labels     - tuple: Multidimensional indexing (channel_key, time_key, ...)     - ndarray[int]: NumPy array of channel indices     - ndarray[bool]: Boolean mask for channel selection</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--returns","title":"Returns","text":"<p>S     New instance containing the selected channel(s).</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--raises","title":"Raises","text":"<p>ValueError     If the key length is invalid for the shape or if boolean mask     length doesn't match number of channels. IndexError     If the channel index is out of range. TypeError     If the key type is invalid or list contains mixed types. KeyError     If a channel label is not found.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--examples","title":"Examples","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __getitem__(\n    self: S,\n    key: int\n    | str\n    | slice\n    | list[int]\n    | list[str]\n    | tuple[\n        int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n        ...,\n    ]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index, label, or advanced indexing.\n\n    This method supports multiple indexing patterns similar to NumPy and pandas:\n\n    - Single channel by index: `frame[0]`\n    - Single channel by label: `frame[\"ch0\"]`\n    - Slice of channels: `frame[0:3]`\n    - Multiple channels by indices: `frame[[0, 2, 5]]`\n    - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n    - NumPy integer array: `frame[np.array([0, 2])]`\n    - Boolean mask: `frame[mask]` where mask is a boolean array\n    - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n    Parameters\n    ----------\n    key : int, str, slice, list, tuple, or ndarray\n        - int: Single channel index (supports negative indexing)\n        - str: Single channel label\n        - slice: Range of channels\n        - list[int]: Multiple channel indices\n        - list[str]: Multiple channel labels\n        - tuple: Multidimensional indexing (channel_key, time_key, ...)\n        - ndarray[int]: NumPy array of channel indices\n        - ndarray[bool]: Boolean mask for channel selection\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Raises\n    ------\n    ValueError\n        If the key length is invalid for the shape or if boolean mask\n        length doesn't match number of channels.\n    IndexError\n        If the channel index is out of range.\n    TypeError\n        If the key type is invalid or list contains mixed types.\n    KeyError\n        If a channel label is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Single channel selection\n    &gt;&gt;&gt; frame[0]  # First channel\n    &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n    &gt;&gt;&gt; frame[-1]  # Last channel\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Multiple channel selection\n    &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n    &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n    &gt;&gt;&gt; frame[0:3]  # Slice\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # NumPy array indexing\n    &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n    &gt;&gt;&gt; mask = np.array([True, False, True])\n    &gt;&gt;&gt; frame[mask]  # Boolean mask\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Time slicing (multidimensional)\n    &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n    &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n    \"\"\"\n\n    # Single index (int)\n    if isinstance(key, numbers.Integral):\n        # Ensure we pass a plain Python int to satisfy the type checker\n        return self.get_channel(int(key))\n\n    # Single label (str)\n    if isinstance(key, str):\n        index = self.label2index(key)\n        return self.get_channel(index)\n\n    # Phase 2: NumPy array support (bool mask and int array)\n    if isinstance(key, np.ndarray):\n        if key.dtype == bool or key.dtype == np.bool_:\n            # Boolean mask\n            if len(key) != self.n_channels:\n                raise ValueError(\n                    f\"Boolean mask length {len(key)} does not match \"\n                    f\"number of channels {self.n_channels}\"\n                )\n            indices = np.where(key)[0]\n            return self.get_channel(indices)\n        elif np.issubdtype(key.dtype, np.integer):\n            # Integer array\n            return self.get_channel(key)\n        else:\n            raise TypeError(\n                f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n            )\n\n    # Phase 1: List support (int or str)\n    if isinstance(key, list):\n        if len(key) == 0:\n            raise ValueError(\"Cannot index with an empty list\")\n\n        # Check if all elements are strings\n        if all(isinstance(k, str) for k in key):\n            # Multiple labels - type narrowing for mypy\n            str_list = cast(list[str], key)\n            indices_from_labels = [self.label2index(label) for label in str_list]\n            return self.get_channel(indices_from_labels)\n\n        # Check if all elements are integers\n        elif all(isinstance(k, int | np.integer) for k in key):\n            # Multiple indices - convert to list[int] for type safety\n            int_list = [int(k) for k in key]\n            return self.get_channel(int_list)\n\n        else:\n            raise TypeError(\n                f\"List must contain all str or all int, got mixed types: \"\n                f\"{[type(k).__name__ for k in key]}\"\n            )\n\n    # Tuple: multidimensional indexing\n    if isinstance(key, tuple):\n        return self._handle_multidim_indexing(key)\n\n    # Slice\n    if isinstance(key, slice):\n        new_data = self._data[key]\n        new_channel_metadata = self._channel_metadata[key]\n        if isinstance(new_channel_metadata, ChannelMetadata):\n            new_channel_metadata = [new_channel_metadata]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    raise TypeError(\n        f\"Invalid key type: {type(key).__name__}. \"\n        f\"Expected int, str, slice, list, tuple, or ndarray.\"\n    )\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--single-channel-selection","title":"Single channel selection","text":"<p>frame[0]  # First channel frame[\"acc_x\"]  # By label frame[-1]  # Last channel</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--multiple-channel-selection","title":"Multiple channel selection","text":"<p>frame[[0, 2, 5]]  # Multiple indices frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels frame[0:3]  # Slice</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--numpy-array-indexing","title":"NumPy array indexing","text":"<p>frame[np.array([0, 2, 4])]  # Integer array mask = np.array([True, False, True]) frame[mask]  # Boolean mask</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.__getitem__--time-slicing-multidimensional","title":"Time slicing (multidimensional)","text":"<p>frame[0, 100:200]  # Channel 0, samples 100-200 frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.label2index--parameters","title":"Parameters","text":"<p>label : str     Channel label.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.label2index--returns","title":"Returns","text":"<p>int     Corresponding index.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.label2index--raises","title":"Raises","text":"<p>KeyError     If the channel label is not found.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n\n    Parameters\n    ----------\n    label : str\n        Channel label.\n\n    Returns\n    -------\n    int\n        Corresponding index.\n\n    Raises\n    ------\n    KeyError\n        If the channel label is not found.\n    \"\"\"\n    for idx, ch in enumerate(self._channel_metadata):\n        if ch.label == label:\n            return idx\n    raise KeyError(f\"Channel label '{label}' not found.\")\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.compute--returns","title":"Returns","text":"<p>NDArrayReal     The computed data.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.compute--raises","title":"Raises","text":"<p>ValueError     If the computed result is not a NumPy array.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def compute(self) -&gt; T:\n    \"\"\"\n    Compute and return the data.\n    This method materializes lazily computed data into a concrete NumPy array.\n\n    Returns\n    -------\n    NDArrayReal\n        The computed data.\n\n    Raises\n    ------\n    ValueError\n        If the computed result is not a NumPy array.\n    \"\"\"\n    logger.debug(\n        \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n    )\n    result = self._data.compute()\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n    logger.debug(f\"Computation complete, result shape: {result.shape}\")\n    return cast(T, result)\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--parameters","title":"Parameters","text":"<p>filename : str, optional     Output filename for the graph image. If None, a unique filename     is generated using UUID. The file is saved in the current working     directory.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--returns","title":"Returns","text":"<p>IPython.display.Image or None     In Jupyter environments: Returns an IPython.display.Image object     that can be displayed inline.     In other environments: Returns None after saving the graph to file.     Returns None if visualization fails.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--notes","title":"Notes","text":"<p>This method requires graphviz to be installed on your system: - Ubuntu/Debian: <code>sudo apt-get install graphviz</code> - macOS: <code>brew install graphviz</code> - Windows: Download from https://graphviz.org/download/</p> <p>The graph displays operation names (e.g., 'normalize', 'lowpass_filter') making it easier to understand the processing pipeline.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"audio.wav\") processed = signal.normalize().low_pass_filter(cutoff=1000)</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--in-jupyter-displays-graph-inline","title":"In Jupyter: displays graph inline","text":"<p>processed.visualize_graph()</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--save-to-specific-file","title":"Save to specific file","text":"<p>processed.visualize_graph(\"my_graph.png\")</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.visualize_graph--see-also","title":"See Also","text":"<p>debug_info : Print detailed debug information about the frame</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n    \"\"\"\n    Visualize the computation graph and save it to a file.\n\n    This method creates a visual representation of the Dask computation graph.\n    In Jupyter notebooks, it returns an IPython.display.Image object that\n    will be displayed inline. In other environments, it saves the graph to\n    a file and returns None.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Output filename for the graph image. If None, a unique filename\n        is generated using UUID. The file is saved in the current working\n        directory.\n\n    Returns\n    -------\n    IPython.display.Image or None\n        In Jupyter environments: Returns an IPython.display.Image object\n        that can be displayed inline.\n        In other environments: Returns None after saving the graph to file.\n        Returns None if visualization fails.\n\n    Notes\n    -----\n    This method requires graphviz to be installed on your system:\n    - Ubuntu/Debian: `sudo apt-get install graphviz`\n    - macOS: `brew install graphviz`\n    - Windows: Download from https://graphviz.org/download/\n\n    The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n    making it easier to understand the processing pipeline.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n    &gt;&gt;&gt; # In Jupyter: displays graph inline\n    &gt;&gt;&gt; processed.visualize_graph()\n    &gt;&gt;&gt; # Save to specific file\n    &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n    See Also\n    --------\n    debug_info : Print detailed debug information about the frame\n    \"\"\"\n    try:\n        filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n        return self._data.visualize(filename=filename)\n    except Exception as e:\n        logger.warning(f\"Failed to visualize the graph: {e}\")\n        return None\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.apply_operation--parameters","title":"Parameters","text":"<p>operation_name : str     Name of the operation to apply. **params : Any     Parameters to pass to the operation.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.apply_operation--returns","title":"Returns","text":"<p>S     A new instance with the operation applied.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n    \"\"\"\n    Apply a named operation.\n\n    Parameters\n    ----------\n    operation_name : str\n        Name of the operation to apply.\n    **params : Any\n        Parameters to pass to the operation.\n\n    Returns\n    -------\n    S\n        A new instance with the operation applied.\n    \"\"\"\n    # Apply the operation through abstract method\n    return self._apply_operation_impl(operation_name, **params)\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.print_operation_history--examples","title":"Examples","text":"<p>cf.print_operation_history() 1: normalize {} 2: low_pass_filter {'cutoff': 1000}</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def print_operation_history(self) -&gt; None:\n    \"\"\"\n    Print the operation history to standard output in a readable format.\n\n    This method writes a human-friendly representation of the\n    `operation_history` list to stdout. Each operation is printed on its\n    own line with an index, the operation name (if available), and the\n    parameters used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf.print_operation_history()\n    1: normalize {}\n    2: low_pass_filter {'cutoff': 1000}\n    \"\"\"\n    if not self.operation_history:\n        print(\"Operation history: &lt;empty&gt;\")\n        return\n\n    print(f\"Operation history ({len(self.operation_history)}):\")\n    for i, record in enumerate(self.operation_history, start=1):\n        # record is expected to be a dict with at least a 'operation' key\n        op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n        # Copy params for display - exclude the 'operation'/'name' keys\n        params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n        print(f\"{i}: {op_name} {params}\")\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.to_numpy--returns","title":"Returns","text":"<p>T     NumPy array containing the frame data.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.to_numpy--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") data = cf.to_numpy() print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def to_numpy(self) -&gt; T:\n    \"\"\"Convert the frame data to a NumPy array.\n\n    This method computes the Dask array and returns it as a concrete NumPy array.\n    The returned array has the same shape as the frame's data.\n\n    Returns\n    -------\n    T\n        NumPy array containing the frame data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; data = cf.to_numpy()\n    &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n    \"\"\"\n    return self.data\n</code></pre>"},{"location":"api/#wandas.core.base_frame.BaseFrame.to_dataframe--returns","title":"Returns","text":"<p>pd.DataFrame     DataFrame with appropriate index and columns.</p>"},{"location":"api/#wandas.core.base_frame.BaseFrame.to_dataframe--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") df = cf.to_dataframe() print(df.head())</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"Convert the frame data to a pandas DataFrame.\n\n    This method provides a common implementation for converting frame data\n    to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with appropriate index and columns.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; df = cf.to_dataframe()\n    &gt;&gt;&gt; print(df.head())\n    \"\"\"\n    # Get data as numpy array\n    data = self.to_numpy()\n\n    # Get column names from subclass\n    columns = self._get_dataframe_columns()\n\n    # Get index from subclass\n    index = self._get_dataframe_index()\n\n    # Create DataFrame\n    if data.ndim == 1:\n        # Single channel case - reshape to 2D\n        df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n    else:\n        # Multi-channel case - transpose to (n_samples, n_channels)\n        df = pd.DataFrame(data.T, columns=columns, index=index)\n\n    return df\n</code></pre>"},{"location":"api/#wandas.core.metadata","title":"<code>metadata</code>","text":""},{"location":"api/#wandas.core.metadata-classes","title":"Classes","text":""},{"location":"api/#wandas.core.metadata.ChannelMetadata","title":"<code>ChannelMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data class for storing channel metadata</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>class ChannelMetadata(BaseModel):\n    \"\"\"\n    Data class for storing channel metadata\n    \"\"\"\n\n    label: str = \"\"\n    unit: str = \"\"\n    ref: float = 1.0\n    # Additional metadata for extensibility\n    extra: dict[str, Any] = Field(default_factory=dict)\n\n    def __init__(self, **data: Any):\n        super().__init__(**data)\n        # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n        if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n            self.ref = unit_to_ref(self.unit)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n        super().__setattr__(name, value)\n        # Only proceed if unit is being set to a non-empty value\n        if name == \"unit\" and value and isinstance(value, str):\n            super().__setattr__(\"ref\", unit_to_ref(value))\n\n    @property\n    def label_value(self) -&gt; str:\n        \"\"\"Get the label value\"\"\"\n        return self.label\n\n    @property\n    def unit_value(self) -&gt; str:\n        \"\"\"Get the unit value\"\"\"\n        return self.unit\n\n    @property\n    def ref_value(self) -&gt; float:\n        \"\"\"Get the ref value\"\"\"\n        return self.ref\n\n    @property\n    def extra_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get the extra metadata dictionary\"\"\"\n        return self.extra\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Provide dictionary-like behavior\"\"\"\n        if key == \"label\":\n            return self.label\n        elif key == \"unit\":\n            return self.unit\n        elif key == \"ref\":\n            return self.ref\n        else:\n            return self.extra.get(key)\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        \"\"\"Provide dictionary-like behavior\"\"\"\n        if key == \"label\":\n            self.label = value\n        elif key == \"unit\":\n            self.unit = value\n            self.ref = unit_to_ref(value)\n        elif key == \"ref\":\n            self.ref = value\n        else:\n            self.extra[key] = value\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert to JSON format\"\"\"\n        json_data: str = self.model_dump_json(indent=4)\n        return json_data\n\n    @classmethod\n    def from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n        \"\"\"Convert from JSON format\"\"\"\n        root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n        return root_model\n</code></pre> Attributes\u00b6 <code></code> <code>label = ''</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>unit = ''</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ref = 1.0</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>extra = Field(default_factory=dict)</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>label_value</code> <code>property</code> \u00b6 <p>Get the label value</p> <code></code> <code>unit_value</code> <code>property</code> \u00b6 <p>Get the unit value</p> <code></code> <code>ref_value</code> <code>property</code> \u00b6 <p>Get the ref value</p> <code></code> <code>extra_data</code> <code>property</code> \u00b6 <p>Get the extra metadata dictionary</p> Functions\u00b6 <code></code> <code>__init__(**data)</code> \u00b6 Source code in <code>wandas/core/metadata.py</code> <pre><code>def __init__(self, **data: Any):\n    super().__init__(**data)\n    # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n    if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n        self.ref = unit_to_ref(self.unit)\n</code></pre> <code></code> <code>__setattr__(name, value)</code> \u00b6 <p>Override setattr to update ref when unit is changed directly</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n    super().__setattr__(name, value)\n    # Only proceed if unit is being set to a non-empty value\n    if name == \"unit\" and value and isinstance(value, str):\n        super().__setattr__(\"ref\", unit_to_ref(value))\n</code></pre> <code></code> <code>__getitem__(key)</code> \u00b6 <p>Provide dictionary-like behavior</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        return self.label\n    elif key == \"unit\":\n        return self.unit\n    elif key == \"ref\":\n        return self.ref\n    else:\n        return self.extra.get(key)\n</code></pre> <code></code> <code>__setitem__(key, value)</code> \u00b6 <p>Provide dictionary-like behavior</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def __setitem__(self, key: str, value: Any) -&gt; None:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        self.label = value\n    elif key == \"unit\":\n        self.unit = value\n        self.ref = unit_to_ref(value)\n    elif key == \"ref\":\n        self.ref = value\n    else:\n        self.extra[key] = value\n</code></pre> <code></code> <code>to_json()</code> \u00b6 <p>Convert to JSON format</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert to JSON format\"\"\"\n    json_data: str = self.model_dump_json(indent=4)\n    return json_data\n</code></pre> <code></code> <code>from_json(json_data)</code> <code>classmethod</code> \u00b6 <p>Convert from JSON format</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n    \"\"\"Convert from JSON format\"\"\"\n    root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n    return root_model\n</code></pre>"},{"location":"api/#wandas.core.metadata-functions","title":"Functions","text":""},{"location":"api/#_2","title":"\u30d5\u30ec\u30fc\u30e0\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u30d5\u30ec\u30fc\u30e0\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u7570\u306a\u308b\u30bf\u30a4\u30d7\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.frames","title":"<code>wandas.frames</code>","text":"<p>Frame classes for wandas.</p>"},{"location":"api/#wandas.frames-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.__all__","title":"<code>__all__ = ['ChannelFrame', 'RoughnessFrame']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.ChannelFrame","title":"<code>ChannelFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code>, <code>ChannelProcessingMixin</code>, <code>ChannelTransformMixin</code></p> <p>Channel-based data frame for handling audio signals and time series data.</p> <p>This frame represents channel-based data such as audio signals and time series data, with each channel containing data samples in the time domain.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>class ChannelFrame(\n    BaseFrame[NDArrayReal], ChannelProcessingMixin, ChannelTransformMixin\n):\n    \"\"\"Channel-based data frame for handling audio signals and time series data.\n\n    This frame represents channel-based data such as audio signals and time series data,\n    with each channel containing data samples in the time domain.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: DaskArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a ChannelFrame.\n\n        Args:\n            data: Dask array containing channel data.\n            Shape should be (n_channels, n_samples).\n            sampling_rate: The sampling rate of the data in Hz.\n                Must be a positive value.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Raises:\n            ValueError: If data has more than 2 dimensions, or if\n                sampling_rate is not positive.\n        \"\"\"\n        # Validate sampling rate\n        validate_sampling_rate(sampling_rate)\n\n        # Validate and reshape data\n        if data.ndim == 1:\n            data = da.reshape(data, (1, -1))\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Invalid data shape for ChannelFrame\\n\"\n                f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n                f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n                f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n                f\"  (1, n_samples).\\n\"\n                f\"For higher-dimensional data, reshape it before creating\\n\"\n                f\"  ChannelFrame:\\n\"\n                f\"  Example: data.reshape(n_channels, -1)\"\n            )\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"Get time array for the signal.\n\n        The time array represents the start time of each sample, calculated as\n        sample_index / sampling_rate. This provides a uniform, evenly-spaced\n        time axis that is consistent across all frame types in wandas.\n\n        For frames resulting from windowed analysis operations (e.g., FFT,\n        loudness, roughness), each time point corresponds to the start of\n        the analysis window, not the center. This differs from some libraries\n        (e.g., MoSQITo) which use window center times, but does not affect\n        the calculated values themselves.\n\n        Returns:\n            Array of time points in seconds, starting from 0.0.\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; time = signal.time\n            &gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n            &gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n        \"\"\"\n        return np.arange(self.n_samples) / self.sampling_rate\n\n    @property\n    def n_samples(self) -&gt; int:\n        \"\"\"Returns the number of samples.\"\"\"\n        n: int = self._data.shape[-1]\n        return n\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Returns the duration in seconds.\"\"\"\n        return self.n_samples / self.sampling_rate\n\n    @property\n    def rms(self) -&gt; NDArrayReal:\n        \"\"\"Calculate RMS (Root Mean Square) value for each channel.\n\n        Returns:\n            Array of RMS values, one per channel.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; rms_values = cf.rms\n            &gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n            &gt;&gt;&gt; # Select channels with RMS &gt; threshold\n            &gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n        \"\"\"\n        # Convert to a concrete NumPy ndarray to satisfy numpy.mean typing\n        # and to ensure dask arrays are materialized for this operation.\n        rms_values = da.sqrt((self._data**2).mean(axis=1))\n        return np.array(rms_values.compute())\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the ChannelFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - Duration\n        - Number of samples\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.info()\n        Channels: 2\n        Sampling rate: 44100 Hz\n        Duration: 1.0 s\n        Samples: 44100\n        Channel labels: ['ch0', 'ch1']\n        \"\"\"\n        print(\"ChannelFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  Duration: {self.duration:.1f} s\")\n        print(f\"  Samples: {self.n_samples}\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        # Get metadata updates from operation\n        metadata_updates = operation.get_metadata_updates()\n\n        # Update channel labels to reflect the operation\n        display_name = operation.get_display_name()\n        new_channel_metadata = self._relabel_channels(operation_name, display_name)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # Apply metadata updates (including sampling_rate if specified)\n        creation_params: dict[str, Any] = {\n            \"data\": processed_data,\n            \"metadata\": new_metadata,\n            \"operation_history\": new_history,\n            \"channel_metadata\": new_channel_metadata,\n        }\n        creation_params.update(metadata_updates)\n\n        return self._create_new_instance(**creation_params)\n\n    def _binary_op(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal | DaskArray\",\n        op: Callable[[\"DaskArray\", Any], \"DaskArray\"],\n        symbol: str,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Common implementation for binary operations\n        - utilizing dask's lazy evaluation.\n\n        Args:\n            other: Right operand for the operation.\n            op: Function to execute the operation (e.g., lambda a, b: a + b).\n            symbol: Symbolic representation of the operation (e.g., '+').\n\n        Returns:\n            A new channel containing the operation result (lazy execution).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, ChannelFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Perform operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Merge channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Perform operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # Operand display string\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n                previous=self,\n            )\n\n    def add(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal\",\n        snr: float | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add another signal or value to the current signal.\n\n        If SNR is specified, performs addition with consideration for\n        signal-to-noise ratio.\n\n        Args:\n            other: Signal or value to add.\n            snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n                other signal based on this SNR.\n                self is treated as the signal, and other as the noise.\n\n        Returns:\n            A new channel frame containing the addition result (lazy execution).\n        \"\"\"\n        logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n        if isinstance(other, ChannelFrame):\n            # Check if sampling rates match\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n        elif isinstance(other, np.ndarray):\n            other = ChannelFrame.from_numpy(\n                other, self.sampling_rate, label=\"array_data\"\n            )\n        elif isinstance(other, int | float):\n            return self + other\n        else:\n            raise TypeError(\n                \"Addition target with SNR must be a ChannelFrame or \"\n                f\"NumPy array: {type(other)}\"\n            )\n\n        # If SNR is specified, adjust the length of the other signal\n        if other.duration != self.duration:\n            other = other.fix_length(length=self.n_samples)\n\n        if snr is None:\n            return self + other\n        return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n\n    def plot(\n        self,\n        plot_type: str = \"waveform\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the frame data.\n\n        Args:\n            plot_type: Type of plot. Default is \"waveform\".\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot. If None, uses the frame label.\n            overlay: Whether to overlay all channels on a single plot (True)\n                or create separate subplots for each channel (False).\n            xlabel: Label for the x-axis. If None, uses default based on plot type.\n            ylabel: Label for the y-axis. If None, uses default based on plot type.\n            alpha: Transparency level for the plot lines (0.0 to 1.0).\n            xlim: Limits for the x-axis as (min, max) tuple.\n            ylim: Limits for the y-axis as (min, max) tuple.\n            **kwargs: Additional matplotlib Line2D parameters\n                (e.g., color, linewidth, linestyle).\n                These are passed to the underlying matplotlib plot functions.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic plot\n            &gt;&gt;&gt; cf.plot()\n            &gt;&gt;&gt; # Overlay all channels\n            &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n        \"\"\"\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        from ..visualization.plotting import create_operation\n\n        plot_strategy = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def rms_plot(\n        self,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = True,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Generate an RMS plot.\n\n        Args:\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot.\n            overlay: Whether to overlay the plot on the existing axis.\n            Aw: Apply A-weighting.\n            **kwargs: Additional arguments passed to the plot() method.\n                Accepts the same arguments as plot() including xlabel, ylabel,\n                alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic RMS plot\n            &gt;&gt;&gt; cf.rms_plot()\n            &gt;&gt;&gt; # With A-weighting\n            &gt;&gt;&gt; cf.rms_plot(Aw=True)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n        \"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n        rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n        return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n\n    def describe(\n        self,\n        normalize: bool = True,\n        is_close: bool = True,\n        *,\n        fmin: float = 0,\n        fmax: float | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        waveform: dict[str, Any] | None = None,\n        spectral: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Display visual and audio representation of the frame.\n\n        This method creates a comprehensive visualization with three plots:\n        1. Time-domain waveform (top)\n        2. Spectrogram (bottom-left)\n        3. Frequency spectrum via Welch method (bottom-right)\n\n        Args:\n            normalize: Whether to normalize the audio data for playback.\n                Default: True\n            is_close: Whether to close the figure after displaying.\n                Default: True\n            fmin: Minimum frequency to display in the spectrogram (Hz).\n                Default: 0\n            fmax: Maximum frequency to display in the spectrogram (Hz).\n                Default: Nyquist frequency (sampling_rate / 2)\n            cmap: Colormap for the spectrogram.\n                Default: 'jet'\n            vmin: Minimum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            vmax: Maximum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            xlim: Time axis limits (seconds) for all time-based plots.\n                Format: (start_time, end_time)\n            ylim: Frequency axis limits (Hz) for frequency-based plots.\n                Format: (min_freq, max_freq)\n            Aw: Apply A-weighting to the frequency analysis.\n                Default: False\n            waveform: Additional configuration dict for waveform subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            spectral: Additional configuration dict for spectral subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            **kwargs: Deprecated parameters for backward compatibility only.\n                - axis_config: Old configuration format (use waveform/spectral instead)\n                - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic usage\n            &gt;&gt;&gt; cf.describe()\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom frequency range\n            &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom color scale\n            &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # A-weighted analysis\n            &gt;&gt;&gt; cf.describe(Aw=True)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom time range\n            &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom waveform subplot settings\n            &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n        \"\"\"\n        # Prepare kwargs with explicit parameters\n        plot_kwargs: dict[str, Any] = {\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"xlim\": xlim,\n            \"ylim\": ylim,\n            \"Aw\": Aw,\n            \"waveform\": waveform or {},\n            \"spectral\": spectral or {},\n        }\n        # Merge with additional kwargs\n        plot_kwargs.update(kwargs)\n\n        if \"axis_config\" in plot_kwargs:\n            logger.warning(\n                \"axis_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            axis_config = plot_kwargs[\"axis_config\"]\n            if \"time_plot\" in axis_config:\n                plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n            if \"freq_plot\" in axis_config:\n                if \"xlim\" in axis_config[\"freq_plot\"]:\n                    vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                    plot_kwargs[\"vmin\"] = vlim[0]\n                    plot_kwargs[\"vmax\"] = vlim[1]\n                if \"ylim\" in axis_config[\"freq_plot\"]:\n                    ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                    plot_kwargs[\"ylim\"] = ylim_config\n\n        if \"cbar_config\" in plot_kwargs:\n            logger.warning(\n                \"cbar_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            cbar_config = plot_kwargs[\"cbar_config\"]\n            if \"vmin\" in cbar_config:\n                plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n            if \"vmax\" in cbar_config:\n                plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n        for ch in self:\n            ax: Axes\n            _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n            if isinstance(_ax, Iterator):\n                ax = next(iter(_ax))\n            elif isinstance(_ax, Axes):\n                ax = _ax\n            else:\n                raise TypeError(\n                    f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n                )\n            # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n            display(ax.figure)\n            if is_close:\n                plt.close(getattr(ax, \"figure\", None))\n            display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayReal,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        ch_labels: list[str] | None = None,\n        ch_units: list[str] | str | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing channel data.\n            sampling_rate: The sampling rate in Hz.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            ch_labels: Labels for each channel.\n            ch_units: Units for each channel.\n\n        Returns:\n            A new ChannelFrame containing the NumPy data.\n        \"\"\"\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n\n        # Convert NumPy array to dask array\n        dask_data = da_from_array(data)\n        cf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=label or \"numpy_data\",\n        )\n        if metadata is not None:\n            cf.metadata = metadata\n        if ch_labels is not None:\n            if len(ch_labels) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel labels does not match the number of channels\"\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        if ch_units is not None:\n            if isinstance(ch_units, str):\n                ch_units = [ch_units] * cf.n_channels\n\n            if len(ch_units) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel units does not match the number of channels\"\n                )\n            for i in range(len(ch_units)):\n                cf._channel_metadata[i].unit = ch_units[i]\n\n        return cf\n\n    @classmethod\n    def from_ndarray(\n        cls,\n        array: NDArrayReal,\n        sampling_rate: float,\n        labels: list[str] | None = None,\n        unit: list[str] | str | None = None,\n        frame_label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        This method is deprecated. Use from_numpy instead.\n\n        Args:\n            array: Signal data. Each row corresponds to a channel.\n            sampling_rate: Sampling rate (Hz).\n            labels: Labels for each channel.\n            unit: Unit of the signal.\n            frame_label: Label for the frame.\n            metadata: Optional metadata dictionary.\n\n        Returns:\n            A new ChannelFrame containing the data.\n        \"\"\"\n        # Redirect to from_numpy for compatibility\n        # However, from_ndarray is deprecated\n        logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n        return cls.from_numpy(\n            data=array,\n            sampling_rate=sampling_rate,\n            label=frame_label,\n            metadata=metadata,\n            ch_labels=labels,\n            ch_units=unit,\n        )\n\n    @classmethod\n    def from_file(\n        cls,\n        path: str | Path,\n        channel: int | list[int] | None = None,\n        start: float | None = None,\n        end: float | None = None,\n        chunk_size: int | None = None,\n        ch_labels: list[str] | None = None,\n        # CSV-specific parameters\n        time_column: int | str = 0,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from an audio file.\n\n        Args:\n            path: Path to the audio file.\n            channel: Channel(s) to load.\n            start: Start time in seconds.\n            end: End time in seconds.\n            chunk_size: Chunk size for processing.\n                Specifies the splitting size for lazy processing.\n            ch_labels: Labels for each channel.\n            time_column: For CSV files, index or name of the time column.\n                Default is 0 (first column).\n            delimiter: For CSV files, delimiter character. Default is \",\".\n            header: For CSV files, row number to use as header.\n                Default is 0 (first row). Set to None if no header.\n\n        Returns:\n            A new ChannelFrame containing the loaded audio data.\n\n        Raises:\n            ValueError: If channel specification is invalid.\n            TypeError: If channel parameter type is invalid.\n            FileNotFoundError: If the file doesn't exist at the specified path.\n                Error message includes absolute path, current directory, and\n                troubleshooting suggestions.\n\n        Examples:\n            &gt;&gt;&gt; # Load WAV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n            &gt;&gt;&gt; # Load specific channels\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n            &gt;&gt;&gt; # Load CSV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\n            ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n            ... )\n        \"\"\"\n        from .channel import ChannelFrame\n\n        path = Path(path)\n        if not path.exists():\n            raise FileNotFoundError(\n                f\"Audio file not found\\n\"\n                f\"  Path: {path.absolute()}\\n\"\n                f\"  Current directory: {Path.cwd()}\\n\"\n                f\"Please check:\\n\"\n                f\"  - File path is correct\\n\"\n                f\"  - File exists at the specified location\\n\"\n                f\"  - You have read permissions for the file\"\n            )\n\n        # Get file reader\n        reader = get_file_reader(path)\n\n        # Build kwargs for reader\n        reader_kwargs: dict[str, Any] = {}\n        if path.suffix.lower() == \".csv\":\n            reader_kwargs[\"time_column\"] = time_column\n            reader_kwargs[\"delimiter\"] = delimiter\n            if header is not None:\n                reader_kwargs[\"header\"] = header\n\n        # Get file info\n        info = reader.get_file_info(path, **reader_kwargs)\n        sr = info[\"samplerate\"]\n        n_channels = info[\"channels\"]\n        n_frames = info[\"frames\"]\n        ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n        logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n        # Channel selection processing\n        all_channels = list(range(n_channels))\n\n        if channel is None:\n            channels_to_load = all_channels\n            logger.debug(f\"Will load all channels: {channels_to_load}\")\n        elif isinstance(channel, int):\n            if channel &lt; 0 or channel &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n            channels_to_load = [channel]\n            logger.debug(f\"Will load single channel: {channel}\")\n        elif isinstance(channel, list | tuple):\n            for ch in channel:\n                if ch &lt; 0 or ch &gt;= n_channels:\n                    raise ValueError(\n                        f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                    )\n            channels_to_load = list(channel)\n            logger.debug(f\"Will load specific channels: {channels_to_load}\")\n        else:\n            raise TypeError(\"channel must be int, list, or None\")\n\n        # Index calculation\n        start_idx = 0 if start is None else max(0, int(start * sr))\n        end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n        frames_to_read = end_idx - start_idx\n\n        logger.debug(\n            f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n            f\"start_idx={start_idx}, end_idx={end_idx}\"\n        )\n\n        # Settings for lazy loading\n        expected_shape = (len(channels_to_load), frames_to_read)\n\n        # Define the loading function using the file reader\n        def _load_audio() -&gt; NDArrayReal:\n            logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n            # Use the reader to get audio data with parameters\n            out = reader.get_data(\n                path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n            )\n            if not isinstance(out, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n            return out\n\n        logger.debug(\n            f\"Creating delayed dask task with expected shape: {expected_shape}\"\n        )\n\n        # Create delayed operation\n        delayed_data = dask_delayed(_load_audio)()\n        logger.debug(\"Wrapping delayed function in dask array\")\n\n        # Create dask array from delayed computation\n        dask_array = da_from_delayed(\n            delayed_data, shape=expected_shape, dtype=np.float32\n        )\n\n        if chunk_size is not None:\n            if chunk_size &lt;= 0:\n                raise ValueError(\"Chunk size must be a positive integer\")\n            logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n            dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n        logger.debug(\n            \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n        )\n\n        cf = ChannelFrame(\n            data=dask_array,\n            sampling_rate=sr,\n            label=path.stem,\n            metadata={\n                \"filename\": str(path),\n            },\n        )\n        if ch_labels is not None:\n            if len(ch_labels) != len(cf):\n                raise ValueError(\n                    \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        return cf\n\n    @classmethod\n    def read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a WAV file.\n\n        Args:\n            filename: Path to the WAV file.\n            labels: Labels to set for each channel.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(filename, ch_labels=labels)\n        return cf\n\n    @classmethod\n    def read_csv(\n        cls,\n        filename: str,\n        time_column: int | str = 0,\n        labels: list[str] | None = None,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a CSV file.\n\n        Args:\n            filename: Path to the CSV file.\n            time_column: Index or name of the time column.\n            labels: Labels to set for each channel.\n            delimiter: Delimiter character.\n            header: Row number to use as header.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n\n        Examples:\n            &gt;&gt;&gt; # Read CSV with default settings\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n            &gt;&gt;&gt; # Read CSV with custom delimiter\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n            &gt;&gt;&gt; # Read CSV without header\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(\n            filename,\n            ch_labels=labels,\n            time_column=time_column,\n            delimiter=delimiter,\n            header=header,\n        )\n        return cf\n\n    def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n        \"\"\"Save the audio data to a WAV file.\n\n        Args:\n            path: Path to save the file.\n            format: File format. If None, determined from file extension.\n        \"\"\"\n        from wandas.io.wav_io import write_wav\n\n        write_wav(str(path), self, format=format)\n\n    def save(\n        self,\n        path: str | Path,\n        *,\n        format: str = \"hdf5\",\n        compress: str | None = \"gzip\",\n        overwrite: bool = False,\n        dtype: str | np.dtype[Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n        This saves the complete frame including all channel data and metadata\n        in a format that can be loaded back with full fidelity.\n\n        Args:\n            path: Path to save the file. '.wdf' extension will be added if not present.\n            format: Format to use (currently only 'hdf5' is supported)\n            compress: Compression method ('gzip' by default, None for no compression)\n            overwrite: Whether to overwrite existing file\n            dtype: Optional data type conversion before saving (e.g. 'float32')\n\n        Raises:\n            FileExistsError: If the file exists and overwrite=False.\n            NotImplementedError: For unsupported formats.\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import save as wdf_save\n\n        wdf_save(\n            self,\n            path,\n            format=format,\n            compress=compress,\n            overwrite=overwrite,\n            dtype=dtype,\n        )\n\n    @classmethod\n    def load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n        \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n        This loads data saved with the save() method, preserving all channel data,\n        metadata, labels, and units.\n\n        Args:\n            path: Path to the WDF file\n            format: Format of the file (currently only 'hdf5' is supported)\n\n        Returns:\n            A new ChannelFrame with all data and metadata loaded\n\n        Raises:\n            FileNotFoundError: If the file doesn't exist\n            NotImplementedError: For unsupported formats\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import load as wdf_load\n\n        return wdf_load(path, format=format)\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"Provide additional initialization arguments required for ChannelFrame.\"\"\"\n        return {}\n\n    def add_channel(\n        self,\n        data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n        label: str | None = None,\n        align: str = \"strict\",\n        suffix_on_dup: str | None = None,\n        inplace: bool = False,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add a new channel to the frame.\n\n        Args:\n            data: Data to add as a new channel. Can be:\n                - numpy array (1D or 2D)\n                - dask array (1D or 2D)\n                - ChannelFrame (channels will be added)\n            label: Label for the new channel. If None, generates a default label.\n                Ignored when data is a ChannelFrame (uses its channel labels).\n            align: How to handle length mismatches:\n                - \"strict\": Raise error if lengths don't match\n                - \"pad\": Pad shorter data with zeros\n                - \"truncate\": Truncate longer data to match\n            suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n            inplace: If True, modifies the frame in place.\n                Otherwise returns a new frame.\n\n        Returns:\n            Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n        Raises:\n            ValueError: If data length doesn't match and align=\"strict\",\n                or if label is duplicate and suffix_on_dup is None.\n            TypeError: If data type is not supported.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Add a numpy array as a new channel\n            &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n            &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n            &gt;&gt;&gt; # Add another ChannelFrame's channels\n            &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n            &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n        \"\"\"\n        # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n        if isinstance(data, ChannelFrame):\n            if self.sampling_rate != data.sampling_rate:\n                raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n            if data.n_samples != self.n_samples:\n                if align == \"pad\":\n                    pad_len = self.n_samples - data.n_samples\n                    arr = data._data\n                    if pad_len &gt; 0:\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                    else:\n                        arr = arr[:, : self.n_samples]\n                elif align == \"truncate\":\n                    arr = data._data[:, : self.n_samples]\n                    if arr.shape[1] &lt; self.n_samples:\n                        pad_len = self.n_samples - arr.shape[1]\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                else:\n                    raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n            else:\n                arr = data._data\n            labels = [ch.label for ch in self._channel_metadata]\n            new_labels = []\n            new_metadata_list = []\n            for chmeta in data._channel_metadata:\n                new_label = chmeta.label\n                if new_label in labels or new_label in new_labels:\n                    if suffix_on_dup:\n                        new_label += suffix_on_dup\n                    else:\n                        raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n                new_labels.append(new_label)\n                # Copy the entire channel_metadata and update only the label\n                new_ch_meta = chmeta.model_copy(deep=True)\n                new_ch_meta.label = new_label\n                new_metadata_list.append(new_ch_meta)\n            new_data = concatenate([self._data, arr], axis=0)\n\n            new_chmeta = self._channel_metadata + new_metadata_list\n            if inplace:\n                self._data = new_data\n                self._channel_metadata = new_chmeta\n                return self\n            else:\n                return ChannelFrame(\n                    data=new_data,\n                    sampling_rate=self.sampling_rate,\n                    label=self.label,\n                    metadata=self.metadata,\n                    operation_history=self.operation_history,\n                    channel_metadata=new_chmeta,\n                    previous=self,\n                )\n        if isinstance(data, np.ndarray):\n            arr = from_array(data.reshape(1, -1))\n        elif isinstance(data, DaskArray):\n            arr = data[None, ...] if data.ndim == 1 else data\n            if arr.shape[0] != 1:\n                arr = arr.reshape((1, -1))\n        else:\n            raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n        if arr.shape[1] != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - arr.shape[1]\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = arr[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        labels = [ch.label for ch in self._channel_metadata]\n        new_label = label or f\"ch{len(labels)}\"\n        if new_label in labels:\n            if suffix_on_dup:\n                new_label += suffix_on_dup\n            else:\n                raise ValueError(\"label\u91cd\u8907\")\n        new_data = concatenate([self._data, arr], axis=0)\n        from ..core.metadata import ChannelMetadata\n\n        new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n        if isinstance(key, int):\n            if not (0 &lt;= key &lt; self.n_channels):\n                raise IndexError(f\"index {key} out of range\")\n            idx = key\n        else:\n            labels = [ch.label for ch in self._channel_metadata]\n            if key not in labels:\n                raise KeyError(f\"label {key} not found\")\n            idx = labels.index(key)\n        new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n        new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get time index for DataFrame.\"\"\"\n        return pd.Index(self.time, name=\"time\")\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.ChannelFrame.time","title":"<code>time</code>  <code>property</code>","text":"<p>Get time array for the signal.</p> <p>The time array represents the start time of each sample, calculated as sample_index / sampling_rate. This provides a uniform, evenly-spaced time axis that is consistent across all frame types in wandas.</p> <p>For frames resulting from windowed analysis operations (e.g., FFT, loudness, roughness), each time point corresponds to the start of the analysis window, not the center. This differs from some libraries (e.g., MoSQITo) which use window center times, but does not affect the calculated values themselves.</p> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Array of time points in seconds, starting from 0.0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; time = signal.time\n&gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n&gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.n_samples","title":"<code>n_samples</code>  <code>property</code>","text":"<p>Returns the number of samples.</p>"},{"location":"api/#wandas.frames.ChannelFrame.duration","title":"<code>duration</code>  <code>property</code>","text":"<p>Returns the duration in seconds.</p>"},{"location":"api/#wandas.frames.ChannelFrame.rms","title":"<code>rms</code>  <code>property</code>","text":"<p>Calculate RMS (Root Mean Square) value for each channel.</p> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Array of RMS values, one per channel.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; rms_values = cf.rms\n&gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n&gt;&gt;&gt; # Select channels with RMS &gt; threshold\n&gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame-functions","title":"Functions","text":""},{"location":"api/#wandas.frames.ChannelFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a ChannelFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Array</code> <p>Dask array containing channel data.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate of the data in Hz. Must be a positive value.</p> required <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data has more than 2 dimensions, or if sampling_rate is not positive.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def __init__(\n    self,\n    data: DaskArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a ChannelFrame.\n\n    Args:\n        data: Dask array containing channel data.\n        Shape should be (n_channels, n_samples).\n        sampling_rate: The sampling rate of the data in Hz.\n            Must be a positive value.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Raises:\n        ValueError: If data has more than 2 dimensions, or if\n            sampling_rate is not positive.\n    \"\"\"\n    # Validate sampling rate\n    validate_sampling_rate(sampling_rate)\n\n    # Validate and reshape data\n    if data.ndim == 1:\n        data = da.reshape(data, (1, -1))\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Invalid data shape for ChannelFrame\\n\"\n            f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n            f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n            f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n            f\"  (1, n_samples).\\n\"\n            f\"For higher-dimensional data, reshape it before creating\\n\"\n            f\"  ChannelFrame:\\n\"\n            f\"  Example: data.reshape(n_channels, -1)\"\n        )\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.info","title":"<code>info()</code>","text":"<p>Display comprehensive information about the ChannelFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - Duration - Number of samples - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p>"},{"location":"api/#wandas.frames.ChannelFrame.info--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.info() Channels: 2 Sampling rate: 44100 Hz Duration: 1.0 s Samples: 44100 Channel labels: ['ch0', 'ch1']</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the ChannelFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - Duration\n    - Number of samples\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; cf.info()\n    Channels: 2\n    Sampling rate: 44100 Hz\n    Duration: 1.0 s\n    Samples: 44100\n    Channel labels: ['ch0', 'ch1']\n    \"\"\"\n    print(\"ChannelFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  Duration: {self.duration:.1f} s\")\n    print(f\"  Samples: {self.n_samples}\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.add","title":"<code>add(other, snr=None)</code>","text":"<p>Add another signal or value to the current signal.</p> <p>If SNR is specified, performs addition with consideration for signal-to-noise ratio.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ChannelFrame | int | float | NDArrayReal</code> <p>Signal or value to add.</p> required <code>snr</code> <code>float | None</code> <p>Signal-to-noise ratio (dB). If specified, adjusts the scale of the other signal based on this SNR. self is treated as the signal, and other as the noise.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new channel frame containing the addition result (lazy execution).</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def add(\n    self,\n    other: \"ChannelFrame | int | float | NDArrayReal\",\n    snr: float | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add another signal or value to the current signal.\n\n    If SNR is specified, performs addition with consideration for\n    signal-to-noise ratio.\n\n    Args:\n        other: Signal or value to add.\n        snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n            other signal based on this SNR.\n            self is treated as the signal, and other as the noise.\n\n    Returns:\n        A new channel frame containing the addition result (lazy execution).\n    \"\"\"\n    logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n    if isinstance(other, ChannelFrame):\n        # Check if sampling rates match\n        if self.sampling_rate != other.sampling_rate:\n            raise ValueError(\n                \"Sampling rates do not match. Cannot perform operation.\"\n            )\n\n    elif isinstance(other, np.ndarray):\n        other = ChannelFrame.from_numpy(\n            other, self.sampling_rate, label=\"array_data\"\n        )\n    elif isinstance(other, int | float):\n        return self + other\n    else:\n        raise TypeError(\n            \"Addition target with SNR must be a ChannelFrame or \"\n            f\"NumPy array: {type(other)}\"\n        )\n\n    # If SNR is specified, adjust the length of the other signal\n    if other.duration != self.duration:\n        other = other.fix_length(length=self.n_samples)\n\n    if snr is None:\n        return self + other\n    return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.plot","title":"<code>plot(plot_type='waveform', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, **kwargs)</code>","text":"<p>Plot the frame data.</p> <p>Parameters:</p> Name Type Description Default <code>plot_type</code> <code>str</code> <p>Type of plot. Default is \"waveform\".</p> <code>'waveform'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot. If None, uses the frame label.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay all channels on a single plot (True) or create separate subplots for each channel (False).</p> <code>False</code> <code>xlabel</code> <code>str | None</code> <p>Label for the x-axis. If None, uses default based on plot type.</p> <code>None</code> <code>ylabel</code> <code>str | None</code> <p>Label for the y-axis. If None, uses default based on plot type.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level for the plot lines (0.0 to 1.0).</p> <code>1.0</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Limits for the x-axis as (min, max) tuple.</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Limits for the y-axis as (min, max) tuple.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional matplotlib Line2D parameters (e.g., color, linewidth, linestyle). These are passed to the underlying matplotlib plot functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic plot\n&gt;&gt;&gt; cf.plot()\n&gt;&gt;&gt; # Overlay all channels\n&gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"waveform\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the frame data.\n\n    Args:\n        plot_type: Type of plot. Default is \"waveform\".\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot. If None, uses the frame label.\n        overlay: Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel: Label for the x-axis. If None, uses default based on plot type.\n        ylabel: Label for the y-axis. If None, uses default based on plot type.\n        alpha: Transparency level for the plot lines (0.0 to 1.0).\n        xlim: Limits for the x-axis as (min, max) tuple.\n        ylim: Limits for the y-axis as (min, max) tuple.\n        **kwargs: Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n            These are passed to the underlying matplotlib plot functions.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic plot\n        &gt;&gt;&gt; cf.plot()\n        &gt;&gt;&gt; # Overlay all channels\n        &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n    \"\"\"\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    from ..visualization.plotting import create_operation\n\n    plot_strategy = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.rms_plot","title":"<code>rms_plot(ax=None, title=None, overlay=True, Aw=False, **kwargs)</code>","text":"<p>Generate an RMS plot.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay the plot on the existing axis.</p> <code>True</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the plot() method. Accepts the same arguments as plot() including xlabel, ylabel, alpha, xlim, ylim, and matplotlib Line2D parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic RMS plot\n&gt;&gt;&gt; cf.rms_plot()\n&gt;&gt;&gt; # With A-weighting\n&gt;&gt;&gt; cf.rms_plot(Aw=True)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def rms_plot(\n    self,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = True,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Generate an RMS plot.\n\n    Args:\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot.\n        overlay: Whether to overlay the plot on the existing axis.\n        Aw: Apply A-weighting.\n        **kwargs: Additional arguments passed to the plot() method.\n            Accepts the same arguments as plot() including xlabel, ylabel,\n            alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic RMS plot\n        &gt;&gt;&gt; cf.rms_plot()\n        &gt;&gt;&gt; # With A-weighting\n        &gt;&gt;&gt; cf.rms_plot(Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n    \"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n    rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n    return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.describe","title":"<code>describe(normalize=True, is_close=True, *, fmin=0, fmax=None, cmap='jet', vmin=None, vmax=None, xlim=None, ylim=None, Aw=False, waveform=None, spectral=None, **kwargs)</code>","text":"<p>Display visual and audio representation of the frame.</p> <p>This method creates a comprehensive visualization with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>Parameters:</p> Name Type Description Default <code>normalize</code> <code>bool</code> <p>Whether to normalize the audio data for playback. Default: True</p> <code>True</code> <code>is_close</code> <code>bool</code> <p>Whether to close the figure after displaying. Default: True</p> <code>True</code> <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>0</code> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency (sampling_rate / 2)</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>'jet'</code> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots. Format: (start_time, end_time)</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots. Format: (min_freq, max_freq)</p> <code>None</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>False</code> <code>waveform</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for waveform subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>spectral</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for spectral subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Deprecated parameters for backward compatibility only. - axis_config: Old configuration format (use waveform/spectral instead) - cbar_config: Old colorbar configuration (use vmin/vmax instead)</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom waveform subplot settings\n&gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def describe(\n    self,\n    normalize: bool = True,\n    is_close: bool = True,\n    *,\n    fmin: float = 0,\n    fmax: float | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    waveform: dict[str, Any] | None = None,\n    spectral: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Display visual and audio representation of the frame.\n\n    This method creates a comprehensive visualization with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Args:\n        normalize: Whether to normalize the audio data for playback.\n            Default: True\n        is_close: Whether to close the figure after displaying.\n            Default: True\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency (sampling_rate / 2)\n        cmap: Colormap for the spectrogram.\n            Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n            Format: (start_time, end_time)\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n            Format: (min_freq, max_freq)\n        Aw: Apply A-weighting to the frequency analysis.\n            Default: False\n        waveform: Additional configuration dict for waveform subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        spectral: Additional configuration dict for spectral subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        **kwargs: Deprecated parameters for backward compatibility only.\n            - axis_config: Old configuration format (use waveform/spectral instead)\n            - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom waveform subplot settings\n        &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n    \"\"\"\n    # Prepare kwargs with explicit parameters\n    plot_kwargs: dict[str, Any] = {\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"xlim\": xlim,\n        \"ylim\": ylim,\n        \"Aw\": Aw,\n        \"waveform\": waveform or {},\n        \"spectral\": spectral or {},\n    }\n    # Merge with additional kwargs\n    plot_kwargs.update(kwargs)\n\n    if \"axis_config\" in plot_kwargs:\n        logger.warning(\n            \"axis_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        axis_config = plot_kwargs[\"axis_config\"]\n        if \"time_plot\" in axis_config:\n            plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n        if \"freq_plot\" in axis_config:\n            if \"xlim\" in axis_config[\"freq_plot\"]:\n                vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                plot_kwargs[\"vmin\"] = vlim[0]\n                plot_kwargs[\"vmax\"] = vlim[1]\n            if \"ylim\" in axis_config[\"freq_plot\"]:\n                ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                plot_kwargs[\"ylim\"] = ylim_config\n\n    if \"cbar_config\" in plot_kwargs:\n        logger.warning(\n            \"cbar_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        cbar_config = plot_kwargs[\"cbar_config\"]\n        if \"vmin\" in cbar_config:\n            plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n        if \"vmax\" in cbar_config:\n            plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n    for ch in self:\n        ax: Axes\n        _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n        if isinstance(_ax, Iterator):\n            ax = next(iter(_ax))\n        elif isinstance(_ax, Axes):\n            ax = _ax\n        else:\n            raise TypeError(\n                f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n            )\n        # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n        display(ax.figure)\n        if is_close:\n            plt.close(getattr(ax, \"figure\", None))\n        display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.from_numpy","title":"<code>from_numpy(data, sampling_rate, label=None, metadata=None, ch_labels=None, ch_units=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayReal</code> <p>NumPy array containing channel data.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> required <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>ch_units</code> <code>list[str] | str | None</code> <p>Units for each channel.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the NumPy data.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayReal,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    ch_labels: list[str] | None = None,\n    ch_units: list[str] | str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing channel data.\n        sampling_rate: The sampling rate in Hz.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        ch_labels: Labels for each channel.\n        ch_units: Units for each channel.\n\n    Returns:\n        A new ChannelFrame containing the NumPy data.\n    \"\"\"\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n\n    # Convert NumPy array to dask array\n    dask_data = da_from_array(data)\n    cf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        label=label or \"numpy_data\",\n    )\n    if metadata is not None:\n        cf.metadata = metadata\n    if ch_labels is not None:\n        if len(ch_labels) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel labels does not match the number of channels\"\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    if ch_units is not None:\n        if isinstance(ch_units, str):\n            ch_units = [ch_units] * cf.n_channels\n\n        if len(ch_units) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel units does not match the number of channels\"\n            )\n        for i in range(len(ch_units)):\n            cf._channel_metadata[i].unit = ch_units[i]\n\n    return cf\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.from_ndarray","title":"<code>from_ndarray(array, sampling_rate, labels=None, unit=None, frame_label=None, metadata=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>This method is deprecated. Use from_numpy instead.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArrayReal</code> <p>Signal data. Each row corresponds to a channel.</p> required <code>sampling_rate</code> <code>float</code> <p>Sampling rate (Hz).</p> required <code>labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>unit</code> <code>list[str] | str | None</code> <p>Unit of the signal.</p> <code>None</code> <code>frame_label</code> <code>str | None</code> <p>Label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_ndarray(\n    cls,\n    array: NDArrayReal,\n    sampling_rate: float,\n    labels: list[str] | None = None,\n    unit: list[str] | str | None = None,\n    frame_label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    This method is deprecated. Use from_numpy instead.\n\n    Args:\n        array: Signal data. Each row corresponds to a channel.\n        sampling_rate: Sampling rate (Hz).\n        labels: Labels for each channel.\n        unit: Unit of the signal.\n        frame_label: Label for the frame.\n        metadata: Optional metadata dictionary.\n\n    Returns:\n        A new ChannelFrame containing the data.\n    \"\"\"\n    # Redirect to from_numpy for compatibility\n    # However, from_ndarray is deprecated\n    logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n    return cls.from_numpy(\n        data=array,\n        sampling_rate=sampling_rate,\n        label=frame_label,\n        metadata=metadata,\n        ch_labels=labels,\n        ch_units=unit,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.from_file","title":"<code>from_file(path, channel=None, start=None, end=None, chunk_size=None, ch_labels=None, time_column=0, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from an audio file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the audio file.</p> required <code>channel</code> <code>int | list[int] | None</code> <p>Channel(s) to load.</p> <code>None</code> <code>start</code> <code>float | None</code> <p>Start time in seconds.</p> <code>None</code> <code>end</code> <code>float | None</code> <p>End time in seconds.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Chunk size for processing. Specifies the splitting size for lazy processing.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>time_column</code> <code>int | str</code> <p>For CSV files, index or name of the time column. Default is 0 (first column).</p> <code>0</code> <code>delimiter</code> <code>str</code> <p>For CSV files, delimiter character. Default is \",\".</p> <code>','</code> <code>header</code> <code>int | None</code> <p>For CSV files, row number to use as header. Default is 0 (first row). Set to None if no header.</p> <code>0</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the loaded audio data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If channel specification is invalid.</p> <code>TypeError</code> <p>If channel parameter type is invalid.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist at the specified path. Error message includes absolute path, current directory, and troubleshooting suggestions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load WAV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n&gt;&gt;&gt; # Load specific channels\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n&gt;&gt;&gt; # Load CSV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\n...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n... )\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    channel: int | list[int] | None = None,\n    start: float | None = None,\n    end: float | None = None,\n    chunk_size: int | None = None,\n    ch_labels: list[str] | None = None,\n    # CSV-specific parameters\n    time_column: int | str = 0,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from an audio file.\n\n    Args:\n        path: Path to the audio file.\n        channel: Channel(s) to load.\n        start: Start time in seconds.\n        end: End time in seconds.\n        chunk_size: Chunk size for processing.\n            Specifies the splitting size for lazy processing.\n        ch_labels: Labels for each channel.\n        time_column: For CSV files, index or name of the time column.\n            Default is 0 (first column).\n        delimiter: For CSV files, delimiter character. Default is \",\".\n        header: For CSV files, row number to use as header.\n            Default is 0 (first row). Set to None if no header.\n\n    Returns:\n        A new ChannelFrame containing the loaded audio data.\n\n    Raises:\n        ValueError: If channel specification is invalid.\n        TypeError: If channel parameter type is invalid.\n        FileNotFoundError: If the file doesn't exist at the specified path.\n            Error message includes absolute path, current directory, and\n            troubleshooting suggestions.\n\n    Examples:\n        &gt;&gt;&gt; # Load WAV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n        &gt;&gt;&gt; # Load specific channels\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n        &gt;&gt;&gt; # Load CSV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\n        ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n        ... )\n    \"\"\"\n    from .channel import ChannelFrame\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Audio file not found\\n\"\n            f\"  Path: {path.absolute()}\\n\"\n            f\"  Current directory: {Path.cwd()}\\n\"\n            f\"Please check:\\n\"\n            f\"  - File path is correct\\n\"\n            f\"  - File exists at the specified location\\n\"\n            f\"  - You have read permissions for the file\"\n        )\n\n    # Get file reader\n    reader = get_file_reader(path)\n\n    # Build kwargs for reader\n    reader_kwargs: dict[str, Any] = {}\n    if path.suffix.lower() == \".csv\":\n        reader_kwargs[\"time_column\"] = time_column\n        reader_kwargs[\"delimiter\"] = delimiter\n        if header is not None:\n            reader_kwargs[\"header\"] = header\n\n    # Get file info\n    info = reader.get_file_info(path, **reader_kwargs)\n    sr = info[\"samplerate\"]\n    n_channels = info[\"channels\"]\n    n_frames = info[\"frames\"]\n    ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n    logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n    # Channel selection processing\n    all_channels = list(range(n_channels))\n\n    if channel is None:\n        channels_to_load = all_channels\n        logger.debug(f\"Will load all channels: {channels_to_load}\")\n    elif isinstance(channel, int):\n        if channel &lt; 0 or channel &gt;= n_channels:\n            raise ValueError(\n                f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n            )\n        channels_to_load = [channel]\n        logger.debug(f\"Will load single channel: {channel}\")\n    elif isinstance(channel, list | tuple):\n        for ch in channel:\n            if ch &lt; 0 or ch &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n        channels_to_load = list(channel)\n        logger.debug(f\"Will load specific channels: {channels_to_load}\")\n    else:\n        raise TypeError(\"channel must be int, list, or None\")\n\n    # Index calculation\n    start_idx = 0 if start is None else max(0, int(start * sr))\n    end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n    frames_to_read = end_idx - start_idx\n\n    logger.debug(\n        f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n        f\"start_idx={start_idx}, end_idx={end_idx}\"\n    )\n\n    # Settings for lazy loading\n    expected_shape = (len(channels_to_load), frames_to_read)\n\n    # Define the loading function using the file reader\n    def _load_audio() -&gt; NDArrayReal:\n        logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n        # Use the reader to get audio data with parameters\n        out = reader.get_data(\n            path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n        )\n        if not isinstance(out, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n        return out\n\n    logger.debug(\n        f\"Creating delayed dask task with expected shape: {expected_shape}\"\n    )\n\n    # Create delayed operation\n    delayed_data = dask_delayed(_load_audio)()\n    logger.debug(\"Wrapping delayed function in dask array\")\n\n    # Create dask array from delayed computation\n    dask_array = da_from_delayed(\n        delayed_data, shape=expected_shape, dtype=np.float32\n    )\n\n    if chunk_size is not None:\n        if chunk_size &lt;= 0:\n            raise ValueError(\"Chunk size must be a positive integer\")\n        logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n        dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n    logger.debug(\n        \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n    )\n\n    cf = ChannelFrame(\n        data=dask_array,\n        sampling_rate=sr,\n        label=path.stem,\n        metadata={\n            \"filename\": str(path),\n        },\n    )\n    if ch_labels is not None:\n        if len(ch_labels) != len(cf):\n            raise ValueError(\n                \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    return cf\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.read_wav","title":"<code>read_wav(filename, labels=None)</code>  <code>classmethod</code>","text":"<p>Utility method to read a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the WAV file.</p> required <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a WAV file.\n\n    Args:\n        filename: Path to the WAV file.\n        labels: Labels to set for each channel.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(filename, ch_labels=labels)\n    return cf\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.read_csv","title":"<code>read_csv(filename, time_column=0, labels=None, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Utility method to read a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> required <code>time_column</code> <code>int | str</code> <p>Index or name of the time column.</p> <code>0</code> <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>Delimiter character.</p> <code>','</code> <code>header</code> <code>int | None</code> <p>Row number to use as header.</p> <code>0</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Read CSV with default settings\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n&gt;&gt;&gt; # Read CSV with custom delimiter\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n&gt;&gt;&gt; # Read CSV without header\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_csv(\n    cls,\n    filename: str,\n    time_column: int | str = 0,\n    labels: list[str] | None = None,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a CSV file.\n\n    Args:\n        filename: Path to the CSV file.\n        time_column: Index or name of the time column.\n        labels: Labels to set for each channel.\n        delimiter: Delimiter character.\n        header: Row number to use as header.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n\n    Examples:\n        &gt;&gt;&gt; # Read CSV with default settings\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n        &gt;&gt;&gt; # Read CSV with custom delimiter\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n        &gt;&gt;&gt; # Read CSV without header\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(\n        filename,\n        ch_labels=labels,\n        time_column=time_column,\n        delimiter=delimiter,\n        header=header,\n    )\n    return cf\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.to_wav","title":"<code>to_wav(path, format=None)</code>","text":"<p>Save the audio data to a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to save the file.</p> required <code>format</code> <code>str | None</code> <p>File format. If None, determined from file extension.</p> <code>None</code> Source code in <code>wandas/frames/channel.py</code> <pre><code>def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n    \"\"\"Save the audio data to a WAV file.\n\n    Args:\n        path: Path to save the file.\n        format: File format. If None, determined from file extension.\n    \"\"\"\n    from wandas.io.wav_io import write_wav\n\n    write_wav(str(path), self, format=format)\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.save","title":"<code>save(path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save the ChannelFrame to a WDF (Wandas Data File) format.</p> <p>This saves the complete frame including all channel data and metadata in a format that can be loaded back with full fidelity.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Example <p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.save(\"audio_analysis.wdf\")</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def save(\n    self,\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n    This saves the complete frame including all channel data and metadata\n    in a format that can be loaded back with full fidelity.\n\n    Args:\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import save as wdf_save\n\n    wdf_save(\n        self,\n        path,\n        format=format,\n        compress=compress,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.load","title":"<code>load(path, *, format='hdf5')</code>  <code>classmethod</code>","text":"<p>Load a ChannelFrame from a WDF (Wandas Data File) file.</p> <p>This loads data saved with the save() method, preserving all channel data, metadata, labels, and units.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file</p> required <code>format</code> <code>str</code> <p>Format of the file (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame with all data and metadata loaded</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>NotImplementedError</code> <p>For unsupported formats</p> Example <p>cf = ChannelFrame.load(\"audio_analysis.wdf\")</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n    This loads data saved with the save() method, preserving all channel data,\n    metadata, labels, and units.\n\n    Args:\n        path: Path to the WDF file\n        format: Format of the file (currently only 'hdf5' is supported)\n\n    Returns:\n        A new ChannelFrame with all data and metadata loaded\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        NotImplementedError: For unsupported formats\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import load as wdf_load\n\n    return wdf_load(path, format=format)\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.add_channel","title":"<code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False)</code>","text":"<p>Add a new channel to the frame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray[Any, Any] | Array | ChannelFrame</code> <p>Data to add as a new channel. Can be: - numpy array (1D or 2D) - dask array (1D or 2D) - ChannelFrame (channels will be added)</p> required <code>label</code> <code>str | None</code> <p>Label for the new channel. If None, generates a default label. Ignored when data is a ChannelFrame (uses its channel labels).</p> <code>None</code> <code>align</code> <code>str</code> <p>How to handle length mismatches: - \"strict\": Raise error if lengths don't match - \"pad\": Pad shorter data with zeros - \"truncate\": Truncate longer data to match</p> <code>'strict'</code> <code>suffix_on_dup</code> <code>str | None</code> <p>Suffix to add to duplicate labels. If None, raises error.</p> <code>None</code> <code>inplace</code> <code>bool</code> <p>If True, modifies the frame in place. Otherwise returns a new frame.</p> <code>False</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>Modified ChannelFrame (self if inplace=True, new frame otherwise).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data length doesn't match and align=\"strict\", or if label is duplicate and suffix_on_dup is None.</p> <code>TypeError</code> <p>If data type is not supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Add a numpy array as a new channel\n&gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n&gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n&gt;&gt;&gt; # Add another ChannelFrame's channels\n&gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n&gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def add_channel(\n    self,\n    data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n    label: str | None = None,\n    align: str = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add a new channel to the frame.\n\n    Args:\n        data: Data to add as a new channel. Can be:\n            - numpy array (1D or 2D)\n            - dask array (1D or 2D)\n            - ChannelFrame (channels will be added)\n        label: Label for the new channel. If None, generates a default label.\n            Ignored when data is a ChannelFrame (uses its channel labels).\n        align: How to handle length mismatches:\n            - \"strict\": Raise error if lengths don't match\n            - \"pad\": Pad shorter data with zeros\n            - \"truncate\": Truncate longer data to match\n        suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n        inplace: If True, modifies the frame in place.\n            Otherwise returns a new frame.\n\n    Returns:\n        Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n    Raises:\n        ValueError: If data length doesn't match and align=\"strict\",\n            or if label is duplicate and suffix_on_dup is None.\n        TypeError: If data type is not supported.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Add a numpy array as a new channel\n        &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n        &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n        &gt;&gt;&gt; # Add another ChannelFrame's channels\n        &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n        &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n    \"\"\"\n    # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n    if isinstance(data, ChannelFrame):\n        if self.sampling_rate != data.sampling_rate:\n            raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n        if data.n_samples != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - data.n_samples\n                arr = data._data\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = data._data[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        else:\n            arr = data._data\n        labels = [ch.label for ch in self._channel_metadata]\n        new_labels = []\n        new_metadata_list = []\n        for chmeta in data._channel_metadata:\n            new_label = chmeta.label\n            if new_label in labels or new_label in new_labels:\n                if suffix_on_dup:\n                    new_label += suffix_on_dup\n                else:\n                    raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n            new_labels.append(new_label)\n            # Copy the entire channel_metadata and update only the label\n            new_ch_meta = chmeta.model_copy(deep=True)\n            new_ch_meta.label = new_label\n            new_metadata_list.append(new_ch_meta)\n        new_data = concatenate([self._data, arr], axis=0)\n\n        new_chmeta = self._channel_metadata + new_metadata_list\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n    if isinstance(data, np.ndarray):\n        arr = from_array(data.reshape(1, -1))\n    elif isinstance(data, DaskArray):\n        arr = data[None, ...] if data.ndim == 1 else data\n        if arr.shape[0] != 1:\n            arr = arr.reshape((1, -1))\n    else:\n        raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n    if arr.shape[1] != self.n_samples:\n        if align == \"pad\":\n            pad_len = self.n_samples - arr.shape[1]\n            if pad_len &gt; 0:\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n            else:\n                arr = arr[:, : self.n_samples]\n        elif align == \"truncate\":\n            arr = arr[:, : self.n_samples]\n            if arr.shape[1] &lt; self.n_samples:\n                pad_len = self.n_samples - arr.shape[1]\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n        else:\n            raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n    labels = [ch.label for ch in self._channel_metadata]\n    new_label = label or f\"ch{len(labels)}\"\n    if new_label in labels:\n        if suffix_on_dup:\n            new_label += suffix_on_dup\n        else:\n            raise ValueError(\"label\u91cd\u8907\")\n    new_data = concatenate([self._data, arr], axis=0)\n    from ..core.metadata import ChannelMetadata\n\n    new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"api/#wandas.frames.ChannelFrame.remove_channel","title":"<code>remove_channel(key, inplace=False)</code>","text":"Source code in <code>wandas/frames/channel.py</code> <pre><code>def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n    if isinstance(key, int):\n        if not (0 &lt;= key &lt; self.n_channels):\n            raise IndexError(f\"index {key} out of range\")\n        idx = key\n    else:\n        labels = [ch.label for ch in self._channel_metadata]\n        if key not in labels:\n            raise KeyError(f\"label {key} not found\")\n        idx = labels.index(key)\n    new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n    new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"api/#wandas.frames.RoughnessFrame","title":"<code>RoughnessFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code></p> <p>Frame for detailed roughness analysis with Bark-band information.</p> <p>This frame contains specific roughness (R_spec) data organized by Bark frequency bands over time, calculated using the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness follows: R = 0.25 * sum(R_spec, axis=bark_bands)</p>"},{"location":"api/#wandas.frames.RoughnessFrame--parameters","title":"Parameters","text":"<p>data : da.Array     Specific roughness data with shape:     - (n_bark_bands, n_time) for mono signals     - (n_channels, n_bark_bands, n_time) for multi-channel signals     where n_bark_bands is always 47. sampling_rate : float     Sampling rate of the roughness time series in Hz.     For overlap=0.5, this is approximately 10 Hz (100ms hop).     For overlap=0.0, this is approximately 5 Hz (200ms hop). bark_axis : NDArrayReal     Bark frequency axis with 47 values from 0.5 to 23.5 Bark. overlap : float     Overlap coefficient used in the calculation (0.0 to 1.0). label : str, optional     Frame label. Defaults to \"roughness_spec\". metadata : dict, optional     Additional metadata. operation_history : list[dict], optional     History of operations applied to this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel. previous : BaseFrame, optional     Reference to the previous frame in the processing chain.</p>"},{"location":"api/#wandas.frames.RoughnessFrame--attributes","title":"Attributes","text":"<p>bark_axis : NDArrayReal     Frequency axis in Bark scale. n_bark_bands : int     Number of Bark bands (always 47). n_time_points : int     Number of time points. time : NDArrayReal     Time axis based on sampling rate. overlap : float     Overlap coefficient used (0.0 to 1.0).</p>"},{"location":"api/#wandas.frames.RoughnessFrame--examples","title":"Examples","text":"<p>Create a roughness frame from a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"motor.wav\") roughness_spec = signal.roughness_dw_spec(overlap=0.5)</p>"},{"location":"api/#wandas.frames.RoughnessFrame--plot-bark-time-heatmap","title":"Plot Bark-Time heatmap","text":"<p>roughness_spec.plot()</p>"},{"location":"api/#wandas.frames.RoughnessFrame--find-dominant-bark-band","title":"Find dominant Bark band","text":"<p>dominant_idx = roughness_spec.data.mean(axis=1).argmax() dominant_bark = roughness_spec.bark_axis[dominant_idx] print(f\"Dominant frequency: {dominant_bark:.1f} Bark\")</p>"},{"location":"api/#wandas.frames.RoughnessFrame--extract-specific-bark-band","title":"Extract specific Bark band","text":"<p>bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0)) roughness_at_10bark = roughness_spec.data[bark_10_idx, :]</p>"},{"location":"api/#wandas.frames.RoughnessFrame--notes","title":"Notes","text":"<p>The Daniel &amp; Weber (1997) roughness model calculates specific roughness for 47 critical bands (Bark scale) over time, then integrates them to produce the total roughness:</p> <p>.. math::     R = 0.25 \\sum_{i=1}^{47} R'_i</p> <p>where R'_i is the specific roughness in the i-th Bark band.</p>"},{"location":"api/#wandas.frames.RoughnessFrame--references","title":"References","text":"<p>.. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:        Implementation of an optimized model\". Acta Acustica united with        Acustica, 83(1), 113-123.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>class RoughnessFrame(BaseFrame[NDArrayReal]):\n    \"\"\"\n    Frame for detailed roughness analysis with Bark-band information.\n\n    This frame contains specific roughness (R_spec) data organized by\n    Bark frequency bands over time, calculated using the Daniel &amp; Weber (1997)\n    method.\n\n    The relationship between total roughness and specific roughness follows:\n    R = 0.25 * sum(R_spec, axis=bark_bands)\n\n    Parameters\n    ----------\n    data : da.Array\n        Specific roughness data with shape:\n        - (n_bark_bands, n_time) for mono signals\n        - (n_channels, n_bark_bands, n_time) for multi-channel signals\n        where n_bark_bands is always 47.\n    sampling_rate : float\n        Sampling rate of the roughness time series in Hz.\n        For overlap=0.5, this is approximately 10 Hz (100ms hop).\n        For overlap=0.0, this is approximately 5 Hz (200ms hop).\n    bark_axis : NDArrayReal\n        Bark frequency axis with 47 values from 0.5 to 23.5 Bark.\n    overlap : float\n        Overlap coefficient used in the calculation (0.0 to 1.0).\n    label : str, optional\n        Frame label. Defaults to \"roughness_spec\".\n    metadata : dict, optional\n        Additional metadata.\n    operation_history : list[dict], optional\n        History of operations applied to this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel.\n    previous : BaseFrame, optional\n        Reference to the previous frame in the processing chain.\n\n    Attributes\n    ----------\n    bark_axis : NDArrayReal\n        Frequency axis in Bark scale.\n    n_bark_bands : int\n        Number of Bark bands (always 47).\n    n_time_points : int\n        Number of time points.\n    time : NDArrayReal\n        Time axis based on sampling rate.\n    overlap : float\n        Overlap coefficient used (0.0 to 1.0).\n\n    Examples\n    --------\n    Create a roughness frame from a signal:\n\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Plot Bark-Time heatmap\n    &gt;&gt;&gt; roughness_spec.plot()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Find dominant Bark band\n    &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n    &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n    &gt;&gt;&gt; print(f\"Dominant frequency: {dominant_bark:.1f} Bark\")\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Extract specific Bark band\n    &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n    &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n\n    Notes\n    -----\n    The Daniel &amp; Weber (1997) roughness model calculates specific roughness\n    for 47 critical bands (Bark scale) over time, then integrates them to\n    produce the total roughness:\n\n    .. math::\n        R = 0.25 \\\\sum_{i=1}^{47} R'_i\n\n    where R'_i is the specific roughness in the i-th Bark band.\n\n    References\n    ----------\n    .. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n           Implementation of an optimized model\". Acta Acustica united with\n           Acustica, 83(1), 113-123.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: da.Array,\n        sampling_rate: float,\n        bark_axis: NDArrayReal,\n        overlap: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a RoughnessFrame.\"\"\"\n        # Validate dimensions\n        if data.ndim not in (2, 3):\n            raise ValueError(\n                f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n            )\n\n        # Validate Bark bands\n        if data.shape[-2] != 47:\n            raise ValueError(\n                f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n                f\"(data shape: {data.shape})\"\n            )\n\n        if len(bark_axis) != 47:\n            raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n        # Validate overlap\n        if not 0.0 &lt;= overlap &lt;= 1.0:\n            raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n        # Store Bark-specific attributes\n        self._bark_axis = bark_axis\n        self._overlap = overlap\n\n        # Initialize base frame\n        metadata = metadata or {}\n        metadata[\"overlap\"] = overlap\n\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label or \"roughness_spec\",\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def data(self) -&gt; NDArrayReal:\n        \"\"\"\n        Returns the computed data without squeezing.\n\n        For RoughnessFrame, even mono signals have 2D shape (47, n_time)\n        so we don't squeeze the channel dimension.\n\n        Returns\n        -------\n        NDArrayReal\n            Computed data array.\n        \"\"\"\n        return self.compute()\n\n    @property\n    def bark_axis(self) -&gt; NDArrayReal:\n        \"\"\"\n        Bark frequency axis.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of 47 Bark values from 0.5 to 23.5 Bark.\n        \"\"\"\n        return self._bark_axis\n\n    @property\n    def n_bark_bands(self) -&gt; int:\n        \"\"\"\n        Number of Bark bands.\n\n        Returns\n        -------\n        int\n            Always 47 for the Daniel &amp; Weber model.\n        \"\"\"\n        return 47\n\n    @property\n    def n_time_points(self) -&gt; int:\n        \"\"\"\n        Number of time points in the roughness time series.\n\n        Returns\n        -------\n        int\n            Number of time frames in the analysis.\n        \"\"\"\n        return int(self._data.shape[-1])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"\n        Time axis based on sampling rate.\n\n        Returns\n        -------\n        NDArrayReal\n            Time values in seconds for each frame.\n        \"\"\"\n        return np.arange(self.n_time_points) / self.sampling_rate\n\n    @property\n    def overlap(self) -&gt; float:\n        \"\"\"\n        Overlap coefficient used in the calculation.\n\n        Returns\n        -------\n        float\n            Overlap value between 0.0 and 1.0.\n        \"\"\"\n        return self._overlap\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Return the number of channels.\n\n        Returns\n        -------\n        int\n            Number of channels. For 2D data (mono), returns 1.\n        \"\"\"\n        if self._data.ndim == 2:\n            return 1\n        return int(self._data.shape[0])\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Provide additional initialization arguments for RoughnessFrame.\n\n        Returns\n        -------\n        dict\n            Dictionary containing bark_axis and overlap\n        \"\"\"\n        return {\n            \"bark_axis\": self._bark_axis,\n            \"overlap\": self._overlap,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"DataFrame index is not supported for RoughnessFrame.\"\"\"\n        raise NotImplementedError(\n            \"DataFrame index is not supported for RoughnessFrame.\"\n        )\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n        RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n        which cannot be directly converted to a 2D DataFrame.\n\n        Raises\n        ------\n        NotImplementedError\n            Always raised as DataFrame conversion is not supported.\n        \"\"\"\n        raise NotImplementedError(\n            \"DataFrame conversion is not supported for RoughnessFrame.\"\n        )\n\n    def _binary_op(\n        self,\n        other: Union[\"RoughnessFrame\", int, float, NDArrayReal, da.Array],\n        op: \"Callable[[da.Array, Any], da.Array]\",\n        symbol: str,\n    ) -&gt; \"RoughnessFrame\":\n        \"\"\"\n        Common implementation for binary operations.\n\n        Parameters\n        ----------\n        other : RoughnessFrame, int, float, NDArrayReal, or da.Array\n            Right operand for the operation.\n        op : Callable\n            Function to execute the operation.\n        symbol : str\n            Symbolic representation of the operation.\n\n        Returns\n        -------\n        RoughnessFrame\n            A new RoughnessFrame with the operation result.\n\n        Raises\n        ------\n        ValueError\n            If sampling rates don't match or shapes are incompatible.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle metadata and operation_history\n        metadata = self.metadata.copy() if self.metadata else {}\n        operation_history = (\n            self.operation_history.copy() if self.operation_history else []\n        )\n\n        # Check if other is a RoughnessFrame\n        if isinstance(other, RoughnessFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    f\"Sampling rates do not match: {self.sampling_rate} vs \"\n                    f\"{other.sampling_rate}\"\n                )\n\n            if self._data.shape != other._data.shape:\n                raise ValueError(\n                    f\"Shape mismatch: {self._data.shape} vs {other._data.shape}\"\n                )\n\n            # Apply operation\n            result_data = op(self._data, other._data)\n\n            # Update operation history\n            operation_history.append(\n                {\"name\": f\"binary_op_{symbol}\", \"params\": {\"other\": \"RoughnessFrame\"}}\n            )\n\n        else:\n            # Scalar or array operation\n            if isinstance(other, np.ndarray):\n                other = da.from_array(other, chunks=self._data.chunks)\n\n            result_data = op(self._data, other)\n\n            operation_history.append(\n                {\"name\": f\"binary_op_{symbol}\", \"params\": {\"other\": str(type(other))}}\n            )\n\n        # Create new instance\n        return RoughnessFrame(\n            data=result_data,\n            sampling_rate=self.sampling_rate,\n            bark_axis=self._bark_axis,\n            overlap=self._overlap,\n            label=self.label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def _apply_operation_impl(\n        self, operation_name: str, **params: Any\n    ) -&gt; \"RoughnessFrame\":\n        \"\"\"\n        Implementation of operation application.\n\n        Note: RoughnessFrame is typically a terminal node in processing chains.\n        Most operations are not directly applicable to spectral roughness data.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Operation parameters.\n\n        Returns\n        -------\n        RoughnessFrame\n            A new RoughnessFrame with the operation applied.\n\n        Raises\n        ------\n        NotImplementedError\n            As most operations are not applicable to roughness spectrograms.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Operation '{operation_name}' is not supported for RoughnessFrame. \"\n            \"RoughnessFrame is typically a terminal node in the processing chain.\"\n        )\n\n    def plot(\n        self,\n        plot_type: str = \"heatmap\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        cmap: str = \"viridis\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlabel: str = \"Time [s]\",\n        ylabel: str = \"Frequency [Bark]\",\n        colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n        **kwargs: Any,\n    ) -&gt; \"Axes\":\n        \"\"\"\n        Plot Bark-Time-Roughness heatmap.\n\n        For multi-channel signals, the mean across channels is plotted.\n\n        Parameters\n        ----------\n        ax : Axes, optional\n            Matplotlib axes to plot on. If None, a new figure is created.\n        title : str, optional\n            Plot title. If None, a default title is used.\n        cmap : str, default=\"viridis\"\n            Colormap name for the heatmap.\n        vmin, vmax : float, optional\n            Color scale limits. If None, automatic scaling is used.\n        xlabel : str, default=\"Time [s]\"\n            Label for the x-axis.\n        ylabel : str, default=\"Frequency [Bark]\"\n            Label for the y-axis.\n        colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n            Label for the colorbar.\n        **kwargs : Any\n            Additional keyword arguments passed to pcolormesh.\n\n        Returns\n        -------\n        Axes\n            The matplotlib axes object containing the plot.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 6))\n\n        # Select data to plot (first channel for mono, mean for multi-channel)\n        # self._data is Dask array, self.data is computed NumPy array\n        computed_data = self.compute()\n\n        if computed_data.ndim == 2:\n            # Mono: (47, n_time)\n            data_to_plot = computed_data\n        else:\n            # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n            data_to_plot = computed_data.mean(axis=0)\n\n        # Create heatmap\n        im = ax.pcolormesh(\n            self.time,\n            self.bark_axis,\n            data_to_plot,\n            shading=\"auto\",\n            cmap=cmap,\n            vmin=vmin,\n            vmax=vmax,\n            **kwargs,\n        )\n\n        # Labels and title\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        if title is None:\n            title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n        ax.set_title(title)\n\n        # Colorbar\n        plt.colorbar(im, ax=ax, label=colorbar_label)\n\n        return ax\n</code></pre>"},{"location":"api/#wandas.frames.RoughnessFrame-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.RoughnessFrame.data","title":"<code>data</code>  <code>property</code>","text":"<p>Returns the computed data without squeezing.</p> <p>For RoughnessFrame, even mono signals have 2D shape (47, n_time) so we don't squeeze the channel dimension.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.data--returns","title":"Returns","text":"<p>NDArrayReal     Computed data array.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.bark_axis","title":"<code>bark_axis</code>  <code>property</code>","text":"<p>Bark frequency axis.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.bark_axis--returns","title":"Returns","text":"<p>NDArrayReal     Array of 47 Bark values from 0.5 to 23.5 Bark.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.n_bark_bands","title":"<code>n_bark_bands</code>  <code>property</code>","text":"<p>Number of Bark bands.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.n_bark_bands--returns","title":"Returns","text":"<p>int     Always 47 for the Daniel &amp; Weber model.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.n_time_points","title":"<code>n_time_points</code>  <code>property</code>","text":"<p>Number of time points in the roughness time series.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.n_time_points--returns","title":"Returns","text":"<p>int     Number of time frames in the analysis.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.time","title":"<code>time</code>  <code>property</code>","text":"<p>Time axis based on sampling rate.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.time--returns","title":"Returns","text":"<p>NDArrayReal     Time values in seconds for each frame.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.overlap","title":"<code>overlap</code>  <code>property</code>","text":"<p>Overlap coefficient used in the calculation.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.overlap--returns","title":"Returns","text":"<p>float     Overlap value between 0.0 and 1.0.</p>"},{"location":"api/#wandas.frames.RoughnessFrame-functions","title":"Functions","text":""},{"location":"api/#wandas.frames.RoughnessFrame.__init__","title":"<code>__init__(data, sampling_rate, bark_axis, overlap, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a RoughnessFrame.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>def __init__(\n    self,\n    data: da.Array,\n    sampling_rate: float,\n    bark_axis: NDArrayReal,\n    overlap: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a RoughnessFrame.\"\"\"\n    # Validate dimensions\n    if data.ndim not in (2, 3):\n        raise ValueError(\n            f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n        )\n\n    # Validate Bark bands\n    if data.shape[-2] != 47:\n        raise ValueError(\n            f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n            f\"(data shape: {data.shape})\"\n        )\n\n    if len(bark_axis) != 47:\n        raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n    # Validate overlap\n    if not 0.0 &lt;= overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n    # Store Bark-specific attributes\n    self._bark_axis = bark_axis\n    self._overlap = overlap\n\n    # Initialize base frame\n    metadata = metadata or {}\n    metadata[\"overlap\"] = overlap\n\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label or \"roughness_spec\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.RoughnessFrame.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>DataFrame conversion is not supported for RoughnessFrame.</p> <p>RoughnessFrame contains 3D data (channels, bark_bands, time_frames) which cannot be directly converted to a 2D DataFrame.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n    RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n    which cannot be directly converted to a 2D DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for RoughnessFrame.\"\n    )\n</code></pre>"},{"location":"api/#wandas.frames.RoughnessFrame.plot","title":"<code>plot(plot_type='heatmap', ax=None, title=None, cmap='viridis', vmin=None, vmax=None, xlabel='Time [s]', ylabel='Frequency [Bark]', colorbar_label='Specific Roughness [Asper/Bark]', **kwargs)</code>","text":"<p>Plot Bark-Time-Roughness heatmap.</p> <p>For multi-channel signals, the mean across channels is plotted.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.plot--parameters","title":"Parameters","text":"<p>ax : Axes, optional     Matplotlib axes to plot on. If None, a new figure is created. title : str, optional     Plot title. If None, a default title is used. cmap : str, default=\"viridis\"     Colormap name for the heatmap. vmin, vmax : float, optional     Color scale limits. If None, automatic scaling is used. xlabel : str, default=\"Time [s]\"     Label for the x-axis. ylabel : str, default=\"Frequency [Bark]\"     Label for the y-axis. colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"     Label for the colorbar. **kwargs : Any     Additional keyword arguments passed to pcolormesh.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.plot--returns","title":"Returns","text":"<p>Axes     The matplotlib axes object containing the plot.</p>"},{"location":"api/#wandas.frames.RoughnessFrame.plot--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"motor.wav\") roughness_spec = signal.roughness_dw_spec(overlap=0.5) roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"heatmap\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"viridis\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlabel: str = \"Time [s]\",\n    ylabel: str = \"Frequency [Bark]\",\n    colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n    **kwargs: Any,\n) -&gt; \"Axes\":\n    \"\"\"\n    Plot Bark-Time-Roughness heatmap.\n\n    For multi-channel signals, the mean across channels is plotted.\n\n    Parameters\n    ----------\n    ax : Axes, optional\n        Matplotlib axes to plot on. If None, a new figure is created.\n    title : str, optional\n        Plot title. If None, a default title is used.\n    cmap : str, default=\"viridis\"\n        Colormap name for the heatmap.\n    vmin, vmax : float, optional\n        Color scale limits. If None, automatic scaling is used.\n    xlabel : str, default=\"Time [s]\"\n        Label for the x-axis.\n    ylabel : str, default=\"Frequency [Bark]\"\n        Label for the y-axis.\n    colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n        Label for the colorbar.\n    **kwargs : Any\n        Additional keyword arguments passed to pcolormesh.\n\n    Returns\n    -------\n    Axes\n        The matplotlib axes object containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=(10, 6))\n\n    # Select data to plot (first channel for mono, mean for multi-channel)\n    # self._data is Dask array, self.data is computed NumPy array\n    computed_data = self.compute()\n\n    if computed_data.ndim == 2:\n        # Mono: (47, n_time)\n        data_to_plot = computed_data\n    else:\n        # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n        data_to_plot = computed_data.mean(axis=0)\n\n    # Create heatmap\n    im = ax.pcolormesh(\n        self.time,\n        self.bark_axis,\n        data_to_plot,\n        shading=\"auto\",\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n        **kwargs,\n    )\n\n    # Labels and title\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    if title is None:\n        title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n    ax.set_title(title)\n\n    # Colorbar\n    plt.colorbar(im, ax=ax, label=colorbar_label)\n\n    return ax\n</code></pre>"},{"location":"api/#wandas.frames-modules","title":"Modules","text":""},{"location":"api/#wandas.frames.channel","title":"<code>channel</code>","text":""},{"location":"api/#wandas.frames.channel-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.channel.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.channel.dask_delayed","title":"<code>dask_delayed = dask.delayed</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.channel.da_from_delayed","title":"<code>da_from_delayed = da.from_delayed</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.channel.da_from_array","title":"<code>da_from_array = da.from_array</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.channel.S","title":"<code>S = TypeVar('S', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.channel-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.channel.ChannelFrame","title":"<code>ChannelFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code>, <code>ChannelProcessingMixin</code>, <code>ChannelTransformMixin</code></p> <p>Channel-based data frame for handling audio signals and time series data.</p> <p>This frame represents channel-based data such as audio signals and time series data, with each channel containing data samples in the time domain.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>class ChannelFrame(\n    BaseFrame[NDArrayReal], ChannelProcessingMixin, ChannelTransformMixin\n):\n    \"\"\"Channel-based data frame for handling audio signals and time series data.\n\n    This frame represents channel-based data such as audio signals and time series data,\n    with each channel containing data samples in the time domain.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: DaskArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a ChannelFrame.\n\n        Args:\n            data: Dask array containing channel data.\n            Shape should be (n_channels, n_samples).\n            sampling_rate: The sampling rate of the data in Hz.\n                Must be a positive value.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Raises:\n            ValueError: If data has more than 2 dimensions, or if\n                sampling_rate is not positive.\n        \"\"\"\n        # Validate sampling rate\n        validate_sampling_rate(sampling_rate)\n\n        # Validate and reshape data\n        if data.ndim == 1:\n            data = da.reshape(data, (1, -1))\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Invalid data shape for ChannelFrame\\n\"\n                f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n                f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n                f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n                f\"  (1, n_samples).\\n\"\n                f\"For higher-dimensional data, reshape it before creating\\n\"\n                f\"  ChannelFrame:\\n\"\n                f\"  Example: data.reshape(n_channels, -1)\"\n            )\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"Get time array for the signal.\n\n        The time array represents the start time of each sample, calculated as\n        sample_index / sampling_rate. This provides a uniform, evenly-spaced\n        time axis that is consistent across all frame types in wandas.\n\n        For frames resulting from windowed analysis operations (e.g., FFT,\n        loudness, roughness), each time point corresponds to the start of\n        the analysis window, not the center. This differs from some libraries\n        (e.g., MoSQITo) which use window center times, but does not affect\n        the calculated values themselves.\n\n        Returns:\n            Array of time points in seconds, starting from 0.0.\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; time = signal.time\n            &gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n            &gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n        \"\"\"\n        return np.arange(self.n_samples) / self.sampling_rate\n\n    @property\n    def n_samples(self) -&gt; int:\n        \"\"\"Returns the number of samples.\"\"\"\n        n: int = self._data.shape[-1]\n        return n\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Returns the duration in seconds.\"\"\"\n        return self.n_samples / self.sampling_rate\n\n    @property\n    def rms(self) -&gt; NDArrayReal:\n        \"\"\"Calculate RMS (Root Mean Square) value for each channel.\n\n        Returns:\n            Array of RMS values, one per channel.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; rms_values = cf.rms\n            &gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n            &gt;&gt;&gt; # Select channels with RMS &gt; threshold\n            &gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n        \"\"\"\n        # Convert to a concrete NumPy ndarray to satisfy numpy.mean typing\n        # and to ensure dask arrays are materialized for this operation.\n        rms_values = da.sqrt((self._data**2).mean(axis=1))\n        return np.array(rms_values.compute())\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the ChannelFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - Duration\n        - Number of samples\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.info()\n        Channels: 2\n        Sampling rate: 44100 Hz\n        Duration: 1.0 s\n        Samples: 44100\n        Channel labels: ['ch0', 'ch1']\n        \"\"\"\n        print(\"ChannelFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  Duration: {self.duration:.1f} s\")\n        print(f\"  Samples: {self.n_samples}\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        # Get metadata updates from operation\n        metadata_updates = operation.get_metadata_updates()\n\n        # Update channel labels to reflect the operation\n        display_name = operation.get_display_name()\n        new_channel_metadata = self._relabel_channels(operation_name, display_name)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # Apply metadata updates (including sampling_rate if specified)\n        creation_params: dict[str, Any] = {\n            \"data\": processed_data,\n            \"metadata\": new_metadata,\n            \"operation_history\": new_history,\n            \"channel_metadata\": new_channel_metadata,\n        }\n        creation_params.update(metadata_updates)\n\n        return self._create_new_instance(**creation_params)\n\n    def _binary_op(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal | DaskArray\",\n        op: Callable[[\"DaskArray\", Any], \"DaskArray\"],\n        symbol: str,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Common implementation for binary operations\n        - utilizing dask's lazy evaluation.\n\n        Args:\n            other: Right operand for the operation.\n            op: Function to execute the operation (e.g., lambda a, b: a + b).\n            symbol: Symbolic representation of the operation (e.g., '+').\n\n        Returns:\n            A new channel containing the operation result (lazy execution).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, ChannelFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Perform operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Merge channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Perform operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # Operand display string\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n                previous=self,\n            )\n\n    def add(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal\",\n        snr: float | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add another signal or value to the current signal.\n\n        If SNR is specified, performs addition with consideration for\n        signal-to-noise ratio.\n\n        Args:\n            other: Signal or value to add.\n            snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n                other signal based on this SNR.\n                self is treated as the signal, and other as the noise.\n\n        Returns:\n            A new channel frame containing the addition result (lazy execution).\n        \"\"\"\n        logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n        if isinstance(other, ChannelFrame):\n            # Check if sampling rates match\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n        elif isinstance(other, np.ndarray):\n            other = ChannelFrame.from_numpy(\n                other, self.sampling_rate, label=\"array_data\"\n            )\n        elif isinstance(other, int | float):\n            return self + other\n        else:\n            raise TypeError(\n                \"Addition target with SNR must be a ChannelFrame or \"\n                f\"NumPy array: {type(other)}\"\n            )\n\n        # If SNR is specified, adjust the length of the other signal\n        if other.duration != self.duration:\n            other = other.fix_length(length=self.n_samples)\n\n        if snr is None:\n            return self + other\n        return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n\n    def plot(\n        self,\n        plot_type: str = \"waveform\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the frame data.\n\n        Args:\n            plot_type: Type of plot. Default is \"waveform\".\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot. If None, uses the frame label.\n            overlay: Whether to overlay all channels on a single plot (True)\n                or create separate subplots for each channel (False).\n            xlabel: Label for the x-axis. If None, uses default based on plot type.\n            ylabel: Label for the y-axis. If None, uses default based on plot type.\n            alpha: Transparency level for the plot lines (0.0 to 1.0).\n            xlim: Limits for the x-axis as (min, max) tuple.\n            ylim: Limits for the y-axis as (min, max) tuple.\n            **kwargs: Additional matplotlib Line2D parameters\n                (e.g., color, linewidth, linestyle).\n                These are passed to the underlying matplotlib plot functions.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic plot\n            &gt;&gt;&gt; cf.plot()\n            &gt;&gt;&gt; # Overlay all channels\n            &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n        \"\"\"\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        from ..visualization.plotting import create_operation\n\n        plot_strategy = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def rms_plot(\n        self,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = True,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Generate an RMS plot.\n\n        Args:\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot.\n            overlay: Whether to overlay the plot on the existing axis.\n            Aw: Apply A-weighting.\n            **kwargs: Additional arguments passed to the plot() method.\n                Accepts the same arguments as plot() including xlabel, ylabel,\n                alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic RMS plot\n            &gt;&gt;&gt; cf.rms_plot()\n            &gt;&gt;&gt; # With A-weighting\n            &gt;&gt;&gt; cf.rms_plot(Aw=True)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n        \"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n        rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n        return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n\n    def describe(\n        self,\n        normalize: bool = True,\n        is_close: bool = True,\n        *,\n        fmin: float = 0,\n        fmax: float | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        waveform: dict[str, Any] | None = None,\n        spectral: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Display visual and audio representation of the frame.\n\n        This method creates a comprehensive visualization with three plots:\n        1. Time-domain waveform (top)\n        2. Spectrogram (bottom-left)\n        3. Frequency spectrum via Welch method (bottom-right)\n\n        Args:\n            normalize: Whether to normalize the audio data for playback.\n                Default: True\n            is_close: Whether to close the figure after displaying.\n                Default: True\n            fmin: Minimum frequency to display in the spectrogram (Hz).\n                Default: 0\n            fmax: Maximum frequency to display in the spectrogram (Hz).\n                Default: Nyquist frequency (sampling_rate / 2)\n            cmap: Colormap for the spectrogram.\n                Default: 'jet'\n            vmin: Minimum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            vmax: Maximum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            xlim: Time axis limits (seconds) for all time-based plots.\n                Format: (start_time, end_time)\n            ylim: Frequency axis limits (Hz) for frequency-based plots.\n                Format: (min_freq, max_freq)\n            Aw: Apply A-weighting to the frequency analysis.\n                Default: False\n            waveform: Additional configuration dict for waveform subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            spectral: Additional configuration dict for spectral subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            **kwargs: Deprecated parameters for backward compatibility only.\n                - axis_config: Old configuration format (use waveform/spectral instead)\n                - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic usage\n            &gt;&gt;&gt; cf.describe()\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom frequency range\n            &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom color scale\n            &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # A-weighted analysis\n            &gt;&gt;&gt; cf.describe(Aw=True)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom time range\n            &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom waveform subplot settings\n            &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n        \"\"\"\n        # Prepare kwargs with explicit parameters\n        plot_kwargs: dict[str, Any] = {\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"xlim\": xlim,\n            \"ylim\": ylim,\n            \"Aw\": Aw,\n            \"waveform\": waveform or {},\n            \"spectral\": spectral or {},\n        }\n        # Merge with additional kwargs\n        plot_kwargs.update(kwargs)\n\n        if \"axis_config\" in plot_kwargs:\n            logger.warning(\n                \"axis_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            axis_config = plot_kwargs[\"axis_config\"]\n            if \"time_plot\" in axis_config:\n                plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n            if \"freq_plot\" in axis_config:\n                if \"xlim\" in axis_config[\"freq_plot\"]:\n                    vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                    plot_kwargs[\"vmin\"] = vlim[0]\n                    plot_kwargs[\"vmax\"] = vlim[1]\n                if \"ylim\" in axis_config[\"freq_plot\"]:\n                    ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                    plot_kwargs[\"ylim\"] = ylim_config\n\n        if \"cbar_config\" in plot_kwargs:\n            logger.warning(\n                \"cbar_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            cbar_config = plot_kwargs[\"cbar_config\"]\n            if \"vmin\" in cbar_config:\n                plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n            if \"vmax\" in cbar_config:\n                plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n        for ch in self:\n            ax: Axes\n            _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n            if isinstance(_ax, Iterator):\n                ax = next(iter(_ax))\n            elif isinstance(_ax, Axes):\n                ax = _ax\n            else:\n                raise TypeError(\n                    f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n                )\n            # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n            display(ax.figure)\n            if is_close:\n                plt.close(getattr(ax, \"figure\", None))\n            display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayReal,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        ch_labels: list[str] | None = None,\n        ch_units: list[str] | str | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing channel data.\n            sampling_rate: The sampling rate in Hz.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            ch_labels: Labels for each channel.\n            ch_units: Units for each channel.\n\n        Returns:\n            A new ChannelFrame containing the NumPy data.\n        \"\"\"\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n\n        # Convert NumPy array to dask array\n        dask_data = da_from_array(data)\n        cf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=label or \"numpy_data\",\n        )\n        if metadata is not None:\n            cf.metadata = metadata\n        if ch_labels is not None:\n            if len(ch_labels) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel labels does not match the number of channels\"\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        if ch_units is not None:\n            if isinstance(ch_units, str):\n                ch_units = [ch_units] * cf.n_channels\n\n            if len(ch_units) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel units does not match the number of channels\"\n                )\n            for i in range(len(ch_units)):\n                cf._channel_metadata[i].unit = ch_units[i]\n\n        return cf\n\n    @classmethod\n    def from_ndarray(\n        cls,\n        array: NDArrayReal,\n        sampling_rate: float,\n        labels: list[str] | None = None,\n        unit: list[str] | str | None = None,\n        frame_label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        This method is deprecated. Use from_numpy instead.\n\n        Args:\n            array: Signal data. Each row corresponds to a channel.\n            sampling_rate: Sampling rate (Hz).\n            labels: Labels for each channel.\n            unit: Unit of the signal.\n            frame_label: Label for the frame.\n            metadata: Optional metadata dictionary.\n\n        Returns:\n            A new ChannelFrame containing the data.\n        \"\"\"\n        # Redirect to from_numpy for compatibility\n        # However, from_ndarray is deprecated\n        logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n        return cls.from_numpy(\n            data=array,\n            sampling_rate=sampling_rate,\n            label=frame_label,\n            metadata=metadata,\n            ch_labels=labels,\n            ch_units=unit,\n        )\n\n    @classmethod\n    def from_file(\n        cls,\n        path: str | Path,\n        channel: int | list[int] | None = None,\n        start: float | None = None,\n        end: float | None = None,\n        chunk_size: int | None = None,\n        ch_labels: list[str] | None = None,\n        # CSV-specific parameters\n        time_column: int | str = 0,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from an audio file.\n\n        Args:\n            path: Path to the audio file.\n            channel: Channel(s) to load.\n            start: Start time in seconds.\n            end: End time in seconds.\n            chunk_size: Chunk size for processing.\n                Specifies the splitting size for lazy processing.\n            ch_labels: Labels for each channel.\n            time_column: For CSV files, index or name of the time column.\n                Default is 0 (first column).\n            delimiter: For CSV files, delimiter character. Default is \",\".\n            header: For CSV files, row number to use as header.\n                Default is 0 (first row). Set to None if no header.\n\n        Returns:\n            A new ChannelFrame containing the loaded audio data.\n\n        Raises:\n            ValueError: If channel specification is invalid.\n            TypeError: If channel parameter type is invalid.\n            FileNotFoundError: If the file doesn't exist at the specified path.\n                Error message includes absolute path, current directory, and\n                troubleshooting suggestions.\n\n        Examples:\n            &gt;&gt;&gt; # Load WAV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n            &gt;&gt;&gt; # Load specific channels\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n            &gt;&gt;&gt; # Load CSV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\n            ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n            ... )\n        \"\"\"\n        from .channel import ChannelFrame\n\n        path = Path(path)\n        if not path.exists():\n            raise FileNotFoundError(\n                f\"Audio file not found\\n\"\n                f\"  Path: {path.absolute()}\\n\"\n                f\"  Current directory: {Path.cwd()}\\n\"\n                f\"Please check:\\n\"\n                f\"  - File path is correct\\n\"\n                f\"  - File exists at the specified location\\n\"\n                f\"  - You have read permissions for the file\"\n            )\n\n        # Get file reader\n        reader = get_file_reader(path)\n\n        # Build kwargs for reader\n        reader_kwargs: dict[str, Any] = {}\n        if path.suffix.lower() == \".csv\":\n            reader_kwargs[\"time_column\"] = time_column\n            reader_kwargs[\"delimiter\"] = delimiter\n            if header is not None:\n                reader_kwargs[\"header\"] = header\n\n        # Get file info\n        info = reader.get_file_info(path, **reader_kwargs)\n        sr = info[\"samplerate\"]\n        n_channels = info[\"channels\"]\n        n_frames = info[\"frames\"]\n        ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n        logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n        # Channel selection processing\n        all_channels = list(range(n_channels))\n\n        if channel is None:\n            channels_to_load = all_channels\n            logger.debug(f\"Will load all channels: {channels_to_load}\")\n        elif isinstance(channel, int):\n            if channel &lt; 0 or channel &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n            channels_to_load = [channel]\n            logger.debug(f\"Will load single channel: {channel}\")\n        elif isinstance(channel, list | tuple):\n            for ch in channel:\n                if ch &lt; 0 or ch &gt;= n_channels:\n                    raise ValueError(\n                        f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                    )\n            channels_to_load = list(channel)\n            logger.debug(f\"Will load specific channels: {channels_to_load}\")\n        else:\n            raise TypeError(\"channel must be int, list, or None\")\n\n        # Index calculation\n        start_idx = 0 if start is None else max(0, int(start * sr))\n        end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n        frames_to_read = end_idx - start_idx\n\n        logger.debug(\n            f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n            f\"start_idx={start_idx}, end_idx={end_idx}\"\n        )\n\n        # Settings for lazy loading\n        expected_shape = (len(channels_to_load), frames_to_read)\n\n        # Define the loading function using the file reader\n        def _load_audio() -&gt; NDArrayReal:\n            logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n            # Use the reader to get audio data with parameters\n            out = reader.get_data(\n                path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n            )\n            if not isinstance(out, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n            return out\n\n        logger.debug(\n            f\"Creating delayed dask task with expected shape: {expected_shape}\"\n        )\n\n        # Create delayed operation\n        delayed_data = dask_delayed(_load_audio)()\n        logger.debug(\"Wrapping delayed function in dask array\")\n\n        # Create dask array from delayed computation\n        dask_array = da_from_delayed(\n            delayed_data, shape=expected_shape, dtype=np.float32\n        )\n\n        if chunk_size is not None:\n            if chunk_size &lt;= 0:\n                raise ValueError(\"Chunk size must be a positive integer\")\n            logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n            dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n        logger.debug(\n            \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n        )\n\n        cf = ChannelFrame(\n            data=dask_array,\n            sampling_rate=sr,\n            label=path.stem,\n            metadata={\n                \"filename\": str(path),\n            },\n        )\n        if ch_labels is not None:\n            if len(ch_labels) != len(cf):\n                raise ValueError(\n                    \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        return cf\n\n    @classmethod\n    def read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a WAV file.\n\n        Args:\n            filename: Path to the WAV file.\n            labels: Labels to set for each channel.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(filename, ch_labels=labels)\n        return cf\n\n    @classmethod\n    def read_csv(\n        cls,\n        filename: str,\n        time_column: int | str = 0,\n        labels: list[str] | None = None,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a CSV file.\n\n        Args:\n            filename: Path to the CSV file.\n            time_column: Index or name of the time column.\n            labels: Labels to set for each channel.\n            delimiter: Delimiter character.\n            header: Row number to use as header.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n\n        Examples:\n            &gt;&gt;&gt; # Read CSV with default settings\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n            &gt;&gt;&gt; # Read CSV with custom delimiter\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n            &gt;&gt;&gt; # Read CSV without header\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(\n            filename,\n            ch_labels=labels,\n            time_column=time_column,\n            delimiter=delimiter,\n            header=header,\n        )\n        return cf\n\n    def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n        \"\"\"Save the audio data to a WAV file.\n\n        Args:\n            path: Path to save the file.\n            format: File format. If None, determined from file extension.\n        \"\"\"\n        from wandas.io.wav_io import write_wav\n\n        write_wav(str(path), self, format=format)\n\n    def save(\n        self,\n        path: str | Path,\n        *,\n        format: str = \"hdf5\",\n        compress: str | None = \"gzip\",\n        overwrite: bool = False,\n        dtype: str | np.dtype[Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n        This saves the complete frame including all channel data and metadata\n        in a format that can be loaded back with full fidelity.\n\n        Args:\n            path: Path to save the file. '.wdf' extension will be added if not present.\n            format: Format to use (currently only 'hdf5' is supported)\n            compress: Compression method ('gzip' by default, None for no compression)\n            overwrite: Whether to overwrite existing file\n            dtype: Optional data type conversion before saving (e.g. 'float32')\n\n        Raises:\n            FileExistsError: If the file exists and overwrite=False.\n            NotImplementedError: For unsupported formats.\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import save as wdf_save\n\n        wdf_save(\n            self,\n            path,\n            format=format,\n            compress=compress,\n            overwrite=overwrite,\n            dtype=dtype,\n        )\n\n    @classmethod\n    def load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n        \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n        This loads data saved with the save() method, preserving all channel data,\n        metadata, labels, and units.\n\n        Args:\n            path: Path to the WDF file\n            format: Format of the file (currently only 'hdf5' is supported)\n\n        Returns:\n            A new ChannelFrame with all data and metadata loaded\n\n        Raises:\n            FileNotFoundError: If the file doesn't exist\n            NotImplementedError: For unsupported formats\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import load as wdf_load\n\n        return wdf_load(path, format=format)\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"Provide additional initialization arguments required for ChannelFrame.\"\"\"\n        return {}\n\n    def add_channel(\n        self,\n        data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n        label: str | None = None,\n        align: str = \"strict\",\n        suffix_on_dup: str | None = None,\n        inplace: bool = False,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add a new channel to the frame.\n\n        Args:\n            data: Data to add as a new channel. Can be:\n                - numpy array (1D or 2D)\n                - dask array (1D or 2D)\n                - ChannelFrame (channels will be added)\n            label: Label for the new channel. If None, generates a default label.\n                Ignored when data is a ChannelFrame (uses its channel labels).\n            align: How to handle length mismatches:\n                - \"strict\": Raise error if lengths don't match\n                - \"pad\": Pad shorter data with zeros\n                - \"truncate\": Truncate longer data to match\n            suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n            inplace: If True, modifies the frame in place.\n                Otherwise returns a new frame.\n\n        Returns:\n            Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n        Raises:\n            ValueError: If data length doesn't match and align=\"strict\",\n                or if label is duplicate and suffix_on_dup is None.\n            TypeError: If data type is not supported.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Add a numpy array as a new channel\n            &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n            &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n            &gt;&gt;&gt; # Add another ChannelFrame's channels\n            &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n            &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n        \"\"\"\n        # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n        if isinstance(data, ChannelFrame):\n            if self.sampling_rate != data.sampling_rate:\n                raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n            if data.n_samples != self.n_samples:\n                if align == \"pad\":\n                    pad_len = self.n_samples - data.n_samples\n                    arr = data._data\n                    if pad_len &gt; 0:\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                    else:\n                        arr = arr[:, : self.n_samples]\n                elif align == \"truncate\":\n                    arr = data._data[:, : self.n_samples]\n                    if arr.shape[1] &lt; self.n_samples:\n                        pad_len = self.n_samples - arr.shape[1]\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                else:\n                    raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n            else:\n                arr = data._data\n            labels = [ch.label for ch in self._channel_metadata]\n            new_labels = []\n            new_metadata_list = []\n            for chmeta in data._channel_metadata:\n                new_label = chmeta.label\n                if new_label in labels or new_label in new_labels:\n                    if suffix_on_dup:\n                        new_label += suffix_on_dup\n                    else:\n                        raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n                new_labels.append(new_label)\n                # Copy the entire channel_metadata and update only the label\n                new_ch_meta = chmeta.model_copy(deep=True)\n                new_ch_meta.label = new_label\n                new_metadata_list.append(new_ch_meta)\n            new_data = concatenate([self._data, arr], axis=0)\n\n            new_chmeta = self._channel_metadata + new_metadata_list\n            if inplace:\n                self._data = new_data\n                self._channel_metadata = new_chmeta\n                return self\n            else:\n                return ChannelFrame(\n                    data=new_data,\n                    sampling_rate=self.sampling_rate,\n                    label=self.label,\n                    metadata=self.metadata,\n                    operation_history=self.operation_history,\n                    channel_metadata=new_chmeta,\n                    previous=self,\n                )\n        if isinstance(data, np.ndarray):\n            arr = from_array(data.reshape(1, -1))\n        elif isinstance(data, DaskArray):\n            arr = data[None, ...] if data.ndim == 1 else data\n            if arr.shape[0] != 1:\n                arr = arr.reshape((1, -1))\n        else:\n            raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n        if arr.shape[1] != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - arr.shape[1]\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = arr[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        labels = [ch.label for ch in self._channel_metadata]\n        new_label = label or f\"ch{len(labels)}\"\n        if new_label in labels:\n            if suffix_on_dup:\n                new_label += suffix_on_dup\n            else:\n                raise ValueError(\"label\u91cd\u8907\")\n        new_data = concatenate([self._data, arr], axis=0)\n        from ..core.metadata import ChannelMetadata\n\n        new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n        if isinstance(key, int):\n            if not (0 &lt;= key &lt; self.n_channels):\n                raise IndexError(f\"index {key} out of range\")\n            idx = key\n        else:\n            labels = [ch.label for ch in self._channel_metadata]\n            if key not in labels:\n                raise KeyError(f\"label {key} not found\")\n            idx = labels.index(key)\n        new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n        new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get time index for DataFrame.\"\"\"\n        return pd.Index(self.time, name=\"time\")\n</code></pre> Attributes\u00b6 <code></code> <code>time</code> <code>property</code> \u00b6 <p>Get time array for the signal.</p> <p>The time array represents the start time of each sample, calculated as sample_index / sampling_rate. This provides a uniform, evenly-spaced time axis that is consistent across all frame types in wandas.</p> <p>For frames resulting from windowed analysis operations (e.g., FFT, loudness, roughness), each time point corresponds to the start of the analysis window, not the center. This differs from some libraries (e.g., MoSQITo) which use window center times, but does not affect the calculated values themselves.</p> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Array of time points in seconds, starting from 0.0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; time = signal.time\n&gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n&gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n</code></pre> <code></code> <code>n_samples</code> <code>property</code> \u00b6 <p>Returns the number of samples.</p> <code></code> <code>duration</code> <code>property</code> \u00b6 <p>Returns the duration in seconds.</p> <code></code> <code>rms</code> <code>property</code> \u00b6 <p>Calculate RMS (Root Mean Square) value for each channel.</p> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Array of RMS values, one per channel.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; rms_values = cf.rms\n&gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n&gt;&gt;&gt; # Select channels with RMS &gt; threshold\n&gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n</code></pre> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 <p>Initialize a ChannelFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Array</code> <p>Dask array containing channel data.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate of the data in Hz. Must be a positive value.</p> required <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data has more than 2 dimensions, or if sampling_rate is not positive.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def __init__(\n    self,\n    data: DaskArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a ChannelFrame.\n\n    Args:\n        data: Dask array containing channel data.\n        Shape should be (n_channels, n_samples).\n        sampling_rate: The sampling rate of the data in Hz.\n            Must be a positive value.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Raises:\n        ValueError: If data has more than 2 dimensions, or if\n            sampling_rate is not positive.\n    \"\"\"\n    # Validate sampling rate\n    validate_sampling_rate(sampling_rate)\n\n    # Validate and reshape data\n    if data.ndim == 1:\n        data = da.reshape(data, (1, -1))\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Invalid data shape for ChannelFrame\\n\"\n            f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n            f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n            f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n            f\"  (1, n_samples).\\n\"\n            f\"For higher-dimensional data, reshape it before creating\\n\"\n            f\"  ChannelFrame:\\n\"\n            f\"  Example: data.reshape(n_channels, -1)\"\n        )\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>info()</code> \u00b6 <p>Display comprehensive information about the ChannelFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - Duration - Number of samples - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p> <code></code> <code>add(other, snr=None)</code> \u00b6 <p>Add another signal or value to the current signal.</p> <p>If SNR is specified, performs addition with consideration for signal-to-noise ratio.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ChannelFrame | int | float | NDArrayReal</code> <p>Signal or value to add.</p> required <code>snr</code> <code>float | None</code> <p>Signal-to-noise ratio (dB). If specified, adjusts the scale of the other signal based on this SNR. self is treated as the signal, and other as the noise.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new channel frame containing the addition result (lazy execution).</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def add(\n    self,\n    other: \"ChannelFrame | int | float | NDArrayReal\",\n    snr: float | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add another signal or value to the current signal.\n\n    If SNR is specified, performs addition with consideration for\n    signal-to-noise ratio.\n\n    Args:\n        other: Signal or value to add.\n        snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n            other signal based on this SNR.\n            self is treated as the signal, and other as the noise.\n\n    Returns:\n        A new channel frame containing the addition result (lazy execution).\n    \"\"\"\n    logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n    if isinstance(other, ChannelFrame):\n        # Check if sampling rates match\n        if self.sampling_rate != other.sampling_rate:\n            raise ValueError(\n                \"Sampling rates do not match. Cannot perform operation.\"\n            )\n\n    elif isinstance(other, np.ndarray):\n        other = ChannelFrame.from_numpy(\n            other, self.sampling_rate, label=\"array_data\"\n        )\n    elif isinstance(other, int | float):\n        return self + other\n    else:\n        raise TypeError(\n            \"Addition target with SNR must be a ChannelFrame or \"\n            f\"NumPy array: {type(other)}\"\n        )\n\n    # If SNR is specified, adjust the length of the other signal\n    if other.duration != self.duration:\n        other = other.fix_length(length=self.n_samples)\n\n    if snr is None:\n        return self + other\n    return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n</code></pre> <code></code> <code>plot(plot_type='waveform', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, **kwargs)</code> \u00b6 <p>Plot the frame data.</p> <p>Parameters:</p> Name Type Description Default <code>plot_type</code> <code>str</code> <p>Type of plot. Default is \"waveform\".</p> <code>'waveform'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot. If None, uses the frame label.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay all channels on a single plot (True) or create separate subplots for each channel (False).</p> <code>False</code> <code>xlabel</code> <code>str | None</code> <p>Label for the x-axis. If None, uses default based on plot type.</p> <code>None</code> <code>ylabel</code> <code>str | None</code> <p>Label for the y-axis. If None, uses default based on plot type.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level for the plot lines (0.0 to 1.0).</p> <code>1.0</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Limits for the x-axis as (min, max) tuple.</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Limits for the y-axis as (min, max) tuple.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional matplotlib Line2D parameters (e.g., color, linewidth, linestyle). These are passed to the underlying matplotlib plot functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic plot\n&gt;&gt;&gt; cf.plot()\n&gt;&gt;&gt; # Overlay all channels\n&gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"waveform\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the frame data.\n\n    Args:\n        plot_type: Type of plot. Default is \"waveform\".\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot. If None, uses the frame label.\n        overlay: Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel: Label for the x-axis. If None, uses default based on plot type.\n        ylabel: Label for the y-axis. If None, uses default based on plot type.\n        alpha: Transparency level for the plot lines (0.0 to 1.0).\n        xlim: Limits for the x-axis as (min, max) tuple.\n        ylim: Limits for the y-axis as (min, max) tuple.\n        **kwargs: Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n            These are passed to the underlying matplotlib plot functions.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic plot\n        &gt;&gt;&gt; cf.plot()\n        &gt;&gt;&gt; # Overlay all channels\n        &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n    \"\"\"\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    from ..visualization.plotting import create_operation\n\n    plot_strategy = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre> <code></code> <code>rms_plot(ax=None, title=None, overlay=True, Aw=False, **kwargs)</code> \u00b6 <p>Generate an RMS plot.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay the plot on the existing axis.</p> <code>True</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the plot() method. Accepts the same arguments as plot() including xlabel, ylabel, alpha, xlim, ylim, and matplotlib Line2D parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic RMS plot\n&gt;&gt;&gt; cf.rms_plot()\n&gt;&gt;&gt; # With A-weighting\n&gt;&gt;&gt; cf.rms_plot(Aw=True)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def rms_plot(\n    self,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = True,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Generate an RMS plot.\n\n    Args:\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot.\n        overlay: Whether to overlay the plot on the existing axis.\n        Aw: Apply A-weighting.\n        **kwargs: Additional arguments passed to the plot() method.\n            Accepts the same arguments as plot() including xlabel, ylabel,\n            alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic RMS plot\n        &gt;&gt;&gt; cf.rms_plot()\n        &gt;&gt;&gt; # With A-weighting\n        &gt;&gt;&gt; cf.rms_plot(Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n    \"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n    rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n    return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n</code></pre> <code></code> <code>describe(normalize=True, is_close=True, *, fmin=0, fmax=None, cmap='jet', vmin=None, vmax=None, xlim=None, ylim=None, Aw=False, waveform=None, spectral=None, **kwargs)</code> \u00b6 <p>Display visual and audio representation of the frame.</p> <p>This method creates a comprehensive visualization with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>Parameters:</p> Name Type Description Default <code>normalize</code> <code>bool</code> <p>Whether to normalize the audio data for playback. Default: True</p> <code>True</code> <code>is_close</code> <code>bool</code> <p>Whether to close the figure after displaying. Default: True</p> <code>True</code> <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>0</code> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency (sampling_rate / 2)</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>'jet'</code> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots. Format: (start_time, end_time)</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots. Format: (min_freq, max_freq)</p> <code>None</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>False</code> <code>waveform</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for waveform subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>spectral</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for spectral subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Deprecated parameters for backward compatibility only. - axis_config: Old configuration format (use waveform/spectral instead) - cbar_config: Old colorbar configuration (use vmin/vmax instead)</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom waveform subplot settings\n&gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def describe(\n    self,\n    normalize: bool = True,\n    is_close: bool = True,\n    *,\n    fmin: float = 0,\n    fmax: float | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    waveform: dict[str, Any] | None = None,\n    spectral: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Display visual and audio representation of the frame.\n\n    This method creates a comprehensive visualization with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Args:\n        normalize: Whether to normalize the audio data for playback.\n            Default: True\n        is_close: Whether to close the figure after displaying.\n            Default: True\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency (sampling_rate / 2)\n        cmap: Colormap for the spectrogram.\n            Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n            Format: (start_time, end_time)\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n            Format: (min_freq, max_freq)\n        Aw: Apply A-weighting to the frequency analysis.\n            Default: False\n        waveform: Additional configuration dict for waveform subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        spectral: Additional configuration dict for spectral subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        **kwargs: Deprecated parameters for backward compatibility only.\n            - axis_config: Old configuration format (use waveform/spectral instead)\n            - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom waveform subplot settings\n        &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n    \"\"\"\n    # Prepare kwargs with explicit parameters\n    plot_kwargs: dict[str, Any] = {\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"xlim\": xlim,\n        \"ylim\": ylim,\n        \"Aw\": Aw,\n        \"waveform\": waveform or {},\n        \"spectral\": spectral or {},\n    }\n    # Merge with additional kwargs\n    plot_kwargs.update(kwargs)\n\n    if \"axis_config\" in plot_kwargs:\n        logger.warning(\n            \"axis_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        axis_config = plot_kwargs[\"axis_config\"]\n        if \"time_plot\" in axis_config:\n            plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n        if \"freq_plot\" in axis_config:\n            if \"xlim\" in axis_config[\"freq_plot\"]:\n                vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                plot_kwargs[\"vmin\"] = vlim[0]\n                plot_kwargs[\"vmax\"] = vlim[1]\n            if \"ylim\" in axis_config[\"freq_plot\"]:\n                ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                plot_kwargs[\"ylim\"] = ylim_config\n\n    if \"cbar_config\" in plot_kwargs:\n        logger.warning(\n            \"cbar_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        cbar_config = plot_kwargs[\"cbar_config\"]\n        if \"vmin\" in cbar_config:\n            plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n        if \"vmax\" in cbar_config:\n            plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n    for ch in self:\n        ax: Axes\n        _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n        if isinstance(_ax, Iterator):\n            ax = next(iter(_ax))\n        elif isinstance(_ax, Axes):\n            ax = _ax\n        else:\n            raise TypeError(\n                f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n            )\n        # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n        display(ax.figure)\n        if is_close:\n            plt.close(getattr(ax, \"figure\", None))\n        display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n</code></pre> <code></code> <code>from_numpy(data, sampling_rate, label=None, metadata=None, ch_labels=None, ch_units=None)</code> <code>classmethod</code> \u00b6 <p>Create a ChannelFrame from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayReal</code> <p>NumPy array containing channel data.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> required <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>ch_units</code> <code>list[str] | str | None</code> <p>Units for each channel.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the NumPy data.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayReal,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    ch_labels: list[str] | None = None,\n    ch_units: list[str] | str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing channel data.\n        sampling_rate: The sampling rate in Hz.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        ch_labels: Labels for each channel.\n        ch_units: Units for each channel.\n\n    Returns:\n        A new ChannelFrame containing the NumPy data.\n    \"\"\"\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n\n    # Convert NumPy array to dask array\n    dask_data = da_from_array(data)\n    cf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        label=label or \"numpy_data\",\n    )\n    if metadata is not None:\n        cf.metadata = metadata\n    if ch_labels is not None:\n        if len(ch_labels) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel labels does not match the number of channels\"\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    if ch_units is not None:\n        if isinstance(ch_units, str):\n            ch_units = [ch_units] * cf.n_channels\n\n        if len(ch_units) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel units does not match the number of channels\"\n            )\n        for i in range(len(ch_units)):\n            cf._channel_metadata[i].unit = ch_units[i]\n\n    return cf\n</code></pre> <code></code> <code>from_ndarray(array, sampling_rate, labels=None, unit=None, frame_label=None, metadata=None)</code> <code>classmethod</code> \u00b6 <p>Create a ChannelFrame from a NumPy array.</p> <p>This method is deprecated. Use from_numpy instead.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArrayReal</code> <p>Signal data. Each row corresponds to a channel.</p> required <code>sampling_rate</code> <code>float</code> <p>Sampling rate (Hz).</p> required <code>labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>unit</code> <code>list[str] | str | None</code> <p>Unit of the signal.</p> <code>None</code> <code>frame_label</code> <code>str | None</code> <p>Label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_ndarray(\n    cls,\n    array: NDArrayReal,\n    sampling_rate: float,\n    labels: list[str] | None = None,\n    unit: list[str] | str | None = None,\n    frame_label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    This method is deprecated. Use from_numpy instead.\n\n    Args:\n        array: Signal data. Each row corresponds to a channel.\n        sampling_rate: Sampling rate (Hz).\n        labels: Labels for each channel.\n        unit: Unit of the signal.\n        frame_label: Label for the frame.\n        metadata: Optional metadata dictionary.\n\n    Returns:\n        A new ChannelFrame containing the data.\n    \"\"\"\n    # Redirect to from_numpy for compatibility\n    # However, from_ndarray is deprecated\n    logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n    return cls.from_numpy(\n        data=array,\n        sampling_rate=sampling_rate,\n        label=frame_label,\n        metadata=metadata,\n        ch_labels=labels,\n        ch_units=unit,\n    )\n</code></pre> <code></code> <code>from_file(path, channel=None, start=None, end=None, chunk_size=None, ch_labels=None, time_column=0, delimiter=',', header=0)</code> <code>classmethod</code> \u00b6 <p>Create a ChannelFrame from an audio file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the audio file.</p> required <code>channel</code> <code>int | list[int] | None</code> <p>Channel(s) to load.</p> <code>None</code> <code>start</code> <code>float | None</code> <p>Start time in seconds.</p> <code>None</code> <code>end</code> <code>float | None</code> <p>End time in seconds.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Chunk size for processing. Specifies the splitting size for lazy processing.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>time_column</code> <code>int | str</code> <p>For CSV files, index or name of the time column. Default is 0 (first column).</p> <code>0</code> <code>delimiter</code> <code>str</code> <p>For CSV files, delimiter character. Default is \",\".</p> <code>','</code> <code>header</code> <code>int | None</code> <p>For CSV files, row number to use as header. Default is 0 (first row). Set to None if no header.</p> <code>0</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the loaded audio data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If channel specification is invalid.</p> <code>TypeError</code> <p>If channel parameter type is invalid.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist at the specified path. Error message includes absolute path, current directory, and troubleshooting suggestions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load WAV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n&gt;&gt;&gt; # Load specific channels\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n&gt;&gt;&gt; # Load CSV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\n...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n... )\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    channel: int | list[int] | None = None,\n    start: float | None = None,\n    end: float | None = None,\n    chunk_size: int | None = None,\n    ch_labels: list[str] | None = None,\n    # CSV-specific parameters\n    time_column: int | str = 0,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from an audio file.\n\n    Args:\n        path: Path to the audio file.\n        channel: Channel(s) to load.\n        start: Start time in seconds.\n        end: End time in seconds.\n        chunk_size: Chunk size for processing.\n            Specifies the splitting size for lazy processing.\n        ch_labels: Labels for each channel.\n        time_column: For CSV files, index or name of the time column.\n            Default is 0 (first column).\n        delimiter: For CSV files, delimiter character. Default is \",\".\n        header: For CSV files, row number to use as header.\n            Default is 0 (first row). Set to None if no header.\n\n    Returns:\n        A new ChannelFrame containing the loaded audio data.\n\n    Raises:\n        ValueError: If channel specification is invalid.\n        TypeError: If channel parameter type is invalid.\n        FileNotFoundError: If the file doesn't exist at the specified path.\n            Error message includes absolute path, current directory, and\n            troubleshooting suggestions.\n\n    Examples:\n        &gt;&gt;&gt; # Load WAV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n        &gt;&gt;&gt; # Load specific channels\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n        &gt;&gt;&gt; # Load CSV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\n        ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n        ... )\n    \"\"\"\n    from .channel import ChannelFrame\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Audio file not found\\n\"\n            f\"  Path: {path.absolute()}\\n\"\n            f\"  Current directory: {Path.cwd()}\\n\"\n            f\"Please check:\\n\"\n            f\"  - File path is correct\\n\"\n            f\"  - File exists at the specified location\\n\"\n            f\"  - You have read permissions for the file\"\n        )\n\n    # Get file reader\n    reader = get_file_reader(path)\n\n    # Build kwargs for reader\n    reader_kwargs: dict[str, Any] = {}\n    if path.suffix.lower() == \".csv\":\n        reader_kwargs[\"time_column\"] = time_column\n        reader_kwargs[\"delimiter\"] = delimiter\n        if header is not None:\n            reader_kwargs[\"header\"] = header\n\n    # Get file info\n    info = reader.get_file_info(path, **reader_kwargs)\n    sr = info[\"samplerate\"]\n    n_channels = info[\"channels\"]\n    n_frames = info[\"frames\"]\n    ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n    logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n    # Channel selection processing\n    all_channels = list(range(n_channels))\n\n    if channel is None:\n        channels_to_load = all_channels\n        logger.debug(f\"Will load all channels: {channels_to_load}\")\n    elif isinstance(channel, int):\n        if channel &lt; 0 or channel &gt;= n_channels:\n            raise ValueError(\n                f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n            )\n        channels_to_load = [channel]\n        logger.debug(f\"Will load single channel: {channel}\")\n    elif isinstance(channel, list | tuple):\n        for ch in channel:\n            if ch &lt; 0 or ch &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n        channels_to_load = list(channel)\n        logger.debug(f\"Will load specific channels: {channels_to_load}\")\n    else:\n        raise TypeError(\"channel must be int, list, or None\")\n\n    # Index calculation\n    start_idx = 0 if start is None else max(0, int(start * sr))\n    end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n    frames_to_read = end_idx - start_idx\n\n    logger.debug(\n        f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n        f\"start_idx={start_idx}, end_idx={end_idx}\"\n    )\n\n    # Settings for lazy loading\n    expected_shape = (len(channels_to_load), frames_to_read)\n\n    # Define the loading function using the file reader\n    def _load_audio() -&gt; NDArrayReal:\n        logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n        # Use the reader to get audio data with parameters\n        out = reader.get_data(\n            path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n        )\n        if not isinstance(out, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n        return out\n\n    logger.debug(\n        f\"Creating delayed dask task with expected shape: {expected_shape}\"\n    )\n\n    # Create delayed operation\n    delayed_data = dask_delayed(_load_audio)()\n    logger.debug(\"Wrapping delayed function in dask array\")\n\n    # Create dask array from delayed computation\n    dask_array = da_from_delayed(\n        delayed_data, shape=expected_shape, dtype=np.float32\n    )\n\n    if chunk_size is not None:\n        if chunk_size &lt;= 0:\n            raise ValueError(\"Chunk size must be a positive integer\")\n        logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n        dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n    logger.debug(\n        \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n    )\n\n    cf = ChannelFrame(\n        data=dask_array,\n        sampling_rate=sr,\n        label=path.stem,\n        metadata={\n            \"filename\": str(path),\n        },\n    )\n    if ch_labels is not None:\n        if len(ch_labels) != len(cf):\n            raise ValueError(\n                \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    return cf\n</code></pre> <code></code> <code>read_wav(filename, labels=None)</code> <code>classmethod</code> \u00b6 <p>Utility method to read a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the WAV file.</p> required <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a WAV file.\n\n    Args:\n        filename: Path to the WAV file.\n        labels: Labels to set for each channel.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(filename, ch_labels=labels)\n    return cf\n</code></pre> <code></code> <code>read_csv(filename, time_column=0, labels=None, delimiter=',', header=0)</code> <code>classmethod</code> \u00b6 <p>Utility method to read a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> required <code>time_column</code> <code>int | str</code> <p>Index or name of the time column.</p> <code>0</code> <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>Delimiter character.</p> <code>','</code> <code>header</code> <code>int | None</code> <p>Row number to use as header.</p> <code>0</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Read CSV with default settings\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n&gt;&gt;&gt; # Read CSV with custom delimiter\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n&gt;&gt;&gt; # Read CSV without header\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_csv(\n    cls,\n    filename: str,\n    time_column: int | str = 0,\n    labels: list[str] | None = None,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a CSV file.\n\n    Args:\n        filename: Path to the CSV file.\n        time_column: Index or name of the time column.\n        labels: Labels to set for each channel.\n        delimiter: Delimiter character.\n        header: Row number to use as header.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n\n    Examples:\n        &gt;&gt;&gt; # Read CSV with default settings\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n        &gt;&gt;&gt; # Read CSV with custom delimiter\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n        &gt;&gt;&gt; # Read CSV without header\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(\n        filename,\n        ch_labels=labels,\n        time_column=time_column,\n        delimiter=delimiter,\n        header=header,\n    )\n    return cf\n</code></pre> <code></code> <code>to_wav(path, format=None)</code> \u00b6 <p>Save the audio data to a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to save the file.</p> required <code>format</code> <code>str | None</code> <p>File format. If None, determined from file extension.</p> <code>None</code> Source code in <code>wandas/frames/channel.py</code> <pre><code>def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n    \"\"\"Save the audio data to a WAV file.\n\n    Args:\n        path: Path to save the file.\n        format: File format. If None, determined from file extension.\n    \"\"\"\n    from wandas.io.wav_io import write_wav\n\n    write_wav(str(path), self, format=format)\n</code></pre> <code></code> <code>save(path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code> \u00b6 <p>Save the ChannelFrame to a WDF (Wandas Data File) format.</p> <p>This saves the complete frame including all channel data and metadata in a format that can be loaded back with full fidelity.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Example <p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.save(\"audio_analysis.wdf\")</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def save(\n    self,\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n    This saves the complete frame including all channel data and metadata\n    in a format that can be loaded back with full fidelity.\n\n    Args:\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import save as wdf_save\n\n    wdf_save(\n        self,\n        path,\n        format=format,\n        compress=compress,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre> <code></code> <code>load(path, *, format='hdf5')</code> <code>classmethod</code> \u00b6 <p>Load a ChannelFrame from a WDF (Wandas Data File) file.</p> <p>This loads data saved with the save() method, preserving all channel data, metadata, labels, and units.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file</p> required <code>format</code> <code>str</code> <p>Format of the file (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame with all data and metadata loaded</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>NotImplementedError</code> <p>For unsupported formats</p> Example <p>cf = ChannelFrame.load(\"audio_analysis.wdf\")</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n    This loads data saved with the save() method, preserving all channel data,\n    metadata, labels, and units.\n\n    Args:\n        path: Path to the WDF file\n        format: Format of the file (currently only 'hdf5' is supported)\n\n    Returns:\n        A new ChannelFrame with all data and metadata loaded\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        NotImplementedError: For unsupported formats\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import load as wdf_load\n\n    return wdf_load(path, format=format)\n</code></pre> <code></code> <code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False)</code> \u00b6 <p>Add a new channel to the frame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray[Any, Any] | Array | ChannelFrame</code> <p>Data to add as a new channel. Can be: - numpy array (1D or 2D) - dask array (1D or 2D) - ChannelFrame (channels will be added)</p> required <code>label</code> <code>str | None</code> <p>Label for the new channel. If None, generates a default label. Ignored when data is a ChannelFrame (uses its channel labels).</p> <code>None</code> <code>align</code> <code>str</code> <p>How to handle length mismatches: - \"strict\": Raise error if lengths don't match - \"pad\": Pad shorter data with zeros - \"truncate\": Truncate longer data to match</p> <code>'strict'</code> <code>suffix_on_dup</code> <code>str | None</code> <p>Suffix to add to duplicate labels. If None, raises error.</p> <code>None</code> <code>inplace</code> <code>bool</code> <p>If True, modifies the frame in place. Otherwise returns a new frame.</p> <code>False</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>Modified ChannelFrame (self if inplace=True, new frame otherwise).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data length doesn't match and align=\"strict\", or if label is duplicate and suffix_on_dup is None.</p> <code>TypeError</code> <p>If data type is not supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Add a numpy array as a new channel\n&gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n&gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n&gt;&gt;&gt; # Add another ChannelFrame's channels\n&gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n&gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def add_channel(\n    self,\n    data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n    label: str | None = None,\n    align: str = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add a new channel to the frame.\n\n    Args:\n        data: Data to add as a new channel. Can be:\n            - numpy array (1D or 2D)\n            - dask array (1D or 2D)\n            - ChannelFrame (channels will be added)\n        label: Label for the new channel. If None, generates a default label.\n            Ignored when data is a ChannelFrame (uses its channel labels).\n        align: How to handle length mismatches:\n            - \"strict\": Raise error if lengths don't match\n            - \"pad\": Pad shorter data with zeros\n            - \"truncate\": Truncate longer data to match\n        suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n        inplace: If True, modifies the frame in place.\n            Otherwise returns a new frame.\n\n    Returns:\n        Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n    Raises:\n        ValueError: If data length doesn't match and align=\"strict\",\n            or if label is duplicate and suffix_on_dup is None.\n        TypeError: If data type is not supported.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Add a numpy array as a new channel\n        &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n        &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n        &gt;&gt;&gt; # Add another ChannelFrame's channels\n        &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n        &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n    \"\"\"\n    # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n    if isinstance(data, ChannelFrame):\n        if self.sampling_rate != data.sampling_rate:\n            raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n        if data.n_samples != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - data.n_samples\n                arr = data._data\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = data._data[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        else:\n            arr = data._data\n        labels = [ch.label for ch in self._channel_metadata]\n        new_labels = []\n        new_metadata_list = []\n        for chmeta in data._channel_metadata:\n            new_label = chmeta.label\n            if new_label in labels or new_label in new_labels:\n                if suffix_on_dup:\n                    new_label += suffix_on_dup\n                else:\n                    raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n            new_labels.append(new_label)\n            # Copy the entire channel_metadata and update only the label\n            new_ch_meta = chmeta.model_copy(deep=True)\n            new_ch_meta.label = new_label\n            new_metadata_list.append(new_ch_meta)\n        new_data = concatenate([self._data, arr], axis=0)\n\n        new_chmeta = self._channel_metadata + new_metadata_list\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n    if isinstance(data, np.ndarray):\n        arr = from_array(data.reshape(1, -1))\n    elif isinstance(data, DaskArray):\n        arr = data[None, ...] if data.ndim == 1 else data\n        if arr.shape[0] != 1:\n            arr = arr.reshape((1, -1))\n    else:\n        raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n    if arr.shape[1] != self.n_samples:\n        if align == \"pad\":\n            pad_len = self.n_samples - arr.shape[1]\n            if pad_len &gt; 0:\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n            else:\n                arr = arr[:, : self.n_samples]\n        elif align == \"truncate\":\n            arr = arr[:, : self.n_samples]\n            if arr.shape[1] &lt; self.n_samples:\n                pad_len = self.n_samples - arr.shape[1]\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n        else:\n            raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n    labels = [ch.label for ch in self._channel_metadata]\n    new_label = label or f\"ch{len(labels)}\"\n    if new_label in labels:\n        if suffix_on_dup:\n            new_label += suffix_on_dup\n        else:\n            raise ValueError(\"label\u91cd\u8907\")\n    new_data = concatenate([self._data, arr], axis=0)\n    from ..core.metadata import ChannelMetadata\n\n    new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre> <code></code> <code>remove_channel(key, inplace=False)</code> \u00b6 Source code in <code>wandas/frames/channel.py</code> <pre><code>def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n    if isinstance(key, int):\n        if not (0 &lt;= key &lt; self.n_channels):\n            raise IndexError(f\"index {key} out of range\")\n        idx = key\n    else:\n        labels = [ch.label for ch in self._channel_metadata]\n        if key not in labels:\n            raise KeyError(f\"label {key} not found\")\n        idx = labels.index(key)\n    new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n    new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"api/#wandas.frames.channel.ChannelFrame.info--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.info() Channels: 2 Sampling rate: 44100 Hz Duration: 1.0 s Samples: 44100 Channel labels: ['ch0', 'ch1']</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the ChannelFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - Duration\n    - Number of samples\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; cf.info()\n    Channels: 2\n    Sampling rate: 44100 Hz\n    Duration: 1.0 s\n    Samples: 44100\n    Channel labels: ['ch0', 'ch1']\n    \"\"\"\n    print(\"ChannelFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  Duration: {self.duration:.1f} s\")\n    print(f\"  Samples: {self.n_samples}\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/#wandas.frames.channel-functions","title":"Functions","text":""},{"location":"api/#wandas.frames.mixins","title":"<code>mixins</code>","text":"<p>Channel frame mixins module.</p>"},{"location":"api/#wandas.frames.mixins-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.mixins.__all__","title":"<code>__all__ = ['ChannelProcessingMixin', 'ChannelTransformMixin']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.mixins-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.mixins.ChannelProcessingMixin","title":"<code>ChannelProcessingMixin</code>","text":"<p>Mixin that provides methods related to signal processing.</p> <p>This mixin provides processing methods applied to audio signals and other time-series data, such as signal processing filters and transformation operations.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>class ChannelProcessingMixin:\n    \"\"\"Mixin that provides methods related to signal processing.\n\n    This mixin provides processing methods applied to audio signals and\n    other time-series data, such as signal processing filters and\n    transformation operations.\n    \"\"\"\n\n    def high_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a high-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def low_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a low-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def band_pass_filter(\n        self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a band-pass filter to the signal.\n\n        Args:\n            low_cutoff: Lower cutoff frequency (Hz)\n            high_cutoff: Higher cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n            f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"bandpass_filter\",\n            low_cutoff=low_cutoff,\n            high_cutoff=high_cutoff,\n            order=order,\n        )\n        return cast(T_Processing, result)\n\n    def normalize(\n        self: T_Processing,\n        norm: float | None = float(\"inf\"),\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Normalize signal levels using librosa.util.normalize.\n\n        This method normalizes the signal amplitude according to the specified norm.\n\n        Args:\n            norm: Norm type. Default is np.inf (maximum absolute value normalization).\n                Supported values:\n                - np.inf: Maximum absolute value normalization\n                - -np.inf: Minimum absolute value normalization\n                - 0: Peak normalization\n                - float: Lp norm\n                - None: No normalization\n            axis: Axis along which to normalize. Default is -1 (time axis).\n                - -1: Normalize along time axis (each channel independently)\n                - None: Global normalization across all axes\n                - int: Normalize along specified axis\n            threshold: Threshold below which values are considered zero.\n                If None, no threshold is applied.\n            fill: Value to fill when the norm is zero.\n                If None, the zero vector remains zero.\n\n        Returns:\n            New ChannelFrame containing the normalized signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n            &gt;&gt;&gt; normalized = signal.normalize()\n            &gt;&gt;&gt; # Global normalization across all channels\n            &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n            &gt;&gt;&gt; # L2 normalization\n            &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n        \"\"\"\n        logger.debug(\n            f\"Setting up normalize: norm={norm}, axis={axis}, \"\n            f\"threshold={threshold}, fill={fill} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        return cast(T_Processing, result)\n\n    def remove_dc(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Remove DC component (DC offset) from the signal.\n\n        This method removes the DC (direct current) component by subtracting\n        the mean value from each channel. This is equivalent to centering the\n        signal around zero.\n\n        Returns:\n            New ChannelFrame with DC component removed\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; # Create signal with DC offset\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n            &gt;&gt;&gt; # Remove DC offset\n            &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n            &gt;&gt;&gt; # Verify DC removal\n            &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n        Notes:\n            - This operation is performed per channel\n            - Equivalent to applying a high-pass filter with very low cutoff\n            - Useful for removing sensor drift or measurement offset\n        \"\"\"\n        logger.debug(\"Setting up DC removal (lazy)\")\n        result = self.apply_operation(\"remove_dc\")\n        return cast(T_Processing, result)\n\n    def a_weighting(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Apply A-weighting filter to the signal.\n\n        A-weighting adjusts the frequency response to approximate human\n        auditory perception, according to the IEC 61672-1:2013 standard.\n\n        Returns:\n            New ChannelFrame containing the A-weighted signal\n        \"\"\"\n        result = self.apply_operation(\"a_weighting\")\n        return cast(T_Processing, result)\n\n    def abs(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Compute the absolute value of the signal.\n\n        Returns:\n            New ChannelFrame containing the absolute values\n        \"\"\"\n        result = self.apply_operation(\"abs\")\n        return cast(T_Processing, result)\n\n    def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n        \"\"\"Compute the power of the signal.\n\n        Args:\n            exponent: Exponent to raise the signal to. Default is 2.0.\n\n        Returns:\n            New ChannelFrame containing the powered signal\n        \"\"\"\n        result = self.apply_operation(\"power\", exponent=exponent)\n        return cast(T_Processing, result)\n\n    def _reduce_channels(self: T_Processing, op: str) -&gt; T_Processing:\n        \"\"\"Helper to reduce all channels with the given operation ('sum' or 'mean').\"\"\"\n        if op == \"sum\":\n            reduced_data = self._data.sum(axis=0, keepdims=True)\n            label = \"sum\"\n        elif op == \"mean\":\n            reduced_data = self._data.mean(axis=0, keepdims=True)\n            label = \"mean\"\n        else:\n            raise ValueError(f\"Unsupported reduction operation: {op}\")\n\n        units = [ch.unit for ch in self._channel_metadata]\n        if all(u == units[0] for u in units):\n            reduced_unit = units[0]\n        else:\n            reduced_unit = \"\"\n\n        reduced_extra = {\"source_extras\": [ch.extra for ch in self._channel_metadata]}\n        new_channel_metadata = [\n            ChannelMetadata(\n                label=label,\n                unit=reduced_unit,\n                extra=reduced_extra,\n            )\n        ]\n        new_history = (\n            self.operation_history.copy() if hasattr(self, \"operation_history\") else []\n        )\n        new_history.append({\"operation\": op})\n        new_metadata = self.metadata.copy() if hasattr(self, \"metadata\") else {}\n        result = self._create_new_instance(\n            data=reduced_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=new_channel_metadata,\n        )\n        return result\n\n    def sum(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Sum all channels.\n\n        Returns:\n            A new ChannelFrame with summed signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n\n    def mean(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Average all channels.\n\n        Returns:\n            A new ChannelFrame with averaged signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n\n    def trim(\n        self: T_Processing,\n        start: float = 0,\n        end: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Trim the signal to the specified time range.\n\n        Args:\n            start: Start time (seconds)\n            end: End time (seconds)\n\n        Returns:\n            New ChannelFrame containing the trimmed signal\n\n        Raises:\n            ValueError: If end time is earlier than start time\n        \"\"\"\n        if end is None:\n            end = self.duration\n        if start &gt; end:\n            raise ValueError(\"start must be less than end\")\n        result = self.apply_operation(\"trim\", start=start, end=end)\n        return cast(T_Processing, result)\n\n    def fix_length(\n        self: T_Processing,\n        length: int | None = None,\n        duration: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Adjust the signal to the specified length.\n\n        Args:\n            duration: Signal length in seconds\n            length: Signal length in samples\n\n        Returns:\n            New ChannelFrame containing the adjusted signal\n        \"\"\"\n\n        result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n        return cast(T_Processing, result)\n\n    def rms_trend(\n        self: T_Processing,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; T_Processing:\n        \"\"\"Compute the RMS trend of the signal.\n\n        This method calculates the root mean square value over a sliding window.\n\n        Args:\n            frame_length: Size of the sliding window in samples. Default is 2048.\n            hop_length: Hop length between windows in samples. Default is 512.\n            dB: Whether to return RMS values in decibels. Default is False.\n            Aw: Whether to apply A-weighting. Default is False.\n\n        Returns:\n            New ChannelFrame containing the RMS trend\n        \"\"\"\n        # Access _channel_metadata to retrieve reference values\n        frame = cast(ProcessingFrameProtocol, self)\n\n        # Ensure _channel_metadata exists before referencing\n        ref_values = []\n        if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n            ref_values = [ch.ref for ch in frame._channel_metadata]\n\n        result = self.apply_operation(\n            \"rms_trend\",\n            frame_length=frame_length,\n            hop_length=hop_length,\n            ref=ref_values,\n            dB=dB,\n            Aw=Aw,\n        )\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def channel_difference(\n        self: T_Processing, other_channel: int | str = 0\n    ) -&gt; T_Processing:\n        \"\"\"Compute the difference between channels.\n\n        Args:\n            other_channel: Index or label of the reference channel. Default is 0.\n\n        Returns:\n            New ChannelFrame containing the channel difference\n        \"\"\"\n        # label2index is a method of BaseFrame\n        if isinstance(other_channel, str):\n            if hasattr(self, \"label2index\"):\n                other_channel = self.label2index(other_channel)\n\n        result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n        return cast(T_Processing, result)\n\n    def resampling(\n        self: T_Processing,\n        target_sr: float,\n        **kwargs: Any,\n    ) -&gt; T_Processing:\n        \"\"\"Resample audio data.\n\n        Args:\n            target_sr: Target sampling rate (Hz)\n            **kwargs: Additional resampling parameters\n\n        Returns:\n            Resampled ChannelFrame\n        \"\"\"\n        return cast(\n            T_Processing,\n            self.apply_operation(\n                \"resampling\",\n                target_sr=target_sr,\n                **kwargs,\n            ),\n        )\n\n    def hpss_harmonic(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract harmonic components using HPSS\n         (Harmonic-Percussive Source Separation).\n\n        This method separates the harmonic (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n            n_fft: Size of FFT window.\n            hop_length: Hop length for STFT.\n            win_length: Window length for STFT.\n            window: Window type for STFT.\n            center: If True, center the frames.\n            pad_mode: Padding mode for STFT.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_harmonic\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def hpss_percussive(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract percussive components using HPSS\n        (Harmonic-Percussive Source Separation).\n\n        This method separates the percussive (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_percussive\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n        \"\"\"\n        Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of non-stationary signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            New ChannelFrame containing time-varying loudness values in sones.\n            Each channel is processed independently.\n            The output sampling rate is adjusted based on the loudness\n            calculation time resolution (typically ~500 Hz for 2ms steps).\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate loudness for a signal:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n        Notes:\n            - The output contains time-varying loudness values in sones\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - The time resolution is approximately 2ms (determined by the algorithm)\n            - For multi-channel signals, loudness is calculated per channel\n            - The output sampling rate is updated to reflect the time resolution\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 2ms analysis step. This differs slightly from the MoSQITo\n            library, which uses the center time of each step. For example:\n\n            - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n            - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n            The difference is very small (~1ms) and does not affect the loudness\n            values themselves. This design choice ensures consistency with\n            wandas's time axis convention across all frame types.\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n        \"\"\"\n        Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of stationary (steady) signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        This method is suitable for analyzing steady sounds such as fan noise,\n        constant machinery sounds, or other stationary signals.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            Loudness values in sones, one per channel. Shape: (n_channels,)\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate steady-state loudness for a fan noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n            &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n        Notes:\n            - Returns a 1D array with one loudness value per channel\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - For multi-channel signals, loudness is calculated independently\n              per channel\n            - This method is designed for stationary signals (constant sounds)\n            - For time-varying signals, use loudness_zwtv() instead\n            - Similar to the rms property, returns NDArrayReal for consistency\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        # Treat self as a ProcessingFrameProtocol so mypy understands\n        # where sampling_rate and data come from.\n        from wandas.processing.psychoacoustic import LoudnessZwst\n        from wandas.utils.types import NDArrayReal\n\n        # Create operation instance\n        operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n        # Get data (triggers computation if lazy)\n        data = self.data\n\n        # Ensure data is 2D (n_channels, n_samples)\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        # Process the array using the public API and materialize to NumPy\n        result = operation.process_array(data).compute()\n\n        # Squeeze to get 1D array (n_channels,)\n        loudness_values: NDArrayReal = result.squeeze()\n\n        # Ensure it's 1D even for single channel\n        if loudness_values.ndim == 0:\n            loudness_values = loudness_values.reshape(1)\n\n        return loudness_values\n\n    def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n        \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n        Roughness is a psychoacoustic metric that quantifies the perceived\n        harshness or roughness of a sound, measured in asper. This method\n        implements the Daniel &amp; Weber (1997) standard calculation.\n\n        The calculation follows the standard formula:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            New ChannelFrame containing time-varying roughness values in asper.\n            The output sampling rate depends on the overlap parameter.\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Calculate roughness for a motor noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n            &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n            &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n            Analyze roughness statistics:\n            &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n            &gt;&gt;&gt; max_roughness = roughness.data.max()\n            &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n            &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n            Compare before and after modification:\n            &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n            &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n            &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n            &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n        Notes:\n            - Returns a ChannelFrame with time-varying roughness values\n            - Typical roughness values: 0-2 asper for most sounds\n            - Higher values indicate rougher, harsher sounds\n            - For multi-channel signals, roughness is calculated independently\n              per channel\n            - This is the standard-compliant total roughness (R)\n            - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 200ms analysis window. This differs from the MoSQITo library,\n            which uses the center time of each window. For example:\n\n            - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n            - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n            The difference is constant (half the window duration = 100ms) and\n            does not affect the roughness values themselves. This design choice\n            ensures consistency with wandas's time axis convention across all\n            frame types.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n        logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n        result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n        return cast(T_Processing, result)\n\n    def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n        \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n        This method returns detailed roughness analysis data organized by\n        Bark frequency bands over time, allowing for frequency-specific\n        roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n        The relationship between total roughness and specific roughness:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            RoughnessFrame containing:\n                - data: Specific roughness by Bark band, shape (47, n_time)\n                        for mono or (n_channels, 47, n_time) for multi-channel\n                - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n                - time: Time axis for each analysis frame\n                - overlap: Overlap coefficient used\n                - plot(): Method for Bark-Time heatmap visualization\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Analyze frequency-specific roughness:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n            &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Plot Bark-Time heatmap\n            &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Find dominant Bark band\n            &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n            &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n            &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Extract specific Bark band time series\n            &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n            &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Verify standard formula\n            &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n            &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n        Notes:\n            - Returns a RoughnessFrame (not ChannelFrame)\n            - Contains 47 Bark bands from 0.5 to 23.5 Bark\n            - Each Bark band corresponds to a critical band of hearing\n            - Useful for identifying which frequencies contribute most to roughness\n            - The specific roughness can be integrated to obtain total roughness\n            - For simple time-series analysis, use roughness_dw() instead\n\n            **Time axis convention:**\n            The time axis represents the start time of each 200ms analysis\n            window, consistent with roughness_dw() and other wandas methods.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n\n        params = {\"overlap\": overlap}\n        operation_name = \"roughness_dw_spec\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance via factory\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing lazily to self._data (Dask)\n        r_spec_dask = operation.process(self._data)\n\n        # Get metadata updates (sampling rate, bark_axis)\n        metadata_updates = operation.get_metadata_updates()\n\n        # Build metadata and history\n        new_metadata = {**self.metadata, **params}\n        new_history = [\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ]\n\n        # Extract bark_axis with proper type handling\n        bark_axis_value = metadata_updates.get(\"bark_axis\")\n        if bark_axis_value is None:\n            raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n        # Create RoughnessFrame. operation.get_metadata_updates() should provide\n        # sampling_rate and bark_axis\n        roughness_frame = RoughnessFrame(\n            data=r_spec_dask,\n            sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n            bark_axis=bark_axis_value,\n            overlap=overlap,\n            label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=cast(\"BaseFrame[NDArrayReal]\", self),\n        )\n\n        logger.debug(\n            \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n            operation_name,\n            r_spec_dask.shape,\n            roughness_frame.sampling_rate,\n        )\n\n        return roughness_frame\n\n    def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n        \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n        This method applies a symmetric fade-in and fade-out envelope to the signal\n        using a Tukey (tapered cosine) window. The fade duration is the same for\n        both the beginning and end of the signal.\n\n        Args:\n            fade_ms: Fade duration in milliseconds for each end of the signal.\n                The total fade duration is 2 * fade_ms. Default is 50 ms.\n                Must be positive and less than half the signal duration.\n\n        Returns:\n            New ChannelFrame containing the faded signal\n\n        Raises:\n            ValueError: If fade_ms is negative or too long for the signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n            &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n            &gt;&gt;&gt; # Apply very short fade (almost no effect)\n            &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n        Notes:\n            - Uses SciPy's Tukey window for smooth fade transitions\n            - Fade is applied symmetrically to both ends of the signal\n            - The Tukey window alpha parameter is computed automatically\n              based on the fade duration and signal length\n            - For multi-channel signals, the same fade envelope is applied\n              to all channels\n            - Lazy evaluation is preserved - computation occurs only when needed\n        \"\"\"\n        logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n        result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n        return cast(T_Processing, result)\n</code></pre> Functions\u00b6 <code></code> <code>high_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a high-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def high_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a high-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>low_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a low-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def low_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a low-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>band_pass_filter(low_cutoff, high_cutoff, order=4)</code> \u00b6 <p>Apply a band-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>low_cutoff</code> <code>float</code> <p>Lower cutoff frequency (Hz)</p> required <code>high_cutoff</code> <code>float</code> <p>Higher cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def band_pass_filter(\n    self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a band-pass filter to the signal.\n\n    Args:\n        low_cutoff: Lower cutoff frequency (Hz)\n        high_cutoff: Higher cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n        f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"bandpass_filter\",\n        low_cutoff=low_cutoff,\n        high_cutoff=high_cutoff,\n        order=order,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>normalize(norm=float('inf'), axis=-1, threshold=None, fill=None)</code> \u00b6 <p>Normalize signal levels using librosa.util.normalize.</p> <p>This method normalizes the signal amplitude according to the specified norm.</p> <p>Parameters:</p> Name Type Description Default <code>norm</code> <code>float | None</code> <p>Norm type. Default is np.inf (maximum absolute value normalization). Supported values: - np.inf: Maximum absolute value normalization - -np.inf: Minimum absolute value normalization - 0: Peak normalization - float: Lp norm - None: No normalization</p> <code>float('inf')</code> <code>axis</code> <code>int | None</code> <p>Axis along which to normalize. Default is -1 (time axis). - -1: Normalize along time axis (each channel independently) - None: Global normalization across all axes - int: Normalize along specified axis</p> <code>-1</code> <code>threshold</code> <code>float | None</code> <p>Threshold below which values are considered zero. If None, no threshold is applied.</p> <code>None</code> <code>fill</code> <code>bool | None</code> <p>Value to fill when the norm is zero. If None, the zero vector remains zero.</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the normalized signal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n&gt;&gt;&gt; normalized = signal.normalize()\n&gt;&gt;&gt; # Global normalization across all channels\n&gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n&gt;&gt;&gt; # L2 normalization\n&gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n</code></pre> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def normalize(\n    self: T_Processing,\n    norm: float | None = float(\"inf\"),\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n) -&gt; T_Processing:\n    \"\"\"Normalize signal levels using librosa.util.normalize.\n\n    This method normalizes the signal amplitude according to the specified norm.\n\n    Args:\n        norm: Norm type. Default is np.inf (maximum absolute value normalization).\n            Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Peak normalization\n            - float: Lp norm\n            - None: No normalization\n        axis: Axis along which to normalize. Default is -1 (time axis).\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold: Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill: Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n    Returns:\n        New ChannelFrame containing the normalized signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n        &gt;&gt;&gt; normalized = signal.normalize()\n        &gt;&gt;&gt; # Global normalization across all channels\n        &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n        &gt;&gt;&gt; # L2 normalization\n        &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n    \"\"\"\n    logger.debug(\n        f\"Setting up normalize: norm={norm}, axis={axis}, \"\n        f\"threshold={threshold}, fill={fill} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>remove_dc()</code> \u00b6 <p>Remove DC component (DC offset) from the signal.</p> <p>This method removes the DC (direct current) component by subtracting the mean value from each channel. This is equivalent to centering the signal around zero.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame with DC component removed</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create signal with DC offset\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n&gt;&gt;&gt; # Remove DC offset\n&gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n&gt;&gt;&gt; # Verify DC removal\n&gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n</code></pre> Notes <ul> <li>This operation is performed per channel</li> <li>Equivalent to applying a high-pass filter with very low cutoff</li> <li>Useful for removing sensor drift or measurement offset</li> </ul> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def remove_dc(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This method removes the DC (direct current) component by subtracting\n    the mean value from each channel. This is equivalent to centering the\n    signal around zero.\n\n    Returns:\n        New ChannelFrame with DC component removed\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # Create signal with DC offset\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n        &gt;&gt;&gt; # Remove DC offset\n        &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n        &gt;&gt;&gt; # Verify DC removal\n        &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n    Notes:\n        - This operation is performed per channel\n        - Equivalent to applying a high-pass filter with very low cutoff\n        - Useful for removing sensor drift or measurement offset\n    \"\"\"\n    logger.debug(\"Setting up DC removal (lazy)\")\n    result = self.apply_operation(\"remove_dc\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>a_weighting()</code> \u00b6 <p>Apply A-weighting filter to the signal.</p> <p>A-weighting adjusts the frequency response to approximate human auditory perception, according to the IEC 61672-1:2013 standard.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the A-weighted signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def a_weighting(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Apply A-weighting filter to the signal.\n\n    A-weighting adjusts the frequency response to approximate human\n    auditory perception, according to the IEC 61672-1:2013 standard.\n\n    Returns:\n        New ChannelFrame containing the A-weighted signal\n    \"\"\"\n    result = self.apply_operation(\"a_weighting\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>abs()</code> \u00b6 <p>Compute the absolute value of the signal.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the absolute values</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def abs(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Compute the absolute value of the signal.\n\n    Returns:\n        New ChannelFrame containing the absolute values\n    \"\"\"\n    result = self.apply_operation(\"abs\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>power(exponent=2.0)</code> \u00b6 <p>Compute the power of the signal.</p> <p>Parameters:</p> Name Type Description Default <code>exponent</code> <code>float</code> <p>Exponent to raise the signal to. Default is 2.0.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the powered signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n    \"\"\"Compute the power of the signal.\n\n    Args:\n        exponent: Exponent to raise the signal to. Default is 2.0.\n\n    Returns:\n        New ChannelFrame containing the powered signal\n    \"\"\"\n    result = self.apply_operation(\"power\", exponent=exponent)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>sum()</code> \u00b6 <p>Sum all channels.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame with summed signal.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def sum(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Sum all channels.\n\n    Returns:\n        A new ChannelFrame with summed signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n</code></pre> <code></code> <code>mean()</code> \u00b6 <p>Average all channels.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame with averaged signal.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def mean(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Average all channels.\n\n    Returns:\n        A new ChannelFrame with averaged signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n</code></pre> <code></code> <code>trim(start=0, end=None)</code> \u00b6 <p>Trim the signal to the specified time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float</code> <p>Start time (seconds)</p> <code>0</code> <code>end</code> <code>float | None</code> <p>End time (seconds)</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the trimmed signal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If end time is earlier than start time</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def trim(\n    self: T_Processing,\n    start: float = 0,\n    end: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Trim the signal to the specified time range.\n\n    Args:\n        start: Start time (seconds)\n        end: End time (seconds)\n\n    Returns:\n        New ChannelFrame containing the trimmed signal\n\n    Raises:\n        ValueError: If end time is earlier than start time\n    \"\"\"\n    if end is None:\n        end = self.duration\n    if start &gt; end:\n        raise ValueError(\"start must be less than end\")\n    result = self.apply_operation(\"trim\", start=start, end=end)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>fix_length(length=None, duration=None)</code> \u00b6 <p>Adjust the signal to the specified length.</p> <p>Parameters:</p> Name Type Description Default <code>duration</code> <code>float | None</code> <p>Signal length in seconds</p> <code>None</code> <code>length</code> <code>int | None</code> <p>Signal length in samples</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the adjusted signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fix_length(\n    self: T_Processing,\n    length: int | None = None,\n    duration: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Adjust the signal to the specified length.\n\n    Args:\n        duration: Signal length in seconds\n        length: Signal length in samples\n\n    Returns:\n        New ChannelFrame containing the adjusted signal\n    \"\"\"\n\n    result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>rms_trend(frame_length=2048, hop_length=512, dB=False, Aw=False)</code> \u00b6 <p>Compute the RMS trend of the signal.</p> <p>This method calculates the root mean square value over a sliding window.</p> <p>Parameters:</p> Name Type Description Default <code>frame_length</code> <code>int</code> <p>Size of the sliding window in samples. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int</code> <p>Hop length between windows in samples. Default is 512.</p> <code>512</code> <code>dB</code> <code>bool</code> <p>Whether to return RMS values in decibels. Default is False.</p> <code>False</code> <code>Aw</code> <code>bool</code> <p>Whether to apply A-weighting. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the RMS trend</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def rms_trend(\n    self: T_Processing,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; T_Processing:\n    \"\"\"Compute the RMS trend of the signal.\n\n    This method calculates the root mean square value over a sliding window.\n\n    Args:\n        frame_length: Size of the sliding window in samples. Default is 2048.\n        hop_length: Hop length between windows in samples. Default is 512.\n        dB: Whether to return RMS values in decibels. Default is False.\n        Aw: Whether to apply A-weighting. Default is False.\n\n    Returns:\n        New ChannelFrame containing the RMS trend\n    \"\"\"\n    # Access _channel_metadata to retrieve reference values\n    frame = cast(ProcessingFrameProtocol, self)\n\n    # Ensure _channel_metadata exists before referencing\n    ref_values = []\n    if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n        ref_values = [ch.ref for ch in frame._channel_metadata]\n\n    result = self.apply_operation(\n        \"rms_trend\",\n        frame_length=frame_length,\n        hop_length=hop_length,\n        ref=ref_values,\n        dB=dB,\n        Aw=Aw,\n    )\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>channel_difference(other_channel=0)</code> \u00b6 <p>Compute the difference between channels.</p> <p>Parameters:</p> Name Type Description Default <code>other_channel</code> <code>int | str</code> <p>Index or label of the reference channel. Default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the channel difference</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def channel_difference(\n    self: T_Processing, other_channel: int | str = 0\n) -&gt; T_Processing:\n    \"\"\"Compute the difference between channels.\n\n    Args:\n        other_channel: Index or label of the reference channel. Default is 0.\n\n    Returns:\n        New ChannelFrame containing the channel difference\n    \"\"\"\n    # label2index is a method of BaseFrame\n    if isinstance(other_channel, str):\n        if hasattr(self, \"label2index\"):\n            other_channel = self.label2index(other_channel)\n\n    result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>resampling(target_sr, **kwargs)</code> \u00b6 <p>Resample audio data.</p> <p>Parameters:</p> Name Type Description Default <code>target_sr</code> <code>float</code> <p>Target sampling rate (Hz)</p> required <code>**kwargs</code> <code>Any</code> <p>Additional resampling parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>Resampled ChannelFrame</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def resampling(\n    self: T_Processing,\n    target_sr: float,\n    **kwargs: Any,\n) -&gt; T_Processing:\n    \"\"\"Resample audio data.\n\n    Args:\n        target_sr: Target sampling rate (Hz)\n        **kwargs: Additional resampling parameters\n\n    Returns:\n        Resampled ChannelFrame\n    \"\"\"\n    return cast(\n        T_Processing,\n        self.apply_operation(\n            \"resampling\",\n            target_sr=target_sr,\n            **kwargs,\n        ),\n    )\n</code></pre> <code></code> <code>hpss_harmonic(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract harmonic components using HPSS  (Harmonic-Percussive Source Separation).</p> <p>This method separates the harmonic (tonal) components from the signal.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <code>n_fft</code> <code>int</code> <p>Size of FFT window.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Hop length for STFT.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length for STFT.</p> <code>None</code> <code>window</code> <code>_WindowSpec</code> <p>Window type for STFT.</p> <code>'hann'</code> <code>center</code> <code>bool</code> <p>If True, center the frames.</p> <code>True</code> <code>pad_mode</code> <code>_PadModeSTFT</code> <p>Padding mode for STFT.</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_harmonic(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract harmonic components using HPSS\n     (Harmonic-Percussive Source Separation).\n\n    This method separates the harmonic (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n        n_fft: Size of FFT window.\n        hop_length: Hop length for STFT.\n        win_length: Window length for STFT.\n        window: Window type for STFT.\n        center: If True, center the frames.\n        pad_mode: Padding mode for STFT.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_harmonic\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>hpss_percussive(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract percussive components using HPSS (Harmonic-Percussive Source Separation).</p> <p>This method separates the percussive (tonal) components from the signal.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_percussive(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract percussive components using HPSS\n    (Harmonic-Percussive Source Separation).\n\n    This method separates the percussive (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_percussive\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwtv(field_type='free')</code> \u00b6 <p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing time-varying loudness values in sones.</p> <code>T_Processing</code> <p>Each channel is processed independently.</p> <code>T_Processing</code> <p>The output sampling rate is adjusted based on the loudness</p> <code>T_Processing</code> <p>calculation time resolution (typically ~500 Hz for 2ms steps).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>Examples:</p> <p>Calculate loudness for a signal:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre> Notes <ul> <li>The output contains time-varying loudness values in sones</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>The time resolution is approximately 2ms (determined by the algorithm)</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The output sampling rate is updated to reflect the time resolution</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 2ms analysis step. This differs slightly from the MoSQITo library, which uses the center time of each step. For example:</p> <ul> <li>wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)</li> <li>MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)</li> </ul> <p>The difference is very small (~1ms) and does not affect the loudness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        New ChannelFrame containing time-varying loudness values in sones.\n        Each channel is processed independently.\n        The output sampling rate is adjusted based on the loudness\n        calculation time resolution (typically ~500 Hz for 2ms steps).\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate loudness for a signal:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n    Notes:\n        - The output contains time-varying loudness values in sones\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - The time resolution is approximately 2ms (determined by the algorithm)\n        - For multi-channel signals, loudness is calculated per channel\n        - The output sampling rate is updated to reflect the time resolution\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 2ms analysis step. This differs slightly from the MoSQITo\n        library, which uses the center time of each step. For example:\n\n        - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n        - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n        The difference is very small (~1ms) and does not affect the loudness\n        values themselves. This design choice ensures consistency with\n        wandas's time axis convention across all frame types.\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwst(field_type='free')</code> \u00b6 <p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>This method is suitable for analyzing steady sounds such as fan noise, constant machinery sounds, or other stationary signals.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Loudness values in sones, one per channel. Shape: (n_channels,)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>Examples:</p> <p>Calculate steady-state loudness for a fan noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n&gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre> Notes <ul> <li>Returns a 1D array with one loudness value per channel</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>For multi-channel signals, loudness is calculated independently   per channel</li> <li>This method is designed for stationary signals (constant sounds)</li> <li>For time-varying signals, use loudness_zwtv() instead</li> <li>Similar to the rms property, returns NDArrayReal for consistency</li> </ul> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    This method is suitable for analyzing steady sounds such as fan noise,\n    constant machinery sounds, or other stationary signals.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        Loudness values in sones, one per channel. Shape: (n_channels,)\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate steady-state loudness for a fan noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n        &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n    Notes:\n        - Returns a 1D array with one loudness value per channel\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - For multi-channel signals, loudness is calculated independently\n          per channel\n        - This method is designed for stationary signals (constant sounds)\n        - For time-varying signals, use loudness_zwtv() instead\n        - Similar to the rms property, returns NDArrayReal for consistency\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    # Treat self as a ProcessingFrameProtocol so mypy understands\n    # where sampling_rate and data come from.\n    from wandas.processing.psychoacoustic import LoudnessZwst\n    from wandas.utils.types import NDArrayReal\n\n    # Create operation instance\n    operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n    # Get data (triggers computation if lazy)\n    data = self.data\n\n    # Ensure data is 2D (n_channels, n_samples)\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    # Process the array using the public API and materialize to NumPy\n    result = operation.process_array(data).compute()\n\n    # Squeeze to get 1D array (n_channels,)\n    loudness_values: NDArrayReal = result.squeeze()\n\n    # Ensure it's 1D even for single channel\n    if loudness_values.ndim == 0:\n        loudness_values = loudness_values.reshape(1)\n\n    return loudness_values\n</code></pre> <code></code> <code>roughness_dw(overlap=0.5)</code> \u00b6 <p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound, measured in asper. This method implements the Daniel &amp; Weber (1997) standard calculation.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>Parameters:</p> Name Type Description Default <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing time-varying roughness values in asper.</p> <code>T_Processing</code> <p>The output sampling rate depends on the overlap parameter.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>Examples:</p> <p>Calculate roughness for a motor noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n&gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n&gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n</code></pre> <p>Analyze roughness statistics:</p> <pre><code>&gt;&gt;&gt; mean_roughness = roughness.data.mean()\n&gt;&gt;&gt; max_roughness = roughness.data.max()\n&gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n&gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n</code></pre> <p>Compare before and after modification:</p> <pre><code>&gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n&gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n&gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n&gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n</code></pre> Notes <ul> <li>Returns a ChannelFrame with time-varying roughness values</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher values indicate rougher, harsher sounds</li> <li>For multi-channel signals, roughness is calculated independently   per channel</li> <li>This is the standard-compliant total roughness (R)</li> <li>For detailed Bark-band analysis, use roughness_dw_spec() instead</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 200ms analysis window. This differs from the MoSQITo library, which uses the center time of each window. For example:</p> <ul> <li>wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)</li> <li>MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)</li> </ul> <p>The difference is constant (half the window duration = 100ms) and does not affect the roughness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n    \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound, measured in asper. This method\n    implements the Daniel &amp; Weber (1997) standard calculation.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        New ChannelFrame containing time-varying roughness values in asper.\n        The output sampling rate depends on the overlap parameter.\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Calculate roughness for a motor noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n        &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n        &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n        Analyze roughness statistics:\n        &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n        &gt;&gt;&gt; max_roughness = roughness.data.max()\n        &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n        &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n        Compare before and after modification:\n        &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n        &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n        &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n        &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n    Notes:\n        - Returns a ChannelFrame with time-varying roughness values\n        - Typical roughness values: 0-2 asper for most sounds\n        - Higher values indicate rougher, harsher sounds\n        - For multi-channel signals, roughness is calculated independently\n          per channel\n        - This is the standard-compliant total roughness (R)\n        - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 200ms analysis window. This differs from the MoSQITo library,\n        which uses the center time of each window. For example:\n\n        - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n        - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n        The difference is constant (half the window duration = 100ms) and\n        does not affect the roughness values themselves. This design choice\n        ensures consistency with wandas's time axis convention across all\n        frame types.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n    logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n    result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>roughness_dw_spec(overlap=0.5)</code> \u00b6 <p>Calculate specific roughness with Bark-band frequency information.</p> <p>This method returns detailed roughness analysis data organized by Bark frequency bands over time, allowing for frequency-specific roughness analysis. It uses the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>Parameters:</p> Name Type Description Default <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>RoughnessFrame</code> <p>RoughnessFrame containing: - data: Specific roughness by Bark band, shape (47, n_time)         for mono or (n_channels, 47, n_time) for multi-channel - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5) - time: Time axis for each analysis frame - overlap: Overlap coefficient used - plot(): Method for Bark-Time heatmap visualization</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>Examples:</p> <p>Analyze frequency-specific roughness:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n&gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot Bark-Time heatmap\n&gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find dominant Bark band\n&gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n&gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n&gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Extract specific Bark band time series\n&gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n&gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify standard formula\n&gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n&gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n</code></pre> Notes <ul> <li>Returns a RoughnessFrame (not ChannelFrame)</li> <li>Contains 47 Bark bands from 0.5 to 23.5 Bark</li> <li>Each Bark band corresponds to a critical band of hearing</li> <li>Useful for identifying which frequencies contribute most to roughness</li> <li>The specific roughness can be integrated to obtain total roughness</li> <li>For simple time-series analysis, use roughness_dw() instead</li> </ul> <p>Time axis convention: The time axis represents the start time of each 200ms analysis window, consistent with roughness_dw() and other wandas methods.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n    \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n    This method returns detailed roughness analysis data organized by\n    Bark frequency bands over time, allowing for frequency-specific\n    roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n    The relationship between total roughness and specific roughness:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        RoughnessFrame containing:\n            - data: Specific roughness by Bark band, shape (47, n_time)\n                    for mono or (n_channels, 47, n_time) for multi-channel\n            - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n            - time: Time axis for each analysis frame\n            - overlap: Overlap coefficient used\n            - plot(): Method for Bark-Time heatmap visualization\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Analyze frequency-specific roughness:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot Bark-Time heatmap\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Find dominant Bark band\n        &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n        &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n        &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Extract specific Bark band time series\n        &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n        &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verify standard formula\n        &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n        &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n    Notes:\n        - Returns a RoughnessFrame (not ChannelFrame)\n        - Contains 47 Bark bands from 0.5 to 23.5 Bark\n        - Each Bark band corresponds to a critical band of hearing\n        - Useful for identifying which frequencies contribute most to roughness\n        - The specific roughness can be integrated to obtain total roughness\n        - For simple time-series analysis, use roughness_dw() instead\n\n        **Time axis convention:**\n        The time axis represents the start time of each 200ms analysis\n        window, consistent with roughness_dw() and other wandas methods.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n\n    params = {\"overlap\": overlap}\n    operation_name = \"roughness_dw_spec\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance via factory\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n\n    # Apply processing lazily to self._data (Dask)\n    r_spec_dask = operation.process(self._data)\n\n    # Get metadata updates (sampling rate, bark_axis)\n    metadata_updates = operation.get_metadata_updates()\n\n    # Build metadata and history\n    new_metadata = {**self.metadata, **params}\n    new_history = [\n        *self.operation_history,\n        {\"operation\": operation_name, \"params\": params},\n    ]\n\n    # Extract bark_axis with proper type handling\n    bark_axis_value = metadata_updates.get(\"bark_axis\")\n    if bark_axis_value is None:\n        raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n    # Create RoughnessFrame. operation.get_metadata_updates() should provide\n    # sampling_rate and bark_axis\n    roughness_frame = RoughnessFrame(\n        data=r_spec_dask,\n        sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n        bark_axis=bark_axis_value,\n        overlap=overlap,\n        label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=cast(\"BaseFrame[NDArrayReal]\", self),\n    )\n\n    logger.debug(\n        \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n        operation_name,\n        r_spec_dask.shape,\n        roughness_frame.sampling_rate,\n    )\n\n    return roughness_frame\n</code></pre> <code></code> <code>fade(fade_ms=50)</code> \u00b6 <p>Apply symmetric fade-in and fade-out to the signal using Tukey window.</p> <p>This method applies a symmetric fade-in and fade-out envelope to the signal using a Tukey (tapered cosine) window. The fade duration is the same for both the beginning and end of the signal.</p> <p>Parameters:</p> Name Type Description Default <code>fade_ms</code> <code>float</code> <p>Fade duration in milliseconds for each end of the signal. The total fade duration is 2 * fade_ms. Default is 50 ms. Must be positive and less than half the signal duration.</p> <code>50</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the faded signal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If fade_ms is negative or too long for the signal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n&gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n&gt;&gt;&gt; # Apply very short fade (almost no effect)\n&gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n</code></pre> Notes <ul> <li>Uses SciPy's Tukey window for smooth fade transitions</li> <li>Fade is applied symmetrically to both ends of the signal</li> <li>The Tukey window alpha parameter is computed automatically   based on the fade duration and signal length</li> <li>For multi-channel signals, the same fade envelope is applied   to all channels</li> <li>Lazy evaluation is preserved - computation occurs only when needed</li> </ul> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n    \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n    This method applies a symmetric fade-in and fade-out envelope to the signal\n    using a Tukey (tapered cosine) window. The fade duration is the same for\n    both the beginning and end of the signal.\n\n    Args:\n        fade_ms: Fade duration in milliseconds for each end of the signal.\n            The total fade duration is 2 * fade_ms. Default is 50 ms.\n            Must be positive and less than half the signal duration.\n\n    Returns:\n        New ChannelFrame containing the faded signal\n\n    Raises:\n        ValueError: If fade_ms is negative or too long for the signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n        &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n        &gt;&gt;&gt; # Apply very short fade (almost no effect)\n        &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n    Notes:\n        - Uses SciPy's Tukey window for smooth fade transitions\n        - Fade is applied symmetrically to both ends of the signal\n        - The Tukey window alpha parameter is computed automatically\n          based on the fade duration and signal length\n        - For multi-channel signals, the same fade envelope is applied\n          to all channels\n        - Lazy evaluation is preserved - computation occurs only when needed\n    \"\"\"\n    logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n    result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/#wandas.frames.mixins.ChannelTransformMixin","title":"<code>ChannelTransformMixin</code>","text":"<p>Mixin providing methods related to frequency transformations.</p> <p>This mixin provides operations related to frequency analysis and transformations such as FFT, STFT, and Welch method.</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>class ChannelTransformMixin:\n    \"\"\"Mixin providing methods related to frequency transformations.\n\n    This mixin provides operations related to frequency analysis and\n    transformations such as FFT, STFT, and Welch method.\n    \"\"\"\n\n    def fft(\n        self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate Fast Fourier Transform (FFT).\n\n        Args:\n            n_fft: Number of FFT points. Default is the next power of 2 of the data\n                length.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectralFrame containing FFT results\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import FFT, create_operation\n\n        params = {\"n_fft\": n_fft, \"window\": window}\n        operation_name = \"fft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"FFT\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        if n_fft is None:\n            is_even = spectrum_data.shape[-1] % 2 == 0\n            _n_fft = (\n                spectrum_data.shape[-1] * 2 - 2\n                if is_even\n                else spectrum_data.shape[-1] * 2 - 1\n            )\n        else:\n            _n_fft = n_fft\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=_n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def welch(\n        self: T_Transform,\n        n_fft: int | None = None,\n        hop_length: int | None = None,\n        win_length: int = 2048,\n        window: str = \"hann\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate power spectral density using Welch's method.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing power spectral density\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import Welch, create_operation\n\n        params = dict(\n            n_fft=n_fft or win_length,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            average=average,\n        )\n        operation_name = \"welch\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Welch\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"welch\", \"params\": params},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def noct_spectrum(\n        self: T_Transform,\n        fmin: float = 25,\n        fmax: float = 20000,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; \"NOctFrame\":\n        \"\"\"Calculate N-octave band spectrum.\n\n        Args:\n            fmin: Minimum center frequency (Hz). Default is 25 Hz.\n            fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n            n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n            G: Reference gain (dB). Default is 10 dB.\n            fr: Reference frequency (Hz). Default is 1000 Hz.\n\n        Returns:\n            NOctFrame containing N-octave band spectrum\n        \"\"\"\n        from wandas.processing import NOctSpectrum, create_operation\n\n        from ..noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_spectrum\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSpectrum\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_spectrum\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def stft(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Calculate Short-Time Fourier Transform.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectrogramFrame containing STFT results\n        \"\"\"\n        from wandas.processing import STFT, create_operation\n\n        from ..spectrogram import SpectrogramFrame\n\n        # Set hop length and window length\n        _hop_length = hop_length if hop_length is not None else n_fft // 4\n        _win_length = win_length if win_length is not None else n_fft\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": _hop_length,\n            \"win_length\": _win_length,\n            \"window\": window,\n        }\n        operation_name = \"stft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"STFT\", operation)\n\n        # Apply processing to data\n        spectrogram_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new instance\n        return SpectrogramFrame(\n            data=spectrogram_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=n_fft,\n            hop_length=_hop_length,\n            win_length=_win_length,\n            window=window,\n            label=f\"stft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def coherence(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate magnitude squared coherence.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n        Returns:\n            SpectralFrame containing magnitude squared coherence\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.processing import Coherence, create_operation\n\n        from ..spectral import SpectralFrame\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n        }\n        operation_name = \"coherence\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Coherence\", operation)\n\n        # Apply processing to data\n        coherence_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=coherence_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Coherence of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def csd(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate cross-spectral density matrix.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing cross-spectral density matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import CSD, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"csd\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"CSD\", operation)\n\n        # Apply processing to data\n        csd_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=csd_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def transfer_function(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate transfer function matrix.\n\n        The transfer function represents the signal transfer characteristics between\n        channels in the frequency domain and represents the input-output relationship\n        of the system.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing transfer function matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import TransferFunction, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"transfer_function\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"TransferFunction\", operation)\n\n        # Apply processing to data\n        tf_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=tf_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Transfer function of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n</code></pre> Functions\u00b6 <code></code> <code>fft(n_fft=None, window='hann')</code> \u00b6 <p>Calculate Fast Fourier Transform (FFT).</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is the next power of 2 of the data length.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing FFT results</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def fft(\n    self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate Fast Fourier Transform (FFT).\n\n    Args:\n        n_fft: Number of FFT points. Default is the next power of 2 of the data\n            length.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectralFrame containing FFT results\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import FFT, create_operation\n\n    params = {\"n_fft\": n_fft, \"window\": window}\n    operation_name = \"fft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"FFT\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    if n_fft is None:\n        is_even = spectrum_data.shape[-1] % 2 == 0\n        _n_fft = (\n            spectrum_data.shape[-1] * 2 - 2\n            if is_even\n            else spectrum_data.shape[-1] * 2 - 1\n        )\n    else:\n        _n_fft = n_fft\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=_n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>welch(n_fft=None, hop_length=None, win_length=2048, window='hann', average='mean')</code> \u00b6 <p>Calculate power spectral density using Welch's method.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is 2048.</p> <code>None</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int</code> <p>Window length. Default is n_fft.</p> <code>2048</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing power spectral density</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def welch(\n    self: T_Transform,\n    n_fft: int | None = None,\n    hop_length: int | None = None,\n    win_length: int = 2048,\n    window: str = \"hann\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate power spectral density using Welch's method.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing power spectral density\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import Welch, create_operation\n\n    params = dict(\n        n_fft=n_fft or win_length,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        average=average,\n    )\n    operation_name = \"welch\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Welch\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"welch\", \"params\": params},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>noct_spectrum(fmin=25, fmax=20000, n=3, G=10, fr=1000)</code> \u00b6 <p>Calculate N-octave band spectrum.</p> <p>Parameters:</p> Name Type Description Default <code>fmin</code> <code>float</code> <p>Minimum center frequency (Hz). Default is 25 Hz.</p> <code>25</code> <code>fmax</code> <code>float</code> <p>Maximum center frequency (Hz). Default is 20000 Hz.</p> <code>20000</code> <code>n</code> <code>int</code> <p>Band division (1: octave, 3: 1/3 octave). Default is 3.</p> <code>3</code> <code>G</code> <code>int</code> <p>Reference gain (dB). Default is 10 dB.</p> <code>10</code> <code>fr</code> <code>int</code> <p>Reference frequency (Hz). Default is 1000 Hz.</p> <code>1000</code> <p>Returns:</p> Type Description <code>NOctFrame</code> <p>NOctFrame containing N-octave band spectrum</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def noct_spectrum(\n    self: T_Transform,\n    fmin: float = 25,\n    fmax: float = 20000,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; \"NOctFrame\":\n    \"\"\"Calculate N-octave band spectrum.\n\n    Args:\n        fmin: Minimum center frequency (Hz). Default is 25 Hz.\n        fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n        n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n        G: Reference gain (dB). Default is 10 dB.\n        fr: Reference frequency (Hz). Default is 1000 Hz.\n\n    Returns:\n        NOctFrame containing N-octave band spectrum\n    \"\"\"\n    from wandas.processing import NOctSpectrum, create_operation\n\n    from ..noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_spectrum\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSpectrum\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_spectrum\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Calculate Short-Time Fourier Transform.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>Returns:</p> Type Description <code>SpectrogramFrame</code> <p>SpectrogramFrame containing STFT results</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def stft(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Calculate Short-Time Fourier Transform.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectrogramFrame containing STFT results\n    \"\"\"\n    from wandas.processing import STFT, create_operation\n\n    from ..spectrogram import SpectrogramFrame\n\n    # Set hop length and window length\n    _hop_length = hop_length if hop_length is not None else n_fft // 4\n    _win_length = win_length if win_length is not None else n_fft\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": _hop_length,\n        \"win_length\": _win_length,\n        \"window\": window,\n    }\n    operation_name = \"stft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"STFT\", operation)\n\n    # Apply processing to data\n    spectrogram_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new instance\n    return SpectrogramFrame(\n        data=spectrogram_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=n_fft,\n        hop_length=_hop_length,\n        win_length=_win_length,\n        window=window,\n        label=f\"stft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>coherence(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code> \u00b6 <p>Calculate magnitude squared coherence.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing magnitude squared coherence</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def coherence(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate magnitude squared coherence.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n    Returns:\n        SpectralFrame containing magnitude squared coherence\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.processing import Coherence, create_operation\n\n    from ..spectral import SpectralFrame\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n    }\n    operation_name = \"coherence\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Coherence\", operation)\n\n    # Apply processing to data\n    coherence_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=coherence_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Coherence of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>csd(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate cross-spectral density matrix.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing cross-spectral density matrix</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def csd(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate cross-spectral density matrix.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing cross-spectral density matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import CSD, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"csd\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"CSD\", operation)\n\n    # Apply processing to data\n    csd_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=csd_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>transfer_function(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate transfer function matrix.</p> <p>The transfer function represents the signal transfer characteristics between channels in the frequency domain and represents the input-output relationship of the system.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing transfer function matrix</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def transfer_function(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate transfer function matrix.\n\n    The transfer function represents the signal transfer characteristics between\n    channels in the frequency domain and represents the input-output relationship\n    of the system.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing transfer function matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import TransferFunction, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"transfer_function\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"TransferFunction\", operation)\n\n    # Apply processing to data\n    tf_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=tf_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Transfer function of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.mixins-modules","title":"Modules","text":""},{"location":"api/#wandas.frames.mixins.channel_collection_mixin","title":"<code>channel_collection_mixin</code>","text":"<p>ChannelCollectionMixin: Common functionality for adding/removing channels in ChannelFrame</p> Attributes\u00b6 <code>T = TypeVar('T', bound='ChannelCollectionMixin')</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>ChannelCollectionMixin</code> \u00b6 Source code in <code>wandas/frames/mixins/channel_collection_mixin.py</code> <pre><code>class ChannelCollectionMixin:\n    def add_channel(\n        self: T,\n        data: np.ndarray[Any, Any] | da.Array | T,\n        label: str | None = None,\n        align: Literal[\"strict\", \"pad\", \"truncate\"] = \"strict\",\n        suffix_on_dup: str | None = None,\n        inplace: bool = False,\n        **kwargs: Any,\n    ) -&gt; T:\n        \"\"\"\n        Add a channel\n        Args:\n            data: Channel to add (1ch ndarray/dask/ChannelFrame)\n            label: Label for the added channel\n            align: Behavior when lengths don't match\n            suffix_on_dup: Suffix when label is duplicated\n            inplace: True for self-modification\n        Returns:\n            New Frame or self\n        Raises:\n            ValueError, TypeError\n        \"\"\"\n        raise NotImplementedError(\"add_channel() must be implemented in subclasses\")\n\n    def remove_channel(\n        self: T,\n        key: int | str,\n        inplace: bool = False,\n    ) -&gt; T:\n        \"\"\"\n        Remove a channel\n        Args:\n            key: Target to remove (index or label)\n            inplace: True for self-modification\n        Returns:\n            New Frame or self\n        Raises:\n            ValueError, KeyError, IndexError\n        \"\"\"\n        raise NotImplementedError(\"remove_channel() must be implemented in subclasses\")\n</code></pre> Functions\u00b6 <code></code> <code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False, **kwargs)</code> \u00b6 <p>Add a channel Args:     data: Channel to add (1ch ndarray/dask/ChannelFrame)     label: Label for the added channel     align: Behavior when lengths don't match     suffix_on_dup: Suffix when label is duplicated     inplace: True for self-modification Returns:     New Frame or self Raises:     ValueError, TypeError</p> Source code in <code>wandas/frames/mixins/channel_collection_mixin.py</code> <pre><code>def add_channel(\n    self: T,\n    data: np.ndarray[Any, Any] | da.Array | T,\n    label: str | None = None,\n    align: Literal[\"strict\", \"pad\", \"truncate\"] = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n    **kwargs: Any,\n) -&gt; T:\n    \"\"\"\n    Add a channel\n    Args:\n        data: Channel to add (1ch ndarray/dask/ChannelFrame)\n        label: Label for the added channel\n        align: Behavior when lengths don't match\n        suffix_on_dup: Suffix when label is duplicated\n        inplace: True for self-modification\n    Returns:\n        New Frame or self\n    Raises:\n        ValueError, TypeError\n    \"\"\"\n    raise NotImplementedError(\"add_channel() must be implemented in subclasses\")\n</code></pre> <code></code> <code>remove_channel(key, inplace=False)</code> \u00b6 <p>Remove a channel Args:     key: Target to remove (index or label)     inplace: True for self-modification Returns:     New Frame or self Raises:     ValueError, KeyError, IndexError</p> Source code in <code>wandas/frames/mixins/channel_collection_mixin.py</code> <pre><code>def remove_channel(\n    self: T,\n    key: int | str,\n    inplace: bool = False,\n) -&gt; T:\n    \"\"\"\n    Remove a channel\n    Args:\n        key: Target to remove (index or label)\n        inplace: True for self-modification\n    Returns:\n        New Frame or self\n    Raises:\n        ValueError, KeyError, IndexError\n    \"\"\"\n    raise NotImplementedError(\"remove_channel() must be implemented in subclasses\")\n</code></pre>"},{"location":"api/#wandas.frames.mixins.channel_processing_mixin","title":"<code>channel_processing_mixin</code>","text":"<p>Module providing mixins related to signal processing.</p> Attributes\u00b6 <code>logger = logging.getLogger(__name__)</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>ChannelProcessingMixin</code> \u00b6 <p>Mixin that provides methods related to signal processing.</p> <p>This mixin provides processing methods applied to audio signals and other time-series data, such as signal processing filters and transformation operations.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>class ChannelProcessingMixin:\n    \"\"\"Mixin that provides methods related to signal processing.\n\n    This mixin provides processing methods applied to audio signals and\n    other time-series data, such as signal processing filters and\n    transformation operations.\n    \"\"\"\n\n    def high_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a high-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def low_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a low-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def band_pass_filter(\n        self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a band-pass filter to the signal.\n\n        Args:\n            low_cutoff: Lower cutoff frequency (Hz)\n            high_cutoff: Higher cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n            f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"bandpass_filter\",\n            low_cutoff=low_cutoff,\n            high_cutoff=high_cutoff,\n            order=order,\n        )\n        return cast(T_Processing, result)\n\n    def normalize(\n        self: T_Processing,\n        norm: float | None = float(\"inf\"),\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Normalize signal levels using librosa.util.normalize.\n\n        This method normalizes the signal amplitude according to the specified norm.\n\n        Args:\n            norm: Norm type. Default is np.inf (maximum absolute value normalization).\n                Supported values:\n                - np.inf: Maximum absolute value normalization\n                - -np.inf: Minimum absolute value normalization\n                - 0: Peak normalization\n                - float: Lp norm\n                - None: No normalization\n            axis: Axis along which to normalize. Default is -1 (time axis).\n                - -1: Normalize along time axis (each channel independently)\n                - None: Global normalization across all axes\n                - int: Normalize along specified axis\n            threshold: Threshold below which values are considered zero.\n                If None, no threshold is applied.\n            fill: Value to fill when the norm is zero.\n                If None, the zero vector remains zero.\n\n        Returns:\n            New ChannelFrame containing the normalized signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n            &gt;&gt;&gt; normalized = signal.normalize()\n            &gt;&gt;&gt; # Global normalization across all channels\n            &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n            &gt;&gt;&gt; # L2 normalization\n            &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n        \"\"\"\n        logger.debug(\n            f\"Setting up normalize: norm={norm}, axis={axis}, \"\n            f\"threshold={threshold}, fill={fill} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        return cast(T_Processing, result)\n\n    def remove_dc(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Remove DC component (DC offset) from the signal.\n\n        This method removes the DC (direct current) component by subtracting\n        the mean value from each channel. This is equivalent to centering the\n        signal around zero.\n\n        Returns:\n            New ChannelFrame with DC component removed\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; # Create signal with DC offset\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n            &gt;&gt;&gt; # Remove DC offset\n            &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n            &gt;&gt;&gt; # Verify DC removal\n            &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n        Notes:\n            - This operation is performed per channel\n            - Equivalent to applying a high-pass filter with very low cutoff\n            - Useful for removing sensor drift or measurement offset\n        \"\"\"\n        logger.debug(\"Setting up DC removal (lazy)\")\n        result = self.apply_operation(\"remove_dc\")\n        return cast(T_Processing, result)\n\n    def a_weighting(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Apply A-weighting filter to the signal.\n\n        A-weighting adjusts the frequency response to approximate human\n        auditory perception, according to the IEC 61672-1:2013 standard.\n\n        Returns:\n            New ChannelFrame containing the A-weighted signal\n        \"\"\"\n        result = self.apply_operation(\"a_weighting\")\n        return cast(T_Processing, result)\n\n    def abs(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Compute the absolute value of the signal.\n\n        Returns:\n            New ChannelFrame containing the absolute values\n        \"\"\"\n        result = self.apply_operation(\"abs\")\n        return cast(T_Processing, result)\n\n    def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n        \"\"\"Compute the power of the signal.\n\n        Args:\n            exponent: Exponent to raise the signal to. Default is 2.0.\n\n        Returns:\n            New ChannelFrame containing the powered signal\n        \"\"\"\n        result = self.apply_operation(\"power\", exponent=exponent)\n        return cast(T_Processing, result)\n\n    def _reduce_channels(self: T_Processing, op: str) -&gt; T_Processing:\n        \"\"\"Helper to reduce all channels with the given operation ('sum' or 'mean').\"\"\"\n        if op == \"sum\":\n            reduced_data = self._data.sum(axis=0, keepdims=True)\n            label = \"sum\"\n        elif op == \"mean\":\n            reduced_data = self._data.mean(axis=0, keepdims=True)\n            label = \"mean\"\n        else:\n            raise ValueError(f\"Unsupported reduction operation: {op}\")\n\n        units = [ch.unit for ch in self._channel_metadata]\n        if all(u == units[0] for u in units):\n            reduced_unit = units[0]\n        else:\n            reduced_unit = \"\"\n\n        reduced_extra = {\"source_extras\": [ch.extra for ch in self._channel_metadata]}\n        new_channel_metadata = [\n            ChannelMetadata(\n                label=label,\n                unit=reduced_unit,\n                extra=reduced_extra,\n            )\n        ]\n        new_history = (\n            self.operation_history.copy() if hasattr(self, \"operation_history\") else []\n        )\n        new_history.append({\"operation\": op})\n        new_metadata = self.metadata.copy() if hasattr(self, \"metadata\") else {}\n        result = self._create_new_instance(\n            data=reduced_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=new_channel_metadata,\n        )\n        return result\n\n    def sum(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Sum all channels.\n\n        Returns:\n            A new ChannelFrame with summed signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n\n    def mean(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Average all channels.\n\n        Returns:\n            A new ChannelFrame with averaged signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n\n    def trim(\n        self: T_Processing,\n        start: float = 0,\n        end: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Trim the signal to the specified time range.\n\n        Args:\n            start: Start time (seconds)\n            end: End time (seconds)\n\n        Returns:\n            New ChannelFrame containing the trimmed signal\n\n        Raises:\n            ValueError: If end time is earlier than start time\n        \"\"\"\n        if end is None:\n            end = self.duration\n        if start &gt; end:\n            raise ValueError(\"start must be less than end\")\n        result = self.apply_operation(\"trim\", start=start, end=end)\n        return cast(T_Processing, result)\n\n    def fix_length(\n        self: T_Processing,\n        length: int | None = None,\n        duration: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Adjust the signal to the specified length.\n\n        Args:\n            duration: Signal length in seconds\n            length: Signal length in samples\n\n        Returns:\n            New ChannelFrame containing the adjusted signal\n        \"\"\"\n\n        result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n        return cast(T_Processing, result)\n\n    def rms_trend(\n        self: T_Processing,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; T_Processing:\n        \"\"\"Compute the RMS trend of the signal.\n\n        This method calculates the root mean square value over a sliding window.\n\n        Args:\n            frame_length: Size of the sliding window in samples. Default is 2048.\n            hop_length: Hop length between windows in samples. Default is 512.\n            dB: Whether to return RMS values in decibels. Default is False.\n            Aw: Whether to apply A-weighting. Default is False.\n\n        Returns:\n            New ChannelFrame containing the RMS trend\n        \"\"\"\n        # Access _channel_metadata to retrieve reference values\n        frame = cast(ProcessingFrameProtocol, self)\n\n        # Ensure _channel_metadata exists before referencing\n        ref_values = []\n        if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n            ref_values = [ch.ref for ch in frame._channel_metadata]\n\n        result = self.apply_operation(\n            \"rms_trend\",\n            frame_length=frame_length,\n            hop_length=hop_length,\n            ref=ref_values,\n            dB=dB,\n            Aw=Aw,\n        )\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def channel_difference(\n        self: T_Processing, other_channel: int | str = 0\n    ) -&gt; T_Processing:\n        \"\"\"Compute the difference between channels.\n\n        Args:\n            other_channel: Index or label of the reference channel. Default is 0.\n\n        Returns:\n            New ChannelFrame containing the channel difference\n        \"\"\"\n        # label2index is a method of BaseFrame\n        if isinstance(other_channel, str):\n            if hasattr(self, \"label2index\"):\n                other_channel = self.label2index(other_channel)\n\n        result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n        return cast(T_Processing, result)\n\n    def resampling(\n        self: T_Processing,\n        target_sr: float,\n        **kwargs: Any,\n    ) -&gt; T_Processing:\n        \"\"\"Resample audio data.\n\n        Args:\n            target_sr: Target sampling rate (Hz)\n            **kwargs: Additional resampling parameters\n\n        Returns:\n            Resampled ChannelFrame\n        \"\"\"\n        return cast(\n            T_Processing,\n            self.apply_operation(\n                \"resampling\",\n                target_sr=target_sr,\n                **kwargs,\n            ),\n        )\n\n    def hpss_harmonic(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract harmonic components using HPSS\n         (Harmonic-Percussive Source Separation).\n\n        This method separates the harmonic (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n            n_fft: Size of FFT window.\n            hop_length: Hop length for STFT.\n            win_length: Window length for STFT.\n            window: Window type for STFT.\n            center: If True, center the frames.\n            pad_mode: Padding mode for STFT.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_harmonic\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def hpss_percussive(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract percussive components using HPSS\n        (Harmonic-Percussive Source Separation).\n\n        This method separates the percussive (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_percussive\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n        \"\"\"\n        Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of non-stationary signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            New ChannelFrame containing time-varying loudness values in sones.\n            Each channel is processed independently.\n            The output sampling rate is adjusted based on the loudness\n            calculation time resolution (typically ~500 Hz for 2ms steps).\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate loudness for a signal:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n        Notes:\n            - The output contains time-varying loudness values in sones\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - The time resolution is approximately 2ms (determined by the algorithm)\n            - For multi-channel signals, loudness is calculated per channel\n            - The output sampling rate is updated to reflect the time resolution\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 2ms analysis step. This differs slightly from the MoSQITo\n            library, which uses the center time of each step. For example:\n\n            - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n            - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n            The difference is very small (~1ms) and does not affect the loudness\n            values themselves. This design choice ensures consistency with\n            wandas's time axis convention across all frame types.\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n        \"\"\"\n        Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of stationary (steady) signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        This method is suitable for analyzing steady sounds such as fan noise,\n        constant machinery sounds, or other stationary signals.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            Loudness values in sones, one per channel. Shape: (n_channels,)\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate steady-state loudness for a fan noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n            &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n        Notes:\n            - Returns a 1D array with one loudness value per channel\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - For multi-channel signals, loudness is calculated independently\n              per channel\n            - This method is designed for stationary signals (constant sounds)\n            - For time-varying signals, use loudness_zwtv() instead\n            - Similar to the rms property, returns NDArrayReal for consistency\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        # Treat self as a ProcessingFrameProtocol so mypy understands\n        # where sampling_rate and data come from.\n        from wandas.processing.psychoacoustic import LoudnessZwst\n        from wandas.utils.types import NDArrayReal\n\n        # Create operation instance\n        operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n        # Get data (triggers computation if lazy)\n        data = self.data\n\n        # Ensure data is 2D (n_channels, n_samples)\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        # Process the array using the public API and materialize to NumPy\n        result = operation.process_array(data).compute()\n\n        # Squeeze to get 1D array (n_channels,)\n        loudness_values: NDArrayReal = result.squeeze()\n\n        # Ensure it's 1D even for single channel\n        if loudness_values.ndim == 0:\n            loudness_values = loudness_values.reshape(1)\n\n        return loudness_values\n\n    def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n        \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n        Roughness is a psychoacoustic metric that quantifies the perceived\n        harshness or roughness of a sound, measured in asper. This method\n        implements the Daniel &amp; Weber (1997) standard calculation.\n\n        The calculation follows the standard formula:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            New ChannelFrame containing time-varying roughness values in asper.\n            The output sampling rate depends on the overlap parameter.\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Calculate roughness for a motor noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n            &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n            &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n            Analyze roughness statistics:\n            &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n            &gt;&gt;&gt; max_roughness = roughness.data.max()\n            &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n            &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n            Compare before and after modification:\n            &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n            &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n            &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n            &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n        Notes:\n            - Returns a ChannelFrame with time-varying roughness values\n            - Typical roughness values: 0-2 asper for most sounds\n            - Higher values indicate rougher, harsher sounds\n            - For multi-channel signals, roughness is calculated independently\n              per channel\n            - This is the standard-compliant total roughness (R)\n            - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 200ms analysis window. This differs from the MoSQITo library,\n            which uses the center time of each window. For example:\n\n            - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n            - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n            The difference is constant (half the window duration = 100ms) and\n            does not affect the roughness values themselves. This design choice\n            ensures consistency with wandas's time axis convention across all\n            frame types.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n        logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n        result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n        return cast(T_Processing, result)\n\n    def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n        \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n        This method returns detailed roughness analysis data organized by\n        Bark frequency bands over time, allowing for frequency-specific\n        roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n        The relationship between total roughness and specific roughness:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            RoughnessFrame containing:\n                - data: Specific roughness by Bark band, shape (47, n_time)\n                        for mono or (n_channels, 47, n_time) for multi-channel\n                - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n                - time: Time axis for each analysis frame\n                - overlap: Overlap coefficient used\n                - plot(): Method for Bark-Time heatmap visualization\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Analyze frequency-specific roughness:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n            &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Plot Bark-Time heatmap\n            &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Find dominant Bark band\n            &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n            &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n            &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Extract specific Bark band time series\n            &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n            &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Verify standard formula\n            &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n            &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n        Notes:\n            - Returns a RoughnessFrame (not ChannelFrame)\n            - Contains 47 Bark bands from 0.5 to 23.5 Bark\n            - Each Bark band corresponds to a critical band of hearing\n            - Useful for identifying which frequencies contribute most to roughness\n            - The specific roughness can be integrated to obtain total roughness\n            - For simple time-series analysis, use roughness_dw() instead\n\n            **Time axis convention:**\n            The time axis represents the start time of each 200ms analysis\n            window, consistent with roughness_dw() and other wandas methods.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n\n        params = {\"overlap\": overlap}\n        operation_name = \"roughness_dw_spec\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance via factory\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing lazily to self._data (Dask)\n        r_spec_dask = operation.process(self._data)\n\n        # Get metadata updates (sampling rate, bark_axis)\n        metadata_updates = operation.get_metadata_updates()\n\n        # Build metadata and history\n        new_metadata = {**self.metadata, **params}\n        new_history = [\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ]\n\n        # Extract bark_axis with proper type handling\n        bark_axis_value = metadata_updates.get(\"bark_axis\")\n        if bark_axis_value is None:\n            raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n        # Create RoughnessFrame. operation.get_metadata_updates() should provide\n        # sampling_rate and bark_axis\n        roughness_frame = RoughnessFrame(\n            data=r_spec_dask,\n            sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n            bark_axis=bark_axis_value,\n            overlap=overlap,\n            label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=cast(\"BaseFrame[NDArrayReal]\", self),\n        )\n\n        logger.debug(\n            \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n            operation_name,\n            r_spec_dask.shape,\n            roughness_frame.sampling_rate,\n        )\n\n        return roughness_frame\n\n    def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n        \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n        This method applies a symmetric fade-in and fade-out envelope to the signal\n        using a Tukey (tapered cosine) window. The fade duration is the same for\n        both the beginning and end of the signal.\n\n        Args:\n            fade_ms: Fade duration in milliseconds for each end of the signal.\n                The total fade duration is 2 * fade_ms. Default is 50 ms.\n                Must be positive and less than half the signal duration.\n\n        Returns:\n            New ChannelFrame containing the faded signal\n\n        Raises:\n            ValueError: If fade_ms is negative or too long for the signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n            &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n            &gt;&gt;&gt; # Apply very short fade (almost no effect)\n            &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n        Notes:\n            - Uses SciPy's Tukey window for smooth fade transitions\n            - Fade is applied symmetrically to both ends of the signal\n            - The Tukey window alpha parameter is computed automatically\n              based on the fade duration and signal length\n            - For multi-channel signals, the same fade envelope is applied\n              to all channels\n            - Lazy evaluation is preserved - computation occurs only when needed\n        \"\"\"\n        logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n        result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n        return cast(T_Processing, result)\n</code></pre> Functions\u00b6 <code></code> <code>high_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a high-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def high_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a high-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>low_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a low-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def low_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a low-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>band_pass_filter(low_cutoff, high_cutoff, order=4)</code> \u00b6 <p>Apply a band-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>low_cutoff</code> <code>float</code> <p>Lower cutoff frequency (Hz)</p> required <code>high_cutoff</code> <code>float</code> <p>Higher cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def band_pass_filter(\n    self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a band-pass filter to the signal.\n\n    Args:\n        low_cutoff: Lower cutoff frequency (Hz)\n        high_cutoff: Higher cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n        f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"bandpass_filter\",\n        low_cutoff=low_cutoff,\n        high_cutoff=high_cutoff,\n        order=order,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>normalize(norm=float('inf'), axis=-1, threshold=None, fill=None)</code> \u00b6 <p>Normalize signal levels using librosa.util.normalize.</p> <p>This method normalizes the signal amplitude according to the specified norm.</p> <p>Parameters:</p> Name Type Description Default <code>norm</code> <code>float | None</code> <p>Norm type. Default is np.inf (maximum absolute value normalization). Supported values: - np.inf: Maximum absolute value normalization - -np.inf: Minimum absolute value normalization - 0: Peak normalization - float: Lp norm - None: No normalization</p> <code>float('inf')</code> <code>axis</code> <code>int | None</code> <p>Axis along which to normalize. Default is -1 (time axis). - -1: Normalize along time axis (each channel independently) - None: Global normalization across all axes - int: Normalize along specified axis</p> <code>-1</code> <code>threshold</code> <code>float | None</code> <p>Threshold below which values are considered zero. If None, no threshold is applied.</p> <code>None</code> <code>fill</code> <code>bool | None</code> <p>Value to fill when the norm is zero. If None, the zero vector remains zero.</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the normalized signal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n&gt;&gt;&gt; normalized = signal.normalize()\n&gt;&gt;&gt; # Global normalization across all channels\n&gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n&gt;&gt;&gt; # L2 normalization\n&gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n</code></pre> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def normalize(\n    self: T_Processing,\n    norm: float | None = float(\"inf\"),\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n) -&gt; T_Processing:\n    \"\"\"Normalize signal levels using librosa.util.normalize.\n\n    This method normalizes the signal amplitude according to the specified norm.\n\n    Args:\n        norm: Norm type. Default is np.inf (maximum absolute value normalization).\n            Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Peak normalization\n            - float: Lp norm\n            - None: No normalization\n        axis: Axis along which to normalize. Default is -1 (time axis).\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold: Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill: Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n    Returns:\n        New ChannelFrame containing the normalized signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n        &gt;&gt;&gt; normalized = signal.normalize()\n        &gt;&gt;&gt; # Global normalization across all channels\n        &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n        &gt;&gt;&gt; # L2 normalization\n        &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n    \"\"\"\n    logger.debug(\n        f\"Setting up normalize: norm={norm}, axis={axis}, \"\n        f\"threshold={threshold}, fill={fill} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>remove_dc()</code> \u00b6 <p>Remove DC component (DC offset) from the signal.</p> <p>This method removes the DC (direct current) component by subtracting the mean value from each channel. This is equivalent to centering the signal around zero.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame with DC component removed</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create signal with DC offset\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n&gt;&gt;&gt; # Remove DC offset\n&gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n&gt;&gt;&gt; # Verify DC removal\n&gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n</code></pre> Notes <ul> <li>This operation is performed per channel</li> <li>Equivalent to applying a high-pass filter with very low cutoff</li> <li>Useful for removing sensor drift or measurement offset</li> </ul> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def remove_dc(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This method removes the DC (direct current) component by subtracting\n    the mean value from each channel. This is equivalent to centering the\n    signal around zero.\n\n    Returns:\n        New ChannelFrame with DC component removed\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # Create signal with DC offset\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n        &gt;&gt;&gt; # Remove DC offset\n        &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n        &gt;&gt;&gt; # Verify DC removal\n        &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n    Notes:\n        - This operation is performed per channel\n        - Equivalent to applying a high-pass filter with very low cutoff\n        - Useful for removing sensor drift or measurement offset\n    \"\"\"\n    logger.debug(\"Setting up DC removal (lazy)\")\n    result = self.apply_operation(\"remove_dc\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>a_weighting()</code> \u00b6 <p>Apply A-weighting filter to the signal.</p> <p>A-weighting adjusts the frequency response to approximate human auditory perception, according to the IEC 61672-1:2013 standard.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the A-weighted signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def a_weighting(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Apply A-weighting filter to the signal.\n\n    A-weighting adjusts the frequency response to approximate human\n    auditory perception, according to the IEC 61672-1:2013 standard.\n\n    Returns:\n        New ChannelFrame containing the A-weighted signal\n    \"\"\"\n    result = self.apply_operation(\"a_weighting\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>abs()</code> \u00b6 <p>Compute the absolute value of the signal.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the absolute values</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def abs(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Compute the absolute value of the signal.\n\n    Returns:\n        New ChannelFrame containing the absolute values\n    \"\"\"\n    result = self.apply_operation(\"abs\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>power(exponent=2.0)</code> \u00b6 <p>Compute the power of the signal.</p> <p>Parameters:</p> Name Type Description Default <code>exponent</code> <code>float</code> <p>Exponent to raise the signal to. Default is 2.0.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the powered signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n    \"\"\"Compute the power of the signal.\n\n    Args:\n        exponent: Exponent to raise the signal to. Default is 2.0.\n\n    Returns:\n        New ChannelFrame containing the powered signal\n    \"\"\"\n    result = self.apply_operation(\"power\", exponent=exponent)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>sum()</code> \u00b6 <p>Sum all channels.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame with summed signal.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def sum(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Sum all channels.\n\n    Returns:\n        A new ChannelFrame with summed signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n</code></pre> <code></code> <code>mean()</code> \u00b6 <p>Average all channels.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame with averaged signal.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def mean(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Average all channels.\n\n    Returns:\n        A new ChannelFrame with averaged signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n</code></pre> <code></code> <code>trim(start=0, end=None)</code> \u00b6 <p>Trim the signal to the specified time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float</code> <p>Start time (seconds)</p> <code>0</code> <code>end</code> <code>float | None</code> <p>End time (seconds)</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the trimmed signal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If end time is earlier than start time</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def trim(\n    self: T_Processing,\n    start: float = 0,\n    end: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Trim the signal to the specified time range.\n\n    Args:\n        start: Start time (seconds)\n        end: End time (seconds)\n\n    Returns:\n        New ChannelFrame containing the trimmed signal\n\n    Raises:\n        ValueError: If end time is earlier than start time\n    \"\"\"\n    if end is None:\n        end = self.duration\n    if start &gt; end:\n        raise ValueError(\"start must be less than end\")\n    result = self.apply_operation(\"trim\", start=start, end=end)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>fix_length(length=None, duration=None)</code> \u00b6 <p>Adjust the signal to the specified length.</p> <p>Parameters:</p> Name Type Description Default <code>duration</code> <code>float | None</code> <p>Signal length in seconds</p> <code>None</code> <code>length</code> <code>int | None</code> <p>Signal length in samples</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the adjusted signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fix_length(\n    self: T_Processing,\n    length: int | None = None,\n    duration: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Adjust the signal to the specified length.\n\n    Args:\n        duration: Signal length in seconds\n        length: Signal length in samples\n\n    Returns:\n        New ChannelFrame containing the adjusted signal\n    \"\"\"\n\n    result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>rms_trend(frame_length=2048, hop_length=512, dB=False, Aw=False)</code> \u00b6 <p>Compute the RMS trend of the signal.</p> <p>This method calculates the root mean square value over a sliding window.</p> <p>Parameters:</p> Name Type Description Default <code>frame_length</code> <code>int</code> <p>Size of the sliding window in samples. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int</code> <p>Hop length between windows in samples. Default is 512.</p> <code>512</code> <code>dB</code> <code>bool</code> <p>Whether to return RMS values in decibels. Default is False.</p> <code>False</code> <code>Aw</code> <code>bool</code> <p>Whether to apply A-weighting. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the RMS trend</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def rms_trend(\n    self: T_Processing,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; T_Processing:\n    \"\"\"Compute the RMS trend of the signal.\n\n    This method calculates the root mean square value over a sliding window.\n\n    Args:\n        frame_length: Size of the sliding window in samples. Default is 2048.\n        hop_length: Hop length between windows in samples. Default is 512.\n        dB: Whether to return RMS values in decibels. Default is False.\n        Aw: Whether to apply A-weighting. Default is False.\n\n    Returns:\n        New ChannelFrame containing the RMS trend\n    \"\"\"\n    # Access _channel_metadata to retrieve reference values\n    frame = cast(ProcessingFrameProtocol, self)\n\n    # Ensure _channel_metadata exists before referencing\n    ref_values = []\n    if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n        ref_values = [ch.ref for ch in frame._channel_metadata]\n\n    result = self.apply_operation(\n        \"rms_trend\",\n        frame_length=frame_length,\n        hop_length=hop_length,\n        ref=ref_values,\n        dB=dB,\n        Aw=Aw,\n    )\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>channel_difference(other_channel=0)</code> \u00b6 <p>Compute the difference between channels.</p> <p>Parameters:</p> Name Type Description Default <code>other_channel</code> <code>int | str</code> <p>Index or label of the reference channel. Default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the channel difference</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def channel_difference(\n    self: T_Processing, other_channel: int | str = 0\n) -&gt; T_Processing:\n    \"\"\"Compute the difference between channels.\n\n    Args:\n        other_channel: Index or label of the reference channel. Default is 0.\n\n    Returns:\n        New ChannelFrame containing the channel difference\n    \"\"\"\n    # label2index is a method of BaseFrame\n    if isinstance(other_channel, str):\n        if hasattr(self, \"label2index\"):\n            other_channel = self.label2index(other_channel)\n\n    result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>resampling(target_sr, **kwargs)</code> \u00b6 <p>Resample audio data.</p> <p>Parameters:</p> Name Type Description Default <code>target_sr</code> <code>float</code> <p>Target sampling rate (Hz)</p> required <code>**kwargs</code> <code>Any</code> <p>Additional resampling parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>Resampled ChannelFrame</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def resampling(\n    self: T_Processing,\n    target_sr: float,\n    **kwargs: Any,\n) -&gt; T_Processing:\n    \"\"\"Resample audio data.\n\n    Args:\n        target_sr: Target sampling rate (Hz)\n        **kwargs: Additional resampling parameters\n\n    Returns:\n        Resampled ChannelFrame\n    \"\"\"\n    return cast(\n        T_Processing,\n        self.apply_operation(\n            \"resampling\",\n            target_sr=target_sr,\n            **kwargs,\n        ),\n    )\n</code></pre> <code></code> <code>hpss_harmonic(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract harmonic components using HPSS  (Harmonic-Percussive Source Separation).</p> <p>This method separates the harmonic (tonal) components from the signal.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <code>n_fft</code> <code>int</code> <p>Size of FFT window.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Hop length for STFT.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length for STFT.</p> <code>None</code> <code>window</code> <code>_WindowSpec</code> <p>Window type for STFT.</p> <code>'hann'</code> <code>center</code> <code>bool</code> <p>If True, center the frames.</p> <code>True</code> <code>pad_mode</code> <code>_PadModeSTFT</code> <p>Padding mode for STFT.</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_harmonic(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract harmonic components using HPSS\n     (Harmonic-Percussive Source Separation).\n\n    This method separates the harmonic (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n        n_fft: Size of FFT window.\n        hop_length: Hop length for STFT.\n        win_length: Window length for STFT.\n        window: Window type for STFT.\n        center: If True, center the frames.\n        pad_mode: Padding mode for STFT.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_harmonic\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>hpss_percussive(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract percussive components using HPSS (Harmonic-Percussive Source Separation).</p> <p>This method separates the percussive (tonal) components from the signal.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_percussive(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract percussive components using HPSS\n    (Harmonic-Percussive Source Separation).\n\n    This method separates the percussive (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_percussive\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwtv(field_type='free')</code> \u00b6 <p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing time-varying loudness values in sones.</p> <code>T_Processing</code> <p>Each channel is processed independently.</p> <code>T_Processing</code> <p>The output sampling rate is adjusted based on the loudness</p> <code>T_Processing</code> <p>calculation time resolution (typically ~500 Hz for 2ms steps).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>Examples:</p> <p>Calculate loudness for a signal:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre> Notes <ul> <li>The output contains time-varying loudness values in sones</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>The time resolution is approximately 2ms (determined by the algorithm)</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The output sampling rate is updated to reflect the time resolution</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 2ms analysis step. This differs slightly from the MoSQITo library, which uses the center time of each step. For example:</p> <ul> <li>wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)</li> <li>MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)</li> </ul> <p>The difference is very small (~1ms) and does not affect the loudness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        New ChannelFrame containing time-varying loudness values in sones.\n        Each channel is processed independently.\n        The output sampling rate is adjusted based on the loudness\n        calculation time resolution (typically ~500 Hz for 2ms steps).\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate loudness for a signal:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n    Notes:\n        - The output contains time-varying loudness values in sones\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - The time resolution is approximately 2ms (determined by the algorithm)\n        - For multi-channel signals, loudness is calculated per channel\n        - The output sampling rate is updated to reflect the time resolution\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 2ms analysis step. This differs slightly from the MoSQITo\n        library, which uses the center time of each step. For example:\n\n        - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n        - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n        The difference is very small (~1ms) and does not affect the loudness\n        values themselves. This design choice ensures consistency with\n        wandas's time axis convention across all frame types.\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwst(field_type='free')</code> \u00b6 <p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>This method is suitable for analyzing steady sounds such as fan noise, constant machinery sounds, or other stationary signals.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Loudness values in sones, one per channel. Shape: (n_channels,)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>Examples:</p> <p>Calculate steady-state loudness for a fan noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n&gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre> Notes <ul> <li>Returns a 1D array with one loudness value per channel</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>For multi-channel signals, loudness is calculated independently   per channel</li> <li>This method is designed for stationary signals (constant sounds)</li> <li>For time-varying signals, use loudness_zwtv() instead</li> <li>Similar to the rms property, returns NDArrayReal for consistency</li> </ul> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    This method is suitable for analyzing steady sounds such as fan noise,\n    constant machinery sounds, or other stationary signals.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        Loudness values in sones, one per channel. Shape: (n_channels,)\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate steady-state loudness for a fan noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n        &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n    Notes:\n        - Returns a 1D array with one loudness value per channel\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - For multi-channel signals, loudness is calculated independently\n          per channel\n        - This method is designed for stationary signals (constant sounds)\n        - For time-varying signals, use loudness_zwtv() instead\n        - Similar to the rms property, returns NDArrayReal for consistency\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    # Treat self as a ProcessingFrameProtocol so mypy understands\n    # where sampling_rate and data come from.\n    from wandas.processing.psychoacoustic import LoudnessZwst\n    from wandas.utils.types import NDArrayReal\n\n    # Create operation instance\n    operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n    # Get data (triggers computation if lazy)\n    data = self.data\n\n    # Ensure data is 2D (n_channels, n_samples)\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    # Process the array using the public API and materialize to NumPy\n    result = operation.process_array(data).compute()\n\n    # Squeeze to get 1D array (n_channels,)\n    loudness_values: NDArrayReal = result.squeeze()\n\n    # Ensure it's 1D even for single channel\n    if loudness_values.ndim == 0:\n        loudness_values = loudness_values.reshape(1)\n\n    return loudness_values\n</code></pre> <code></code> <code>roughness_dw(overlap=0.5)</code> \u00b6 <p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound, measured in asper. This method implements the Daniel &amp; Weber (1997) standard calculation.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>Parameters:</p> Name Type Description Default <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing time-varying roughness values in asper.</p> <code>T_Processing</code> <p>The output sampling rate depends on the overlap parameter.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>Examples:</p> <p>Calculate roughness for a motor noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n&gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n&gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n</code></pre> <p>Analyze roughness statistics:</p> <pre><code>&gt;&gt;&gt; mean_roughness = roughness.data.mean()\n&gt;&gt;&gt; max_roughness = roughness.data.max()\n&gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n&gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n</code></pre> <p>Compare before and after modification:</p> <pre><code>&gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n&gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n&gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n&gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n</code></pre> Notes <ul> <li>Returns a ChannelFrame with time-varying roughness values</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher values indicate rougher, harsher sounds</li> <li>For multi-channel signals, roughness is calculated independently   per channel</li> <li>This is the standard-compliant total roughness (R)</li> <li>For detailed Bark-band analysis, use roughness_dw_spec() instead</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 200ms analysis window. This differs from the MoSQITo library, which uses the center time of each window. For example:</p> <ul> <li>wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)</li> <li>MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)</li> </ul> <p>The difference is constant (half the window duration = 100ms) and does not affect the roughness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n    \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound, measured in asper. This method\n    implements the Daniel &amp; Weber (1997) standard calculation.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        New ChannelFrame containing time-varying roughness values in asper.\n        The output sampling rate depends on the overlap parameter.\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Calculate roughness for a motor noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n        &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n        &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n        Analyze roughness statistics:\n        &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n        &gt;&gt;&gt; max_roughness = roughness.data.max()\n        &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n        &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n        Compare before and after modification:\n        &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n        &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n        &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n        &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n    Notes:\n        - Returns a ChannelFrame with time-varying roughness values\n        - Typical roughness values: 0-2 asper for most sounds\n        - Higher values indicate rougher, harsher sounds\n        - For multi-channel signals, roughness is calculated independently\n          per channel\n        - This is the standard-compliant total roughness (R)\n        - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 200ms analysis window. This differs from the MoSQITo library,\n        which uses the center time of each window. For example:\n\n        - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n        - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n        The difference is constant (half the window duration = 100ms) and\n        does not affect the roughness values themselves. This design choice\n        ensures consistency with wandas's time axis convention across all\n        frame types.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n    logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n    result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>roughness_dw_spec(overlap=0.5)</code> \u00b6 <p>Calculate specific roughness with Bark-band frequency information.</p> <p>This method returns detailed roughness analysis data organized by Bark frequency bands over time, allowing for frequency-specific roughness analysis. It uses the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>Parameters:</p> Name Type Description Default <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>RoughnessFrame</code> <p>RoughnessFrame containing: - data: Specific roughness by Bark band, shape (47, n_time)         for mono or (n_channels, 47, n_time) for multi-channel - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5) - time: Time axis for each analysis frame - overlap: Overlap coefficient used - plot(): Method for Bark-Time heatmap visualization</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>Examples:</p> <p>Analyze frequency-specific roughness:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n&gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot Bark-Time heatmap\n&gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find dominant Bark band\n&gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n&gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n&gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Extract specific Bark band time series\n&gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n&gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify standard formula\n&gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n&gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n</code></pre> Notes <ul> <li>Returns a RoughnessFrame (not ChannelFrame)</li> <li>Contains 47 Bark bands from 0.5 to 23.5 Bark</li> <li>Each Bark band corresponds to a critical band of hearing</li> <li>Useful for identifying which frequencies contribute most to roughness</li> <li>The specific roughness can be integrated to obtain total roughness</li> <li>For simple time-series analysis, use roughness_dw() instead</li> </ul> <p>Time axis convention: The time axis represents the start time of each 200ms analysis window, consistent with roughness_dw() and other wandas methods.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n    \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n    This method returns detailed roughness analysis data organized by\n    Bark frequency bands over time, allowing for frequency-specific\n    roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n    The relationship between total roughness and specific roughness:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        RoughnessFrame containing:\n            - data: Specific roughness by Bark band, shape (47, n_time)\n                    for mono or (n_channels, 47, n_time) for multi-channel\n            - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n            - time: Time axis for each analysis frame\n            - overlap: Overlap coefficient used\n            - plot(): Method for Bark-Time heatmap visualization\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Analyze frequency-specific roughness:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot Bark-Time heatmap\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Find dominant Bark band\n        &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n        &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n        &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Extract specific Bark band time series\n        &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n        &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verify standard formula\n        &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n        &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n    Notes:\n        - Returns a RoughnessFrame (not ChannelFrame)\n        - Contains 47 Bark bands from 0.5 to 23.5 Bark\n        - Each Bark band corresponds to a critical band of hearing\n        - Useful for identifying which frequencies contribute most to roughness\n        - The specific roughness can be integrated to obtain total roughness\n        - For simple time-series analysis, use roughness_dw() instead\n\n        **Time axis convention:**\n        The time axis represents the start time of each 200ms analysis\n        window, consistent with roughness_dw() and other wandas methods.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n\n    params = {\"overlap\": overlap}\n    operation_name = \"roughness_dw_spec\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance via factory\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n\n    # Apply processing lazily to self._data (Dask)\n    r_spec_dask = operation.process(self._data)\n\n    # Get metadata updates (sampling rate, bark_axis)\n    metadata_updates = operation.get_metadata_updates()\n\n    # Build metadata and history\n    new_metadata = {**self.metadata, **params}\n    new_history = [\n        *self.operation_history,\n        {\"operation\": operation_name, \"params\": params},\n    ]\n\n    # Extract bark_axis with proper type handling\n    bark_axis_value = metadata_updates.get(\"bark_axis\")\n    if bark_axis_value is None:\n        raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n    # Create RoughnessFrame. operation.get_metadata_updates() should provide\n    # sampling_rate and bark_axis\n    roughness_frame = RoughnessFrame(\n        data=r_spec_dask,\n        sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n        bark_axis=bark_axis_value,\n        overlap=overlap,\n        label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=cast(\"BaseFrame[NDArrayReal]\", self),\n    )\n\n    logger.debug(\n        \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n        operation_name,\n        r_spec_dask.shape,\n        roughness_frame.sampling_rate,\n    )\n\n    return roughness_frame\n</code></pre> <code></code> <code>fade(fade_ms=50)</code> \u00b6 <p>Apply symmetric fade-in and fade-out to the signal using Tukey window.</p> <p>This method applies a symmetric fade-in and fade-out envelope to the signal using a Tukey (tapered cosine) window. The fade duration is the same for both the beginning and end of the signal.</p> <p>Parameters:</p> Name Type Description Default <code>fade_ms</code> <code>float</code> <p>Fade duration in milliseconds for each end of the signal. The total fade duration is 2 * fade_ms. Default is 50 ms. Must be positive and less than half the signal duration.</p> <code>50</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the faded signal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If fade_ms is negative or too long for the signal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n&gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n&gt;&gt;&gt; # Apply very short fade (almost no effect)\n&gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n</code></pre> Notes <ul> <li>Uses SciPy's Tukey window for smooth fade transitions</li> <li>Fade is applied symmetrically to both ends of the signal</li> <li>The Tukey window alpha parameter is computed automatically   based on the fade duration and signal length</li> <li>For multi-channel signals, the same fade envelope is applied   to all channels</li> <li>Lazy evaluation is preserved - computation occurs only when needed</li> </ul> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n    \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n    This method applies a symmetric fade-in and fade-out envelope to the signal\n    using a Tukey (tapered cosine) window. The fade duration is the same for\n    both the beginning and end of the signal.\n\n    Args:\n        fade_ms: Fade duration in milliseconds for each end of the signal.\n            The total fade duration is 2 * fade_ms. Default is 50 ms.\n            Must be positive and less than half the signal duration.\n\n    Returns:\n        New ChannelFrame containing the faded signal\n\n    Raises:\n        ValueError: If fade_ms is negative or too long for the signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n        &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n        &gt;&gt;&gt; # Apply very short fade (almost no effect)\n        &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n    Notes:\n        - Uses SciPy's Tukey window for smooth fade transitions\n        - Fade is applied symmetrically to both ends of the signal\n        - The Tukey window alpha parameter is computed automatically\n          based on the fade duration and signal length\n        - For multi-channel signals, the same fade envelope is applied\n          to all channels\n        - Lazy evaluation is preserved - computation occurs only when needed\n    \"\"\"\n    logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n    result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n    return cast(T_Processing, result)\n</code></pre> Functions\u00b6"},{"location":"api/#wandas.frames.mixins.channel_transform_mixin","title":"<code>channel_transform_mixin</code>","text":"<p>Module providing mixins related to frequency transformations and transform operations.</p> Attributes\u00b6 <code>logger = logging.getLogger(__name__)</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>ChannelTransformMixin</code> \u00b6 <p>Mixin providing methods related to frequency transformations.</p> <p>This mixin provides operations related to frequency analysis and transformations such as FFT, STFT, and Welch method.</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>class ChannelTransformMixin:\n    \"\"\"Mixin providing methods related to frequency transformations.\n\n    This mixin provides operations related to frequency analysis and\n    transformations such as FFT, STFT, and Welch method.\n    \"\"\"\n\n    def fft(\n        self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate Fast Fourier Transform (FFT).\n\n        Args:\n            n_fft: Number of FFT points. Default is the next power of 2 of the data\n                length.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectralFrame containing FFT results\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import FFT, create_operation\n\n        params = {\"n_fft\": n_fft, \"window\": window}\n        operation_name = \"fft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"FFT\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        if n_fft is None:\n            is_even = spectrum_data.shape[-1] % 2 == 0\n            _n_fft = (\n                spectrum_data.shape[-1] * 2 - 2\n                if is_even\n                else spectrum_data.shape[-1] * 2 - 1\n            )\n        else:\n            _n_fft = n_fft\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=_n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def welch(\n        self: T_Transform,\n        n_fft: int | None = None,\n        hop_length: int | None = None,\n        win_length: int = 2048,\n        window: str = \"hann\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate power spectral density using Welch's method.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing power spectral density\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import Welch, create_operation\n\n        params = dict(\n            n_fft=n_fft or win_length,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            average=average,\n        )\n        operation_name = \"welch\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Welch\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"welch\", \"params\": params},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def noct_spectrum(\n        self: T_Transform,\n        fmin: float = 25,\n        fmax: float = 20000,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; \"NOctFrame\":\n        \"\"\"Calculate N-octave band spectrum.\n\n        Args:\n            fmin: Minimum center frequency (Hz). Default is 25 Hz.\n            fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n            n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n            G: Reference gain (dB). Default is 10 dB.\n            fr: Reference frequency (Hz). Default is 1000 Hz.\n\n        Returns:\n            NOctFrame containing N-octave band spectrum\n        \"\"\"\n        from wandas.processing import NOctSpectrum, create_operation\n\n        from ..noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_spectrum\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSpectrum\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_spectrum\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def stft(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Calculate Short-Time Fourier Transform.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectrogramFrame containing STFT results\n        \"\"\"\n        from wandas.processing import STFT, create_operation\n\n        from ..spectrogram import SpectrogramFrame\n\n        # Set hop length and window length\n        _hop_length = hop_length if hop_length is not None else n_fft // 4\n        _win_length = win_length if win_length is not None else n_fft\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": _hop_length,\n            \"win_length\": _win_length,\n            \"window\": window,\n        }\n        operation_name = \"stft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"STFT\", operation)\n\n        # Apply processing to data\n        spectrogram_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new instance\n        return SpectrogramFrame(\n            data=spectrogram_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=n_fft,\n            hop_length=_hop_length,\n            win_length=_win_length,\n            window=window,\n            label=f\"stft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def coherence(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate magnitude squared coherence.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n        Returns:\n            SpectralFrame containing magnitude squared coherence\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.processing import Coherence, create_operation\n\n        from ..spectral import SpectralFrame\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n        }\n        operation_name = \"coherence\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Coherence\", operation)\n\n        # Apply processing to data\n        coherence_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=coherence_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Coherence of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def csd(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate cross-spectral density matrix.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing cross-spectral density matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import CSD, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"csd\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"CSD\", operation)\n\n        # Apply processing to data\n        csd_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=csd_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def transfer_function(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate transfer function matrix.\n\n        The transfer function represents the signal transfer characteristics between\n        channels in the frequency domain and represents the input-output relationship\n        of the system.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing transfer function matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import TransferFunction, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"transfer_function\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"TransferFunction\", operation)\n\n        # Apply processing to data\n        tf_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=tf_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Transfer function of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n</code></pre> Functions\u00b6 <code></code> <code>fft(n_fft=None, window='hann')</code> \u00b6 <p>Calculate Fast Fourier Transform (FFT).</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is the next power of 2 of the data length.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing FFT results</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def fft(\n    self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate Fast Fourier Transform (FFT).\n\n    Args:\n        n_fft: Number of FFT points. Default is the next power of 2 of the data\n            length.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectralFrame containing FFT results\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import FFT, create_operation\n\n    params = {\"n_fft\": n_fft, \"window\": window}\n    operation_name = \"fft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"FFT\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    if n_fft is None:\n        is_even = spectrum_data.shape[-1] % 2 == 0\n        _n_fft = (\n            spectrum_data.shape[-1] * 2 - 2\n            if is_even\n            else spectrum_data.shape[-1] * 2 - 1\n        )\n    else:\n        _n_fft = n_fft\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=_n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>welch(n_fft=None, hop_length=None, win_length=2048, window='hann', average='mean')</code> \u00b6 <p>Calculate power spectral density using Welch's method.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is 2048.</p> <code>None</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int</code> <p>Window length. Default is n_fft.</p> <code>2048</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing power spectral density</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def welch(\n    self: T_Transform,\n    n_fft: int | None = None,\n    hop_length: int | None = None,\n    win_length: int = 2048,\n    window: str = \"hann\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate power spectral density using Welch's method.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing power spectral density\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import Welch, create_operation\n\n    params = dict(\n        n_fft=n_fft or win_length,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        average=average,\n    )\n    operation_name = \"welch\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Welch\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"welch\", \"params\": params},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>noct_spectrum(fmin=25, fmax=20000, n=3, G=10, fr=1000)</code> \u00b6 <p>Calculate N-octave band spectrum.</p> <p>Parameters:</p> Name Type Description Default <code>fmin</code> <code>float</code> <p>Minimum center frequency (Hz). Default is 25 Hz.</p> <code>25</code> <code>fmax</code> <code>float</code> <p>Maximum center frequency (Hz). Default is 20000 Hz.</p> <code>20000</code> <code>n</code> <code>int</code> <p>Band division (1: octave, 3: 1/3 octave). Default is 3.</p> <code>3</code> <code>G</code> <code>int</code> <p>Reference gain (dB). Default is 10 dB.</p> <code>10</code> <code>fr</code> <code>int</code> <p>Reference frequency (Hz). Default is 1000 Hz.</p> <code>1000</code> <p>Returns:</p> Type Description <code>NOctFrame</code> <p>NOctFrame containing N-octave band spectrum</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def noct_spectrum(\n    self: T_Transform,\n    fmin: float = 25,\n    fmax: float = 20000,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; \"NOctFrame\":\n    \"\"\"Calculate N-octave band spectrum.\n\n    Args:\n        fmin: Minimum center frequency (Hz). Default is 25 Hz.\n        fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n        n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n        G: Reference gain (dB). Default is 10 dB.\n        fr: Reference frequency (Hz). Default is 1000 Hz.\n\n    Returns:\n        NOctFrame containing N-octave band spectrum\n    \"\"\"\n    from wandas.processing import NOctSpectrum, create_operation\n\n    from ..noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_spectrum\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSpectrum\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_spectrum\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Calculate Short-Time Fourier Transform.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>Returns:</p> Type Description <code>SpectrogramFrame</code> <p>SpectrogramFrame containing STFT results</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def stft(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Calculate Short-Time Fourier Transform.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectrogramFrame containing STFT results\n    \"\"\"\n    from wandas.processing import STFT, create_operation\n\n    from ..spectrogram import SpectrogramFrame\n\n    # Set hop length and window length\n    _hop_length = hop_length if hop_length is not None else n_fft // 4\n    _win_length = win_length if win_length is not None else n_fft\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": _hop_length,\n        \"win_length\": _win_length,\n        \"window\": window,\n    }\n    operation_name = \"stft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"STFT\", operation)\n\n    # Apply processing to data\n    spectrogram_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new instance\n    return SpectrogramFrame(\n        data=spectrogram_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=n_fft,\n        hop_length=_hop_length,\n        win_length=_win_length,\n        window=window,\n        label=f\"stft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>coherence(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code> \u00b6 <p>Calculate magnitude squared coherence.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing magnitude squared coherence</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def coherence(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate magnitude squared coherence.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n    Returns:\n        SpectralFrame containing magnitude squared coherence\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.processing import Coherence, create_operation\n\n    from ..spectral import SpectralFrame\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n    }\n    operation_name = \"coherence\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Coherence\", operation)\n\n    # Apply processing to data\n    coherence_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=coherence_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Coherence of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>csd(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate cross-spectral density matrix.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing cross-spectral density matrix</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def csd(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate cross-spectral density matrix.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing cross-spectral density matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import CSD, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"csd\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"CSD\", operation)\n\n    # Apply processing to data\n    csd_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=csd_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>transfer_function(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate transfer function matrix.</p> <p>The transfer function represents the signal transfer characteristics between channels in the frequency domain and represents the input-output relationship of the system.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing transfer function matrix</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def transfer_function(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate transfer function matrix.\n\n    The transfer function represents the signal transfer characteristics between\n    channels in the frequency domain and represents the input-output relationship\n    of the system.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing transfer function matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import TransferFunction, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"transfer_function\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"TransferFunction\", operation)\n\n    # Apply processing to data\n    tf_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=tf_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Transfer function of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.mixins.protocols","title":"<code>protocols</code>","text":"<p>Common protocol definition module.</p> <p>This module contains common protocols used by mixin classes.</p> Attributes\u00b6 <code>logger = logging.getLogger(__name__)</code> <code>module-attribute</code> \u00b6 <code></code> <code>T_Base = TypeVar('T_Base', bound='BaseFrameProtocol')</code> <code>module-attribute</code> \u00b6 <code></code> <code>T_Processing = TypeVar('T_Processing', bound=ProcessingFrameProtocol)</code> <code>module-attribute</code> \u00b6 <code></code> <code>T_Transform = TypeVar('T_Transform', bound=TransformFrameProtocol)</code> <code>module-attribute</code> \u00b6 <code></code> <code>__all__ = ['BaseFrameProtocol', 'ProcessingFrameProtocol', 'TransformFrameProtocol', 'T_Processing']</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>BaseFrameProtocol</code> \u00b6 <p>               Bases: <code>Protocol</code></p> <p>Protocol that defines basic frame operations.</p> <p>Defines the basic methods and properties provided by all frame classes.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>@runtime_checkable\nclass BaseFrameProtocol(Protocol):\n    \"\"\"Protocol that defines basic frame operations.\n\n    Defines the basic methods and properties provided by all frame classes.\n    \"\"\"\n\n    _data: DaArray\n    sampling_rate: float\n    _channel_metadata: list[ChannelMetadata]\n    metadata: dict[str, Any]\n    operation_history: list[dict[str, Any]]\n    label: str\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Returns the duration in seconds.\"\"\"\n        ...\n\n    @property\n    def data(self) -&gt; NDArrayReal:\n        \"\"\"Returns the computed data as a NumPy array.\n\n        Implementations should materialize any lazy computation (e.g. Dask)\n        and return a concrete NumPy array.\n        \"\"\"\n        ...\n\n    def label2index(self, label: str) -&gt; int:\n        \"\"\"\n        Get the index from a channel label.\n        \"\"\"\n        ...\n\n    def apply_operation(\n        self, operation_name: str, **params: Any\n    ) -&gt; \"BaseFrameProtocol\":\n        \"\"\"Apply a named operation.\n\n        Args:\n            operation_name: Name of the operation to apply\n            **params: Parameters to pass to the operation\n\n        Returns:\n            A new frame instance with the operation applied\n        \"\"\"\n        ...\n\n    def _create_new_instance(self: T_Base, data: DaArray, **kwargs: Any) -&gt; T_Base:\n        \"\"\"Create a new instance of the frame with updated data and metadata.\n        Args:\n            data: The new data for the frame\n            metadata: The new metadata for the frame\n            operation_history: The new operation history for the frame\n            channel_metadata: The new channel metadata for the frame\n        Returns:\n            A new instance of the frame with the updated data and metadata\n        \"\"\"\n        ...\n</code></pre> Attributes\u00b6 <code></code> <code>sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>metadata</code> <code>instance-attribute</code> \u00b6 <code></code> <code>operation_history</code> <code>instance-attribute</code> \u00b6 <code></code> <code>label</code> <code>instance-attribute</code> \u00b6 <code></code> <code>duration</code> <code>property</code> \u00b6 <p>Returns the duration in seconds.</p> <code></code> <code>data</code> <code>property</code> \u00b6 <p>Returns the computed data as a NumPy array.</p> <p>Implementations should materialize any lazy computation (e.g. Dask) and return a concrete NumPy array.</p> Functions\u00b6 <code></code> <code>label2index(label)</code> \u00b6 <p>Get the index from a channel label.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n    \"\"\"\n    ...\n</code></pre> <code></code> <code>apply_operation(operation_name, **params)</code> \u00b6 <p>Apply a named operation.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>Name of the operation to apply</p> required <code>**params</code> <code>Any</code> <p>Parameters to pass to the operation</p> <code>{}</code> <p>Returns:</p> Type Description <code>BaseFrameProtocol</code> <p>A new frame instance with the operation applied</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>def apply_operation(\n    self, operation_name: str, **params: Any\n) -&gt; \"BaseFrameProtocol\":\n    \"\"\"Apply a named operation.\n\n    Args:\n        operation_name: Name of the operation to apply\n        **params: Parameters to pass to the operation\n\n    Returns:\n        A new frame instance with the operation applied\n    \"\"\"\n    ...\n</code></pre> <code></code> <code>ProcessingFrameProtocol</code> \u00b6 <p>               Bases: <code>BaseFrameProtocol</code>, <code>Protocol</code></p> <p>Protocol that defines operations related to signal processing.</p> <p>Defines methods that provide frame operations related to signal processing.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>@runtime_checkable\nclass ProcessingFrameProtocol(BaseFrameProtocol, Protocol):\n    \"\"\"Protocol that defines operations related to signal processing.\n\n    Defines methods that provide frame operations related to signal processing.\n    \"\"\"\n\n    pass\n</code></pre> <code></code> <code>TransformFrameProtocol</code> \u00b6 <p>               Bases: <code>BaseFrameProtocol</code>, <code>Protocol</code></p> <p>Protocol related to transform operations.</p> <p>Defines methods that provide operations such as frequency analysis and spectral transformation.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>@runtime_checkable\nclass TransformFrameProtocol(BaseFrameProtocol, Protocol):\n    \"\"\"Protocol related to transform operations.\n\n    Defines methods that provide operations such as frequency analysis and\n    spectral transformation.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#wandas.frames.noct","title":"<code>noct</code>","text":""},{"location":"api/#wandas.frames.noct-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.noct.dask_delayed","title":"<code>dask_delayed = dask.delayed</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.noct.da_from_delayed","title":"<code>da_from_delayed = da.from_delayed</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.noct.da_from_array","title":"<code>da_from_array = da.from_array</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.noct.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.noct.S","title":"<code>S = TypeVar('S', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.noct-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.noct.NOctFrame","title":"<code>NOctFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code></p> <p>Class for handling N-octave band analysis data.</p> <p>This class represents frequency data analyzed in fractional octave bands, typically used in acoustic and vibration analysis. It handles real-valued data representing energy or power in each frequency band, following standard acoustical band definitions.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The N-octave band data. Must be a dask array with shape:     - (channels, frequency_bins) for multi-channel data     - (frequency_bins,) for single-channel data, which will be       reshaped to (1, frequency_bins) sampling_rate : float     The sampling rate of the original time-domain signal in Hz. fmin : float, default=0     Lower frequency bound in Hz. fmax : float, default=0     Upper frequency bound in Hz. n : int, default=3     Number of bands per octave (e.g., 3 for third-octave bands). G : int, default=10     Reference band number according to IEC 61260-1:2014. fr : int, default=1000     Reference frequency in Hz, typically 1000 Hz for acoustic analysis. label : str, optional     A label for the frame. metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel in the frame. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame--attributes","title":"Attributes","text":"<p>freqs : NDArrayReal     The center frequencies of each band in Hz, calculated according to     the standard fractional octave band definitions. dB : NDArrayReal     The spectrum in decibels relative to channel reference values. dBA : NDArrayReal     The A-weighted spectrum in decibels, applying frequency weighting     for better correlation with perceived loudness. fmin : float     Lower frequency bound in Hz. fmax : float     Upper frequency bound in Hz. n : int     Number of bands per octave. G : int     Reference band number. fr : int     Reference frequency in Hz.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame--examples","title":"Examples","text":"<p>Create an N-octave band spectrum from a time-domain signal:</p> <p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrum = signal.noct_spectrum(fmin=20, fmax=20000, n=3)</p> <p>Plot the N-octave band spectrum:</p> <p>spectrum.plot()</p> <p>Plot with A-weighting applied:</p> <p>spectrum.plot(Aw=True)</p>"},{"location":"api/#wandas.frames.noct.NOctFrame--notes","title":"Notes","text":"<ul> <li>Binary operations (addition, multiplication, etc.) are not currently   supported for N-octave band data.</li> <li>The actual frequency bands are determined by the parameters n, G, and fr   according to IEC 61260-1:2014 standard for fractional octave band filters.</li> <li>The class follows acoustic standards for band definitions and analysis,   making it suitable for noise measurements and sound level analysis.</li> <li>A-weighting is available for better correlation with human hearing   perception, following IEC 61672-1:2013.</li> </ul> Source code in <code>wandas/frames/noct.py</code> <pre><code>class NOctFrame(BaseFrame[NDArrayReal]):\n    \"\"\"\n    Class for handling N-octave band analysis data.\n\n    This class represents frequency data analyzed in fractional octave bands,\n    typically used in acoustic and vibration analysis. It handles real-valued\n    data representing energy or power in each frequency band, following standard\n    acoustical band definitions.\n\n    Parameters\n    ----------\n    data : DaArray\n        The N-octave band data. Must be a dask array with shape:\n        - (channels, frequency_bins) for multi-channel data\n        - (frequency_bins,) for single-channel data, which will be\n          reshaped to (1, frequency_bins)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    fmin : float, default=0\n        Lower frequency bound in Hz.\n    fmax : float, default=0\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number according to IEC 61260-1:2014.\n    fr : int, default=1000\n        Reference frequency in Hz, typically 1000 Hz for acoustic analysis.\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    freqs : NDArrayReal\n        The center frequencies of each band in Hz, calculated according to\n        the standard fractional octave band definitions.\n    dB : NDArrayReal\n        The spectrum in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrum in decibels, applying frequency weighting\n        for better correlation with perceived loudness.\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int\n        Number of bands per octave.\n    G : int\n        Reference band number.\n    fr : int\n        Reference frequency in Hz.\n\n    Examples\n    --------\n    Create an N-octave band spectrum from a time-domain signal:\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrum = signal.noct_spectrum(fmin=20, fmax=20000, n=3)\n\n    Plot the N-octave band spectrum:\n    &gt;&gt;&gt; spectrum.plot()\n\n    Plot with A-weighting applied:\n    &gt;&gt;&gt; spectrum.plot(Aw=True)\n\n    Notes\n    -----\n    - Binary operations (addition, multiplication, etc.) are not currently\n      supported for N-octave band data.\n    - The actual frequency bands are determined by the parameters n, G, and fr\n      according to IEC 61260-1:2014 standard for fractional octave band filters.\n    - The class follows acoustic standards for band definitions and analysis,\n      making it suitable for noise measurements and sound level analysis.\n    - A-weighting is available for better correlation with human hearing\n      perception, following IEC 61672-1:2013.\n    \"\"\"\n\n    fmin: float\n    fmax: float\n    n: int\n    G: int\n    fr: int\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        fmin: float = 0,\n        fmax: float = 0,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a NOctFrame instance.\n\n        Sets up N-octave band analysis parameters and prepares the frame for\n        storing band-filtered data. Data shape is validated to ensure compatibility\n        with N-octave band analysis.\n\n        See class docstring for parameter descriptions.\n        \"\"\"\n        self.n = n\n        self.G = G\n        self.fr = fr\n        self.fmin = fmin\n        self.fmax = fmax\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrum in decibels relative to each channel's reference value.\n\n        The reference value for each channel is specified in its metadata.\n        A minimum value of -120 dB is enforced to avoid numerical issues.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrum in decibels. Shape matches the input data shape:\n            (channels, frequency_bins).\n        \"\"\"\n        # Collect dB reference values from _channel_metadata\n        ref = np.array([ch.ref for ch in self._channel_metadata])\n        # Convert to dB\n        # Use either the maximum value or 1e-12 to avoid division by zero\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(self.data / ref[..., np.newaxis], 1e-12)\n        )\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrum in decibels.\n\n        A-weighting applies a frequency-dependent weighting filter that approximates\n        the human ear's response to different frequencies. This is particularly useful\n        for analyzing noise and acoustic measurements as it provides a better\n        correlation with perceived loudness.\n\n        The weighting is applied according to IEC 61672-1:2013 standard.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrum in decibels. Shape matches the input data shape:\n            (channels, frequency_bins).\n        \"\"\"\n        # Collect dB reference values from _channel_metadata\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels in the N-octave band data.\n        \"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the center frequencies of each band in Hz.\n\n        These frequencies are calculated based on the N-octave band parameters\n        (n, G, fr) and the frequency bounds (fmin, fmax) according to\n        IEC 61260-1:2014 standard for fractional octave band filters.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of center frequencies for each frequency band.\n\n        Raises\n        ------\n        ValueError\n            If the center frequencies cannot be calculated or the result\n            is not a numpy array.\n        \"\"\"\n        _, freqs = _center_freq(\n            fmax=self.fmax,\n            fmin=self.fmin,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if isinstance(freqs, np.ndarray):\n            return freqs\n        else:\n            raise ValueError(\"freqs is not numpy array.\")\n\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"\n        Binary operations are not currently supported for N-octave band data.\n\n        Parameters\n        ----------\n        other : Union[S, int, float, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation.\n        symbol : str\n            String representation of the operation (e.g., '+', '-', '*', '/').\n\n        Raises\n        ------\n        NotImplementedError\n            Always raises this error as operations are not implemented\n            for N-octave band data.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Operation {symbol} is not implemented for NOctFrame.\"\n        )\n        return self\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply operations using lazy evaluation.\n        \"\"\"\n        # Apply operations using lazy evaluation\n        raise NotImplementedError(\n            f\"Operation {operation_name} is not implemented for NOctFrame.\"\n        )\n        return self\n\n    def plot(\n        self,\n        plot_type: str = \"noct\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the N-octave band data using various visualization strategies.\n\n        Supports standard plotting configurations for acoustic analysis,\n        including decibel scales and A-weighting.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"noct\"\n            Type of plot to create. The default \"noct\" type creates a step plot\n            suitable for displaying N-octave band data.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses a default title with band specification.\n        overlay : bool, default=False\n            Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel : str, optional\n            Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n        ylabel : str, optional\n            Label for the y-axis. If None, uses default based on data type.\n        alpha : float, default=1.0\n            Transparency level for the plot lines (0.0 to 1.0).\n        xlim : tuple[float, float], optional\n            Limits for the x-axis as (min, max) tuple.\n        ylim : tuple[float, float], optional\n            Limits for the y-axis as (min, max) tuple.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the data.\n        **kwargs : dict\n            Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; noct = spectrum.noct(n=3)\n        &gt;&gt;&gt; # Basic 1/3-octave plot\n        &gt;&gt;&gt; noct.plot()\n        &gt;&gt;&gt; # Overlay with A-weighting\n        &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get additional initialization arguments for NOctFrame.\n\n        This internal method provides the additional initialization arguments\n        required by NOctFrame beyond those required by BaseFrame. These include\n        the N-octave band analysis parameters that define the frequency bands.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments specific to NOctFrame:\n            - n: Number of bands per octave\n            - G: Reference band number\n            - fr: Reference frequency\n            - fmin: Lower frequency bound\n            - fmax: Upper frequency bound\n        \"\"\"\n        return {\n            \"n\": self.n,\n            \"G\": self.G,\n            \"fr\": self.fr,\n            \"fmin\": self.fmin,\n            \"fmax\": self.fmax,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get frequency index for DataFrame.\"\"\"\n        return pd.Index(self.freqs, name=\"frequency\")\n</code></pre> Attributes\u00b6 <code></code> <code>n = n</code> <code>instance-attribute</code> \u00b6 <code></code> <code>G = G</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fr = fr</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmin = fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax = fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>dB</code> <code>property</code> \u00b6 <p>Get the spectrum in decibels relative to each channel's reference value.</p> <p>The reference value for each channel is specified in its metadata. A minimum value of -120 dB is enforced to avoid numerical issues.</p> <code></code> <code>dBA</code> <code>property</code> \u00b6 <p>Get the A-weighted spectrum in decibels.</p> <p>A-weighting applies a frequency-dependent weighting filter that approximates the human ear's response to different frequencies. This is particularly useful for analyzing noise and acoustic measurements as it provides a better correlation with perceived loudness.</p> <p>The weighting is applied according to IEC 61672-1:2013 standard.</p> <code></code> <code>freqs</code> <code>property</code> \u00b6 <p>Get the center frequencies of each band in Hz.</p> <p>These frequencies are calculated based on the N-octave band parameters (n, G, fr) and the frequency bounds (fmin, fmax) according to IEC 61260-1:2014 standard for fractional octave band filters.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, fmin=0, fmax=0, n=3, G=10, fr=1000, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 <p>Initialize a NOctFrame instance.</p> <p>Sets up N-octave band analysis parameters and prepares the frame for storing band-filtered data. Data shape is validated to ensure compatibility with N-octave band analysis.</p> <p>See class docstring for parameter descriptions.</p> Source code in <code>wandas/frames/noct.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    fmin: float = 0,\n    fmax: float = 0,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a NOctFrame instance.\n\n    Sets up N-octave band analysis parameters and prepares the frame for\n    storing band-filtered data. Data shape is validated to ensure compatibility\n    with N-octave band analysis.\n\n    See class docstring for parameter descriptions.\n    \"\"\"\n    self.n = n\n    self.G = G\n    self.fr = fr\n    self.fmin = fmin\n    self.fmax = fmax\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>plot(plot_type='noct', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, Aw=False, **kwargs)</code> \u00b6 <p>Plot the N-octave band data using various visualization strategies.</p> <p>Supports standard plotting configurations for acoustic analysis, including decibel scales and A-weighting.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.dB--returns","title":"Returns","text":"<p>NDArrayReal     The spectrum in decibels. Shape matches the input data shape:     (channels, frequency_bins).</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.dBA--returns","title":"Returns","text":"<p>NDArrayReal     The A-weighted spectrum in decibels. Shape matches the input data shape:     (channels, frequency_bins).</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.freqs--returns","title":"Returns","text":"<p>NDArrayReal     Array of center frequencies for each frequency band.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.freqs--raises","title":"Raises","text":"<p>ValueError     If the center frequencies cannot be calculated or the result     is not a numpy array.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.plot--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"noct\"     Type of plot to create. The default \"noct\" type creates a step plot     suitable for displaying N-octave band data. ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. title : str, optional     Title for the plot. If None, uses a default title with band specification. overlay : bool, default=False     Whether to overlay all channels on a single plot (True)     or create separate subplots for each channel (False). xlabel : str, optional     Label for the x-axis. If None, uses default \"Center frequency [Hz]\". ylabel : str, optional     Label for the y-axis. If None, uses default based on data type. alpha : float, default=1.0     Transparency level for the plot lines (0.0 to 1.0). xlim : tuple[float, float], optional     Limits for the x-axis as (min, max) tuple. ylim : tuple[float, float], optional     Limits for the y-axis as (min, max) tuple. Aw : bool, default=False     Whether to apply A-weighting to the data. **kwargs : dict     Additional matplotlib Line2D parameters     (e.g., color, linewidth, linestyle).</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.plot--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot, or an iterator of axes     for multi-plot outputs.</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.plot--examples","title":"Examples","text":"<p>noct = spectrum.noct(n=3)</p> Source code in <code>wandas/frames/noct.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"noct\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the N-octave band data using various visualization strategies.\n\n    Supports standard plotting configurations for acoustic analysis,\n    including decibel scales and A-weighting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"noct\"\n        Type of plot to create. The default \"noct\" type creates a step plot\n        suitable for displaying N-octave band data.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses a default title with band specification.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; noct = spectrum.noct(n=3)\n    &gt;&gt;&gt; # Basic 1/3-octave plot\n    &gt;&gt;&gt; noct.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/#wandas.frames.noct.NOctFrame.plot--basic-13-octave-plot","title":"Basic 1/3-octave plot","text":"<p>noct.plot()</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.plot--overlay-with-a-weighting","title":"Overlay with A-weighting","text":"<p>noct.plot(overlay=True, Aw=True)</p>"},{"location":"api/#wandas.frames.noct.NOctFrame.plot--custom-styling","title":"Custom styling","text":"<p>noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)</p>"},{"location":"api/#wandas.frames.roughness","title":"<code>roughness</code>","text":"<p>Roughness analysis frame for detailed psychoacoustic analysis.</p>"},{"location":"api/#wandas.frames.roughness-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.roughness.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.roughness-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.roughness.RoughnessFrame","title":"<code>RoughnessFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code></p> <p>Frame for detailed roughness analysis with Bark-band information.</p> <p>This frame contains specific roughness (R_spec) data organized by Bark frequency bands over time, calculated using the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness follows: R = 0.25 * sum(R_spec, axis=bark_bands)</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--parameters","title":"Parameters","text":"<p>data : da.Array     Specific roughness data with shape:     - (n_bark_bands, n_time) for mono signals     - (n_channels, n_bark_bands, n_time) for multi-channel signals     where n_bark_bands is always 47. sampling_rate : float     Sampling rate of the roughness time series in Hz.     For overlap=0.5, this is approximately 10 Hz (100ms hop).     For overlap=0.0, this is approximately 5 Hz (200ms hop). bark_axis : NDArrayReal     Bark frequency axis with 47 values from 0.5 to 23.5 Bark. overlap : float     Overlap coefficient used in the calculation (0.0 to 1.0). label : str, optional     Frame label. Defaults to \"roughness_spec\". metadata : dict, optional     Additional metadata. operation_history : list[dict], optional     History of operations applied to this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel. previous : BaseFrame, optional     Reference to the previous frame in the processing chain.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--attributes","title":"Attributes","text":"<p>bark_axis : NDArrayReal     Frequency axis in Bark scale. n_bark_bands : int     Number of Bark bands (always 47). n_time_points : int     Number of time points. time : NDArrayReal     Time axis based on sampling rate. overlap : float     Overlap coefficient used (0.0 to 1.0).</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--examples","title":"Examples","text":"<p>Create a roughness frame from a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"motor.wav\") roughness_spec = signal.roughness_dw_spec(overlap=0.5)</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--plot-bark-time-heatmap","title":"Plot Bark-Time heatmap","text":"<p>roughness_spec.plot()</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--find-dominant-bark-band","title":"Find dominant Bark band","text":"<p>dominant_idx = roughness_spec.data.mean(axis=1).argmax() dominant_bark = roughness_spec.bark_axis[dominant_idx] print(f\"Dominant frequency: {dominant_bark:.1f} Bark\")</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--extract-specific-bark-band","title":"Extract specific Bark band","text":"<p>bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0)) roughness_at_10bark = roughness_spec.data[bark_10_idx, :]</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--notes","title":"Notes","text":"<p>The Daniel &amp; Weber (1997) roughness model calculates specific roughness for 47 critical bands (Bark scale) over time, then integrates them to produce the total roughness:</p> <p>.. math::     R = 0.25 \\sum_{i=1}^{47} R'_i</p> <p>where R'_i is the specific roughness in the i-th Bark band.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame--references","title":"References","text":"<p>.. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:        Implementation of an optimized model\". Acta Acustica united with        Acustica, 83(1), 113-123.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>class RoughnessFrame(BaseFrame[NDArrayReal]):\n    \"\"\"\n    Frame for detailed roughness analysis with Bark-band information.\n\n    This frame contains specific roughness (R_spec) data organized by\n    Bark frequency bands over time, calculated using the Daniel &amp; Weber (1997)\n    method.\n\n    The relationship between total roughness and specific roughness follows:\n    R = 0.25 * sum(R_spec, axis=bark_bands)\n\n    Parameters\n    ----------\n    data : da.Array\n        Specific roughness data with shape:\n        - (n_bark_bands, n_time) for mono signals\n        - (n_channels, n_bark_bands, n_time) for multi-channel signals\n        where n_bark_bands is always 47.\n    sampling_rate : float\n        Sampling rate of the roughness time series in Hz.\n        For overlap=0.5, this is approximately 10 Hz (100ms hop).\n        For overlap=0.0, this is approximately 5 Hz (200ms hop).\n    bark_axis : NDArrayReal\n        Bark frequency axis with 47 values from 0.5 to 23.5 Bark.\n    overlap : float\n        Overlap coefficient used in the calculation (0.0 to 1.0).\n    label : str, optional\n        Frame label. Defaults to \"roughness_spec\".\n    metadata : dict, optional\n        Additional metadata.\n    operation_history : list[dict], optional\n        History of operations applied to this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel.\n    previous : BaseFrame, optional\n        Reference to the previous frame in the processing chain.\n\n    Attributes\n    ----------\n    bark_axis : NDArrayReal\n        Frequency axis in Bark scale.\n    n_bark_bands : int\n        Number of Bark bands (always 47).\n    n_time_points : int\n        Number of time points.\n    time : NDArrayReal\n        Time axis based on sampling rate.\n    overlap : float\n        Overlap coefficient used (0.0 to 1.0).\n\n    Examples\n    --------\n    Create a roughness frame from a signal:\n\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Plot Bark-Time heatmap\n    &gt;&gt;&gt; roughness_spec.plot()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Find dominant Bark band\n    &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n    &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n    &gt;&gt;&gt; print(f\"Dominant frequency: {dominant_bark:.1f} Bark\")\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Extract specific Bark band\n    &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n    &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n\n    Notes\n    -----\n    The Daniel &amp; Weber (1997) roughness model calculates specific roughness\n    for 47 critical bands (Bark scale) over time, then integrates them to\n    produce the total roughness:\n\n    .. math::\n        R = 0.25 \\\\sum_{i=1}^{47} R'_i\n\n    where R'_i is the specific roughness in the i-th Bark band.\n\n    References\n    ----------\n    .. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n           Implementation of an optimized model\". Acta Acustica united with\n           Acustica, 83(1), 113-123.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: da.Array,\n        sampling_rate: float,\n        bark_axis: NDArrayReal,\n        overlap: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a RoughnessFrame.\"\"\"\n        # Validate dimensions\n        if data.ndim not in (2, 3):\n            raise ValueError(\n                f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n            )\n\n        # Validate Bark bands\n        if data.shape[-2] != 47:\n            raise ValueError(\n                f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n                f\"(data shape: {data.shape})\"\n            )\n\n        if len(bark_axis) != 47:\n            raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n        # Validate overlap\n        if not 0.0 &lt;= overlap &lt;= 1.0:\n            raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n        # Store Bark-specific attributes\n        self._bark_axis = bark_axis\n        self._overlap = overlap\n\n        # Initialize base frame\n        metadata = metadata or {}\n        metadata[\"overlap\"] = overlap\n\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label or \"roughness_spec\",\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def data(self) -&gt; NDArrayReal:\n        \"\"\"\n        Returns the computed data without squeezing.\n\n        For RoughnessFrame, even mono signals have 2D shape (47, n_time)\n        so we don't squeeze the channel dimension.\n\n        Returns\n        -------\n        NDArrayReal\n            Computed data array.\n        \"\"\"\n        return self.compute()\n\n    @property\n    def bark_axis(self) -&gt; NDArrayReal:\n        \"\"\"\n        Bark frequency axis.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of 47 Bark values from 0.5 to 23.5 Bark.\n        \"\"\"\n        return self._bark_axis\n\n    @property\n    def n_bark_bands(self) -&gt; int:\n        \"\"\"\n        Number of Bark bands.\n\n        Returns\n        -------\n        int\n            Always 47 for the Daniel &amp; Weber model.\n        \"\"\"\n        return 47\n\n    @property\n    def n_time_points(self) -&gt; int:\n        \"\"\"\n        Number of time points in the roughness time series.\n\n        Returns\n        -------\n        int\n            Number of time frames in the analysis.\n        \"\"\"\n        return int(self._data.shape[-1])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"\n        Time axis based on sampling rate.\n\n        Returns\n        -------\n        NDArrayReal\n            Time values in seconds for each frame.\n        \"\"\"\n        return np.arange(self.n_time_points) / self.sampling_rate\n\n    @property\n    def overlap(self) -&gt; float:\n        \"\"\"\n        Overlap coefficient used in the calculation.\n\n        Returns\n        -------\n        float\n            Overlap value between 0.0 and 1.0.\n        \"\"\"\n        return self._overlap\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Return the number of channels.\n\n        Returns\n        -------\n        int\n            Number of channels. For 2D data (mono), returns 1.\n        \"\"\"\n        if self._data.ndim == 2:\n            return 1\n        return int(self._data.shape[0])\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Provide additional initialization arguments for RoughnessFrame.\n\n        Returns\n        -------\n        dict\n            Dictionary containing bark_axis and overlap\n        \"\"\"\n        return {\n            \"bark_axis\": self._bark_axis,\n            \"overlap\": self._overlap,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"DataFrame index is not supported for RoughnessFrame.\"\"\"\n        raise NotImplementedError(\n            \"DataFrame index is not supported for RoughnessFrame.\"\n        )\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n        RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n        which cannot be directly converted to a 2D DataFrame.\n\n        Raises\n        ------\n        NotImplementedError\n            Always raised as DataFrame conversion is not supported.\n        \"\"\"\n        raise NotImplementedError(\n            \"DataFrame conversion is not supported for RoughnessFrame.\"\n        )\n\n    def _binary_op(\n        self,\n        other: Union[\"RoughnessFrame\", int, float, NDArrayReal, da.Array],\n        op: \"Callable[[da.Array, Any], da.Array]\",\n        symbol: str,\n    ) -&gt; \"RoughnessFrame\":\n        \"\"\"\n        Common implementation for binary operations.\n\n        Parameters\n        ----------\n        other : RoughnessFrame, int, float, NDArrayReal, or da.Array\n            Right operand for the operation.\n        op : Callable\n            Function to execute the operation.\n        symbol : str\n            Symbolic representation of the operation.\n\n        Returns\n        -------\n        RoughnessFrame\n            A new RoughnessFrame with the operation result.\n\n        Raises\n        ------\n        ValueError\n            If sampling rates don't match or shapes are incompatible.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle metadata and operation_history\n        metadata = self.metadata.copy() if self.metadata else {}\n        operation_history = (\n            self.operation_history.copy() if self.operation_history else []\n        )\n\n        # Check if other is a RoughnessFrame\n        if isinstance(other, RoughnessFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    f\"Sampling rates do not match: {self.sampling_rate} vs \"\n                    f\"{other.sampling_rate}\"\n                )\n\n            if self._data.shape != other._data.shape:\n                raise ValueError(\n                    f\"Shape mismatch: {self._data.shape} vs {other._data.shape}\"\n                )\n\n            # Apply operation\n            result_data = op(self._data, other._data)\n\n            # Update operation history\n            operation_history.append(\n                {\"name\": f\"binary_op_{symbol}\", \"params\": {\"other\": \"RoughnessFrame\"}}\n            )\n\n        else:\n            # Scalar or array operation\n            if isinstance(other, np.ndarray):\n                other = da.from_array(other, chunks=self._data.chunks)\n\n            result_data = op(self._data, other)\n\n            operation_history.append(\n                {\"name\": f\"binary_op_{symbol}\", \"params\": {\"other\": str(type(other))}}\n            )\n\n        # Create new instance\n        return RoughnessFrame(\n            data=result_data,\n            sampling_rate=self.sampling_rate,\n            bark_axis=self._bark_axis,\n            overlap=self._overlap,\n            label=self.label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def _apply_operation_impl(\n        self, operation_name: str, **params: Any\n    ) -&gt; \"RoughnessFrame\":\n        \"\"\"\n        Implementation of operation application.\n\n        Note: RoughnessFrame is typically a terminal node in processing chains.\n        Most operations are not directly applicable to spectral roughness data.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Operation parameters.\n\n        Returns\n        -------\n        RoughnessFrame\n            A new RoughnessFrame with the operation applied.\n\n        Raises\n        ------\n        NotImplementedError\n            As most operations are not applicable to roughness spectrograms.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Operation '{operation_name}' is not supported for RoughnessFrame. \"\n            \"RoughnessFrame is typically a terminal node in the processing chain.\"\n        )\n\n    def plot(\n        self,\n        plot_type: str = \"heatmap\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        cmap: str = \"viridis\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlabel: str = \"Time [s]\",\n        ylabel: str = \"Frequency [Bark]\",\n        colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n        **kwargs: Any,\n    ) -&gt; \"Axes\":\n        \"\"\"\n        Plot Bark-Time-Roughness heatmap.\n\n        For multi-channel signals, the mean across channels is plotted.\n\n        Parameters\n        ----------\n        ax : Axes, optional\n            Matplotlib axes to plot on. If None, a new figure is created.\n        title : str, optional\n            Plot title. If None, a default title is used.\n        cmap : str, default=\"viridis\"\n            Colormap name for the heatmap.\n        vmin, vmax : float, optional\n            Color scale limits. If None, automatic scaling is used.\n        xlabel : str, default=\"Time [s]\"\n            Label for the x-axis.\n        ylabel : str, default=\"Frequency [Bark]\"\n            Label for the y-axis.\n        colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n            Label for the colorbar.\n        **kwargs : Any\n            Additional keyword arguments passed to pcolormesh.\n\n        Returns\n        -------\n        Axes\n            The matplotlib axes object containing the plot.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 6))\n\n        # Select data to plot (first channel for mono, mean for multi-channel)\n        # self._data is Dask array, self.data is computed NumPy array\n        computed_data = self.compute()\n\n        if computed_data.ndim == 2:\n            # Mono: (47, n_time)\n            data_to_plot = computed_data\n        else:\n            # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n            data_to_plot = computed_data.mean(axis=0)\n\n        # Create heatmap\n        im = ax.pcolormesh(\n            self.time,\n            self.bark_axis,\n            data_to_plot,\n            shading=\"auto\",\n            cmap=cmap,\n            vmin=vmin,\n            vmax=vmax,\n            **kwargs,\n        )\n\n        # Labels and title\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        if title is None:\n            title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n        ax.set_title(title)\n\n        # Colorbar\n        plt.colorbar(im, ax=ax, label=colorbar_label)\n\n        return ax\n</code></pre> Attributes\u00b6 <code></code> <code>data</code> <code>property</code> \u00b6 <p>Returns the computed data without squeezing.</p> <p>For RoughnessFrame, even mono signals have 2D shape (47, n_time) so we don't squeeze the channel dimension.</p> <code></code> <code>bark_axis</code> <code>property</code> \u00b6 <p>Bark frequency axis.</p> <code></code> <code>n_bark_bands</code> <code>property</code> \u00b6 <p>Number of Bark bands.</p> <code></code> <code>n_time_points</code> <code>property</code> \u00b6 <p>Number of time points in the roughness time series.</p> <code></code> <code>time</code> <code>property</code> \u00b6 <p>Time axis based on sampling rate.</p> <code></code> <code>overlap</code> <code>property</code> \u00b6 <p>Overlap coefficient used in the calculation.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, bark_axis, overlap, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 <p>Initialize a RoughnessFrame.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>def __init__(\n    self,\n    data: da.Array,\n    sampling_rate: float,\n    bark_axis: NDArrayReal,\n    overlap: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a RoughnessFrame.\"\"\"\n    # Validate dimensions\n    if data.ndim not in (2, 3):\n        raise ValueError(\n            f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n        )\n\n    # Validate Bark bands\n    if data.shape[-2] != 47:\n        raise ValueError(\n            f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n            f\"(data shape: {data.shape})\"\n        )\n\n    if len(bark_axis) != 47:\n        raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n    # Validate overlap\n    if not 0.0 &lt;= overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n    # Store Bark-specific attributes\n    self._bark_axis = bark_axis\n    self._overlap = overlap\n\n    # Initialize base frame\n    metadata = metadata or {}\n    metadata[\"overlap\"] = overlap\n\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label or \"roughness_spec\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>to_dataframe()</code> \u00b6 <p>DataFrame conversion is not supported for RoughnessFrame.</p> <p>RoughnessFrame contains 3D data (channels, bark_bands, time_frames) which cannot be directly converted to a 2D DataFrame.</p> <code></code> <code>plot(plot_type='heatmap', ax=None, title=None, cmap='viridis', vmin=None, vmax=None, xlabel='Time [s]', ylabel='Frequency [Bark]', colorbar_label='Specific Roughness [Asper/Bark]', **kwargs)</code> \u00b6 <p>Plot Bark-Time-Roughness heatmap.</p> <p>For multi-channel signals, the mean across channels is plotted.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.data--returns","title":"Returns","text":"<p>NDArrayReal     Computed data array.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.bark_axis--returns","title":"Returns","text":"<p>NDArrayReal     Array of 47 Bark values from 0.5 to 23.5 Bark.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.n_bark_bands--returns","title":"Returns","text":"<p>int     Always 47 for the Daniel &amp; Weber model.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.n_time_points--returns","title":"Returns","text":"<p>int     Number of time frames in the analysis.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.time--returns","title":"Returns","text":"<p>NDArrayReal     Time values in seconds for each frame.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.overlap--returns","title":"Returns","text":"<p>float     Overlap value between 0.0 and 1.0.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n    RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n    which cannot be directly converted to a 2D DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for RoughnessFrame.\"\n    )\n</code></pre>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.plot--parameters","title":"Parameters","text":"<p>ax : Axes, optional     Matplotlib axes to plot on. If None, a new figure is created. title : str, optional     Plot title. If None, a default title is used. cmap : str, default=\"viridis\"     Colormap name for the heatmap. vmin, vmax : float, optional     Color scale limits. If None, automatic scaling is used. xlabel : str, default=\"Time [s]\"     Label for the x-axis. ylabel : str, default=\"Frequency [Bark]\"     Label for the y-axis. colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"     Label for the colorbar. **kwargs : Any     Additional keyword arguments passed to pcolormesh.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.plot--returns","title":"Returns","text":"<p>Axes     The matplotlib axes object containing the plot.</p>"},{"location":"api/#wandas.frames.roughness.RoughnessFrame.plot--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"motor.wav\") roughness_spec = signal.roughness_dw_spec(overlap=0.5) roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"heatmap\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"viridis\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlabel: str = \"Time [s]\",\n    ylabel: str = \"Frequency [Bark]\",\n    colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n    **kwargs: Any,\n) -&gt; \"Axes\":\n    \"\"\"\n    Plot Bark-Time-Roughness heatmap.\n\n    For multi-channel signals, the mean across channels is plotted.\n\n    Parameters\n    ----------\n    ax : Axes, optional\n        Matplotlib axes to plot on. If None, a new figure is created.\n    title : str, optional\n        Plot title. If None, a default title is used.\n    cmap : str, default=\"viridis\"\n        Colormap name for the heatmap.\n    vmin, vmax : float, optional\n        Color scale limits. If None, automatic scaling is used.\n    xlabel : str, default=\"Time [s]\"\n        Label for the x-axis.\n    ylabel : str, default=\"Frequency [Bark]\"\n        Label for the y-axis.\n    colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n        Label for the colorbar.\n    **kwargs : Any\n        Additional keyword arguments passed to pcolormesh.\n\n    Returns\n    -------\n    Axes\n        The matplotlib axes object containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=(10, 6))\n\n    # Select data to plot (first channel for mono, mean for multi-channel)\n    # self._data is Dask array, self.data is computed NumPy array\n    computed_data = self.compute()\n\n    if computed_data.ndim == 2:\n        # Mono: (47, n_time)\n        data_to_plot = computed_data\n    else:\n        # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n        data_to_plot = computed_data.mean(axis=0)\n\n    # Create heatmap\n    im = ax.pcolormesh(\n        self.time,\n        self.bark_axis,\n        data_to_plot,\n        shading=\"auto\",\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n        **kwargs,\n    )\n\n    # Labels and title\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    if title is None:\n        title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n    ax.set_title(title)\n\n    # Colorbar\n    plt.colorbar(im, ax=ax, label=colorbar_label)\n\n    return ax\n</code></pre>"},{"location":"api/#wandas.frames.spectral","title":"<code>spectral</code>","text":""},{"location":"api/#wandas.frames.spectral-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.spectral.dask_delayed","title":"<code>dask_delayed = dask.delayed</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectral.da_from_delayed","title":"<code>da_from_delayed = da.from_delayed</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectral.da_from_array","title":"<code>da_from_array = da.from_array</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectral.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectral.S","title":"<code>S = TypeVar('S', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectral-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.spectral.SpectralFrame","title":"<code>SpectralFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayComplex]</code></p> <p>Class for handling frequency-domain signal data.</p> <p>This class represents spectral data, providing methods for spectral analysis, manipulation, and visualization. It handles complex-valued frequency domain data obtained through operations like FFT.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The spectral data. Must be a dask array with shape:     - (channels, frequency_bins) for multi-channel data     - (frequency_bins,) for single-channel data, which will be       reshaped to (1, frequency_bins) sampling_rate : float     The sampling rate of the original time-domain signal in Hz. n_fft : int     The FFT size used to generate this spectral data. window : str, default=\"hann\"     The window function used in the FFT. label : str, optional     A label for the frame. metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel in the frame. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame--attributes","title":"Attributes","text":"<p>magnitude : NDArrayReal     The magnitude spectrum of the data. phase : NDArrayReal     The phase spectrum in radians. unwrapped_phase : NDArrayReal     The unwrapped phase spectrum in radians. power : NDArrayReal     The power spectrum (magnitude squared). dB : NDArrayReal     The spectrum in decibels relative to channel reference values. dBA : NDArrayReal     The A-weighted spectrum in decibels. freqs : NDArrayReal     The frequency axis values in Hz.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame--examples","title":"Examples","text":"<p>Create a SpectralFrame from FFT:</p> <p>signal = ChannelFrame.from_numpy(data, sampling_rate=44100) spectrum = signal.fft(n_fft=2048)</p> <p>Plot the magnitude spectrum:</p> <p>spectrum.plot()</p> <p>Perform binary operations:</p> <p>scaled = spectrum * 2.0 summed = spectrum1 + spectrum2  # Must have matching sampling rates</p> <p>Convert back to time domain:</p> <p>time_signal = spectrum.ifft()</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame--notes","title":"Notes","text":"<ul> <li>All operations are performed lazily using dask arrays for efficient memory usage.</li> <li>Binary operations (+, -, *, /) can be performed between SpectralFrames or with   scalar values.</li> <li>The class maintains the processing history and metadata through all operations.</li> </ul> Source code in <code>wandas/frames/spectral.py</code> <pre><code>class SpectralFrame(BaseFrame[NDArrayComplex]):\n    \"\"\"\n    Class for handling frequency-domain signal data.\n\n    This class represents spectral data, providing methods for spectral analysis,\n    manipulation, and visualization. It handles complex-valued frequency domain data\n    obtained through operations like FFT.\n\n    Parameters\n    ----------\n    data : DaArray\n        The spectral data. Must be a dask array with shape:\n        - (channels, frequency_bins) for multi-channel data\n        - (frequency_bins,) for single-channel data, which will be\n          reshaped to (1, frequency_bins)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    n_fft : int\n        The FFT size used to generate this spectral data.\n    window : str, default=\"hann\"\n        The window function used in the FFT.\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    magnitude : NDArrayReal\n        The magnitude spectrum of the data.\n    phase : NDArrayReal\n        The phase spectrum in radians.\n    unwrapped_phase : NDArrayReal\n        The unwrapped phase spectrum in radians.\n    power : NDArrayReal\n        The power spectrum (magnitude squared).\n    dB : NDArrayReal\n        The spectrum in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrum in decibels.\n    freqs : NDArrayReal\n        The frequency axis values in Hz.\n\n    Examples\n    --------\n    Create a SpectralFrame from FFT:\n    &gt;&gt;&gt; signal = ChannelFrame.from_numpy(data, sampling_rate=44100)\n    &gt;&gt;&gt; spectrum = signal.fft(n_fft=2048)\n\n    Plot the magnitude spectrum:\n    &gt;&gt;&gt; spectrum.plot()\n\n    Perform binary operations:\n    &gt;&gt;&gt; scaled = spectrum * 2.0\n    &gt;&gt;&gt; summed = spectrum1 + spectrum2  # Must have matching sampling rates\n\n    Convert back to time domain:\n    &gt;&gt;&gt; time_signal = spectrum.ifft()\n\n    Notes\n    -----\n    - All operations are performed lazily using dask arrays for efficient memory usage.\n    - Binary operations (+, -, *, /) can be performed between SpectralFrames or with\n      scalar values.\n    - The class maintains the processing history and metadata through all operations.\n    \"\"\"\n\n    n_fft: int\n    window: str\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        n_fft: int,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: BaseFrame[Any] | None = None,\n    ) -&gt; None:\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def magnitude(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the magnitude spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The absolute values of the complex spectrum.\n        \"\"\"\n        return np.abs(self.data)\n\n    @property\n    def phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the phase spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The phase angles of the complex spectrum in radians.\n        \"\"\"\n        return np.angle(self.data)\n\n    @property\n    def unwrapped_phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the unwrapped phase spectrum.\n\n        The unwrapped phase removes discontinuities of 2\u03c0 radians, providing\n        continuous phase values across frequency bins.\n\n        Returns\n        -------\n        NDArrayReal\n            The unwrapped phase angles of the complex spectrum in radians.\n        \"\"\"\n        return np.unwrap(np.angle(self.data))\n\n    @property\n    def power(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the power spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The squared magnitude spectrum.\n        \"\"\"\n        return self.magnitude**2\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrum in decibels.\n\n        The reference values are taken from channel metadata. If no reference\n        is specified, uses 1.0.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrum in dB relative to channel references.\n        \"\"\"\n        mag: NDArrayReal = self.magnitude\n        ref_values: NDArrayReal = np.array([ch.ref for ch in self._channel_metadata])\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(mag / ref_values[:, np.newaxis], 1e-12)\n        )\n\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrum in decibels.\n\n        Applies A-weighting filter to the spectrum for better correlation with\n        perceived loudness.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrum in dB.\n        \"\"\"\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels.\n        \"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the frequency axis values in Hz.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of frequency values corresponding to each frequency bin.\n        \"\"\"\n        return np.fft.rfftfreq(self.n_fft, 1.0 / self.sampling_rate)\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Implementation of operation application for spectral data.\n\n        This internal method handles the application of various operations to\n        spectral data, maintaining lazy evaluation through dask.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters for the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n        return self._create_new_instance(\n            data=processed_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n        )\n\n    def _binary_op(\n        self,\n        other: (\n            SpectralFrame\n            | int\n            | float\n            | complex\n            | NDArrayComplex\n            | NDArrayReal\n            | DaArray\n        ),\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; SpectralFrame:\n        \"\"\"\n        Common implementation for binary operations.\n\n        This method handles binary operations between SpectralFrames and various types\n        of operands, maintaining lazy evaluation through dask arrays.\n\n        Parameters\n        ----------\n        other : Union[SpectralFrame, int, float, complex,\n                        NDArrayComplex, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation (e.g., lambda a, b: a + b)\n        symbol : str\n            String representation of the operation (e.g., '+')\n\n        Returns\n        -------\n        SpectralFrame\n            A new SpectralFrame containing the result of the operation.\n\n        Raises\n        ------\n        ValueError\n            If attempting to operate with a SpectralFrame\n            with a different sampling rate.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, SpectralFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Directly operate on dask arrays (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Combine channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return SpectralFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly to dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # String representation of operand for display\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, complex):\n                other_str = f\"complex({other.real}, {other.imag})\"\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return SpectralFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n            )\n\n    def plot(\n        self,\n        plot_type: str = \"frequency\",\n        ax: Axes | None = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"\n        Plot the spectral data using various visualization strategies.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"frequency\"\n            Type of plot to create. Options include:\n            - \"frequency\": Standard frequency plot\n            - \"matrix\": Matrix plot for comparing channels\n            - Other types as defined by available plot strategies\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses the frame label.\n        overlay : bool, default=False\n            Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel : str, optional\n            Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n        ylabel : str, optional\n            Label for the y-axis. If None, uses default based on data type.\n        alpha : float, default=1.0\n            Transparency level for the plot lines (0.0 to 1.0).\n        xlim : tuple[float, float], optional\n            Limits for the x-axis as (min, max) tuple.\n        ylim : tuple[float, float], optional\n            Limits for the y-axis as (min, max) tuple.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the data.\n        **kwargs : dict\n            Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; spectrum = cf.fft()\n        &gt;&gt;&gt; # Basic frequency plot\n        &gt;&gt;&gt; spectrum.plot()\n        &gt;&gt;&gt; # Overlay with A-weighting\n        &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def ifft(self) -&gt; ChannelFrame:\n        \"\"\"\n        Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n        This method transforms the frequency-domain data back to the time domain using\n        the inverse FFT operation. The window function used in the forward FFT is\n        taken into account to ensure proper reconstruction.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the time-domain signal.\n        \"\"\"\n        from ..processing import IFFT, create_operation\n        from .channel import ChannelFrame\n\n        params = {\"n_fft\": self.n_fft, \"window\": self.window}\n        operation_name = \"ifft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"IFFT\", operation)\n        # Apply processing to data\n        time_series = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Create new instance\n        return ChannelFrame(\n            data=time_series,\n            sampling_rate=self.sampling_rate,\n            label=f\"ifft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Provide additional initialization arguments required for SpectralFrame.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments for SpectralFrame.\n        \"\"\"\n        return {\n            \"n_fft\": self.n_fft,\n            \"window\": self.window,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; pd.Index[Any]:\n        \"\"\"Get frequency index for DataFrame.\"\"\"\n        return pd.Index(self.freqs, name=\"frequency\")\n\n    def noct_synthesis(\n        self,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; NOctFrame:\n        \"\"\"\n        Synthesize N-octave band spectrum.\n\n        This method combines frequency components into N-octave bands according to\n        standard acoustical band definitions. This is commonly used in noise and\n        vibration analysis.\n\n        Parameters\n        ----------\n        fmin : float\n            Lower frequency bound in Hz.\n        fmax : float\n            Upper frequency bound in Hz.\n        n : int, default=3\n            Number of bands per octave (e.g., 3 for third-octave bands).\n        G : int, default=10\n            Reference band number.\n        fr : int, default=1000\n            Reference frequency in Hz.\n\n        Returns\n        -------\n        NOctFrame\n            A new NOctFrame containing the N-octave band spectrum.\n\n        Raises\n        ------\n        ValueError\n            If the sampling rate is not 48000 Hz, which is required for this operation.\n        \"\"\"\n        if self.sampling_rate != 48000:\n            raise ValueError(\n                \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n            )\n        from ..processing import NOctSynthesis\n        from .noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_synthesis\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSynthesis\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_synthesis\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def plot_matrix(\n        self,\n        plot_type: str = \"matrix\",\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"\n        Plot channel relationships in matrix format.\n\n        This method creates a matrix plot showing relationships between channels,\n        such as coherence, transfer functions, or cross-spectral density.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"matrix\"\n            Type of matrix plot to create.\n        **kwargs : dict\n            Additional plot parameters:\n            - vmin, vmax: Color scale limits\n            - cmap: Colormap name\n            - title: Plot title\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot.\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, **kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the SpectralFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - FFT size\n        - Frequency range\n        - Number of frequency bins\n        - Frequency resolution (\u0394F)\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; spectrum = cf.fft()\n        &gt;&gt;&gt; spectrum.info()\n        SpectralFrame Information:\n          Channels: 2\n          Sampling rate: 44100 Hz\n          FFT size: 2048\n          Frequency range: 0.0 - 22050.0 Hz\n          Frequency bins: 1025\n          Frequency resolution (\u0394F): 21.5 Hz\n          Channel labels: ['ch0', 'ch1']\n          Operations Applied: 1\n        \"\"\"\n        # Calculate frequency resolution (\u0394F)\n        delta_f = self.sampling_rate / self.n_fft\n\n        print(\"SpectralFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  FFT size: {self.n_fft}\")\n        print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n        print(f\"  Frequency bins: {len(self.freqs)}\")\n        print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n</code></pre> Attributes\u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>magnitude</code> <code>property</code> \u00b6 <p>Get the magnitude spectrum.</p> <code></code> <code>phase</code> <code>property</code> \u00b6 <p>Get the phase spectrum.</p> <code></code> <code>unwrapped_phase</code> <code>property</code> \u00b6 <p>Get the unwrapped phase spectrum.</p> <p>The unwrapped phase removes discontinuities of 2\u03c0 radians, providing continuous phase values across frequency bins.</p> <code></code> <code>power</code> <code>property</code> \u00b6 <p>Get the power spectrum.</p> <code></code> <code>dB</code> <code>property</code> \u00b6 <p>Get the spectrum in decibels.</p> <p>The reference values are taken from channel metadata. If no reference is specified, uses 1.0.</p> <code></code> <code>dBA</code> <code>property</code> \u00b6 <p>Get the A-weighted spectrum in decibels.</p> <p>Applies A-weighting filter to the spectrum for better correlation with perceived loudness.</p> <code></code> <code>freqs</code> <code>property</code> \u00b6 <p>Get the frequency axis values in Hz.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, n_fft, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 Source code in <code>wandas/frames/spectral.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: BaseFrame[Any] | None = None,\n) -&gt; None:\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>plot(plot_type='frequency', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, Aw=False, **kwargs)</code> \u00b6 <p>Plot the spectral data using various visualization strategies.</p> <code></code> <code>ifft()</code> \u00b6 <p>Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.</p> <p>This method transforms the frequency-domain data back to the time domain using the inverse FFT operation. The window function used in the forward FFT is taken into account to ensure proper reconstruction.</p> <code></code> <code>noct_synthesis(fmin, fmax, n=3, G=10, fr=1000)</code> \u00b6 <p>Synthesize N-octave band spectrum.</p> <p>This method combines frequency components into N-octave bands according to standard acoustical band definitions. This is commonly used in noise and vibration analysis.</p> <code></code> <code>plot_matrix(plot_type='matrix', **kwargs)</code> \u00b6 <p>Plot channel relationships in matrix format.</p> <p>This method creates a matrix plot showing relationships between channels, such as coherence, transfer functions, or cross-spectral density.</p> <code></code> <code>info()</code> \u00b6 <p>Display comprehensive information about the SpectralFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - FFT size - Frequency range - Number of frequency bins - Frequency resolution (\u0394F) - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.magnitude--returns","title":"Returns","text":"<p>NDArrayReal     The absolute values of the complex spectrum.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.phase--returns","title":"Returns","text":"<p>NDArrayReal     The phase angles of the complex spectrum in radians.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.unwrapped_phase--returns","title":"Returns","text":"<p>NDArrayReal     The unwrapped phase angles of the complex spectrum in radians.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.power--returns","title":"Returns","text":"<p>NDArrayReal     The squared magnitude spectrum.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.dB--returns","title":"Returns","text":"<p>NDArrayReal     The spectrum in dB relative to channel references.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.dBA--returns","title":"Returns","text":"<p>NDArrayReal     The A-weighted spectrum in dB.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.freqs--returns","title":"Returns","text":"<p>NDArrayReal     Array of frequency values corresponding to each frequency bin.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"frequency\"     Type of plot to create. Options include:     - \"frequency\": Standard frequency plot     - \"matrix\": Matrix plot for comparing channels     - Other types as defined by available plot strategies ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. title : str, optional     Title for the plot. If None, uses the frame label. overlay : bool, default=False     Whether to overlay all channels on a single plot (True)     or create separate subplots for each channel (False). xlabel : str, optional     Label for the x-axis. If None, uses default \"Frequency [Hz]\". ylabel : str, optional     Label for the y-axis. If None, uses default based on data type. alpha : float, default=1.0     Transparency level for the plot lines (0.0 to 1.0). xlim : tuple[float, float], optional     Limits for the x-axis as (min, max) tuple. ylim : tuple[float, float], optional     Limits for the y-axis as (min, max) tuple. Aw : bool, default=False     Whether to apply A-weighting to the data. **kwargs : dict     Additional matplotlib Line2D parameters     (e.g., color, linewidth, linestyle).</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot, or an iterator of axes     for multi-plot outputs.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot--examples","title":"Examples","text":"<p>spectrum = cf.fft()</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"frequency\",\n    ax: Axes | None = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot the spectral data using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"frequency\"\n        Type of plot to create. Options include:\n        - \"frequency\": Standard frequency plot\n        - \"matrix\": Matrix plot for comparing channels\n        - Other types as defined by available plot strategies\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; # Basic frequency plot\n    &gt;&gt;&gt; spectrum.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot--basic-frequency-plot","title":"Basic frequency plot","text":"<p>spectrum.plot()</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot--overlay-with-a-weighting","title":"Overlay with A-weighting","text":"<p>spectrum.plot(overlay=True, Aw=True)</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot--custom-styling","title":"Custom styling","text":"<p>spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.ifft--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the time-domain signal.</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def ifft(self) -&gt; ChannelFrame:\n    \"\"\"\n    Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n    This method transforms the frequency-domain data back to the time domain using\n    the inverse FFT operation. The window function used in the forward FFT is\n    taken into account to ensure proper reconstruction.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the time-domain signal.\n    \"\"\"\n    from ..processing import IFFT, create_operation\n    from .channel import ChannelFrame\n\n    params = {\"n_fft\": self.n_fft, \"window\": self.window}\n    operation_name = \"ifft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"IFFT\", operation)\n    # Apply processing to data\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Create new instance\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"ifft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.noct_synthesis--parameters","title":"Parameters","text":"<p>fmin : float     Lower frequency bound in Hz. fmax : float     Upper frequency bound in Hz. n : int, default=3     Number of bands per octave (e.g., 3 for third-octave bands). G : int, default=10     Reference band number. fr : int, default=1000     Reference frequency in Hz.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.noct_synthesis--returns","title":"Returns","text":"<p>NOctFrame     A new NOctFrame containing the N-octave band spectrum.</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.noct_synthesis--raises","title":"Raises","text":"<p>ValueError     If the sampling rate is not 48000 Hz, which is required for this operation.</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def noct_synthesis(\n    self,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; NOctFrame:\n    \"\"\"\n    Synthesize N-octave band spectrum.\n\n    This method combines frequency components into N-octave bands according to\n    standard acoustical band definitions. This is commonly used in noise and\n    vibration analysis.\n\n    Parameters\n    ----------\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number.\n    fr : int, default=1000\n        Reference frequency in Hz.\n\n    Returns\n    -------\n    NOctFrame\n        A new NOctFrame containing the N-octave band spectrum.\n\n    Raises\n    ------\n    ValueError\n        If the sampling rate is not 48000 Hz, which is required for this operation.\n    \"\"\"\n    if self.sampling_rate != 48000:\n        raise ValueError(\n            \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n        )\n    from ..processing import NOctSynthesis\n    from .noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_synthesis\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n    from ..processing import create_operation\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSynthesis\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_synthesis\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot_matrix--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"matrix\"     Type of matrix plot to create. **kwargs : dict     Additional plot parameters:     - vmin, vmax: Color scale limits     - cmap: Colormap name     - title: Plot title</p>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.plot_matrix--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot.</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def plot_matrix(\n    self,\n    plot_type: str = \"matrix\",\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot channel relationships in matrix format.\n\n    This method creates a matrix plot showing relationships between channels,\n    such as coherence, transfer functions, or cross-spectral density.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"matrix\"\n        Type of matrix plot to create.\n    **kwargs : dict\n        Additional plot parameters:\n        - vmin, vmax: Color scale limits\n        - cmap: Colormap name\n        - title: Plot title\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, **kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/#wandas.frames.spectral.SpectralFrame.info--examples","title":"Examples","text":"<p>spectrum = cf.fft() spectrum.info() SpectralFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectralFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; spectrum.info()\n    SpectralFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F)\n    delta_f = self.sampling_rate / self.n_fft\n\n    print(\"SpectralFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {len(self.freqs)}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram","title":"<code>spectrogram</code>","text":""},{"location":"api/#wandas.frames.spectrogram-attributes","title":"Attributes","text":""},{"location":"api/#wandas.frames.spectrogram.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectrogram.S","title":"<code>S = TypeVar('S', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.frames.spectrogram-classes","title":"Classes","text":""},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame","title":"<code>SpectrogramFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayComplex]</code></p> <p>Class for handling time-frequency domain data (spectrograms).</p> <p>This class represents spectrogram data obtained through Short-Time Fourier Transform (STFT) or similar time-frequency analysis methods. It provides methods for visualization, manipulation, and conversion back to time domain.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The spectrogram data. Must be a dask array with shape:     - (channels, frequency_bins, time_frames) for multi-channel data     - (frequency_bins, time_frames) for single-channel data, which will be       reshaped to (1, frequency_bins, time_frames) sampling_rate : float     The sampling rate of the original time-domain signal in Hz. n_fft : int     The FFT size used to generate this spectrogram. hop_length : int     Number of samples between successive frames. win_length : int, optional     The window length in samples. If None, defaults to n_fft. window : str, default=\"hann\"     The window function to use (e.g., \"hann\", \"hamming\", \"blackman\"). label : str, optional     A label for the frame. metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel in the frame. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame--attributes","title":"Attributes","text":"<p>magnitude : NDArrayReal     The magnitude spectrogram. phase : NDArrayReal     The phase spectrogram in radians. power : NDArrayReal     The power spectrogram. dB : NDArrayReal     The spectrogram in decibels relative to channel reference values. dBA : NDArrayReal     The A-weighted spectrogram in decibels. n_frames : int     Number of time frames. n_freq_bins : int     Number of frequency bins. freqs : NDArrayReal     The frequency axis values in Hz. times : NDArrayReal     The time axis values in seconds.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame--examples","title":"Examples","text":"<p>Create a spectrogram from a time-domain signal:</p> <p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512)</p> <p>Extract a specific time frame:</p> <p>frame_at_1s = spectrogram.get_frame_at(int(1.0 * sampling_rate / hop_length))</p> <p>Convert back to time domain:</p> <p>reconstructed = spectrogram.to_channel_frame()</p> <p>Plot the spectrogram:</p> <p>spectrogram.plot()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>class SpectrogramFrame(BaseFrame[NDArrayComplex]):\n    \"\"\"\n    Class for handling time-frequency domain data (spectrograms).\n\n    This class represents spectrogram data obtained through\n    Short-Time Fourier Transform (STFT)\n    or similar time-frequency analysis methods. It provides methods for visualization,\n    manipulation, and conversion back to time domain.\n\n    Parameters\n    ----------\n    data : DaArray\n        The spectrogram data. Must be a dask array with shape:\n        - (channels, frequency_bins, time_frames) for multi-channel data\n        - (frequency_bins, time_frames) for single-channel data, which will be\n          reshaped to (1, frequency_bins, time_frames)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    n_fft : int\n        The FFT size used to generate this spectrogram.\n    hop_length : int\n        Number of samples between successive frames.\n    win_length : int, optional\n        The window length in samples. If None, defaults to n_fft.\n    window : str, default=\"hann\"\n        The window function to use (e.g., \"hann\", \"hamming\", \"blackman\").\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    magnitude : NDArrayReal\n        The magnitude spectrogram.\n    phase : NDArrayReal\n        The phase spectrogram in radians.\n    power : NDArrayReal\n        The power spectrogram.\n    dB : NDArrayReal\n        The spectrogram in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrogram in decibels.\n    n_frames : int\n        Number of time frames.\n    n_freq_bins : int\n        Number of frequency bins.\n    freqs : NDArrayReal\n        The frequency axis values in Hz.\n    times : NDArrayReal\n        The time axis values in seconds.\n\n    Examples\n    --------\n    Create a spectrogram from a time-domain signal:\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n\n    Extract a specific time frame:\n    &gt;&gt;&gt; frame_at_1s = spectrogram.get_frame_at(int(1.0 * sampling_rate / hop_length))\n\n    Convert back to time domain:\n    &gt;&gt;&gt; reconstructed = spectrogram.to_channel_frame()\n\n    Plot the spectrogram:\n    &gt;&gt;&gt; spectrogram.plot()\n    \"\"\"\n\n    n_fft: int\n    hop_length: int\n    win_length: int\n    window: str\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        n_fft: int,\n        hop_length: int,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        if data.ndim == 2:\n            data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n        elif data.ndim != 3:\n            raise ValueError(\n                f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n            )\n        if not data.shape[-2] == n_fft // 2 + 1:\n            raise ValueError(\n                f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n            )\n\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.win_length = win_length if win_length is not None else n_fft\n        self.window = window\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def magnitude(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the magnitude spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The absolute values of the complex spectrogram.\n        \"\"\"\n        return np.abs(self.data)\n\n    @property\n    def phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the phase spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The phase angles of the complex spectrogram in radians.\n        \"\"\"\n        return np.angle(self.data)\n\n    @property\n    def power(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the power spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The squared magnitude of the complex spectrogram.\n        \"\"\"\n        return np.abs(self.data) ** 2\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrogram in decibels relative to each channel's reference value.\n\n        The reference value for each channel is specified in its metadata.\n        A minimum value of -120 dB is enforced to avoid numerical issues.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrogram in decibels.\n        \"\"\"\n        # dB\u898f\u5b9a\u5024\u3092_channel_metadata\u304b\u3089\u53ce\u96c6\n        ref = np.array([ch.ref for ch in self._channel_metadata])\n        # dB\u5909\u63db\n        # 0\u9664\u7b97\u3092\u907f\u3051\u308b\u305f\u3081\u306b\u3001\u6700\u5927\u5024\u30681e-12\u306e\u3044\u305a\u308c\u304b\u3092\u4f7f\u7528\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(self.magnitude / ref[..., np.newaxis, np.newaxis], 1e-12)\n        )\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrogram in decibels.\n\n        A-weighting applies a frequency-dependent weighting filter that approximates\n        the human ear's response. This is particularly useful for analyzing noise\n        and acoustic measurements.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrogram in decibels.\n        \"\"\"\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted[:, np.newaxis]  # \u5468\u6ce2\u6570\u8ef8\u306b\u6cbf\u3063\u3066\u30d6\u30ed\u30fc\u30c9\u30ad\u30e3\u30b9\u30c8\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels.\n        \"\"\"\n        return int(self._data.shape[-3])\n\n    @property\n    def n_frames(self) -&gt; int:\n        \"\"\"\n        Get the number of time frames.\n\n        Returns\n        -------\n        int\n            The number of time frames in the spectrogram.\n        \"\"\"\n        return self.shape[-1]\n\n    @property\n    def n_freq_bins(self) -&gt; int:\n        \"\"\"\n        Get the number of frequency bins.\n\n        Returns\n        -------\n        int\n            The number of frequency bins (n_fft // 2 + 1).\n        \"\"\"\n        return self.shape[-2]\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the frequency axis values in Hz.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of frequency values corresponding to each frequency bin.\n        \"\"\"\n        return np.fft.rfftfreq(self.n_fft, 1.0 / self.sampling_rate)\n\n    @property\n    def times(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the time axis values in seconds.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of time values corresponding to each time frame.\n        \"\"\"\n        return np.arange(self.n_frames) * self.hop_length / self.sampling_rate\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Implementation of operation application for spectrogram data.\n\n        This internal method handles the application of various operations to\n        spectrogram data, maintaining lazy evaluation through dask.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters for the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from wandas.processing import create_operation\n\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        processed_data = operation.process(self._data)\n\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n        return self._create_new_instance(\n            data=processed_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n        )\n\n    def _binary_op(\n        self,\n        other: Union[\n            \"SpectrogramFrame\",\n            int,\n            float,\n            complex,\n            NDArrayComplex,\n            NDArrayReal,\n            \"DaArray\",\n        ],\n        op: Callable[[\"DaArray\", Any], \"DaArray\"],\n        symbol: str,\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"\n        Common implementation for binary operations.\n\n        This method handles binary operations between\n        SpectrogramFrames and various types\n        of operands, maintaining lazy evaluation through dask arrays.\n\n        Parameters\n        ----------\n        other : Union[SpectrogramFrame, int, float, complex,\n            NDArrayComplex, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation (e.g., lambda a, b: a + b)\n        symbol : str\n            String representation of the operation (e.g., '+')\n\n        Returns\n        -------\n        SpectrogramFrame\n            A new SpectrogramFrame containing the result of the operation.\n\n        Raises\n        ------\n        ValueError\n            If attempting to operate with a SpectrogramFrame\n            with a different sampling rate.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        if isinstance(other, SpectrogramFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u304c\u4e00\u81f4\u3057\u3066\u3044\u307e\u305b\u3093\u3002\u6f14\u7b97\u3067\u304d\u307e\u305b\u3093\u3002\"\n                )\n\n            result_data = op(self._data, other._data)\n\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return SpectrogramFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                hop_length=self.hop_length,\n                win_length=self.win_length,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n        else:\n            result_data = op(self._data, other)\n\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, complex):\n                other_str = f\"complex({other.real}, {other.imag})\"\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return SpectrogramFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                hop_length=self.hop_length,\n                win_length=self.win_length,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n            )\n\n    def plot(\n        self,\n        plot_type: str = \"spectrogram\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        fmin: float = 0,\n        fmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the spectrogram using various visualization strategies.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"spectrogram\"\n            Type of plot to create.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses the frame label.\n        cmap : str, default=\"jet\"\n            Colormap name for the spectrogram visualization.\n        vmin : float, optional\n            Minimum value for colormap scaling (dB). Auto-calculated if None.\n        vmax : float, optional\n            Maximum value for colormap scaling (dB). Auto-calculated if None.\n        fmin : float, default=0\n            Minimum frequency to display (Hz).\n        fmax : float, optional\n            Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n        xlim : tuple[float, float], optional\n            Time axis limits as (start_time, end_time) in seconds.\n        ylim : tuple[float, float], optional\n            Frequency axis limits as (min_freq, max_freq) in Hz.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the spectrogram.\n        **kwargs : dict\n            Additional keyword arguments passed to librosa.display.specshow().\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; stft = cf.stft()\n        &gt;&gt;&gt; # Basic spectrogram\n        &gt;&gt;&gt; stft.plot()\n        &gt;&gt;&gt; # Custom color scale and frequency range\n        &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n        &gt;&gt;&gt; # A-weighted spectrogram\n        &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n        plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def plot_Aw(  # noqa: N802\n        self,\n        plot_type: str = \"spectrogram\",\n        ax: Optional[\"Axes\"] = None,\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the A-weighted spectrogram.\n\n        A convenience method that calls plot() with Aw=True, applying A-weighting\n        to the spectrogram before plotting.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"spectrogram\"\n            Type of plot to create.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        **kwargs : dict\n            Additional keyword arguments passed to plot().\n            Accepts all parameters from plot() except Aw (which is set to True).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot.\n\n        Examples\n        --------\n        &gt;&gt;&gt; stft = cf.stft()\n        &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n        &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n        \"\"\"\n        return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n\n    def abs(self) -&gt; \"SpectrogramFrame\":\n        \"\"\"\n        Compute the absolute value (magnitude) of the complex spectrogram.\n\n        This method calculates the magnitude of each complex value in the\n        spectrogram, converting the complex-valued data to real-valued magnitude data.\n        The result is stored in a new SpectrogramFrame with complex dtype to maintain\n        compatibility with other spectrogram operations.\n\n        Returns\n        -------\n        SpectrogramFrame\n            A new SpectrogramFrame containing the magnitude values as complex numbers\n            (with zero imaginary parts).\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n        &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n        &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n        \"\"\"\n        logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n        # Compute the absolute value using dask for lazy evaluation\n        magnitude_data = da.absolute(self._data)\n\n        # Update operation history\n        operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[\"abs\"] = {}\n\n        logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n        return SpectrogramFrame(\n            data=magnitude_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=self.n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=self.window,\n            label=f\"abs({self.label})\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n        \"\"\"\n        Extract spectral data at a specific time frame.\n\n        Parameters\n        ----------\n        time_idx : int\n            Index of the time frame to extract.\n\n        Returns\n        -------\n        SpectralFrame\n            A new SpectralFrame containing the spectral data at the specified time.\n\n        Raises\n        ------\n        IndexError\n            If time_idx is out of range.\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n\n        if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n            raise IndexError(\n                f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n            )\n\n        frame_data = self._data[..., time_idx]\n\n        return SpectralFrame(\n            data=frame_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=self.n_fft,\n            window=self.window,\n            label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def to_channel_frame(self) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Convert the spectrogram back to time domain using inverse STFT.\n\n        This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n        reconstruct the time-domain signal from the spectrogram.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the reconstructed time-domain signal.\n\n        See Also\n        --------\n        istft : Alias for this method with more intuitive naming.\n        \"\"\"\n        from wandas.frames.channel import ChannelFrame\n        from wandas.processing import ISTFT, create_operation\n\n        params = {\n            \"n_fft\": self.n_fft,\n            \"hop_length\": self.hop_length,\n            \"win_length\": self.win_length,\n            \"window\": self.window,\n        }\n        operation_name = \"istft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"ISTFT\", operation)\n        # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n        time_series = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n        return ChannelFrame(\n            data=time_series,\n            sampling_rate=self.sampling_rate,\n            label=f\"istft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def istft(self) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Convert the spectrogram back to time domain using inverse STFT.\n\n        This is an alias for `to_channel_frame()` with a more intuitive name.\n        It performs an inverse Short-Time Fourier Transform (ISTFT) to\n        reconstruct the time-domain signal from the spectrogram.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the reconstructed time-domain signal.\n\n        See Also\n        --------\n        to_channel_frame : The underlying implementation.\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; reconstructed = spectrogram.istft()\n        \"\"\"\n        return self.to_channel_frame()\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get additional initialization arguments for SpectrogramFrame.\n\n        This internal method provides the additional initialization arguments\n        required by SpectrogramFrame beyond those required by BaseFrame.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments.\n        \"\"\"\n        return {\n            \"n_fft\": self.n_fft,\n            \"hop_length\": self.hop_length,\n            \"win_length\": self.win_length,\n            \"window\": self.window,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"DataFrame index is not supported for SpectrogramFrame.\"\"\"\n        raise NotImplementedError(\n            \"DataFrame index is not supported for SpectrogramFrame.\"\n        )\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n        SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n        which cannot be directly converted to a 2D DataFrame. Consider using\n        get_frame_at() to extract a specific time frame as a SpectralFrame,\n        then convert that to a DataFrame.\n\n        Raises\n        ------\n        NotImplementedError\n            Always raised as DataFrame conversion is not supported.\n        \"\"\"\n        raise NotImplementedError(\n            \"DataFrame conversion is not supported for SpectrogramFrame. \"\n            \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n            \"then convert that to a DataFrame.\"\n        )\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - FFT size\n        - Hop length\n        - Window length\n        - Window function\n        - Frequency range\n        - Number of frequency bins\n        - Frequency resolution (\u0394F)\n        - Number of time frames\n        - Time resolution (\u0394T)\n        - Total duration\n        - Channel labels\n        - Number of operations applied\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; spectrogram.info()\n        SpectrogramFrame Information:\n          Channels: 2\n          Sampling rate: 44100 Hz\n          FFT size: 2048\n          Hop length: 512 samples\n          Window length: 2048 samples\n          Window: hann\n          Frequency range: 0.0 - 22050.0 Hz\n          Frequency bins: 1025\n          Frequency resolution (\u0394F): 21.5 Hz\n          Time frames: 100\n          Time resolution (\u0394T): 11.6 ms\n          Total duration: 1.16 s\n          Channel labels: ['ch0', 'ch1']\n          Operations Applied: 1\n        \"\"\"\n        # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n        delta_f = self.sampling_rate / self.n_fft\n        delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n        total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n        print(\"SpectrogramFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  FFT size: {self.n_fft}\")\n        print(f\"  Hop length: {self.hop_length} samples\")\n        print(f\"  Window length: {self.win_length} samples\")\n        print(f\"  Window: {self.window}\")\n        print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n        print(f\"  Frequency bins: {self.n_freq_bins}\")\n        print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n        print(f\"  Time frames: {self.n_frames}\")\n        print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n        print(f\"  Total duration: {total_duration:.2f} s\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayComplex,\n        sampling_rate: float,\n        n_fft: int,\n        hop_length: int,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing spectrogram data.\n                Shape should be (n_channels, n_freq_bins, n_time_frames) or\n                (n_freq_bins, n_time_frames) for single channel.\n            sampling_rate: The sampling rate in Hz.\n            n_fft: The FFT size used to generate this spectrogram.\n            hop_length: Number of samples between successive frames.\n            win_length: The window length in samples. If None, defaults to n_fft.\n            window: The window function used (e.g., \"hann\", \"hamming\").\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Returns:\n            A new SpectrogramFrame containing the NumPy data.\n        \"\"\"\n\n        # Convert NumPy array to dask array\n        dask_data = da.from_array(data)\n        sf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            label=label or \"numpy_spectrogram\",\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n        return sf\n</code></pre> Attributes\u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = win_length if win_length is not None else n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>magnitude</code> <code>property</code> \u00b6 <p>Get the magnitude spectrogram.</p> <code></code> <code>phase</code> <code>property</code> \u00b6 <p>Get the phase spectrogram.</p> <code></code> <code>power</code> <code>property</code> \u00b6 <p>Get the power spectrogram.</p> <code></code> <code>dB</code> <code>property</code> \u00b6 <p>Get the spectrogram in decibels relative to each channel's reference value.</p> <p>The reference value for each channel is specified in its metadata. A minimum value of -120 dB is enforced to avoid numerical issues.</p> <code></code> <code>dBA</code> <code>property</code> \u00b6 <p>Get the A-weighted spectrogram in decibels.</p> <p>A-weighting applies a frequency-dependent weighting filter that approximates the human ear's response. This is particularly useful for analyzing noise and acoustic measurements.</p> <code></code> <code>n_frames</code> <code>property</code> \u00b6 <p>Get the number of time frames.</p> <code></code> <code>n_freq_bins</code> <code>property</code> \u00b6 <p>Get the number of frequency bins.</p> <code></code> <code>freqs</code> <code>property</code> \u00b6 <p>Get the frequency axis values in Hz.</p> <code></code> <code>times</code> <code>property</code> \u00b6 <p>Get the time axis values in seconds.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    if data.ndim == 2:\n        data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n    elif data.ndim != 3:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n        )\n    if not data.shape[-2] == n_fft // 2 + 1:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n        )\n\n    self.n_fft = n_fft\n    self.hop_length = hop_length\n    self.win_length = win_length if win_length is not None else n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>plot(plot_type='spectrogram', ax=None, title=None, cmap='jet', vmin=None, vmax=None, fmin=0, fmax=None, xlim=None, ylim=None, Aw=False, **kwargs)</code> \u00b6 <p>Plot the spectrogram using various visualization strategies.</p> <code></code> <code>plot_Aw(plot_type='spectrogram', ax=None, **kwargs)</code> \u00b6 <p>Plot the A-weighted spectrogram.</p> <p>A convenience method that calls plot() with Aw=True, applying A-weighting to the spectrogram before plotting.</p> <code></code> <code>abs()</code> \u00b6 <p>Compute the absolute value (magnitude) of the complex spectrogram.</p> <p>This method calculates the magnitude of each complex value in the spectrogram, converting the complex-valued data to real-valued magnitude data. The result is stored in a new SpectrogramFrame with complex dtype to maintain compatibility with other spectrogram operations.</p> <code></code> <code>get_frame_at(time_idx)</code> \u00b6 <p>Extract spectral data at a specific time frame.</p> <code></code> <code>to_channel_frame()</code> \u00b6 <p>Convert the spectrogram back to time domain using inverse STFT.</p> <p>This method performs an inverse Short-Time Fourier Transform (ISTFT) to reconstruct the time-domain signal from the spectrogram.</p> <code></code> <code>istft()</code> \u00b6 <p>Convert the spectrogram back to time domain using inverse STFT.</p> <p>This is an alias for <code>to_channel_frame()</code> with a more intuitive name. It performs an inverse Short-Time Fourier Transform (ISTFT) to reconstruct the time-domain signal from the spectrogram.</p> <code></code> <code>to_dataframe()</code> \u00b6 <p>DataFrame conversion is not supported for SpectrogramFrame.</p> <p>SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames) which cannot be directly converted to a 2D DataFrame. Consider using get_frame_at() to extract a specific time frame as a SpectralFrame, then convert that to a DataFrame.</p> <code></code> <code>info()</code> \u00b6 <p>Display comprehensive information about the SpectrogramFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - FFT size - Hop length - Window length - Window function - Frequency range - Number of frequency bins - Frequency resolution (\u0394F) - Number of time frames - Time resolution (\u0394T) - Total duration - Channel labels - Number of operations applied</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p> <code></code> <code>from_numpy(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> <code>classmethod</code> \u00b6 <p>Create a SpectrogramFrame from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayComplex</code> <p>NumPy array containing spectrogram data. Shape should be (n_channels, n_freq_bins, n_time_frames) or (n_freq_bins, n_time_frames) for single channel.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> required <code>n_fft</code> <code>int</code> <p>The FFT size used to generate this spectrogram.</p> required <code>hop_length</code> <code>int</code> <p>Number of samples between successive frames.</p> required <code>win_length</code> <code>int | None</code> <p>The window length in samples. If None, defaults to n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>The window function used (e.g., \"hann\", \"hamming\").</p> <code>'hann'</code> <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpectrogramFrame</code> <p>A new SpectrogramFrame containing the NumPy data.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayComplex,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing spectrogram data.\n            Shape should be (n_channels, n_freq_bins, n_time_frames) or\n            (n_freq_bins, n_time_frames) for single channel.\n        sampling_rate: The sampling rate in Hz.\n        n_fft: The FFT size used to generate this spectrogram.\n        hop_length: Number of samples between successive frames.\n        win_length: The window length in samples. If None, defaults to n_fft.\n        window: The window function used (e.g., \"hann\", \"hamming\").\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Returns:\n        A new SpectrogramFrame containing the NumPy data.\n    \"\"\"\n\n    # Convert NumPy array to dask array\n    dask_data = da.from_array(data)\n    sf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        label=label or \"numpy_spectrogram\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n    return sf\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.magnitude--returns","title":"Returns","text":"<p>NDArrayReal     The absolute values of the complex spectrogram.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.phase--returns","title":"Returns","text":"<p>NDArrayReal     The phase angles of the complex spectrogram in radians.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.power--returns","title":"Returns","text":"<p>NDArrayReal     The squared magnitude of the complex spectrogram.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.dB--returns","title":"Returns","text":"<p>NDArrayReal     The spectrogram in decibels.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.dBA--returns","title":"Returns","text":"<p>NDArrayReal     The A-weighted spectrogram in decibels.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.n_frames--returns","title":"Returns","text":"<p>int     The number of time frames in the spectrogram.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.n_freq_bins--returns","title":"Returns","text":"<p>int     The number of frequency bins (n_fft // 2 + 1).</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.freqs--returns","title":"Returns","text":"<p>NDArrayReal     Array of frequency values corresponding to each frequency bin.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.times--returns","title":"Returns","text":"<p>NDArrayReal     Array of time values corresponding to each time frame.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"spectrogram\"     Type of plot to create. ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. title : str, optional     Title for the plot. If None, uses the frame label. cmap : str, default=\"jet\"     Colormap name for the spectrogram visualization. vmin : float, optional     Minimum value for colormap scaling (dB). Auto-calculated if None. vmax : float, optional     Maximum value for colormap scaling (dB). Auto-calculated if None. fmin : float, default=0     Minimum frequency to display (Hz). fmax : float, optional     Maximum frequency to display (Hz). If None, uses Nyquist frequency. xlim : tuple[float, float], optional     Time axis limits as (start_time, end_time) in seconds. ylim : tuple[float, float], optional     Frequency axis limits as (min_freq, max_freq) in Hz. Aw : bool, default=False     Whether to apply A-weighting to the spectrogram. **kwargs : dict     Additional keyword arguments passed to librosa.display.specshow().</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot, or an iterator of axes     for multi-plot outputs.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot--examples","title":"Examples","text":"<p>stft = cf.stft()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    fmin: float = 0,\n    fmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the spectrogram using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    cmap : str, default=\"jet\"\n        Colormap name for the spectrogram visualization.\n    vmin : float, optional\n        Minimum value for colormap scaling (dB). Auto-calculated if None.\n    vmax : float, optional\n        Maximum value for colormap scaling (dB). Auto-calculated if None.\n    fmin : float, default=0\n        Minimum frequency to display (Hz).\n    fmax : float, optional\n        Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n    xlim : tuple[float, float], optional\n        Time axis limits as (start_time, end_time) in seconds.\n    ylim : tuple[float, float], optional\n        Frequency axis limits as (min_freq, max_freq) in Hz.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the spectrogram.\n    **kwargs : dict\n        Additional keyword arguments passed to librosa.display.specshow().\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # Basic spectrogram\n    &gt;&gt;&gt; stft.plot()\n    &gt;&gt;&gt; # Custom color scale and frequency range\n    &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n    &gt;&gt;&gt; # A-weighted spectrogram\n    &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n    plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot--basic-spectrogram","title":"Basic spectrogram","text":"<p>stft.plot()</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot--custom-color-scale-and-frequency-range","title":"Custom color scale and frequency range","text":"<p>stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot--a-weighted-spectrogram","title":"A-weighted spectrogram","text":"<p>stft.plot(Aw=True, cmap=\"viridis\")</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"spectrogram\"     Type of plot to create. ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. **kwargs : dict     Additional keyword arguments passed to plot().     Accepts all parameters from plot() except Aw (which is set to True).</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--examples","title":"Examples","text":"<p>stft = cf.stft()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def plot_Aw(  # noqa: N802\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the A-weighted spectrogram.\n\n    A convenience method that calls plot() with Aw=True, applying A-weighting\n    to the spectrogram before plotting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    **kwargs : dict\n        Additional keyword arguments passed to plot().\n        Accepts all parameters from plot() except Aw (which is set to True).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n    &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n    \"\"\"\n    return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--a-weighted-spectrogram-with-custom-settings","title":"A-weighted spectrogram with custom settings","text":"<p>stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.abs--returns","title":"Returns","text":"<p>SpectrogramFrame     A new SpectrogramFrame containing the magnitude values as complex numbers     (with zero imaginary parts).</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.abs--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) magnitude_spectrogram = spectrogram.abs()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def abs(self) -&gt; \"SpectrogramFrame\":\n    \"\"\"\n    Compute the absolute value (magnitude) of the complex spectrogram.\n\n    This method calculates the magnitude of each complex value in the\n    spectrogram, converting the complex-valued data to real-valued magnitude data.\n    The result is stored in a new SpectrogramFrame with complex dtype to maintain\n    compatibility with other spectrogram operations.\n\n    Returns\n    -------\n    SpectrogramFrame\n        A new SpectrogramFrame containing the magnitude values as complex numbers\n        (with zero imaginary parts).\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n    &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n    &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n    \"\"\"\n    logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n    # Compute the absolute value using dask for lazy evaluation\n    magnitude_data = da.absolute(self._data)\n\n    # Update operation history\n    operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n    new_history = self.operation_history.copy()\n    new_history.append(operation_metadata)\n    new_metadata = {**self.metadata}\n    new_metadata[\"abs\"] = {}\n\n    logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n    return SpectrogramFrame(\n        data=magnitude_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=self.window,\n        label=f\"abs({self.label})\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.abs--the-magnitude-can-be-accessed-via-the-magnitude-property-or-data","title":"The magnitude can be accessed via the magnitude property or data","text":"<p>print(magnitude_spectrogram.magnitude.shape)</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--parameters","title":"Parameters","text":"<p>time_idx : int     Index of the time frame to extract.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--returns","title":"Returns","text":"<p>SpectralFrame     A new SpectralFrame containing the spectral data at the specified time.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--raises","title":"Raises","text":"<p>IndexError     If time_idx is out of range.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n    \"\"\"\n    Extract spectral data at a specific time frame.\n\n    Parameters\n    ----------\n    time_idx : int\n        Index of the time frame to extract.\n\n    Returns\n    -------\n    SpectralFrame\n        A new SpectralFrame containing the spectral data at the specified time.\n\n    Raises\n    ------\n    IndexError\n        If time_idx is out of range.\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n\n    if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n        raise IndexError(\n            f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n        )\n\n    frame_data = self._data[..., time_idx]\n\n    return SpectralFrame(\n        data=frame_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        window=self.window,\n        label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the reconstructed time-domain signal.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame--see-also","title":"See Also","text":"<p>istft : Alias for this method with more intuitive naming.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def to_channel_frame(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    istft : Alias for this method with more intuitive naming.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n    from wandas.processing import ISTFT, create_operation\n\n    params = {\n        \"n_fft\": self.n_fft,\n        \"hop_length\": self.hop_length,\n        \"win_length\": self.win_length,\n        \"window\": self.window,\n    }\n    operation_name = \"istft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"ISTFT\", operation)\n    # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n    )\n\n    # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"istft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.istft--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the reconstructed time-domain signal.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.istft--see-also","title":"See Also","text":"<p>to_channel_frame : The underlying implementation.</p>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.istft--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) reconstructed = spectrogram.istft()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def istft(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This is an alias for `to_channel_frame()` with a more intuitive name.\n    It performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    to_channel_frame : The underlying implementation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; reconstructed = spectrogram.istft()\n    \"\"\"\n    return self.to_channel_frame()\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n    SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n    which cannot be directly converted to a 2D DataFrame. Consider using\n    get_frame_at() to extract a specific time frame as a SpectralFrame,\n    then convert that to a DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for SpectrogramFrame. \"\n        \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n        \"then convert that to a DataFrame.\"\n    )\n</code></pre>"},{"location":"api/#wandas.frames.spectrogram.SpectrogramFrame.info--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) spectrogram.info() SpectrogramFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Hop length: 512 samples   Window length: 2048 samples   Window: hann   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Time frames: 100   Time resolution (\u0394T): 11.6 ms   Total duration: 1.16 s   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Hop length\n    - Window length\n    - Window function\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Number of time frames\n    - Time resolution (\u0394T)\n    - Total duration\n    - Channel labels\n    - Number of operations applied\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; spectrogram.info()\n    SpectrogramFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Hop length: 512 samples\n      Window length: 2048 samples\n      Window: hann\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Time frames: 100\n      Time resolution (\u0394T): 11.6 ms\n      Total duration: 1.16 s\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n    delta_f = self.sampling_rate / self.n_fft\n    delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n    total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n    print(\"SpectrogramFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Hop length: {self.hop_length} samples\")\n    print(f\"  Window length: {self.win_length} samples\")\n    print(f\"  Window: {self.window}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {self.n_freq_bins}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Time frames: {self.n_frames}\")\n    print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n    print(f\"  Total duration: {total_duration:.2f} s\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/#_3","title":"\u51e6\u7406\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u51e6\u7406\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u69d8\u3005\u306a\u51e6\u7406\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.processing","title":"<code>wandas.processing</code>","text":"<p>Audio time series processing operations.</p> <p>This module provides audio processing operations for time series data.</p>"},{"location":"api/#wandas.processing-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.__all__","title":"<code>__all__ = ['AudioOperation', '_OPERATION_REGISTRY', 'create_operation', 'get_operation', 'register_operation', 'AWeighting', 'HighPassFilter', 'LowPassFilter', 'CSD', 'Coherence', 'FFT', 'IFFT', 'ISTFT', 'NOctSpectrum', 'NOctSynthesis', 'STFT', 'TransferFunction', 'Welch', 'ReSampling', 'RmsTrend', 'Trim', 'AddWithSNR', 'HpssHarmonic', 'HpssPercussive', 'ABS', 'ChannelDifference', 'Mean', 'Power', 'Sum', 'LoudnessZwst', 'LoudnessZwtv']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.AudioOperation","title":"<code>AudioOperation</code>","text":"<p>               Bases: <code>Generic[InputArrayType, OutputArrayType]</code></p> <p>Abstract base class for audio processing operations.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>class AudioOperation(Generic[InputArrayType, OutputArrayType]):\n    \"\"\"Abstract base class for audio processing operations.\"\"\"\n\n    # Class variable: operation name\n    name: ClassVar[str]\n\n    def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n        \"\"\"\n        Initialize AudioOperation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        pure : bool, default=True\n            Whether the operation is pure (deterministic with no side effects).\n            When True, Dask can cache results for identical inputs.\n            Set to False only if the operation has side effects or is non-deterministic.\n        **params : Any\n            Operation-specific parameters\n        \"\"\"\n        self.sampling_rate = sampling_rate\n        self.pure = pure\n        self.params = params\n\n        # Validate parameters during initialization\n        self.validate_params()\n\n        # Create processor function (lazy initialization possible)\n        self._setup_processor()\n\n        logger.debug(\n            f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n        pass\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up processor function (implemented by subclasses)\"\"\"\n        pass\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get metadata updates to apply after processing.\n\n        This method allows operations to specify how metadata should be\n        updated after processing. By default, no metadata is updated.\n\n        Returns\n        -------\n        dict\n            Dictionary of metadata updates. Can include:\n            - 'sampling_rate': New sampling rate (float)\n            - Other metadata keys as needed\n\n        Examples\n        --------\n        Return empty dict for operations that don't change metadata:\n\n        &gt;&gt;&gt; return {}\n\n        Return new sampling rate for operations that resample:\n\n        &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n        Notes\n        -----\n        This method is called by the framework after processing to update\n        the frame metadata. Subclasses should override this method if they\n        need to update metadata (e.g., changing sampling rate).\n\n        Design principle: Operations should use parameters provided at\n        initialization (via __init__). All necessary information should be\n        available as instance variables.\n        \"\"\"\n        return {}\n\n    def get_display_name(self) -&gt; str | None:\n        \"\"\"\n        Get display name for the operation for use in channel labels.\n\n        This method allows operations to customize how they appear in\n        channel labels. By default, returns None, which means the\n        operation name will be used.\n\n        Returns\n        -------\n        str or None\n            Display name for the operation. If None, the operation name\n            (from the `name` class variable) is used.\n\n        Examples\n        --------\n        Default behavior (returns None, uses operation name):\n\n        &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n        ...     name = \"normalize\"\n        &gt;&gt;&gt; op = NormalizeOp(44100)\n        &gt;&gt;&gt; op.get_display_name()  # Returns None\n        &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n        Custom display name:\n\n        &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n        ...     name = \"lowpass_filter\"\n        ...\n        ...     def __init__(self, sr, cutoff):\n        ...         self.cutoff = cutoff\n        ...         super().__init__(sr, cutoff=cutoff)\n        ...\n        ...     def get_display_name(self):\n        ...         return f\"lpf_{self.cutoff}Hz\"\n        &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n        &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n        &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n        Notes\n        -----\n        Subclasses can override this method to provide operation-specific\n        display names that include parameter information, making labels\n        more informative.\n        \"\"\"\n        return None\n\n    def _process_array(self, x: InputArrayType) -&gt; OutputArrayType:\n        \"\"\"Processing function (implemented by subclasses)\"\"\"\n        # Default is no-op function\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n\n    def _create_named_wrapper(self) -&gt; Any:\n        \"\"\"\n        Create a named wrapper function for better Dask graph visualization.\n\n        Returns\n        -------\n        callable\n            A wrapper function with the operation name set as __name__.\n        \"\"\"\n\n        def operation_wrapper(x: InputArrayType) -&gt; OutputArrayType:\n            return self._process_array(x)\n\n        # Set the function name to the operation name for better visualization\n        operation_wrapper.__name__ = self.name\n        return operation_wrapper\n\n    def process_array(self, x: InputArrayType) -&gt; Any:\n        \"\"\"\n        Processing function wrapped with @dask.delayed.\n\n        This method returns a Delayed object that can be computed later.\n        The operation name is used in the Dask task graph for better visualization.\n\n        Parameters\n        ----------\n        x : InputArrayType\n            Input array to process.\n\n        Returns\n        -------\n        dask.delayed.Delayed\n            A Delayed object representing the computation.\n        \"\"\"\n        logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n        # Create wrapper with operation name and wrap it with dask.delayed\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        return delayed_func(x)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        This method can be overridden by subclasses for efficiency.\n        If not overridden, it will execute _process_array on a small test array\n        to determine the output shape.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n\n        Notes\n        -----\n        The default implementation creates a minimal test array and processes it\n        to determine output shape. For performance-critical code, subclasses should\n        override this method with a direct calculation.\n        \"\"\"\n        # Try to infer shape by executing _process_array on test data\n        import numpy as np\n\n        try:\n            # Create minimal test array with input shape\n            if len(input_shape) == 0:\n                return input_shape\n\n            # Create test input with correct dtype\n            # Try complex first, fall back to float if needed\n            test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n            # Process test input\n            test_output: Any = self._process_array(test_input)\n\n            # Return the shape of the output\n            if isinstance(test_output, np.ndarray):\n                return tuple(int(s) for s in test_output.shape)\n            return input_shape\n        except Exception as e:\n            logger.warning(\n                f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n                \"Please implement calculate_output_shape method.\"\n            )\n            raise NotImplementedError(\n                f\"Subclass {self.__class__.__name__} must implement \"\n                f\"calculate_output_shape or ensure _process_array can be \"\n                f\"called with test data.\"\n            ) from e\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        \"\"\"\n        Execute operation and return result\n        data shape is (channels, samples)\n        \"\"\"\n        # Add task as delayed processing with custom name for visualization\n        logger.debug(\"Adding delayed operation to computation graph\")\n\n        # Create a wrapper function with the operation name\n        # This allows Dask to use the operation name in the task graph\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        delayed_result = delayed_func(data)\n\n        # Convert delayed result to dask array and return\n        output_shape = self.calculate_output_shape(data.shape)\n        return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.AudioOperation.name","title":"<code>name</code>  <code>class-attribute</code>","text":""},{"location":"api/#wandas.processing.AudioOperation.sampling_rate","title":"<code>sampling_rate = sampling_rate</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AudioOperation.pure","title":"<code>pure = pure</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AudioOperation.params","title":"<code>params = params</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AudioOperation-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.AudioOperation.__init__","title":"<code>__init__(sampling_rate, *, pure=True, **params)</code>","text":"<p>Initialize AudioOperation.</p>"},{"location":"api/#wandas.processing.AudioOperation.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) pure : bool, default=True     Whether the operation is pure (deterministic with no side effects).     When True, Dask can cache results for identical inputs.     Set to False only if the operation has side effects or is non-deterministic. **params : Any     Operation-specific parameters</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n    \"\"\"\n    Initialize AudioOperation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    pure : bool, default=True\n        Whether the operation is pure (deterministic with no side effects).\n        When True, Dask can cache results for identical inputs.\n        Set to False only if the operation has side effects or is non-deterministic.\n    **params : Any\n        Operation-specific parameters\n    \"\"\"\n    self.sampling_rate = sampling_rate\n    self.pure = pure\n    self.params = params\n\n    # Validate parameters during initialization\n    self.validate_params()\n\n    # Create processor function (lazy initialization possible)\n    self._setup_processor()\n\n    logger.debug(\n        f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n    )\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters (raises exception if invalid)</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n    pass\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Get metadata updates to apply after processing.</p> <p>This method allows operations to specify how metadata should be updated after processing. By default, no metadata is updated.</p>"},{"location":"api/#wandas.processing.AudioOperation.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Dictionary of metadata updates. Can include:     - 'sampling_rate': New sampling rate (float)     - Other metadata keys as needed</p>"},{"location":"api/#wandas.processing.AudioOperation.get_metadata_updates--examples","title":"Examples","text":"<p>Return empty dict for operations that don't change metadata:</p> <p>return {}</p> <p>Return new sampling rate for operations that resample:</p> <p>return {\"sampling_rate\": self.target_sr}</p>"},{"location":"api/#wandas.processing.AudioOperation.get_metadata_updates--notes","title":"Notes","text":"<p>This method is called by the framework after processing to update the frame metadata. Subclasses should override this method if they need to update metadata (e.g., changing sampling rate).</p> <p>Design principle: Operations should use parameters provided at initialization (via init). All necessary information should be available as instance variables.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    This method allows operations to specify how metadata should be\n    updated after processing. By default, no metadata is updated.\n\n    Returns\n    -------\n    dict\n        Dictionary of metadata updates. Can include:\n        - 'sampling_rate': New sampling rate (float)\n        - Other metadata keys as needed\n\n    Examples\n    --------\n    Return empty dict for operations that don't change metadata:\n\n    &gt;&gt;&gt; return {}\n\n    Return new sampling rate for operations that resample:\n\n    &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n    Notes\n    -----\n    This method is called by the framework after processing to update\n    the frame metadata. Subclasses should override this method if they\n    need to update metadata (e.g., changing sampling rate).\n\n    Design principle: Operations should use parameters provided at\n    initialization (via __init__). All necessary information should be\n    available as instance variables.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> <p>This method allows operations to customize how they appear in channel labels. By default, returns None, which means the operation name will be used.</p>"},{"location":"api/#wandas.processing.AudioOperation.get_display_name--returns","title":"Returns","text":"<p>str or None     Display name for the operation. If None, the operation name     (from the <code>name</code> class variable) is used.</p>"},{"location":"api/#wandas.processing.AudioOperation.get_display_name--examples","title":"Examples","text":"<p>Default behavior (returns None, uses operation name):</p> <p>class NormalizeOp(AudioOperation): ...     name = \"normalize\" op = NormalizeOp(44100) op.get_display_name()  # Returns None</p> <p>Custom display name:</p> <p>class LowPassFilter(AudioOperation): ...     name = \"lowpass_filter\" ... ...     def init(self, sr, cutoff): ...         self.cutoff = cutoff ...         super().init(sr, cutoff=cutoff) ... ...     def get_display_name(self): ...         return f\"lpf_{self.cutoff}Hz\" op = LowPassFilter(44100, cutoff=1000) op.get_display_name()  # Returns \"lpf_1000Hz\"</p>"},{"location":"api/#wandas.processing.AudioOperation.get_display_name--channel-label-normalizech0","title":"Channel label: \"normalize(ch0)\"","text":""},{"location":"api/#wandas.processing.AudioOperation.get_display_name--channel-label-lpf_1000hzch0","title":"Channel label: \"lpf_1000Hz(ch0)\"","text":""},{"location":"api/#wandas.processing.AudioOperation.get_display_name--notes","title":"Notes","text":"<p>Subclasses can override this method to provide operation-specific display names that include parameter information, making labels more informative.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_display_name(self) -&gt; str | None:\n    \"\"\"\n    Get display name for the operation for use in channel labels.\n\n    This method allows operations to customize how they appear in\n    channel labels. By default, returns None, which means the\n    operation name will be used.\n\n    Returns\n    -------\n    str or None\n        Display name for the operation. If None, the operation name\n        (from the `name` class variable) is used.\n\n    Examples\n    --------\n    Default behavior (returns None, uses operation name):\n\n    &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n    ...     name = \"normalize\"\n    &gt;&gt;&gt; op = NormalizeOp(44100)\n    &gt;&gt;&gt; op.get_display_name()  # Returns None\n    &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n    Custom display name:\n\n    &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n    ...     name = \"lowpass_filter\"\n    ...\n    ...     def __init__(self, sr, cutoff):\n    ...         self.cutoff = cutoff\n    ...         super().__init__(sr, cutoff=cutoff)\n    ...\n    ...     def get_display_name(self):\n    ...         return f\"lpf_{self.cutoff}Hz\"\n    &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n    &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n    &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n    Notes\n    -----\n    Subclasses can override this method to provide operation-specific\n    display names that include parameter information, making labels\n    more informative.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation.process_array","title":"<code>process_array(x)</code>","text":"<p>Processing function wrapped with @dask.delayed.</p> <p>This method returns a Delayed object that can be computed later. The operation name is used in the Dask task graph for better visualization.</p>"},{"location":"api/#wandas.processing.AudioOperation.process_array--parameters","title":"Parameters","text":"<p>x : InputArrayType     Input array to process.</p>"},{"location":"api/#wandas.processing.AudioOperation.process_array--returns","title":"Returns","text":"<p>dask.delayed.Delayed     A Delayed object representing the computation.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def process_array(self, x: InputArrayType) -&gt; Any:\n    \"\"\"\n    Processing function wrapped with @dask.delayed.\n\n    This method returns a Delayed object that can be computed later.\n    The operation name is used in the Dask task graph for better visualization.\n\n    Parameters\n    ----------\n    x : InputArrayType\n        Input array to process.\n\n    Returns\n    -------\n    dask.delayed.Delayed\n        A Delayed object representing the computation.\n    \"\"\"\n    logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n    # Create wrapper with operation name and wrap it with dask.delayed\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    return delayed_func(x)\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation.</p> <p>This method can be overridden by subclasses for efficiency. If not overridden, it will execute _process_array on a small test array to determine the output shape.</p>"},{"location":"api/#wandas.processing.AudioOperation.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.AudioOperation.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p>"},{"location":"api/#wandas.processing.AudioOperation.calculate_output_shape--notes","title":"Notes","text":"<p>The default implementation creates a minimal test array and processes it to determine output shape. For performance-critical code, subclasses should override this method with a direct calculation.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    This method can be overridden by subclasses for efficiency.\n    If not overridden, it will execute _process_array on a small test array\n    to determine the output shape.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n\n    Notes\n    -----\n    The default implementation creates a minimal test array and processes it\n    to determine output shape. For performance-critical code, subclasses should\n    override this method with a direct calculation.\n    \"\"\"\n    # Try to infer shape by executing _process_array on test data\n    import numpy as np\n\n    try:\n        # Create minimal test array with input shape\n        if len(input_shape) == 0:\n            return input_shape\n\n        # Create test input with correct dtype\n        # Try complex first, fall back to float if needed\n        test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n        # Process test input\n        test_output: Any = self._process_array(test_input)\n\n        # Return the shape of the output\n        if isinstance(test_output, np.ndarray):\n            return tuple(int(s) for s in test_output.shape)\n        return input_shape\n    except Exception as e:\n        logger.warning(\n            f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n            \"Please implement calculate_output_shape method.\"\n        )\n        raise NotImplementedError(\n            f\"Subclass {self.__class__.__name__} must implement \"\n            f\"calculate_output_shape or ensure _process_array can be \"\n            f\"called with test data.\"\n        ) from e\n</code></pre>"},{"location":"api/#wandas.processing.AudioOperation.process","title":"<code>process(data)</code>","text":"<p>Execute operation and return result data shape is (channels, samples)</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    \"\"\"\n    Execute operation and return result\n    data shape is (channels, samples)\n    \"\"\"\n    # Add task as delayed processing with custom name for visualization\n    logger.debug(\"Adding delayed operation to computation graph\")\n\n    # Create a wrapper function with the operation name\n    # This allows Dask to use the operation name in the task graph\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    delayed_result = delayed_func(data)\n\n    # Convert delayed result to dask array and return\n    output_shape = self.calculate_output_shape(data.shape)\n    return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"api/#wandas.processing.AddWithSNR","title":"<code>AddWithSNR</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Addition operation considering SNR</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class AddWithSNR(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Addition operation considering SNR\"\"\"\n\n    name = \"add_with_snr\"\n\n    def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n        \"\"\"\n        Initialize addition operation considering SNR\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other : DaArray\n            Noise signal to add (channel-frame format)\n        snr : float\n            Signal-to-noise ratio (dB)\n        \"\"\"\n        super().__init__(sampling_rate, other=other, snr=snr)\n\n        self.other = other\n        self.snr = snr\n        logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"+SNR\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform addition processing considering SNR\"\"\"\n        logger.debug(f\"Applying SNR-based addition with shape: {x.shape}\")\n        other: NDArrayReal = self.other.compute()\n\n        # Use multi-channel versions of calculate_rms and calculate_desired_noise_rms\n        clean_rms = util.calculate_rms(x)\n        other_rms = util.calculate_rms(other)\n\n        # Adjust noise gain based on specified SNR (apply per channel)\n        desired_noise_rms = util.calculate_desired_noise_rms(clean_rms, self.snr)\n\n        # Apply gain per channel using broadcasting\n        gain = desired_noise_rms / other_rms\n        # Add adjusted noise to signal\n        result: NDArrayReal = x + other * gain\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.AddWithSNR-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.AddWithSNR.name","title":"<code>name = 'add_with_snr'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AddWithSNR.other","title":"<code>other = other</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AddWithSNR.snr","title":"<code>snr = snr</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AddWithSNR-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.AddWithSNR.__init__","title":"<code>__init__(sampling_rate, other, snr=1.0)</code>","text":"<p>Initialize addition operation considering SNR</p>"},{"location":"api/#wandas.processing.AddWithSNR.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other : DaArray     Noise signal to add (channel-frame format) snr : float     Signal-to-noise ratio (dB)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n    \"\"\"\n    Initialize addition operation considering SNR\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other : DaArray\n        Noise signal to add (channel-frame format)\n    snr : float\n        Signal-to-noise ratio (dB)\n    \"\"\"\n    super().__init__(sampling_rate, other=other, snr=snr)\n\n    self.other = other\n    self.snr = snr\n    logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n</code></pre>"},{"location":"api/#wandas.processing.AddWithSNR.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.AddWithSNR.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.AddWithSNR.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.AddWithSNR.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"+SNR\"\n</code></pre>"},{"location":"api/#wandas.processing.HpssHarmonic","title":"<code>HpssHarmonic</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Harmonic operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssHarmonic(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Harmonic operation\"\"\"\n\n    name = \"hpss_harmonic\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Harmonic\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Hrm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Harmonic\"\"\"\n        logger.debug(f\"Applying HPSS Harmonic to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.harmonic(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Harmonic applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.HpssHarmonic-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.HpssHarmonic.name","title":"<code>name = 'hpss_harmonic'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HpssHarmonic.kwargs","title":"<code>kwargs = kwargs</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HpssHarmonic-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.HpssHarmonic.__init__","title":"<code>__init__(sampling_rate, **kwargs)</code>","text":"<p>Initialize HPSS Harmonic</p>"},{"location":"api/#wandas.processing.HpssHarmonic.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Harmonic\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"api/#wandas.processing.HpssHarmonic.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.HpssHarmonic.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Hrm\"\n</code></pre>"},{"location":"api/#wandas.processing.HpssPercussive","title":"<code>HpssPercussive</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Percussive operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssPercussive(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Percussive operation\"\"\"\n\n    name = \"hpss_percussive\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Percussive\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Prc\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Percussive\"\"\"\n        logger.debug(f\"Applying HPSS Percussive to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.percussive(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Percussive applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.HpssPercussive-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.HpssPercussive.name","title":"<code>name = 'hpss_percussive'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HpssPercussive.kwargs","title":"<code>kwargs = kwargs</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HpssPercussive-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.HpssPercussive.__init__","title":"<code>__init__(sampling_rate, **kwargs)</code>","text":"<p>Initialize HPSS Percussive</p>"},{"location":"api/#wandas.processing.HpssPercussive.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Percussive\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"api/#wandas.processing.HpssPercussive.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.HpssPercussive.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Prc\"\n</code></pre>"},{"location":"api/#wandas.processing.AWeighting","title":"<code>AWeighting</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>A-weighting filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class AWeighting(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"A-weighting filter operation\"\"\"\n\n    name = \"a_weighting\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize A-weighting filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Aw\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for A-weighting filter\"\"\"\n        logger.debug(f\"Applying A-weighting to array with shape: {x.shape}\")\n        result = A_weight(x, self.sampling_rate)\n\n        # Handle case where A_weight returns a tuple\n        if isinstance(result, tuple):\n            # Use the first element of the tuple\n            result = result[0]\n\n        logger.debug(\n            f\"A-weighting applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre>"},{"location":"api/#wandas.processing.AWeighting-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.AWeighting.name","title":"<code>name = 'a_weighting'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.AWeighting-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.AWeighting.__init__","title":"<code>__init__(sampling_rate)</code>","text":"<p>Initialize A-weighting filter</p>"},{"location":"api/#wandas.processing.AWeighting.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize A-weighting filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"api/#wandas.processing.AWeighting.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.AWeighting.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Aw\"\n</code></pre>"},{"location":"api/#wandas.processing.HighPassFilter","title":"<code>HighPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>High-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class HighPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"High-pass filter operation\"\"\"\n\n    name = \"highpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize high-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up high-pass filter processor\"\"\"\n        # Calculate filter coefficients (once) - safely retrieve from instance variables\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"high\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Highpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"hpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying highpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.HighPassFilter-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.HighPassFilter.name","title":"<code>name = 'highpass_filter'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HighPassFilter.a","title":"<code>a</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HighPassFilter.b","title":"<code>b</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HighPassFilter.cutoff","title":"<code>cutoff = cutoff</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HighPassFilter.order","title":"<code>order = order</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.HighPassFilter-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.HighPassFilter.__init__","title":"<code>__init__(sampling_rate, cutoff, order=4)</code>","text":"<p>Initialize high-pass filter</p>"},{"location":"api/#wandas.processing.HighPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) cutoff : float     Cutoff frequency (Hz). Must be between 0 and Nyquist frequency     (sampling_rate / 2). order : int, optional     Filter order, default is 4</p>"},{"location":"api/#wandas.processing.HighPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize high-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"api/#wandas.processing.HighPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"api/#wandas.processing.HighPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.HighPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"hpf\"\n</code></pre>"},{"location":"api/#wandas.processing.LowPassFilter","title":"<code>LowPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Low-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class LowPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Low-pass filter operation\"\"\"\n\n    name = \"lowpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize low-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up low-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"low\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Lowpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"lpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying lowpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.LowPassFilter-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.LowPassFilter.name","title":"<code>name = 'lowpass_filter'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LowPassFilter.a","title":"<code>a</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LowPassFilter.b","title":"<code>b</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LowPassFilter.cutoff","title":"<code>cutoff = cutoff</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LowPassFilter.order","title":"<code>order = order</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LowPassFilter-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.LowPassFilter.__init__","title":"<code>__init__(sampling_rate, cutoff, order=4)</code>","text":"<p>Initialize low-pass filter</p>"},{"location":"api/#wandas.processing.LowPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) cutoff : float     Cutoff frequency (Hz). Must be between 0 and Nyquist frequency     (sampling_rate / 2). order : int, optional     Filter order, default is 4</p>"},{"location":"api/#wandas.processing.LowPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize low-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"api/#wandas.processing.LowPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"api/#wandas.processing.LowPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.LowPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"lpf\"\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwst","title":"<code>LoudnessZwst</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This operation computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's implementation of the standardized loudness calculation for steady signals.</p> <p>The loudness is calculated in sones, a unit of perceived loudness where a doubling of sones corresponds to a doubling of perceived loudness.</p>"},{"location":"api/#wandas.processing.LoudnessZwst--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz. The signal should be sampled at a rate appropriate     for the analysis (typically 44100 Hz or 48000 Hz for audio). field_type : str, default=\"free\"     Type of sound field. Options:     - 'free': Free field (sound arriving from a specific direction)     - 'diffuse': Diffuse field (sound arriving uniformly from all directions)</p>"},{"location":"api/#wandas.processing.LoudnessZwst--attributes","title":"Attributes","text":"<p>name : str     Operation name: \"loudness_zwst\" field_type : str     The sound field type used for calculation</p>"},{"location":"api/#wandas.processing.LoudnessZwst--examples","title":"Examples","text":"<p>Calculate steady-state loudness for a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"fan_noise.wav\") loudness = signal.loudness_zwst(field_type=\"free\") print(f\"Steady-state loudness: {loudness.data[0]:.2f} sones\")</p>"},{"location":"api/#wandas.processing.LoudnessZwst--notes","title":"Notes","text":"<ul> <li>The output contains a single loudness value in sones for each channel</li> <li>For mono signals, the loudness is calculated directly</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The method follows ISO 532-1:2017 standard for steady-state loudness</li> <li>Typical loudness values: 1 sone \u2248 40 phon (loudness level)</li> <li>This method is suitable for stationary signals such as fan noise,   constant machinery sounds, or other steady sounds</li> </ul>"},{"location":"api/#wandas.processing.LoudnessZwst--references","title":"References","text":"<p>.. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014        Part 1: Zwicker method\" .. [2] MoSQITo documentation:        https://mosqito.readthedocs.io/en/latest/</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class LoudnessZwst(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This operation computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's\n    implementation of the standardized loudness calculation for steady signals.\n\n    The loudness is calculated in sones, a unit of perceived loudness where a doubling\n    of sones corresponds to a doubling of perceived loudness.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz. The signal should be sampled at a rate appropriate\n        for the analysis (typically 44100 Hz or 48000 Hz for audio).\n    field_type : str, default=\"free\"\n        Type of sound field. Options:\n        - 'free': Free field (sound arriving from a specific direction)\n        - 'diffuse': Diffuse field (sound arriving uniformly from all directions)\n\n    Attributes\n    ----------\n    name : str\n        Operation name: \"loudness_zwst\"\n    field_type : str\n        The sound field type used for calculation\n\n    Examples\n    --------\n    Calculate steady-state loudness for a signal:\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n    &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n    &gt;&gt;&gt; print(f\"Steady-state loudness: {loudness.data[0]:.2f} sones\")\n\n    Notes\n    -----\n    - The output contains a single loudness value in sones for each channel\n    - For mono signals, the loudness is calculated directly\n    - For multi-channel signals, loudness is calculated per channel\n    - The method follows ISO 532-1:2017 standard for steady-state loudness\n    - Typical loudness values: 1 sone \u2248 40 phon (loudness level)\n    - This method is suitable for stationary signals such as fan noise,\n      constant machinery sounds, or other steady sounds\n\n    References\n    ----------\n    .. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n           Part 1: Zwicker method\"\n    .. [2] MoSQITo documentation:\n           https://mosqito.readthedocs.io/en/latest/\n    \"\"\"\n\n    name = \"loudness_zwst\"\n\n    def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n        \"\"\"\n        Initialize steady-state loudness calculation operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        field_type : str, default=\"free\"\n            Type of sound field ('free' or 'diffuse')\n        \"\"\"\n        self.field_type = field_type\n        super().__init__(sampling_rate, field_type=field_type)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"\n        Validate parameters.\n\n        Raises\n        ------\n        ValueError\n            If field_type is not 'free' or 'diffuse'\n        \"\"\"\n        if self.field_type not in (\"free\", \"diffuse\"):\n            raise ValueError(\n                f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n            )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get metadata updates to apply after processing.\n\n        For steady-state loudness, the output is a single value per channel,\n        so no sampling rate update is needed (output is scalar, not time-series).\n\n        Returns\n        -------\n        dict\n            Empty dictionary (no metadata updates needed)\n\n        Notes\n        -----\n        Unlike time-varying loudness, steady-state loudness produces a single\n        value, not a time series, so the sampling rate concept doesn't apply.\n        \"\"\"\n        return {}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        The steady-state loudness calculation produces a single loudness value\n        per channel.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape: (channels, 1) - one loudness value per channel\n        \"\"\"\n        n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n        return (n_channels, 1)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"\n        Process array to calculate steady-state loudness.\n\n        This method calculates the steady-state loudness for each channel\n        of the input signal using the Zwicker method.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array with shape (channels, samples) or (samples,)\n\n        Returns\n        -------\n        NDArrayReal\n            Steady-state loudness in sones for each channel.\n            Shape: (channels, 1)\n\n        Notes\n        -----\n        The function processes each channel independently and returns\n        a single loudness value per channel.\n        \"\"\"\n        logger.debug(\n            f\"Calculating steady-state loudness for signal with shape: {x.shape}, \"\n            f\"field_type: {self.field_type}\"\n        )\n\n        # Handle 1D input (single channel)\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        n_channels = x.shape[0]\n        loudness_results = []\n\n        for ch in range(n_channels):\n            channel_data = x[ch, :]\n\n            # Ensure channel_data is a contiguous 1D NumPy array\n            channel_data = np.asarray(channel_data).ravel()\n\n            # Call MoSQITo's loudness_zwst function\n            # Returns: N (single loudness value), N_spec (specific loudness),\n            #          bark_axis\n            loudness_n, _, _ = loudness_zwst_mosqito(\n                channel_data, self.sampling_rate, field_type=self.field_type\n            )\n\n            loudness_results.append(loudness_n)\n\n            logger.debug(\n                f\"Channel {ch}: Calculated steady-state loudness: \"\n                f\"{loudness_n:.2f} sones\"\n            )\n\n        # Stack results and reshape to (channels, 1)\n        result: NDArrayReal = np.array(loudness_results).reshape(n_channels, 1)\n\n        logger.debug(\n            f\"Steady-state loudness calculation complete, output shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwst-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.LoudnessZwst.name","title":"<code>name = 'loudness_zwst'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LoudnessZwst.field_type","title":"<code>field_type = field_type</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LoudnessZwst-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.LoudnessZwst.__init__","title":"<code>__init__(sampling_rate, field_type='free')</code>","text":"<p>Initialize steady-state loudness calculation operation.</p>"},{"location":"api/#wandas.processing.LoudnessZwst.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize steady-state loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwst.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters.</p>"},{"location":"api/#wandas.processing.LoudnessZwst.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwst.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Get metadata updates to apply after processing.</p> <p>For steady-state loudness, the output is a single value per channel, so no sampling rate update is needed (output is scalar, not time-series).</p>"},{"location":"api/#wandas.processing.LoudnessZwst.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Empty dictionary (no metadata updates needed)</p>"},{"location":"api/#wandas.processing.LoudnessZwst.get_metadata_updates--notes","title":"Notes","text":"<p>Unlike time-varying loudness, steady-state loudness produces a single value, not a time series, so the sampling rate concept doesn't apply.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    For steady-state loudness, the output is a single value per channel,\n    so no sampling rate update is needed (output is scalar, not time-series).\n\n    Returns\n    -------\n    dict\n        Empty dictionary (no metadata updates needed)\n\n    Notes\n    -----\n    Unlike time-varying loudness, steady-state loudness produces a single\n    value, not a time series, so the sampling rate concept doesn't apply.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwst.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation.</p> <p>The steady-state loudness calculation produces a single loudness value per channel.</p>"},{"location":"api/#wandas.processing.LoudnessZwst.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.LoudnessZwst.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape: (channels, 1) - one loudness value per channel</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The steady-state loudness calculation produces a single loudness value\n    per channel.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape: (channels, 1) - one loudness value per channel\n    \"\"\"\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    return (n_channels, 1)\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwtv","title":"<code>LoudnessZwtv</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This operation computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's implementation of the standardized loudness calculation.</p> <p>The loudness is calculated in sones, a unit of perceived loudness where a doubling of sones corresponds to a doubling of perceived loudness.</p>"},{"location":"api/#wandas.processing.LoudnessZwtv--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz. The signal should be sampled at a rate appropriate     for the analysis (typically 44100 Hz or 48000 Hz for audio). field_type : str, default=\"free\"     Type of sound field. Options:     - 'free': Free field (sound arriving from a specific direction)     - 'diffuse': Diffuse field (sound arriving uniformly from all directions)</p>"},{"location":"api/#wandas.processing.LoudnessZwtv--attributes","title":"Attributes","text":"<p>name : str     Operation name: \"loudness_zwtv\" field_type : str     The sound field type used for calculation</p>"},{"location":"api/#wandas.processing.LoudnessZwtv--examples","title":"Examples","text":"<p>Calculate loudness for a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"audio.wav\") loudness = signal.loudness_zwtv(field_type=\"free\")</p>"},{"location":"api/#wandas.processing.LoudnessZwtv--notes","title":"Notes","text":"<ul> <li>The output contains time-varying loudness values in sones</li> <li>For mono signals, the loudness is calculated directly</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The method follows ISO 532-1:2017 standard for time-varying loudness</li> <li>Typical loudness values: 1 sone \u2248 40 phon (loudness level)</li> </ul>"},{"location":"api/#wandas.processing.LoudnessZwtv--references","title":"References","text":"<p>.. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014        Part 1: Zwicker method\" .. [2] MoSQITo documentation:        https://mosqito.readthedocs.io/en/latest/</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class LoudnessZwtv(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This operation computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's\n    implementation of the standardized loudness calculation.\n\n    The loudness is calculated in sones, a unit of perceived loudness where a doubling\n    of sones corresponds to a doubling of perceived loudness.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz. The signal should be sampled at a rate appropriate\n        for the analysis (typically 44100 Hz or 48000 Hz for audio).\n    field_type : str, default=\"free\"\n        Type of sound field. Options:\n        - 'free': Free field (sound arriving from a specific direction)\n        - 'diffuse': Diffuse field (sound arriving uniformly from all directions)\n\n    Attributes\n    ----------\n    name : str\n        Operation name: \"loudness_zwtv\"\n    field_type : str\n        The sound field type used for calculation\n\n    Examples\n    --------\n    Calculate loudness for a signal:\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n\n    Notes\n    -----\n    - The output contains time-varying loudness values in sones\n    - For mono signals, the loudness is calculated directly\n    - For multi-channel signals, loudness is calculated per channel\n    - The method follows ISO 532-1:2017 standard for time-varying loudness\n    - Typical loudness values: 1 sone \u2248 40 phon (loudness level)\n\n    References\n    ----------\n    .. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n           Part 1: Zwicker method\"\n    .. [2] MoSQITo documentation:\n           https://mosqito.readthedocs.io/en/latest/\n    \"\"\"\n\n    name = \"loudness_zwtv\"\n\n    def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n        \"\"\"\n        Initialize Loudness calculation operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        field_type : str, default=\"free\"\n            Type of sound field ('free' or 'diffuse')\n        \"\"\"\n        self.field_type = field_type\n        super().__init__(sampling_rate, field_type=field_type)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"\n        Validate parameters.\n\n        Raises\n        ------\n        ValueError\n            If field_type is not 'free' or 'diffuse'\n        \"\"\"\n        if self.field_type not in (\"free\", \"diffuse\"):\n            raise ValueError(\n                f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n            )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on MoSQITo's time resolution.\n\n        The Zwicker method uses approximately 2ms time steps,\n        which corresponds to 500 Hz sampling rate, independent of\n        the input sampling rate.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        All necessary parameters are provided at initialization.\n        The output sampling rate is always 500 Hz regardless of input.\n        \"\"\"\n        return {\"sampling_rate\": 500.0}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        The loudness calculation produces a time-varying output where the time\n        resolution depends on the algorithm's internal processing. The exact\n        output length is determined dynamically by the loudness_zwtv function.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape. For loudness, we return a placeholder shape\n            since the actual length is determined by the algorithm.\n            The shape will be (channels, time_samples) where time_samples\n            depends on the input length and algorithm parameters.\n        \"\"\"\n        # Return a placeholder shape - the actual shape will be determined\n        # after processing since loudness_zwtv determines the time resolution\n        # For now, we estimate based on typical behavior (approx 2ms time steps)\n        n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n        # Rough estimate: one loudness value per 2ms (0.002s)\n        estimated_time_samples = int(input_shape[-1] / (self.sampling_rate * 0.002))\n        return (n_channels, estimated_time_samples)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"\n        Process array to calculate loudness.\n\n        This method calculates the time-varying loudness for each channel\n        of the input signal using the Zwicker method.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array with shape (channels, samples) or (samples,)\n\n        Returns\n        -------\n        NDArrayReal\n            Time-varying loudness in sones for each channel.\n            Shape: (channels, time_samples)\n\n        Notes\n        -----\n        The function processes each channel independently and returns\n        the loudness values. The time axis information is not returned\n        here but can be reconstructed based on the MoSQITo algorithm's\n        behavior (typically 2ms time steps).\n        \"\"\"\n        logger.debug(\n            f\"Calculating loudness for signal with shape: {x.shape}, \"\n            f\"field_type: {self.field_type}\"\n        )\n\n        # Handle 1D input (single channel)\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        n_channels = x.shape[0]\n        loudness_results = []\n\n        for ch in range(n_channels):\n            channel_data = x[ch, :]\n\n            # Ensure channel_data is a contiguous 1D NumPy array\n            channel_data = np.asarray(channel_data).ravel()\n\n            # Call MoSQITo's loudness_zwtv function\n            # Returns: N (loudness), N_spec (specific loudness),\n            #          bark_axis, time_axis\n            loudness_n, _, _, _ = loudness_zwtv_mosqito(\n                channel_data, self.sampling_rate, field_type=self.field_type\n            )\n\n            loudness_results.append(loudness_n)\n\n            logger.debug(\n                f\"Channel {ch}: Calculated loudness with \"\n                f\"{len(loudness_n)} time points, \"\n                f\"max loudness: {np.max(loudness_n):.2f} sones\"\n            )\n\n        # Stack results\n        result: NDArrayReal = np.stack(loudness_results, axis=0)\n\n        logger.debug(f\"Loudness calculation complete, output shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwtv-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.LoudnessZwtv.name","title":"<code>name = 'loudness_zwtv'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LoudnessZwtv.field_type","title":"<code>field_type = field_type</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.LoudnessZwtv-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.LoudnessZwtv.__init__","title":"<code>__init__(sampling_rate, field_type='free')</code>","text":"<p>Initialize Loudness calculation operation.</p>"},{"location":"api/#wandas.processing.LoudnessZwtv.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize Loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwtv.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters.</p>"},{"location":"api/#wandas.processing.LoudnessZwtv.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwtv.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Update sampling rate based on MoSQITo's time resolution.</p> <p>The Zwicker method uses approximately 2ms time steps, which corresponds to 500 Hz sampling rate, independent of the input sampling rate.</p>"},{"location":"api/#wandas.processing.LoudnessZwtv.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate</p>"},{"location":"api/#wandas.processing.LoudnessZwtv.get_metadata_updates--notes","title":"Notes","text":"<p>All necessary parameters are provided at initialization. The output sampling rate is always 500 Hz regardless of input.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on MoSQITo's time resolution.\n\n    The Zwicker method uses approximately 2ms time steps,\n    which corresponds to 500 Hz sampling rate, independent of\n    the input sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    All necessary parameters are provided at initialization.\n    The output sampling rate is always 500 Hz regardless of input.\n    \"\"\"\n    return {\"sampling_rate\": 500.0}\n</code></pre>"},{"location":"api/#wandas.processing.LoudnessZwtv.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation.</p> <p>The loudness calculation produces a time-varying output where the time resolution depends on the algorithm's internal processing. The exact output length is determined dynamically by the loudness_zwtv function.</p>"},{"location":"api/#wandas.processing.LoudnessZwtv.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.LoudnessZwtv.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape. For loudness, we return a placeholder shape     since the actual length is determined by the algorithm.     The shape will be (channels, time_samples) where time_samples     depends on the input length and algorithm parameters.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The loudness calculation produces a time-varying output where the time\n    resolution depends on the algorithm's internal processing. The exact\n    output length is determined dynamically by the loudness_zwtv function.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape. For loudness, we return a placeholder shape\n        since the actual length is determined by the algorithm.\n        The shape will be (channels, time_samples) where time_samples\n        depends on the input length and algorithm parameters.\n    \"\"\"\n    # Return a placeholder shape - the actual shape will be determined\n    # after processing since loudness_zwtv determines the time resolution\n    # For now, we estimate based on typical behavior (approx 2ms time steps)\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    # Rough estimate: one loudness value per 2ms (0.002s)\n    estimated_time_samples = int(input_shape[-1] / (self.sampling_rate * 0.002))\n    return (n_channels, estimated_time_samples)\n</code></pre>"},{"location":"api/#wandas.processing.CSD","title":"<code>CSD</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Cross-spectral density estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class CSD(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Cross-spectral density estimation operation\"\"\"\n\n    name = \"csd\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize cross-spectral density estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"CSD\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"CSD\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for cross-spectral density estimation operation\"\"\"\n        logger.debug(f\"Applying CSD estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        # Calculate all combinations using scipy's csd function\n        _, csd_result = ss.csd(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayComplex = csd_result.transpose(1, 0, 2).reshape(\n            -1, csd_result.shape[-1]\n        )\n\n        logger.debug(f\"CSD estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.CSD-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.CSD.name","title":"<code>name = 'csd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.scaling","title":"<code>scaling = scaling</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD.average","title":"<code>average = average</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.CSD-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.CSD.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Initialize cross-spectral density estimation operation</p>"},{"location":"api/#wandas.processing.CSD.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant' scaling : str     Type of scaling, default is 'spectrum' average : str     Method of averaging, default is 'mean'</p>"},{"location":"api/#wandas.processing.CSD.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize cross-spectral density estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"CSD\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.CSD.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.CSD.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.CSD.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.CSD.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"CSD\"\n</code></pre>"},{"location":"api/#wandas.processing.FFT","title":"<code>FFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>FFT (Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class FFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"FFT (Fast Fourier Transform) operation\"\"\"\n\n    name = \"fft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize FFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is None (determined by input size)\n        window : str, optional\n            Window function type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not a positive integer\n        \"\"\"\n        # Validate n_fft parameter\n        if n_fft is not None and n_fft &lt;= 0:\n            raise ValueError(\n                f\"Invalid FFT size\\n\"\n                f\"  Got: {n_fft}\\n\"\n                f\"  Expected: Positive integer &gt; 0\\n\"\n                f\"FFT size must be a positive integer.\\n\"\n                f\"Common values: 512, 1024, 2048, 4096,\\n\"\n                f\"8192 (powers of 2 are most efficient)\"\n            )\n\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n        Parameters\n        ----------\n        input_shape : tuple\n            \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n        Returns\n        -------\n        tuple\n            \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"FFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"FFT\u64cd\u4f5c\u306e\u30d7\u30ed\u30bb\u30c3\u30b5\u95a2\u6570\u3092\u4f5c\u6210\"\"\"\n        from scipy.signal import get_window\n\n        if self.n_fft is not None and x.shape[-1] &gt; self.n_fft:\n            # If n_fft is specified and input length exceeds it, truncate\n            x = x[..., : self.n_fft]\n\n        win = get_window(self.window, x.shape[-1])\n        x = x * win\n        result: NDArrayComplex = np.fft.rfft(x, n=self.n_fft, axis=-1)\n        result[..., 1:-1] *= 2.0\n        # \u7a93\u95a2\u6570\u88dc\u6b63\n        scaling_factor = np.sum(win)\n        result = result / scaling_factor\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.FFT-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.FFT.name","title":"<code>name = 'fft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.FFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.FFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.FFT-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.FFT.__init__","title":"<code>__init__(sampling_rate, n_fft=None, window='hann')</code>","text":"<p>Initialize FFT operation</p>"},{"location":"api/#wandas.processing.FFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int, optional     FFT size, default is None (determined by input size) window : str, optional     Window function type, default is 'hann'</p>"},{"location":"api/#wandas.processing.FFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not a positive integer</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize FFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is None (determined by input size)\n    window : str, optional\n        Window function type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not a positive integer\n    \"\"\"\n    # Validate n_fft parameter\n    if n_fft is not None and n_fft &lt;= 0:\n        raise ValueError(\n            f\"Invalid FFT size\\n\"\n            f\"  Got: {n_fft}\\n\"\n            f\"  Expected: Positive integer &gt; 0\\n\"\n            f\"FFT size must be a positive integer.\\n\"\n            f\"Common values: 512, 1024, 2048, 4096,\\n\"\n            f\"8192 (powers of 2 are most efficient)\"\n        )\n\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"api/#wandas.processing.FFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>\u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059</p>"},{"location":"api/#wandas.processing.FFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)</p>"},{"location":"api/#wandas.processing.FFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n    Parameters\n    ----------\n    input_shape : tuple\n        \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n    Returns\n    -------\n    tuple\n        \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.FFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"FFT\"\n</code></pre>"},{"location":"api/#wandas.processing.IFFT","title":"<code>IFFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>IFFT (Inverse Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class IFFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"IFFT (Inverse Fast Fourier Transform) operation\"\"\"\n\n    name = \"ifft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize IFFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : Optional[int], optional\n            IFFT size, default is None (determined based on input size)\n        window : str, optional\n            Window function type, default is 'hann'\n        \"\"\"\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, freqs)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, samples)\n        \"\"\"\n        n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iFFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"Create processor function for IFFT operation\"\"\"\n        logger.debug(f\"Applying IFFT to array with shape: {x.shape}\")\n\n        # Restore frequency component scaling (remove the 2.0 multiplier applied in FFT)\n        _x = x.copy()\n        _x[..., 1:-1] /= 2.0\n\n        # Execute IFFT\n        result: NDArrayReal = np.fft.irfft(_x, n=self.n_fft, axis=-1)\n\n        # Window function correction (inverse of FFT operation)\n        from scipy.signal import get_window\n\n        win = get_window(self.window, result.shape[-1])\n\n        # Correct the FFT window function scaling\n        scaling_factor = np.sum(win) / result.shape[-1]\n        result = result / scaling_factor\n\n        logger.debug(f\"IFFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.IFFT-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.IFFT.name","title":"<code>name = 'ifft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.IFFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.IFFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.IFFT-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.IFFT.__init__","title":"<code>__init__(sampling_rate, n_fft=None, window='hann')</code>","text":"<p>Initialize IFFT operation</p>"},{"location":"api/#wandas.processing.IFFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : Optional[int], optional     IFFT size, default is None (determined based on input size) window : str, optional     Window function type, default is 'hann'</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize IFFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : Optional[int], optional\n        IFFT size, default is None (determined based on input size)\n    window : str, optional\n        Window function type, default is 'hann'\n    \"\"\"\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"api/#wandas.processing.IFFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.IFFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, freqs)</p>"},{"location":"api/#wandas.processing.IFFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, samples)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, freqs)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, samples)\n    \"\"\"\n    n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/#wandas.processing.IFFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iFFT\"\n</code></pre>"},{"location":"api/#wandas.processing.ISTFT","title":"<code>ISTFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>Inverse Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class ISTFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"Inverse Short-Time Fourier Transform operation\"\"\"\n\n    name = \"istft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        length: int | None = None,\n    ):\n        \"\"\"\n        Initialize ISTFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n        length : int, optional\n            Length of output signal. Default is None (determined from input)\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"ISTFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.length = length\n\n        # Instantiate ShortTimeFFT for ISTFT calculation\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",  # Consistent scaling with STFT\n        )\n\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            length=length,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after ISTFT operation.\n\n        Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n        output length based on the input spectrogram dimensions and output range\n        parameters (k0, k1).\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input spectrogram shape (channels, n_freqs, n_frames)\n            where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n        Returns\n        -------\n        tuple\n            Output shape (channels, output_samples) where output_samples is the\n            reconstructed signal length determined by the output range [k0, k1).\n\n        Notes\n        -----\n        The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n        When k1 is None (default), the maximum reconstructible signal length is\n        computed as:\n\n        .. math::\n\n            q_{max} = n_{frames} + p_{min}\n\n            k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n        The output length is then:\n\n        .. math::\n\n            output\\\\_samples = k_1 - k_0\n\n        where k0 defaults to 0 and k1 defaults to k_max.\n\n        Parameters that affect the calculation:\n        - n_frames: number of time frames in the STFT\n        - p_min: minimum frame index (ShortTimeFFT property)\n        - hop: hop length (samples between frames)\n        - m_num: window length\n        - m_num_mid: window midpoint position\n        - self.length: optional length override (if set, limits output)\n\n        References\n        ----------\n        - SciPy ShortTimeFFT.istft:\n          https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n        - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        \"\"\"\n        n_channels = input_shape[0]\n        n_frames = input_shape[-1]  # time_frames\n\n        # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n        # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        q_max = n_frames + self.SFT.p_min\n        k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n        # Default parameters: k0=0, k1=None (which becomes k_max)\n        # The output length is k1 - k0 = k_max - 0 = k_max\n        k0 = 0\n        k1 = k_max\n\n        # If self.length is specified, it acts as an override to limit the output\n        if self.length is not None:\n            k1 = min(self.length, k1)\n\n        output_samples = k1 - k0\n\n        return (n_channels, output_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iSTFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"\n        Apply SciPy ISTFT processing to multiple channels at once using ShortTimeFFT\"\"\"\n        logger.debug(\n            f\"Applying SciPy ISTFT (ShortTimeFFT) to array with shape: {x.shape}\"\n        )\n\n        # Convert 2D input to 3D (assume single channel)\n        if x.ndim == 2:\n            x = x.reshape(1, *x.shape)\n\n        # Adjust scaling back if STFT applied factor of 2\n        _x = np.copy(x)\n        _x[..., 1:-1, :] /= 2.0\n\n        # Apply ISTFT using the ShortTimeFFT instance\n        result: NDArrayReal = self.SFT.istft(_x)\n\n        # Trim to desired length if specified\n        if self.length is not None:\n            result = result[..., : self.length]\n\n        logger.debug(\n            f\"ShortTimeFFT applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.ISTFT-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.ISTFT.name","title":"<code>name = 'istft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT.length","title":"<code>length = length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT.SFT","title":"<code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ISTFT-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.ISTFT.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', length=None)</code>","text":"<p>Initialize ISTFT operation</p>"},{"location":"api/#wandas.processing.ISTFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window type, default is 'hann' length : int, optional     Length of output signal. Default is None (determined from input)</p>"},{"location":"api/#wandas.processing.ISTFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    length: int | None = None,\n):\n    \"\"\"\n    Initialize ISTFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n    length : int, optional\n        Length of output signal. Default is None (determined from input)\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"ISTFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.length = length\n\n    # Instantiate ShortTimeFFT for ISTFT calculation\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",  # Consistent scaling with STFT\n    )\n\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        length=length,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.ISTFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after ISTFT operation.</p> <p>Uses the SciPy ShortTimeFFT calculation formula to compute the expected output length based on the input spectrogram dimensions and output range parameters (k0, k1).</p>"},{"location":"api/#wandas.processing.ISTFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input spectrogram shape (channels, n_freqs, n_frames)     where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.</p>"},{"location":"api/#wandas.processing.ISTFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output shape (channels, output_samples) where output_samples is the     reconstructed signal length determined by the output range [k0, k1).</p>"},{"location":"api/#wandas.processing.ISTFT.calculate_output_shape--notes","title":"Notes","text":"<p>The calculation follows SciPy's ShortTimeFFT.istft() implementation. When k1 is None (default), the maximum reconstructible signal length is computed as:</p> <p>.. math::</p> <pre><code>q_{max} = n_{frames} + p_{min}\n\nk_{max} = (q_{max} - 1) \\cdot hop + m_{num} - m_{num\\_mid}\n</code></pre> <p>The output length is then:</p> <p>.. math::</p> <pre><code>output\\_samples = k_1 - k_0\n</code></pre> <p>where k0 defaults to 0 and k1 defaults to k_max.</p> <p>Parameters that affect the calculation: - n_frames: number of time frames in the STFT - p_min: minimum frame index (ShortTimeFFT property) - hop: hop length (samples between frames) - m_num: window length - m_num_mid: window midpoint position - self.length: optional length override (if set, limits output)</p>"},{"location":"api/#wandas.processing.ISTFT.calculate_output_shape--references","title":"References","text":"<ul> <li>SciPy ShortTimeFFT.istft:   https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html</li> <li>SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py</li> </ul> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after ISTFT operation.\n\n    Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n    output length based on the input spectrogram dimensions and output range\n    parameters (k0, k1).\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input spectrogram shape (channels, n_freqs, n_frames)\n        where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n    Returns\n    -------\n    tuple\n        Output shape (channels, output_samples) where output_samples is the\n        reconstructed signal length determined by the output range [k0, k1).\n\n    Notes\n    -----\n    The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n    When k1 is None (default), the maximum reconstructible signal length is\n    computed as:\n\n    .. math::\n\n        q_{max} = n_{frames} + p_{min}\n\n        k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n    The output length is then:\n\n    .. math::\n\n        output\\\\_samples = k_1 - k_0\n\n    where k0 defaults to 0 and k1 defaults to k_max.\n\n    Parameters that affect the calculation:\n    - n_frames: number of time frames in the STFT\n    - p_min: minimum frame index (ShortTimeFFT property)\n    - hop: hop length (samples between frames)\n    - m_num: window length\n    - m_num_mid: window midpoint position\n    - self.length: optional length override (if set, limits output)\n\n    References\n    ----------\n    - SciPy ShortTimeFFT.istft:\n      https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n    - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    \"\"\"\n    n_channels = input_shape[0]\n    n_frames = input_shape[-1]  # time_frames\n\n    # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n    # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    q_max = n_frames + self.SFT.p_min\n    k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n    # Default parameters: k0=0, k1=None (which becomes k_max)\n    # The output length is k1 - k0 = k_max - 0 = k_max\n    k0 = 0\n    k1 = k_max\n\n    # If self.length is specified, it acts as an override to limit the output\n    if self.length is not None:\n        k1 = min(self.length, k1)\n\n    output_samples = k1 - k0\n\n    return (n_channels, output_samples)\n</code></pre>"},{"location":"api/#wandas.processing.ISTFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iSTFT\"\n</code></pre>"},{"location":"api/#wandas.processing.STFT","title":"<code>STFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class STFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Short-Time Fourier Transform operation\"\"\"\n\n    name = \"stft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ):\n        \"\"\"\n        Initialize STFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"STFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",\n        )\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        n_samples = input_shape[-1]\n        n_f = len(self.SFT.f)\n        n_t = len(self.SFT.t(n_samples))\n        return (input_shape[0], n_f, n_t)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"STFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Apply SciPy STFT processing to multiple channels at once\"\"\"\n        logger.debug(f\"Applying SciPy STFT to array with shape: {x.shape}\")\n\n        # Convert 1D input to 2D\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        # Apply STFT to all channels at once\n        result: NDArrayComplex = self.SFT.stft(x)\n        result[..., 1:-1, :] *= 2.0\n        logger.debug(f\"SciPy STFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.STFT-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.STFT.name","title":"<code>name = 'stft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT.noverlap","title":"<code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT.SFT","title":"<code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.STFT-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.STFT.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann')</code>","text":"<p>Initialize STFT operation</p>"},{"location":"api/#wandas.processing.STFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window type, default is 'hann'</p>"},{"location":"api/#wandas.processing.STFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n):\n    \"\"\"\n    Initialize STFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"STFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",\n    )\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.STFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.STFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.STFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    n_samples = input_shape[-1]\n    n_f = len(self.SFT.f)\n    n_t = len(self.SFT.t(n_samples))\n    return (input_shape[0], n_f, n_t)\n</code></pre>"},{"location":"api/#wandas.processing.STFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"STFT\"\n</code></pre>"},{"location":"api/#wandas.processing.Coherence","title":"<code>Coherence</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Coherence estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Coherence(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Coherence estimation operation\"\"\"\n\n    name = \"coherence\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize coherence estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Coherence\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Coh\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Processor function for coherence estimation operation\"\"\"\n        logger.debug(f\"Applying coherence estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        _, coh = ss.coherence(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayReal = coh.transpose(1, 0, 2).reshape(-1, coh.shape[-1])\n\n        logger.debug(f\"Coherence estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.Coherence-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.Coherence.name","title":"<code>name = 'coherence'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Coherence.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Coherence.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Coherence.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Coherence.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Coherence.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Coherence-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.Coherence.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code>","text":"<p>Initialize coherence estimation operation</p>"},{"location":"api/#wandas.processing.Coherence.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant'</p>"},{"location":"api/#wandas.processing.Coherence.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize coherence estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Coherence\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.Coherence.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.Coherence.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.Coherence.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.Coherence.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Coh\"\n</code></pre>"},{"location":"api/#wandas.processing.NOctSpectrum","title":"<code>NOctSpectrum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>N-octave spectrum operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSpectrum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"N-octave spectrum operation\"\"\"\n\n    name = \"noct_spectrum\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize N-octave spectrum\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Oct\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave spectrum\"\"\"\n        logger.debug(f\"Applying NoctSpectrum to array with shape: {x.shape}\")\n        spec, _ = noct_spectrum(\n            sig=x.T,\n            fs=self.sampling_rate,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if spec.ndim == 1:\n            # Add channel dimension for 1D\n            spec = np.expand_dims(spec, axis=0)\n        else:\n            spec = spec.T\n        logger.debug(f\"NoctSpectrum applied, returning result with shape: {spec.shape}\")\n        return np.array(spec)\n</code></pre>"},{"location":"api/#wandas.processing.NOctSpectrum-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.NOctSpectrum.name","title":"<code>name = 'noct_spectrum'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSpectrum.fmin","title":"<code>fmin = fmin</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSpectrum.fmax","title":"<code>fmax = fmax</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSpectrum.n","title":"<code>n = n</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSpectrum.G","title":"<code>G = G</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSpectrum.fr","title":"<code>fr = fr</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSpectrum-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.NOctSpectrum.__init__","title":"<code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code>","text":"<p>Initialize N-octave spectrum</p>"},{"location":"api/#wandas.processing.NOctSpectrum.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize N-octave spectrum\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"api/#wandas.processing.NOctSpectrum.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.NOctSpectrum.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.NOctSpectrum.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"api/#wandas.processing.NOctSpectrum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Oct\"\n</code></pre>"},{"location":"api/#wandas.processing.NOctSynthesis","title":"<code>NOctSynthesis</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Octave synthesis operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSynthesis(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Octave synthesis operation\"\"\"\n\n    name = \"noct_synthesis\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize octave synthesis\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Octs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave synthesis\"\"\"\n        logger.debug(f\"Applying NoctSynthesis to array with shape: {x.shape}\")\n        # Calculate n from shape[-1]\n        n = x.shape[-1]  # Calculate n from shape[-1]\n        if n % 2 == 0:\n            n = n * 2 - 1\n        else:\n            n = (n - 1) * 2\n        freqs = np.fft.rfftfreq(n, d=1 / self.sampling_rate)\n        result, _ = noct_synthesis(\n            spectrum=np.abs(x).T,\n            freqs=freqs,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        result = result.T\n        logger.debug(\n            f\"NoctSynthesis applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre>"},{"location":"api/#wandas.processing.NOctSynthesis-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.NOctSynthesis.name","title":"<code>name = 'noct_synthesis'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSynthesis.fmin","title":"<code>fmin = fmin</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSynthesis.fmax","title":"<code>fmax = fmax</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSynthesis.n","title":"<code>n = n</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSynthesis.G","title":"<code>G = G</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSynthesis.fr","title":"<code>fr = fr</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.NOctSynthesis-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.NOctSynthesis.__init__","title":"<code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code>","text":"<p>Initialize octave synthesis</p>"},{"location":"api/#wandas.processing.NOctSynthesis.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize octave synthesis\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"api/#wandas.processing.NOctSynthesis.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.NOctSynthesis.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.NOctSynthesis.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"api/#wandas.processing.NOctSynthesis.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Octs\"\n</code></pre>"},{"location":"api/#wandas.processing.TransferFunction","title":"<code>TransferFunction</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Transfer function estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class TransferFunction(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Transfer function estimation operation\"\"\"\n\n    name = \"transfer_function\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize transfer function estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Transfer function\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"H\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for transfer function estimation operation\"\"\"\n        logger.debug(\n            f\"Applying transfer function estimation to array with shape: {x.shape}\"\n        )\n        from scipy import signal as ss\n\n        # Calculate cross-spectral density between all channels\n        f, p_yx = ss.csd(\n            x=x[:, np.newaxis, :],\n            y=x[np.newaxis, :, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_yx shape: (num_channels, num_channels, num_frequencies)\n\n        # Calculate power spectral density for each channel\n        f, p_xx = ss.welch(\n            x=x,\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_xx shape: (num_channels, num_frequencies)\n\n        # Calculate transfer function H(f) = P_yx / P_xx\n        h_f = p_yx / p_xx[np.newaxis, :, :]\n        result: NDArrayComplex = h_f.transpose(1, 0, 2).reshape(-1, h_f.shape[-1])\n\n        logger.debug(\n            f\"Transfer function estimation applied, result shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.TransferFunction-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.TransferFunction.name","title":"<code>name = 'transfer_function'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.scaling","title":"<code>scaling = scaling</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction.average","title":"<code>average = average</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.TransferFunction-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.TransferFunction.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Initialize transfer function estimation operation</p>"},{"location":"api/#wandas.processing.TransferFunction.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant' scaling : str     Type of scaling, default is 'spectrum' average : str     Method of averaging, default is 'mean'</p>"},{"location":"api/#wandas.processing.TransferFunction.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize transfer function estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Transfer function\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.TransferFunction.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.TransferFunction.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.TransferFunction.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.TransferFunction.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"H\"\n</code></pre>"},{"location":"api/#wandas.processing.Welch","title":"<code>Welch</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Welch</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Welch(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Welch\"\"\"\n\n    name = \"welch\"\n    n_fft: int\n    window: str\n    hop_length: int | None\n    win_length: int | None\n    average: str\n    detrend: str\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        average: str = \"mean\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize Welch operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str, optional\n            Window function type, default is 'hann'\n        average : str, optional\n            Averaging method, default is 'mean'\n        detrend : str, optional\n            Detrend method, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft, win_length, or hop_length are invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Welch method\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n        self.average = average\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            average=average,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"PS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for Welch operation\"\"\"\n        from scipy import signal as ss\n\n        _, result = ss.welch(\n            x,\n            nperseg=self.win_length,\n            noverlap=self.noverlap,\n            nfft=self.n_fft,\n            window=self.window,\n            average=self.average,\n            detrend=self.detrend,\n            scaling=\"spectrum\",\n        )\n\n        if not isinstance(x, np.ndarray):\n            # Trigger computation for Dask array\n            raise ValueError(\n                \"Welch operation requires a Dask array, but received a non-ndarray.\"\n            )\n        return np.array(result)\n</code></pre>"},{"location":"api/#wandas.processing.Welch-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.Welch.name","title":"<code>name = 'welch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.average","title":"<code>average = average</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch.noverlap","title":"<code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Welch-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.Welch.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', average='mean', detrend='constant')</code>","text":"<p>Initialize Welch operation</p>"},{"location":"api/#wandas.processing.Welch.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int, optional     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str, optional     Window function type, default is 'hann' average : str, optional     Averaging method, default is 'mean' detrend : str, optional     Detrend method, default is 'constant'</p>"},{"location":"api/#wandas.processing.Welch.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft, win_length, or hop_length are invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    average: str = \"mean\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize Welch operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str, optional\n        Window function type, default is 'hann'\n    average : str, optional\n        Averaging method, default is 'mean'\n    detrend : str, optional\n        Detrend method, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft, win_length, or hop_length are invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Welch method\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n    self.average = average\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        average=average,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.Welch.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.Welch.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.Welch.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.Welch.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"PS\"\n</code></pre>"},{"location":"api/#wandas.processing.ABS","title":"<code>ABS</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Absolute value operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ABS(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Absolute value operation\"\"\"\n\n    name = \"abs\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize absolute value operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"abs\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/#wandas.processing.ABS-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.ABS.name","title":"<code>name = 'abs'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ABS-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.ABS.__init__","title":"<code>__init__(sampling_rate)</code>","text":"<p>Initialize absolute value operation</p>"},{"location":"api/#wandas.processing.ABS.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize absolute value operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"api/#wandas.processing.ABS.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"abs\"\n</code></pre>"},{"location":"api/#wandas.processing.ABS.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/#wandas.processing.ChannelDifference","title":"<code>ChannelDifference</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Channel difference calculation operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ChannelDifference(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Channel difference calculation operation\"\"\"\n\n    name = \"channel_difference\"\n    other_channel: int\n\n    def __init__(self, sampling_rate: float, other_channel: int = 0):\n        \"\"\"\n        Initialize channel difference calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other_channel : int\n            Channel to calculate difference with, default is 0\n        \"\"\"\n        self.other_channel = other_channel\n        super().__init__(sampling_rate, other_channel=other_channel)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"diff\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        result = data - data[self.other_channel]\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.ChannelDifference-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.ChannelDifference.name","title":"<code>name = 'channel_difference'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ChannelDifference.other_channel","title":"<code>other_channel = other_channel</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ChannelDifference-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.ChannelDifference.__init__","title":"<code>__init__(sampling_rate, other_channel=0)</code>","text":"<p>Initialize channel difference calculation</p>"},{"location":"api/#wandas.processing.ChannelDifference.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other_channel : int     Channel to calculate difference with, default is 0</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, other_channel: int = 0):\n    \"\"\"\n    Initialize channel difference calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other_channel : int\n        Channel to calculate difference with, default is 0\n    \"\"\"\n    self.other_channel = other_channel\n    super().__init__(sampling_rate, other_channel=other_channel)\n</code></pre>"},{"location":"api/#wandas.processing.ChannelDifference.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"diff\"\n</code></pre>"},{"location":"api/#wandas.processing.ChannelDifference.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    result = data - data[self.other_channel]\n    return result\n</code></pre>"},{"location":"api/#wandas.processing.Mean","title":"<code>Mean</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Mean calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Mean(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Mean calculation\"\"\"\n\n    name = \"mean\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"mean\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/#wandas.processing.Mean-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.Mean.name","title":"<code>name = 'mean'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Mean-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.Mean.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"mean\"\n</code></pre>"},{"location":"api/#wandas.processing.Mean.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/#wandas.processing.Power","title":"<code>Power</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Power operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Power(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Power operation\"\"\"\n\n    name = \"power\"\n\n    def __init__(self, sampling_rate: float, exponent: float):\n        \"\"\"\n        Initialize power operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        exponent : float\n            Power exponent\n        \"\"\"\n        super().__init__(sampling_rate)\n        self.exp = exponent\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"pow\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/#wandas.processing.Power-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.Power.name","title":"<code>name = 'power'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Power.exp","title":"<code>exp = exponent</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Power-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.Power.__init__","title":"<code>__init__(sampling_rate, exponent)</code>","text":"<p>Initialize power operation</p>"},{"location":"api/#wandas.processing.Power.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) exponent : float     Power exponent</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, exponent: float):\n    \"\"\"\n    Initialize power operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    exponent : float\n        Power exponent\n    \"\"\"\n    super().__init__(sampling_rate)\n    self.exp = exponent\n</code></pre>"},{"location":"api/#wandas.processing.Power.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"pow\"\n</code></pre>"},{"location":"api/#wandas.processing.Power.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/#wandas.processing.Sum","title":"<code>Sum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Sum calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Sum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Sum calculation\"\"\"\n\n    name = \"sum\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"sum\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/#wandas.processing.Sum-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.Sum.name","title":"<code>name = 'sum'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Sum-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.Sum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"sum\"\n</code></pre>"},{"location":"api/#wandas.processing.Sum.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/#wandas.processing.ReSampling","title":"<code>ReSampling</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Resampling operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class ReSampling(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Resampling operation\"\"\"\n\n    name = \"resampling\"\n\n    def __init__(self, sampling_rate: float, target_sr: float):\n        \"\"\"\n        Initialize resampling operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        target_sampling_rate : float\n            Target sampling rate (Hz)\n\n        Raises\n        ------\n        ValueError\n            If sampling_rate or target_sr is not positive\n        \"\"\"\n        validate_sampling_rate(sampling_rate, \"source sampling rate\")\n        validate_sampling_rate(target_sr, \"target sampling rate\")\n        super().__init__(sampling_rate, target_sr=target_sr)\n        self.target_sr = target_sr\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate to target sampling rate.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        Resampling always produces output at target_sr, regardless of input\n        sampling rate. All necessary parameters are provided at initialization.\n        \"\"\"\n        return {\"sampling_rate\": self.target_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after resampling\n        ratio = float(self.target_sr) / float(self.sampling_rate)\n        n_samples = int(np.ceil(input_shape[-1] * ratio))\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"rs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for resampling operation\"\"\"\n        logger.debug(f\"Applying resampling to array with shape: {x.shape}\")\n        result: NDArrayReal = librosa.resample(\n            x, orig_sr=self.sampling_rate, target_sr=self.target_sr\n        )\n        logger.debug(f\"Resampling applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.ReSampling-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.ReSampling.name","title":"<code>name = 'resampling'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ReSampling.target_sr","title":"<code>target_sr = target_sr</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.ReSampling-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.ReSampling.__init__","title":"<code>__init__(sampling_rate, target_sr)</code>","text":"<p>Initialize resampling operation</p>"},{"location":"api/#wandas.processing.ReSampling.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) target_sampling_rate : float     Target sampling rate (Hz)</p>"},{"location":"api/#wandas.processing.ReSampling.__init__--raises","title":"Raises","text":"<p>ValueError     If sampling_rate or target_sr is not positive</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(self, sampling_rate: float, target_sr: float):\n    \"\"\"\n    Initialize resampling operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    target_sampling_rate : float\n        Target sampling rate (Hz)\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate or target_sr is not positive\n    \"\"\"\n    validate_sampling_rate(sampling_rate, \"source sampling rate\")\n    validate_sampling_rate(target_sr, \"target sampling rate\")\n    super().__init__(sampling_rate, target_sr=target_sr)\n    self.target_sr = target_sr\n</code></pre>"},{"location":"api/#wandas.processing.ReSampling.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Update sampling rate to target sampling rate.</p>"},{"location":"api/#wandas.processing.ReSampling.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate</p>"},{"location":"api/#wandas.processing.ReSampling.get_metadata_updates--notes","title":"Notes","text":"<p>Resampling always produces output at target_sr, regardless of input sampling rate. All necessary parameters are provided at initialization.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate to target sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    Resampling always produces output at target_sr, regardless of input\n    sampling rate. All necessary parameters are provided at initialization.\n    \"\"\"\n    return {\"sampling_rate\": self.target_sr}\n</code></pre>"},{"location":"api/#wandas.processing.ReSampling.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.ReSampling.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.ReSampling.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after resampling\n    ratio = float(self.target_sr) / float(self.sampling_rate)\n    n_samples = int(np.ceil(input_shape[-1] * ratio))\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/#wandas.processing.ReSampling.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"rs\"\n</code></pre>"},{"location":"api/#wandas.processing.RmsTrend","title":"<code>RmsTrend</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class RmsTrend(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"RMS calculation\"\"\"\n\n    name = \"rms_trend\"\n    frame_length: int\n    hop_length: int\n    Aw: bool\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        ref: list[float] | float = 1.0,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; None:\n        \"\"\"\n        Initialize RMS calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        frame_length : int\n            Frame length, default is 2048\n        hop_length : int\n            Hop length, default is 512\n        ref : Union[list[float], float]\n            Reference value(s) for dB calculation\n        dB : bool\n            Whether to convert to decibels\n        Aw : bool\n            Whether to apply A-weighting before RMS calculation\n        \"\"\"\n        self.frame_length = frame_length\n        self.hop_length = hop_length\n        self.dB = dB\n        self.Aw = Aw\n        self.ref = np.array(ref if isinstance(ref, list) else [ref])\n        super().__init__(\n            sampling_rate,\n            frame_length=frame_length,\n            hop_length=hop_length,\n            dB=dB,\n            Aw=Aw,\n            ref=self.ref,\n        )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on hop length.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate based on hop length\n\n        Notes\n        -----\n        The output sampling rate is determined by downsampling the input\n        by hop_length. All necessary parameters are provided at initialization.\n        \"\"\"\n        new_sr = self.sampling_rate / self.hop_length\n        return {\"sampling_rate\": new_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, frames)\n        \"\"\"\n        n_frames = librosa.feature.rms(\n            y=np.ones((1, input_shape[-1])),\n            frame_length=self.frame_length,\n            hop_length=self.hop_length,\n        ).shape[-1]\n        return (*input_shape[:-1], n_frames)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"RMS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for RMS calculation\"\"\"\n        logger.debug(f\"Applying RMS to array with shape: {x.shape}\")\n\n        if self.Aw:\n            # Apply A-weighting\n            _x = A_weight(x, self.sampling_rate)\n            if isinstance(_x, np.ndarray):\n                # A_weight\u304c\u30bf\u30d7\u30eb\u3092\u8fd4\u3059\u5834\u5408\u3001\u6700\u521d\u306e\u8981\u7d20\u3092\u4f7f\u7528\n                x = _x\n            elif isinstance(_x, tuple):\n                # Use the first element if A_weight returns a tuple\n                x = _x[0]\n            else:\n                raise ValueError(\"A_weighting returned an unexpected type.\")\n\n        # Calculate RMS\n        result: NDArrayReal = librosa.feature.rms(\n            y=x, frame_length=self.frame_length, hop_length=self.hop_length\n        )[..., 0, :]\n\n        if self.dB:\n            # Convert to dB\n            result = 20 * np.log10(\n                np.maximum(result / self.ref[..., np.newaxis], 1e-12)\n            )\n        #\n        logger.debug(f\"RMS applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.RmsTrend-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.RmsTrend.name","title":"<code>name = 'rms_trend'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.RmsTrend.frame_length","title":"<code>frame_length = frame_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.RmsTrend.hop_length","title":"<code>hop_length = hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.RmsTrend.Aw","title":"<code>Aw = Aw</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.RmsTrend.dB","title":"<code>dB = dB</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.RmsTrend.ref","title":"<code>ref = np.array(ref if isinstance(ref, list) else [ref])</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.RmsTrend-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.RmsTrend.__init__","title":"<code>__init__(sampling_rate, frame_length=2048, hop_length=512, ref=1.0, dB=False, Aw=False)</code>","text":"<p>Initialize RMS calculation</p>"},{"location":"api/#wandas.processing.RmsTrend.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) frame_length : int     Frame length, default is 2048 hop_length : int     Hop length, default is 512 ref : Union[list[float], float]     Reference value(s) for dB calculation dB : bool     Whether to convert to decibels Aw : bool     Whether to apply A-weighting before RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    ref: list[float] | float = 1.0,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; None:\n    \"\"\"\n    Initialize RMS calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    frame_length : int\n        Frame length, default is 2048\n    hop_length : int\n        Hop length, default is 512\n    ref : Union[list[float], float]\n        Reference value(s) for dB calculation\n    dB : bool\n        Whether to convert to decibels\n    Aw : bool\n        Whether to apply A-weighting before RMS calculation\n    \"\"\"\n    self.frame_length = frame_length\n    self.hop_length = hop_length\n    self.dB = dB\n    self.Aw = Aw\n    self.ref = np.array(ref if isinstance(ref, list) else [ref])\n    super().__init__(\n        sampling_rate,\n        frame_length=frame_length,\n        hop_length=hop_length,\n        dB=dB,\n        Aw=Aw,\n        ref=self.ref,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.RmsTrend.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Update sampling rate based on hop length.</p>"},{"location":"api/#wandas.processing.RmsTrend.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate based on hop length</p>"},{"location":"api/#wandas.processing.RmsTrend.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is determined by downsampling the input by hop_length. All necessary parameters are provided at initialization.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on hop length.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate based on hop length\n\n    Notes\n    -----\n    The output sampling rate is determined by downsampling the input\n    by hop_length. All necessary parameters are provided at initialization.\n    \"\"\"\n    new_sr = self.sampling_rate / self.hop_length\n    return {\"sampling_rate\": new_sr}\n</code></pre>"},{"location":"api/#wandas.processing.RmsTrend.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.RmsTrend.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.RmsTrend.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, frames)</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, frames)\n    \"\"\"\n    n_frames = librosa.feature.rms(\n        y=np.ones((1, input_shape[-1])),\n        frame_length=self.frame_length,\n        hop_length=self.hop_length,\n    ).shape[-1]\n    return (*input_shape[:-1], n_frames)\n</code></pre>"},{"location":"api/#wandas.processing.RmsTrend.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"RMS\"\n</code></pre>"},{"location":"api/#wandas.processing.Trim","title":"<code>Trim</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Trimming operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class Trim(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Trimming operation\"\"\"\n\n    name = \"trim\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        start: float,\n        end: float,\n    ):\n        \"\"\"\n        Initialize trimming operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        start : float\n            Start time for trimming (seconds)\n        end : float\n            End time for trimming (seconds)\n        \"\"\"\n        super().__init__(sampling_rate, start=start, end=end)\n        self.start = start\n        self.end = end\n        self.start_sample = int(start * sampling_rate)\n        self.end_sample = int(end * sampling_rate)\n        logger.debug(\n            f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after trimming\n        # Exclude parts where there is no signal\n        end_sample = min(self.end_sample, input_shape[-1])\n        n_samples = end_sample - self.start_sample\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"trim\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for trimming operation\"\"\"\n        logger.debug(f\"Applying trim to array with shape: {x.shape}\")\n        # Apply trimming\n        result = x[..., self.start_sample : self.end_sample]\n        logger.debug(f\"Trim applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/#wandas.processing.Trim-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.Trim.name","title":"<code>name = 'trim'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Trim.start","title":"<code>start = start</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Trim.end","title":"<code>end = end</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Trim.start_sample","title":"<code>start_sample = int(start * sampling_rate)</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Trim.end_sample","title":"<code>end_sample = int(end * sampling_rate)</code>  <code>instance-attribute</code>","text":""},{"location":"api/#wandas.processing.Trim-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.Trim.__init__","title":"<code>__init__(sampling_rate, start, end)</code>","text":"<p>Initialize trimming operation</p>"},{"location":"api/#wandas.processing.Trim.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) start : float     Start time for trimming (seconds) end : float     End time for trimming (seconds)</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    start: float,\n    end: float,\n):\n    \"\"\"\n    Initialize trimming operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    start : float\n        Start time for trimming (seconds)\n    end : float\n        End time for trimming (seconds)\n    \"\"\"\n    super().__init__(sampling_rate, start=start, end=end)\n    self.start = start\n    self.end = end\n    self.start_sample = int(start * sampling_rate)\n    self.end_sample = int(end * sampling_rate)\n    logger.debug(\n        f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n    )\n</code></pre>"},{"location":"api/#wandas.processing.Trim.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/#wandas.processing.Trim.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.Trim.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after trimming\n    # Exclude parts where there is no signal\n    end_sample = min(self.end_sample, input_shape[-1])\n    n_samples = end_sample - self.start_sample\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/#wandas.processing.Trim.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"trim\"\n</code></pre>"},{"location":"api/#wandas.processing-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.create_operation","title":"<code>create_operation(name, sampling_rate, **params)</code>","text":"<p>Create operation instance from name and parameters</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def create_operation(\n    name: str, sampling_rate: float, **params: Any\n) -&gt; AudioOperation[Any, Any]:\n    \"\"\"Create operation instance from name and parameters\"\"\"\n    operation_class = get_operation(name)\n    return operation_class(sampling_rate, **params)\n</code></pre>"},{"location":"api/#wandas.processing.get_operation","title":"<code>get_operation(name)</code>","text":"<p>Get operation class by name</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_operation(name: str) -&gt; type[AudioOperation[Any, Any]]:\n    \"\"\"Get operation class by name\"\"\"\n    if name not in _OPERATION_REGISTRY:\n        raise ValueError(f\"Unknown operation type: {name}\")\n    return _OPERATION_REGISTRY[name]\n</code></pre>"},{"location":"api/#wandas.processing.register_operation","title":"<code>register_operation(operation_class)</code>","text":"<p>Register a new operation type</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def register_operation(operation_class: type) -&gt; None:\n    \"\"\"Register a new operation type\"\"\"\n\n    if not issubclass(operation_class, AudioOperation):\n        raise TypeError(\"Strategy class must inherit from AudioOperation.\")\n    if inspect.isabstract(operation_class):\n        raise TypeError(\"Cannot register abstract AudioOperation class.\")\n\n    _OPERATION_REGISTRY[operation_class.name] = operation_class\n</code></pre>"},{"location":"api/#wandas.processing-modules","title":"Modules","text":""},{"location":"api/#wandas.processing.base","title":"<code>base</code>","text":""},{"location":"api/#wandas.processing.base-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.base.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.base.InputArrayType","title":"<code>InputArrayType = TypeVar('InputArrayType', NDArrayReal, NDArrayComplex)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.base.OutputArrayType","title":"<code>OutputArrayType = TypeVar('OutputArrayType', NDArrayReal, NDArrayComplex)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.base-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.base.AudioOperation","title":"<code>AudioOperation</code>","text":"<p>               Bases: <code>Generic[InputArrayType, OutputArrayType]</code></p> <p>Abstract base class for audio processing operations.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>class AudioOperation(Generic[InputArrayType, OutputArrayType]):\n    \"\"\"Abstract base class for audio processing operations.\"\"\"\n\n    # Class variable: operation name\n    name: ClassVar[str]\n\n    def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n        \"\"\"\n        Initialize AudioOperation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        pure : bool, default=True\n            Whether the operation is pure (deterministic with no side effects).\n            When True, Dask can cache results for identical inputs.\n            Set to False only if the operation has side effects or is non-deterministic.\n        **params : Any\n            Operation-specific parameters\n        \"\"\"\n        self.sampling_rate = sampling_rate\n        self.pure = pure\n        self.params = params\n\n        # Validate parameters during initialization\n        self.validate_params()\n\n        # Create processor function (lazy initialization possible)\n        self._setup_processor()\n\n        logger.debug(\n            f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n        pass\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up processor function (implemented by subclasses)\"\"\"\n        pass\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get metadata updates to apply after processing.\n\n        This method allows operations to specify how metadata should be\n        updated after processing. By default, no metadata is updated.\n\n        Returns\n        -------\n        dict\n            Dictionary of metadata updates. Can include:\n            - 'sampling_rate': New sampling rate (float)\n            - Other metadata keys as needed\n\n        Examples\n        --------\n        Return empty dict for operations that don't change metadata:\n\n        &gt;&gt;&gt; return {}\n\n        Return new sampling rate for operations that resample:\n\n        &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n        Notes\n        -----\n        This method is called by the framework after processing to update\n        the frame metadata. Subclasses should override this method if they\n        need to update metadata (e.g., changing sampling rate).\n\n        Design principle: Operations should use parameters provided at\n        initialization (via __init__). All necessary information should be\n        available as instance variables.\n        \"\"\"\n        return {}\n\n    def get_display_name(self) -&gt; str | None:\n        \"\"\"\n        Get display name for the operation for use in channel labels.\n\n        This method allows operations to customize how they appear in\n        channel labels. By default, returns None, which means the\n        operation name will be used.\n\n        Returns\n        -------\n        str or None\n            Display name for the operation. If None, the operation name\n            (from the `name` class variable) is used.\n\n        Examples\n        --------\n        Default behavior (returns None, uses operation name):\n\n        &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n        ...     name = \"normalize\"\n        &gt;&gt;&gt; op = NormalizeOp(44100)\n        &gt;&gt;&gt; op.get_display_name()  # Returns None\n        &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n        Custom display name:\n\n        &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n        ...     name = \"lowpass_filter\"\n        ...\n        ...     def __init__(self, sr, cutoff):\n        ...         self.cutoff = cutoff\n        ...         super().__init__(sr, cutoff=cutoff)\n        ...\n        ...     def get_display_name(self):\n        ...         return f\"lpf_{self.cutoff}Hz\"\n        &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n        &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n        &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n        Notes\n        -----\n        Subclasses can override this method to provide operation-specific\n        display names that include parameter information, making labels\n        more informative.\n        \"\"\"\n        return None\n\n    def _process_array(self, x: InputArrayType) -&gt; OutputArrayType:\n        \"\"\"Processing function (implemented by subclasses)\"\"\"\n        # Default is no-op function\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n\n    def _create_named_wrapper(self) -&gt; Any:\n        \"\"\"\n        Create a named wrapper function for better Dask graph visualization.\n\n        Returns\n        -------\n        callable\n            A wrapper function with the operation name set as __name__.\n        \"\"\"\n\n        def operation_wrapper(x: InputArrayType) -&gt; OutputArrayType:\n            return self._process_array(x)\n\n        # Set the function name to the operation name for better visualization\n        operation_wrapper.__name__ = self.name\n        return operation_wrapper\n\n    def process_array(self, x: InputArrayType) -&gt; Any:\n        \"\"\"\n        Processing function wrapped with @dask.delayed.\n\n        This method returns a Delayed object that can be computed later.\n        The operation name is used in the Dask task graph for better visualization.\n\n        Parameters\n        ----------\n        x : InputArrayType\n            Input array to process.\n\n        Returns\n        -------\n        dask.delayed.Delayed\n            A Delayed object representing the computation.\n        \"\"\"\n        logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n        # Create wrapper with operation name and wrap it with dask.delayed\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        return delayed_func(x)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        This method can be overridden by subclasses for efficiency.\n        If not overridden, it will execute _process_array on a small test array\n        to determine the output shape.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n\n        Notes\n        -----\n        The default implementation creates a minimal test array and processes it\n        to determine output shape. For performance-critical code, subclasses should\n        override this method with a direct calculation.\n        \"\"\"\n        # Try to infer shape by executing _process_array on test data\n        import numpy as np\n\n        try:\n            # Create minimal test array with input shape\n            if len(input_shape) == 0:\n                return input_shape\n\n            # Create test input with correct dtype\n            # Try complex first, fall back to float if needed\n            test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n            # Process test input\n            test_output: Any = self._process_array(test_input)\n\n            # Return the shape of the output\n            if isinstance(test_output, np.ndarray):\n                return tuple(int(s) for s in test_output.shape)\n            return input_shape\n        except Exception as e:\n            logger.warning(\n                f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n                \"Please implement calculate_output_shape method.\"\n            )\n            raise NotImplementedError(\n                f\"Subclass {self.__class__.__name__} must implement \"\n                f\"calculate_output_shape or ensure _process_array can be \"\n                f\"called with test data.\"\n            ) from e\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        \"\"\"\n        Execute operation and return result\n        data shape is (channels, samples)\n        \"\"\"\n        # Add task as delayed processing with custom name for visualization\n        logger.debug(\"Adding delayed operation to computation graph\")\n\n        # Create a wrapper function with the operation name\n        # This allows Dask to use the operation name in the task graph\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        delayed_result = delayed_func(data)\n\n        # Convert delayed result to dask array and return\n        output_shape = self.calculate_output_shape(data.shape)\n        return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre> Attributes\u00b6 <code></code> <code>name</code> <code>class-attribute</code> \u00b6 <code></code> <code>sampling_rate = sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>pure = pure</code> <code>instance-attribute</code> \u00b6 <code></code> <code>params = params</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, *, pure=True, **params)</code> \u00b6 <p>Initialize AudioOperation.</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters (raises exception if invalid)</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n    pass\n</code></pre> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Get metadata updates to apply after processing.</p> <p>This method allows operations to specify how metadata should be updated after processing. By default, no metadata is updated.</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> <p>This method allows operations to customize how they appear in channel labels. By default, returns None, which means the operation name will be used.</p> <code></code> <code>process_array(x)</code> \u00b6 <p>Processing function wrapped with @dask.delayed.</p> <p>This method returns a Delayed object that can be computed later. The operation name is used in the Dask task graph for better visualization.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <p>This method can be overridden by subclasses for efficiency. If not overridden, it will execute _process_array on a small test array to determine the output shape.</p> <code></code> <code>process(data)</code> \u00b6 <p>Execute operation and return result data shape is (channels, samples)</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    \"\"\"\n    Execute operation and return result\n    data shape is (channels, samples)\n    \"\"\"\n    # Add task as delayed processing with custom name for visualization\n    logger.debug(\"Adding delayed operation to computation graph\")\n\n    # Create a wrapper function with the operation name\n    # This allows Dask to use the operation name in the task graph\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    delayed_result = delayed_func(data)\n\n    # Convert delayed result to dask array and return\n    output_shape = self.calculate_output_shape(data.shape)\n    return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"api/#wandas.processing.base.AudioOperation.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) pure : bool, default=True     Whether the operation is pure (deterministic with no side effects).     When True, Dask can cache results for identical inputs.     Set to False only if the operation has side effects or is non-deterministic. **params : Any     Operation-specific parameters</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n    \"\"\"\n    Initialize AudioOperation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    pure : bool, default=True\n        Whether the operation is pure (deterministic with no side effects).\n        When True, Dask can cache results for identical inputs.\n        Set to False only if the operation has side effects or is non-deterministic.\n    **params : Any\n        Operation-specific parameters\n    \"\"\"\n    self.sampling_rate = sampling_rate\n    self.pure = pure\n    self.params = params\n\n    # Validate parameters during initialization\n    self.validate_params()\n\n    # Create processor function (lazy initialization possible)\n    self._setup_processor()\n\n    logger.debug(\n        f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n    )\n</code></pre>"},{"location":"api/#wandas.processing.base.AudioOperation.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Dictionary of metadata updates. Can include:     - 'sampling_rate': New sampling rate (float)     - Other metadata keys as needed</p>"},{"location":"api/#wandas.processing.base.AudioOperation.get_metadata_updates--examples","title":"Examples","text":"<p>Return empty dict for operations that don't change metadata:</p> <p>return {}</p> <p>Return new sampling rate for operations that resample:</p> <p>return {\"sampling_rate\": self.target_sr}</p>"},{"location":"api/#wandas.processing.base.AudioOperation.get_metadata_updates--notes","title":"Notes","text":"<p>This method is called by the framework after processing to update the frame metadata. Subclasses should override this method if they need to update metadata (e.g., changing sampling rate).</p> <p>Design principle: Operations should use parameters provided at initialization (via init). All necessary information should be available as instance variables.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    This method allows operations to specify how metadata should be\n    updated after processing. By default, no metadata is updated.\n\n    Returns\n    -------\n    dict\n        Dictionary of metadata updates. Can include:\n        - 'sampling_rate': New sampling rate (float)\n        - Other metadata keys as needed\n\n    Examples\n    --------\n    Return empty dict for operations that don't change metadata:\n\n    &gt;&gt;&gt; return {}\n\n    Return new sampling rate for operations that resample:\n\n    &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n    Notes\n    -----\n    This method is called by the framework after processing to update\n    the frame metadata. Subclasses should override this method if they\n    need to update metadata (e.g., changing sampling rate).\n\n    Design principle: Operations should use parameters provided at\n    initialization (via __init__). All necessary information should be\n    available as instance variables.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/#wandas.processing.base.AudioOperation.get_display_name--returns","title":"Returns","text":"<p>str or None     Display name for the operation. If None, the operation name     (from the <code>name</code> class variable) is used.</p>"},{"location":"api/#wandas.processing.base.AudioOperation.get_display_name--examples","title":"Examples","text":"<p>Default behavior (returns None, uses operation name):</p> <p>class NormalizeOp(AudioOperation): ...     name = \"normalize\" op = NormalizeOp(44100) op.get_display_name()  # Returns None</p> <p>Custom display name:</p> <p>class LowPassFilter(AudioOperation): ...     name = \"lowpass_filter\" ... ...     def init(self, sr, cutoff): ...         self.cutoff = cutoff ...         super().init(sr, cutoff=cutoff) ... ...     def get_display_name(self): ...         return f\"lpf_{self.cutoff}Hz\" op = LowPassFilter(44100, cutoff=1000) op.get_display_name()  # Returns \"lpf_1000Hz\"</p>"},{"location":"api/#wandas.processing.base.AudioOperation.get_display_name--channel-label-normalizech0","title":"Channel label: \"normalize(ch0)\"","text":""},{"location":"api/#wandas.processing.base.AudioOperation.get_display_name--channel-label-lpf_1000hzch0","title":"Channel label: \"lpf_1000Hz(ch0)\"","text":""},{"location":"api/#wandas.processing.base.AudioOperation.get_display_name--notes","title":"Notes","text":"<p>Subclasses can override this method to provide operation-specific display names that include parameter information, making labels more informative.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_display_name(self) -&gt; str | None:\n    \"\"\"\n    Get display name for the operation for use in channel labels.\n\n    This method allows operations to customize how they appear in\n    channel labels. By default, returns None, which means the\n    operation name will be used.\n\n    Returns\n    -------\n    str or None\n        Display name for the operation. If None, the operation name\n        (from the `name` class variable) is used.\n\n    Examples\n    --------\n    Default behavior (returns None, uses operation name):\n\n    &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n    ...     name = \"normalize\"\n    &gt;&gt;&gt; op = NormalizeOp(44100)\n    &gt;&gt;&gt; op.get_display_name()  # Returns None\n    &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n    Custom display name:\n\n    &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n    ...     name = \"lowpass_filter\"\n    ...\n    ...     def __init__(self, sr, cutoff):\n    ...         self.cutoff = cutoff\n    ...         super().__init__(sr, cutoff=cutoff)\n    ...\n    ...     def get_display_name(self):\n    ...         return f\"lpf_{self.cutoff}Hz\"\n    &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n    &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n    &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n    Notes\n    -----\n    Subclasses can override this method to provide operation-specific\n    display names that include parameter information, making labels\n    more informative.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/#wandas.processing.base.AudioOperation.process_array--parameters","title":"Parameters","text":"<p>x : InputArrayType     Input array to process.</p>"},{"location":"api/#wandas.processing.base.AudioOperation.process_array--returns","title":"Returns","text":"<p>dask.delayed.Delayed     A Delayed object representing the computation.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def process_array(self, x: InputArrayType) -&gt; Any:\n    \"\"\"\n    Processing function wrapped with @dask.delayed.\n\n    This method returns a Delayed object that can be computed later.\n    The operation name is used in the Dask task graph for better visualization.\n\n    Parameters\n    ----------\n    x : InputArrayType\n        Input array to process.\n\n    Returns\n    -------\n    dask.delayed.Delayed\n        A Delayed object representing the computation.\n    \"\"\"\n    logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n    # Create wrapper with operation name and wrap it with dask.delayed\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    return delayed_func(x)\n</code></pre>"},{"location":"api/#wandas.processing.base.AudioOperation.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.base.AudioOperation.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p>"},{"location":"api/#wandas.processing.base.AudioOperation.calculate_output_shape--notes","title":"Notes","text":"<p>The default implementation creates a minimal test array and processes it to determine output shape. For performance-critical code, subclasses should override this method with a direct calculation.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    This method can be overridden by subclasses for efficiency.\n    If not overridden, it will execute _process_array on a small test array\n    to determine the output shape.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n\n    Notes\n    -----\n    The default implementation creates a minimal test array and processes it\n    to determine output shape. For performance-critical code, subclasses should\n    override this method with a direct calculation.\n    \"\"\"\n    # Try to infer shape by executing _process_array on test data\n    import numpy as np\n\n    try:\n        # Create minimal test array with input shape\n        if len(input_shape) == 0:\n            return input_shape\n\n        # Create test input with correct dtype\n        # Try complex first, fall back to float if needed\n        test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n        # Process test input\n        test_output: Any = self._process_array(test_input)\n\n        # Return the shape of the output\n        if isinstance(test_output, np.ndarray):\n            return tuple(int(s) for s in test_output.shape)\n        return input_shape\n    except Exception as e:\n        logger.warning(\n            f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n            \"Please implement calculate_output_shape method.\"\n        )\n        raise NotImplementedError(\n            f\"Subclass {self.__class__.__name__} must implement \"\n            f\"calculate_output_shape or ensure _process_array can be \"\n            f\"called with test data.\"\n        ) from e\n</code></pre>"},{"location":"api/#wandas.processing.base-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.base.register_operation","title":"<code>register_operation(operation_class)</code>","text":"<p>Register a new operation type</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def register_operation(operation_class: type) -&gt; None:\n    \"\"\"Register a new operation type\"\"\"\n\n    if not issubclass(operation_class, AudioOperation):\n        raise TypeError(\"Strategy class must inherit from AudioOperation.\")\n    if inspect.isabstract(operation_class):\n        raise TypeError(\"Cannot register abstract AudioOperation class.\")\n\n    _OPERATION_REGISTRY[operation_class.name] = operation_class\n</code></pre>"},{"location":"api/#wandas.processing.base.get_operation","title":"<code>get_operation(name)</code>","text":"<p>Get operation class by name</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_operation(name: str) -&gt; type[AudioOperation[Any, Any]]:\n    \"\"\"Get operation class by name\"\"\"\n    if name not in _OPERATION_REGISTRY:\n        raise ValueError(f\"Unknown operation type: {name}\")\n    return _OPERATION_REGISTRY[name]\n</code></pre>"},{"location":"api/#wandas.processing.base.create_operation","title":"<code>create_operation(name, sampling_rate, **params)</code>","text":"<p>Create operation instance from name and parameters</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def create_operation(\n    name: str, sampling_rate: float, **params: Any\n) -&gt; AudioOperation[Any, Any]:\n    \"\"\"Create operation instance from name and parameters\"\"\"\n    operation_class = get_operation(name)\n    return operation_class(sampling_rate, **params)\n</code></pre>"},{"location":"api/#wandas.processing.effects","title":"<code>effects</code>","text":""},{"location":"api/#wandas.processing.effects-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.effects.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.effects-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.effects.HpssHarmonic","title":"<code>HpssHarmonic</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Harmonic operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssHarmonic(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Harmonic operation\"\"\"\n\n    name = \"hpss_harmonic\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Harmonic\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Hrm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Harmonic\"\"\"\n        logger.debug(f\"Applying HPSS Harmonic to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.harmonic(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Harmonic applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'hpss_harmonic'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>kwargs = kwargs</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, **kwargs)</code> \u00b6 <p>Initialize HPSS Harmonic</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Hrm\"\n</code></pre>"},{"location":"api/#wandas.processing.effects.HpssHarmonic.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Harmonic\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"api/#wandas.processing.effects.HpssPercussive","title":"<code>HpssPercussive</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Percussive operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssPercussive(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Percussive operation\"\"\"\n\n    name = \"hpss_percussive\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Percussive\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Prc\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Percussive\"\"\"\n        logger.debug(f\"Applying HPSS Percussive to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.percussive(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Percussive applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'hpss_percussive'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>kwargs = kwargs</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, **kwargs)</code> \u00b6 <p>Initialize HPSS Percussive</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Prc\"\n</code></pre>"},{"location":"api/#wandas.processing.effects.HpssPercussive.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Percussive\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"api/#wandas.processing.effects.Normalize","title":"<code>Normalize</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Signal normalization operation using librosa.util.normalize</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class Normalize(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Signal normalization operation using librosa.util.normalize\"\"\"\n\n    name = \"normalize\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        norm: float | None = np.inf,\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ):\n        \"\"\"\n        Initialize normalization operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        norm : float or np.inf, default=np.inf\n            Norm type. Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n            - float: Lp norm\n            - None: No normalization\n        axis : int or None, default=-1\n            Axis along which to normalize.\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold : float or None, optional\n            Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill : bool or None, optional\n            Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n        Raises\n        ------\n        ValueError\n            If norm parameter is invalid or threshold is negative\n        \"\"\"\n        # Validate norm parameter\n        if norm is not None and not isinstance(norm, int | float):\n            raise ValueError(\n                f\"Invalid normalization method\\n\"\n                f\"  Got: {type(norm).__name__} ({norm})\\n\"\n                f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n                f\"Norm parameter must be a numeric value or None.\\n\"\n                f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n                f\"1 (L1 norm), 0 (pseudo L0)\"\n            )\n\n        # Validate that norm is non-negative (except for -np.inf which is valid)\n        if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n            raise ValueError(\n                f\"Invalid normalization method\\n\"\n                f\"  Got: {norm}\\n\"\n                f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n                f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n                f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n                f\"1 (L1 norm), 0 (pseudo L0)\"\n            )\n\n        # Validate threshold\n        if threshold is not None and threshold &lt; 0:\n            raise ValueError(\n                f\"Invalid threshold for normalization\\n\"\n                f\"  Got: {threshold}\\n\"\n                f\"  Expected: Non-negative value or None\\n\"\n                f\"Threshold must be non-negative.\\n\"\n                f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n            )\n\n        super().__init__(\n            sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        self.norm = norm\n        self.axis = axis\n        self.threshold = threshold\n        self.fill = fill\n        logger.debug(\n            f\"Initialized Normalize operation with norm={norm}, \"\n            f\"axis={axis}, threshold={threshold}, fill={fill}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"norm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform normalization processing\"\"\"\n        logger.debug(\n            f\"Applying normalization to array with shape: {x.shape}, \"\n            f\"norm={self.norm}, axis={self.axis}\"\n        )\n\n        # Apply librosa.util.normalize\n        result: NDArrayReal = librosa_util.normalize(\n            x, norm=self.norm, axis=self.axis, threshold=self.threshold, fill=self.fill\n        )\n\n        logger.debug(\n            f\"Normalization applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'normalize'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>norm = norm</code> <code>instance-attribute</code> \u00b6 <code></code> <code>axis = axis</code> <code>instance-attribute</code> \u00b6 <code></code> <code>threshold = threshold</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fill = fill</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, norm=np.inf, axis=-1, threshold=None, fill=None)</code> \u00b6 <p>Initialize normalization operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"norm\"\n</code></pre>"},{"location":"api/#wandas.processing.effects.Normalize.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) norm : float or np.inf, default=np.inf     Norm type. Supported values:     - np.inf: Maximum absolute value normalization     - -np.inf: Minimum absolute value normalization     - 0: Pseudo L0 normalization (divide by number of non-zero elements)     - float: Lp norm     - None: No normalization axis : int or None, default=-1     Axis along which to normalize.     - -1: Normalize along time axis (each channel independently)     - None: Global normalization across all axes     - int: Normalize along specified axis threshold : float or None, optional     Threshold below which values are considered zero.     If None, no threshold is applied. fill : bool or None, optional     Value to fill when the norm is zero.     If None, the zero vector remains zero.</p>"},{"location":"api/#wandas.processing.effects.Normalize.__init__--raises","title":"Raises","text":"<p>ValueError     If norm parameter is invalid or threshold is negative</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    norm: float | None = np.inf,\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n):\n    \"\"\"\n    Initialize normalization operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    norm : float or np.inf, default=np.inf\n        Norm type. Supported values:\n        - np.inf: Maximum absolute value normalization\n        - -np.inf: Minimum absolute value normalization\n        - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n        - float: Lp norm\n        - None: No normalization\n    axis : int or None, default=-1\n        Axis along which to normalize.\n        - -1: Normalize along time axis (each channel independently)\n        - None: Global normalization across all axes\n        - int: Normalize along specified axis\n    threshold : float or None, optional\n        Threshold below which values are considered zero.\n        If None, no threshold is applied.\n    fill : bool or None, optional\n        Value to fill when the norm is zero.\n        If None, the zero vector remains zero.\n\n    Raises\n    ------\n    ValueError\n        If norm parameter is invalid or threshold is negative\n    \"\"\"\n    # Validate norm parameter\n    if norm is not None and not isinstance(norm, int | float):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {type(norm).__name__} ({norm})\\n\"\n            f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be a numeric value or None.\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate that norm is non-negative (except for -np.inf which is valid)\n    if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {norm}\\n\"\n            f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate threshold\n    if threshold is not None and threshold &lt; 0:\n        raise ValueError(\n            f\"Invalid threshold for normalization\\n\"\n            f\"  Got: {threshold}\\n\"\n            f\"  Expected: Non-negative value or None\\n\"\n            f\"Threshold must be non-negative.\\n\"\n            f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n        )\n\n    super().__init__(\n        sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    self.norm = norm\n    self.axis = axis\n    self.threshold = threshold\n    self.fill = fill\n    logger.debug(\n        f\"Initialized Normalize operation with norm={norm}, \"\n        f\"axis={axis}, threshold={threshold}, fill={fill}\"\n    )\n</code></pre>"},{"location":"api/#wandas.processing.effects.Normalize.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.effects.Normalize.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.effects.RemoveDC","title":"<code>RemoveDC</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Remove DC component (DC offset) from the signal.</p> <p>This operation removes the DC component by subtracting the mean value from each channel, centering the signal around zero.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class RemoveDC(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This operation removes the DC component by subtracting the mean value\n    from each channel, centering the signal around zero.\n    \"\"\"\n\n    name = \"remove_dc\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"Initialize DC removal operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n        logger.debug(\"Initialized RemoveDC operation\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"Calculate output data shape after operation.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"dcRM\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform DC removal processing.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array (channels, samples)\n\n        Returns\n        -------\n        NDArrayReal\n            Signal with DC component removed\n        \"\"\"\n        logger.debug(f\"Removing DC component from array with shape: {x.shape}\")\n\n        # Subtract mean along time axis (axis=1 for channel data)\n        mean_values = x.mean(axis=-1, keepdims=True)\n        result: NDArrayReal = x - mean_values\n\n        logger.debug(f\"DC removal applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'remove_dc'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate)</code> \u00b6 <p>Initialize DC removal operation.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"dcRM\"\n</code></pre>"},{"location":"api/#wandas.processing.effects.RemoveDC.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"Initialize DC removal operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n    logger.debug(\"Initialized RemoveDC operation\")\n</code></pre>"},{"location":"api/#wandas.processing.effects.RemoveDC.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.effects.RemoveDC.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"Calculate output data shape after operation.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.effects.AddWithSNR","title":"<code>AddWithSNR</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Addition operation considering SNR</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class AddWithSNR(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Addition operation considering SNR\"\"\"\n\n    name = \"add_with_snr\"\n\n    def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n        \"\"\"\n        Initialize addition operation considering SNR\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other : DaArray\n            Noise signal to add (channel-frame format)\n        snr : float\n            Signal-to-noise ratio (dB)\n        \"\"\"\n        super().__init__(sampling_rate, other=other, snr=snr)\n\n        self.other = other\n        self.snr = snr\n        logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"+SNR\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform addition processing considering SNR\"\"\"\n        logger.debug(f\"Applying SNR-based addition with shape: {x.shape}\")\n        other: NDArrayReal = self.other.compute()\n\n        # Use multi-channel versions of calculate_rms and calculate_desired_noise_rms\n        clean_rms = util.calculate_rms(x)\n        other_rms = util.calculate_rms(other)\n\n        # Adjust noise gain based on specified SNR (apply per channel)\n        desired_noise_rms = util.calculate_desired_noise_rms(clean_rms, self.snr)\n\n        # Apply gain per channel using broadcasting\n        gain = desired_noise_rms / other_rms\n        # Add adjusted noise to signal\n        result: NDArrayReal = x + other * gain\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'add_with_snr'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>other = other</code> <code>instance-attribute</code> \u00b6 <code></code> <code>snr = snr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, other, snr=1.0)</code> \u00b6 <p>Initialize addition operation considering SNR</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"+SNR\"\n</code></pre>"},{"location":"api/#wandas.processing.effects.AddWithSNR.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other : DaArray     Noise signal to add (channel-frame format) snr : float     Signal-to-noise ratio (dB)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n    \"\"\"\n    Initialize addition operation considering SNR\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other : DaArray\n        Noise signal to add (channel-frame format)\n    snr : float\n        Signal-to-noise ratio (dB)\n    \"\"\"\n    super().__init__(sampling_rate, other=other, snr=snr)\n\n    self.other = other\n    self.snr = snr\n    logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n</code></pre>"},{"location":"api/#wandas.processing.effects.AddWithSNR.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.effects.AddWithSNR.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/#wandas.processing.effects.Fade","title":"<code>Fade</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Fade operation using a Tukey (tapered cosine) window.</p> <p>This operation applies symmetric fade-in and fade-out with the same duration. The Tukey window alpha parameter is computed from the fade duration so that the tapered portion equals the requested fade length at each end.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class Fade(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Fade operation using a Tukey (tapered cosine) window.\n\n    This operation applies symmetric fade-in and fade-out with the same\n    duration. The Tukey window alpha parameter is computed from the fade\n    duration so that the tapered portion equals the requested fade length\n    at each end.\n    \"\"\"\n\n    name = \"fade\"\n\n    def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n        self.fade_ms = float(fade_ms)\n        # Precompute fade length in samples at construction time\n        self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n        super().__init__(sampling_rate, fade_ms=fade_ms)\n\n    def validate_params(self) -&gt; None:\n        if self.fade_ms &lt; 0:\n            raise ValueError(\"fade_ms must be non-negative\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"fade\"\n\n    @staticmethod\n    def calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n        \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n        The alpha parameter determines what fraction of the window is tapered.\n        For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n        that each side's taper has exactly fade_len samples.\n\n        Parameters\n        ----------\n        fade_len : int\n            Desired fade length in samples for each end (in and out).\n        n_samples : int\n            Total number of samples in the signal.\n\n        Returns\n        -------\n        float\n            Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n        Examples\n        --------\n        &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n        0.2\n        &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n        1.0\n        \"\"\"\n        alpha = float(2 * fade_len) / float(n_samples)\n        return min(1.0, alpha)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        logger.debug(f\"Applying Tukey Fade to array with shape: {x.shape}\")\n\n        arr = x\n        if arr.ndim == 1:\n            arr = arr.reshape(1, -1)\n\n        n_samples = int(arr.shape[-1])\n\n        # If no fade requested, return input\n        if self.fade_len &lt;= 0:\n            return arr\n\n        if 2 * self.fade_len &gt;= n_samples:\n            raise ValueError(\n                \"Fade length too long: 2*fade_ms must be less than signal length\"\n            )\n\n        # Calculate Tukey window alpha parameter\n        alpha = self.calculate_tukey_alpha(self.fade_len, n_samples)\n\n        # Create tukey window (numpy) and apply\n        env = sp_windows.tukey(n_samples, alpha=alpha)\n\n        result: NDArrayReal = arr * env[None, :]\n        logger.debug(\"Tukey fade applied\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'fade'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fade_ms = float(fade_ms)</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, fade_ms=50)</code> \u00b6 Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n    self.fade_ms = float(fade_ms)\n    # Precompute fade length in samples at construction time\n    self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n    super().__init__(sampling_rate, fade_ms=fade_ms)\n</code></pre> <code></code> <code>validate_params()</code> \u00b6 Source code in <code>wandas/processing/effects.py</code> <pre><code>def validate_params(self) -&gt; None:\n    if self.fade_ms &lt; 0:\n        raise ValueError(\"fade_ms must be non-negative\")\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fade\"\n</code></pre> <code></code> <code>calculate_tukey_alpha(fade_len, n_samples)</code> <code>staticmethod</code> \u00b6 <p>Calculate Tukey window alpha parameter from fade length.</p> <p>The alpha parameter determines what fraction of the window is tapered. For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures that each side's taper has exactly fade_len samples.</p>"},{"location":"api/#wandas.processing.effects.Fade.calculate_tukey_alpha--parameters","title":"Parameters","text":"<p>fade_len : int     Desired fade length in samples for each end (in and out). n_samples : int     Total number of samples in the signal.</p>"},{"location":"api/#wandas.processing.effects.Fade.calculate_tukey_alpha--returns","title":"Returns","text":"<p>float     Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].</p>"},{"location":"api/#wandas.processing.effects.Fade.calculate_tukey_alpha--examples","title":"Examples","text":"<p>Fade.calculate_tukey_alpha(fade_len=20, n_samples=200) 0.2 Fade.calculate_tukey_alpha(fade_len=100, n_samples=100) 1.0</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>@staticmethod\ndef calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n    \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n    The alpha parameter determines what fraction of the window is tapered.\n    For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n    that each side's taper has exactly fade_len samples.\n\n    Parameters\n    ----------\n    fade_len : int\n        Desired fade length in samples for each end (in and out).\n    n_samples : int\n        Total number of samples in the signal.\n\n    Returns\n    -------\n    float\n        Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n    Examples\n    --------\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n    0.2\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n    1.0\n    \"\"\"\n    alpha = float(2 * fade_len) / float(n_samples)\n    return min(1.0, alpha)\n</code></pre>"},{"location":"api/#wandas.processing.effects-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.effects-modules","title":"Modules","text":""},{"location":"api/#wandas.processing.filters","title":"<code>filters</code>","text":""},{"location":"api/#wandas.processing.filters-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.filters.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.filters-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.filters.HighPassFilter","title":"<code>HighPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>High-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class HighPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"High-pass filter operation\"\"\"\n\n    name = \"highpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize high-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up high-pass filter processor\"\"\"\n        # Calculate filter coefficients (once) - safely retrieve from instance variables\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"high\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Highpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"hpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying highpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'highpass_filter'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>a</code> <code>instance-attribute</code> \u00b6 <code></code> <code>b</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cutoff = cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>order = order</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, cutoff, order=4)</code> \u00b6 <p>Initialize high-pass filter</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"hpf\"\n</code></pre>"},{"location":"api/#wandas.processing.filters.HighPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) cutoff : float     Cutoff frequency (Hz). Must be between 0 and Nyquist frequency     (sampling_rate / 2). order : int, optional     Filter order, default is 4</p>"},{"location":"api/#wandas.processing.filters.HighPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize high-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"api/#wandas.processing.filters.LowPassFilter","title":"<code>LowPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Low-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class LowPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Low-pass filter operation\"\"\"\n\n    name = \"lowpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize low-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up low-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"low\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Lowpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"lpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying lowpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'lowpass_filter'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>a</code> <code>instance-attribute</code> \u00b6 <code></code> <code>b</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cutoff = cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>order = order</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, cutoff, order=4)</code> \u00b6 <p>Initialize low-pass filter</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"lpf\"\n</code></pre>"},{"location":"api/#wandas.processing.filters.LowPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) cutoff : float     Cutoff frequency (Hz). Must be between 0 and Nyquist frequency     (sampling_rate / 2). order : int, optional     Filter order, default is 4</p>"},{"location":"api/#wandas.processing.filters.LowPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize low-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"api/#wandas.processing.filters.BandPassFilter","title":"<code>BandPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Band-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class BandPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Band-pass filter operation\"\"\"\n\n    name = \"bandpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        low_cutoff: float,\n        high_cutoff: float,\n        order: int = 4,\n    ):\n        \"\"\"\n        Initialize band-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        low_cutoff : float\n            Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n        high_cutoff : float\n            Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            and greater than low_cutoff.\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n            or if low_cutoff &gt;= high_cutoff\n        \"\"\"\n        self.low_cutoff = low_cutoff\n        self.high_cutoff = high_cutoff\n        self.order = order\n        super().__init__(\n            sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Lower cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.low_cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Use a lower cutoff frequency below {nyquist} Hz\"\n            )\n        if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Higher cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.high_cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Use a cutoff frequency below {nyquist} Hz\"\n            )\n        if self.low_cutoff &gt;= self.high_cutoff:\n            raise ValueError(\n                f\"Invalid bandpass filter cutoff frequencies\\n\"\n                f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n                f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n                f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n                f\"A bandpass filter passes frequencies between low and high\\n\"\n                f\"  cutoffs.\\n\"\n                f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n                f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up band-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        low_normal_cutoff = self.low_cutoff / nyquist\n        high_normal_cutoff = self.high_cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(\n            self.order, [low_normal_cutoff, high_normal_cutoff], btype=\"band\"\n        )  # type: ignore [unused-ignore]\n        logger.debug(f\"Bandpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"bpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying bandpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'bandpass_filter'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>a</code> <code>instance-attribute</code> \u00b6 <code></code> <code>b</code> <code>instance-attribute</code> \u00b6 <code></code> <code>low_cutoff = low_cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>high_cutoff = high_cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>order = order</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, low_cutoff, high_cutoff, order=4)</code> \u00b6 <p>Initialize band-pass filter</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Lower cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.low_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a lower cutoff frequency below {nyquist} Hz\"\n        )\n    if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Higher cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.high_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a cutoff frequency below {nyquist} Hz\"\n        )\n    if self.low_cutoff &gt;= self.high_cutoff:\n        raise ValueError(\n            f\"Invalid bandpass filter cutoff frequencies\\n\"\n            f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n            f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n            f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n            f\"A bandpass filter passes frequencies between low and high\\n\"\n            f\"  cutoffs.\\n\"\n            f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n            f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n        )\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"bpf\"\n</code></pre>"},{"location":"api/#wandas.processing.filters.BandPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) low_cutoff : float     Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency. high_cutoff : float     Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency     and greater than low_cutoff. order : int, optional     Filter order, default is 4</p>"},{"location":"api/#wandas.processing.filters.BandPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),     or if low_cutoff &gt;= high_cutoff</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    low_cutoff: float,\n    high_cutoff: float,\n    order: int = 4,\n):\n    \"\"\"\n    Initialize band-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    low_cutoff : float\n        Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n    high_cutoff : float\n        Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        and greater than low_cutoff.\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n        or if low_cutoff &gt;= high_cutoff\n    \"\"\"\n    self.low_cutoff = low_cutoff\n    self.high_cutoff = high_cutoff\n    self.order = order\n    super().__init__(\n        sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n    )\n</code></pre>"},{"location":"api/#wandas.processing.filters.AWeighting","title":"<code>AWeighting</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>A-weighting filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class AWeighting(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"A-weighting filter operation\"\"\"\n\n    name = \"a_weighting\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize A-weighting filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Aw\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for A-weighting filter\"\"\"\n        logger.debug(f\"Applying A-weighting to array with shape: {x.shape}\")\n        result = A_weight(x, self.sampling_rate)\n\n        # Handle case where A_weight returns a tuple\n        if isinstance(result, tuple):\n            # Use the first element of the tuple\n            result = result[0]\n\n        logger.debug(\n            f\"A-weighting applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'a_weighting'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate)</code> \u00b6 <p>Initialize A-weighting filter</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Aw\"\n</code></pre>"},{"location":"api/#wandas.processing.filters.AWeighting.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize A-weighting filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"api/#wandas.processing.filters-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.psychoacoustic","title":"<code>psychoacoustic</code>","text":"<p>Psychoacoustic metrics processing operations.</p> <p>This module provides psychoacoustic metrics operations for audio signals, including loudness calculation using standardized methods.</p>"},{"location":"api/#wandas.processing.psychoacoustic-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.psychoacoustic.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.psychoacoustic-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv","title":"<code>LoudnessZwtv</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This operation computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's implementation of the standardized loudness calculation.</p> <p>The loudness is calculated in sones, a unit of perceived loudness where a doubling of sones corresponds to a doubling of perceived loudness.</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz. The signal should be sampled at a rate appropriate     for the analysis (typically 44100 Hz or 48000 Hz for audio). field_type : str, default=\"free\"     Type of sound field. Options:     - 'free': Free field (sound arriving from a specific direction)     - 'diffuse': Diffuse field (sound arriving uniformly from all directions)</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv--attributes","title":"Attributes","text":"<p>name : str     Operation name: \"loudness_zwtv\" field_type : str     The sound field type used for calculation</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv--examples","title":"Examples","text":"<p>Calculate loudness for a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"audio.wav\") loudness = signal.loudness_zwtv(field_type=\"free\")</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv--notes","title":"Notes","text":"<ul> <li>The output contains time-varying loudness values in sones</li> <li>For mono signals, the loudness is calculated directly</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The method follows ISO 532-1:2017 standard for time-varying loudness</li> <li>Typical loudness values: 1 sone \u2248 40 phon (loudness level)</li> </ul>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv--references","title":"References","text":"<p>.. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014        Part 1: Zwicker method\" .. [2] MoSQITo documentation:        https://mosqito.readthedocs.io/en/latest/</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class LoudnessZwtv(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This operation computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's\n    implementation of the standardized loudness calculation.\n\n    The loudness is calculated in sones, a unit of perceived loudness where a doubling\n    of sones corresponds to a doubling of perceived loudness.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz. The signal should be sampled at a rate appropriate\n        for the analysis (typically 44100 Hz or 48000 Hz for audio).\n    field_type : str, default=\"free\"\n        Type of sound field. Options:\n        - 'free': Free field (sound arriving from a specific direction)\n        - 'diffuse': Diffuse field (sound arriving uniformly from all directions)\n\n    Attributes\n    ----------\n    name : str\n        Operation name: \"loudness_zwtv\"\n    field_type : str\n        The sound field type used for calculation\n\n    Examples\n    --------\n    Calculate loudness for a signal:\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n\n    Notes\n    -----\n    - The output contains time-varying loudness values in sones\n    - For mono signals, the loudness is calculated directly\n    - For multi-channel signals, loudness is calculated per channel\n    - The method follows ISO 532-1:2017 standard for time-varying loudness\n    - Typical loudness values: 1 sone \u2248 40 phon (loudness level)\n\n    References\n    ----------\n    .. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n           Part 1: Zwicker method\"\n    .. [2] MoSQITo documentation:\n           https://mosqito.readthedocs.io/en/latest/\n    \"\"\"\n\n    name = \"loudness_zwtv\"\n\n    def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n        \"\"\"\n        Initialize Loudness calculation operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        field_type : str, default=\"free\"\n            Type of sound field ('free' or 'diffuse')\n        \"\"\"\n        self.field_type = field_type\n        super().__init__(sampling_rate, field_type=field_type)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"\n        Validate parameters.\n\n        Raises\n        ------\n        ValueError\n            If field_type is not 'free' or 'diffuse'\n        \"\"\"\n        if self.field_type not in (\"free\", \"diffuse\"):\n            raise ValueError(\n                f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n            )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on MoSQITo's time resolution.\n\n        The Zwicker method uses approximately 2ms time steps,\n        which corresponds to 500 Hz sampling rate, independent of\n        the input sampling rate.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        All necessary parameters are provided at initialization.\n        The output sampling rate is always 500 Hz regardless of input.\n        \"\"\"\n        return {\"sampling_rate\": 500.0}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        The loudness calculation produces a time-varying output where the time\n        resolution depends on the algorithm's internal processing. The exact\n        output length is determined dynamically by the loudness_zwtv function.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape. For loudness, we return a placeholder shape\n            since the actual length is determined by the algorithm.\n            The shape will be (channels, time_samples) where time_samples\n            depends on the input length and algorithm parameters.\n        \"\"\"\n        # Return a placeholder shape - the actual shape will be determined\n        # after processing since loudness_zwtv determines the time resolution\n        # For now, we estimate based on typical behavior (approx 2ms time steps)\n        n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n        # Rough estimate: one loudness value per 2ms (0.002s)\n        estimated_time_samples = int(input_shape[-1] / (self.sampling_rate * 0.002))\n        return (n_channels, estimated_time_samples)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"\n        Process array to calculate loudness.\n\n        This method calculates the time-varying loudness for each channel\n        of the input signal using the Zwicker method.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array with shape (channels, samples) or (samples,)\n\n        Returns\n        -------\n        NDArrayReal\n            Time-varying loudness in sones for each channel.\n            Shape: (channels, time_samples)\n\n        Notes\n        -----\n        The function processes each channel independently and returns\n        the loudness values. The time axis information is not returned\n        here but can be reconstructed based on the MoSQITo algorithm's\n        behavior (typically 2ms time steps).\n        \"\"\"\n        logger.debug(\n            f\"Calculating loudness for signal with shape: {x.shape}, \"\n            f\"field_type: {self.field_type}\"\n        )\n\n        # Handle 1D input (single channel)\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        n_channels = x.shape[0]\n        loudness_results = []\n\n        for ch in range(n_channels):\n            channel_data = x[ch, :]\n\n            # Ensure channel_data is a contiguous 1D NumPy array\n            channel_data = np.asarray(channel_data).ravel()\n\n            # Call MoSQITo's loudness_zwtv function\n            # Returns: N (loudness), N_spec (specific loudness),\n            #          bark_axis, time_axis\n            loudness_n, _, _, _ = loudness_zwtv_mosqito(\n                channel_data, self.sampling_rate, field_type=self.field_type\n            )\n\n            loudness_results.append(loudness_n)\n\n            logger.debug(\n                f\"Channel {ch}: Calculated loudness with \"\n                f\"{len(loudness_n)} time points, \"\n                f\"max loudness: {np.max(loudness_n):.2f} sones\"\n            )\n\n        # Stack results\n        result: NDArrayReal = np.stack(loudness_results, axis=0)\n\n        logger.debug(f\"Loudness calculation complete, output shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'loudness_zwtv'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>field_type = field_type</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, field_type='free')</code> \u00b6 <p>Initialize Loudness calculation operation.</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters.</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Update sampling rate based on MoSQITo's time resolution.</p> <p>The Zwicker method uses approximately 2ms time steps, which corresponds to 500 Hz sampling rate, independent of the input sampling rate.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <p>The loudness calculation produces a time-varying output where the time resolution depends on the algorithm's internal processing. The exact output length is determined dynamically by the loudness_zwtv function.</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize Loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv.get_metadata_updates--notes","title":"Notes","text":"<p>All necessary parameters are provided at initialization. The output sampling rate is always 500 Hz regardless of input.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on MoSQITo's time resolution.\n\n    The Zwicker method uses approximately 2ms time steps,\n    which corresponds to 500 Hz sampling rate, independent of\n    the input sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    All necessary parameters are provided at initialization.\n    The output sampling rate is always 500 Hz regardless of input.\n    \"\"\"\n    return {\"sampling_rate\": 500.0}\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwtv.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape. For loudness, we return a placeholder shape     since the actual length is determined by the algorithm.     The shape will be (channels, time_samples) where time_samples     depends on the input length and algorithm parameters.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The loudness calculation produces a time-varying output where the time\n    resolution depends on the algorithm's internal processing. The exact\n    output length is determined dynamically by the loudness_zwtv function.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape. For loudness, we return a placeholder shape\n        since the actual length is determined by the algorithm.\n        The shape will be (channels, time_samples) where time_samples\n        depends on the input length and algorithm parameters.\n    \"\"\"\n    # Return a placeholder shape - the actual shape will be determined\n    # after processing since loudness_zwtv determines the time resolution\n    # For now, we estimate based on typical behavior (approx 2ms time steps)\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    # Rough estimate: one loudness value per 2ms (0.002s)\n    estimated_time_samples = int(input_shape[-1] / (self.sampling_rate * 0.002))\n    return (n_channels, estimated_time_samples)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst","title":"<code>LoudnessZwst</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This operation computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's implementation of the standardized loudness calculation for steady signals.</p> <p>The loudness is calculated in sones, a unit of perceived loudness where a doubling of sones corresponds to a doubling of perceived loudness.</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz. The signal should be sampled at a rate appropriate     for the analysis (typically 44100 Hz or 48000 Hz for audio). field_type : str, default=\"free\"     Type of sound field. Options:     - 'free': Free field (sound arriving from a specific direction)     - 'diffuse': Diffuse field (sound arriving uniformly from all directions)</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst--attributes","title":"Attributes","text":"<p>name : str     Operation name: \"loudness_zwst\" field_type : str     The sound field type used for calculation</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst--examples","title":"Examples","text":"<p>Calculate steady-state loudness for a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"fan_noise.wav\") loudness = signal.loudness_zwst(field_type=\"free\") print(f\"Steady-state loudness: {loudness.data[0]:.2f} sones\")</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst--notes","title":"Notes","text":"<ul> <li>The output contains a single loudness value in sones for each channel</li> <li>For mono signals, the loudness is calculated directly</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The method follows ISO 532-1:2017 standard for steady-state loudness</li> <li>Typical loudness values: 1 sone \u2248 40 phon (loudness level)</li> <li>This method is suitable for stationary signals such as fan noise,   constant machinery sounds, or other steady sounds</li> </ul>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst--references","title":"References","text":"<p>.. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014        Part 1: Zwicker method\" .. [2] MoSQITo documentation:        https://mosqito.readthedocs.io/en/latest/</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class LoudnessZwst(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This operation computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. It uses the MoSQITo library's\n    implementation of the standardized loudness calculation for steady signals.\n\n    The loudness is calculated in sones, a unit of perceived loudness where a doubling\n    of sones corresponds to a doubling of perceived loudness.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz. The signal should be sampled at a rate appropriate\n        for the analysis (typically 44100 Hz or 48000 Hz for audio).\n    field_type : str, default=\"free\"\n        Type of sound field. Options:\n        - 'free': Free field (sound arriving from a specific direction)\n        - 'diffuse': Diffuse field (sound arriving uniformly from all directions)\n\n    Attributes\n    ----------\n    name : str\n        Operation name: \"loudness_zwst\"\n    field_type : str\n        The sound field type used for calculation\n\n    Examples\n    --------\n    Calculate steady-state loudness for a signal:\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n    &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n    &gt;&gt;&gt; print(f\"Steady-state loudness: {loudness.data[0]:.2f} sones\")\n\n    Notes\n    -----\n    - The output contains a single loudness value in sones for each channel\n    - For mono signals, the loudness is calculated directly\n    - For multi-channel signals, loudness is calculated per channel\n    - The method follows ISO 532-1:2017 standard for steady-state loudness\n    - Typical loudness values: 1 sone \u2248 40 phon (loudness level)\n    - This method is suitable for stationary signals such as fan noise,\n      constant machinery sounds, or other steady sounds\n\n    References\n    ----------\n    .. [1] ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n           Part 1: Zwicker method\"\n    .. [2] MoSQITo documentation:\n           https://mosqito.readthedocs.io/en/latest/\n    \"\"\"\n\n    name = \"loudness_zwst\"\n\n    def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n        \"\"\"\n        Initialize steady-state loudness calculation operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        field_type : str, default=\"free\"\n            Type of sound field ('free' or 'diffuse')\n        \"\"\"\n        self.field_type = field_type\n        super().__init__(sampling_rate, field_type=field_type)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"\n        Validate parameters.\n\n        Raises\n        ------\n        ValueError\n            If field_type is not 'free' or 'diffuse'\n        \"\"\"\n        if self.field_type not in (\"free\", \"diffuse\"):\n            raise ValueError(\n                f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n            )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get metadata updates to apply after processing.\n\n        For steady-state loudness, the output is a single value per channel,\n        so no sampling rate update is needed (output is scalar, not time-series).\n\n        Returns\n        -------\n        dict\n            Empty dictionary (no metadata updates needed)\n\n        Notes\n        -----\n        Unlike time-varying loudness, steady-state loudness produces a single\n        value, not a time series, so the sampling rate concept doesn't apply.\n        \"\"\"\n        return {}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        The steady-state loudness calculation produces a single loudness value\n        per channel.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape: (channels, 1) - one loudness value per channel\n        \"\"\"\n        n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n        return (n_channels, 1)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"\n        Process array to calculate steady-state loudness.\n\n        This method calculates the steady-state loudness for each channel\n        of the input signal using the Zwicker method.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array with shape (channels, samples) or (samples,)\n\n        Returns\n        -------\n        NDArrayReal\n            Steady-state loudness in sones for each channel.\n            Shape: (channels, 1)\n\n        Notes\n        -----\n        The function processes each channel independently and returns\n        a single loudness value per channel.\n        \"\"\"\n        logger.debug(\n            f\"Calculating steady-state loudness for signal with shape: {x.shape}, \"\n            f\"field_type: {self.field_type}\"\n        )\n\n        # Handle 1D input (single channel)\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        n_channels = x.shape[0]\n        loudness_results = []\n\n        for ch in range(n_channels):\n            channel_data = x[ch, :]\n\n            # Ensure channel_data is a contiguous 1D NumPy array\n            channel_data = np.asarray(channel_data).ravel()\n\n            # Call MoSQITo's loudness_zwst function\n            # Returns: N (single loudness value), N_spec (specific loudness),\n            #          bark_axis\n            loudness_n, _, _ = loudness_zwst_mosqito(\n                channel_data, self.sampling_rate, field_type=self.field_type\n            )\n\n            loudness_results.append(loudness_n)\n\n            logger.debug(\n                f\"Channel {ch}: Calculated steady-state loudness: \"\n                f\"{loudness_n:.2f} sones\"\n            )\n\n        # Stack results and reshape to (channels, 1)\n        result: NDArrayReal = np.array(loudness_results).reshape(n_channels, 1)\n\n        logger.debug(\n            f\"Steady-state loudness calculation complete, output shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'loudness_zwst'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>field_type = field_type</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, field_type='free')</code> \u00b6 <p>Initialize steady-state loudness calculation operation.</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters.</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Get metadata updates to apply after processing.</p> <p>For steady-state loudness, the output is a single value per channel, so no sampling rate update is needed (output is scalar, not time-series).</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <p>The steady-state loudness calculation produces a single loudness value per channel.</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize steady-state loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Empty dictionary (no metadata updates needed)</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst.get_metadata_updates--notes","title":"Notes","text":"<p>Unlike time-varying loudness, steady-state loudness produces a single value, not a time series, so the sampling rate concept doesn't apply.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    For steady-state loudness, the output is a single value per channel,\n    so no sampling rate update is needed (output is scalar, not time-series).\n\n    Returns\n    -------\n    dict\n        Empty dictionary (no metadata updates needed)\n\n    Notes\n    -----\n    Unlike time-varying loudness, steady-state loudness produces a single\n    value, not a time series, so the sampling rate concept doesn't apply.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.psychoacoustic.LoudnessZwst.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape: (channels, 1) - one loudness value per channel</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The steady-state loudness calculation produces a single loudness value\n    per channel.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape: (channels, 1) - one loudness value per channel\n    \"\"\"\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    return (n_channels, 1)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw","title":"<code>RoughnessDw</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>This operation computes the roughness of audio signals according to the Daniel and Weber (1997) method. It uses the MoSQITo library's implementation of the standardized roughness calculation.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound. The unit is asper, where higher values indicate rougher sounds.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz. The signal should be sampled at a rate appropriate     for the analysis (typically 44100 Hz or 48000 Hz for audio). overlap : float, default=0.5     Overlapping coefficient for the analysis windows (0.0 to 1.0).     The analysis uses 200ms windows:     - overlap=0.5: 100ms hop size \u2192 ~10 Hz output sampling rate     - overlap=0.0: 200ms hop size \u2192 ~5 Hz output sampling rate</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw--attributes","title":"Attributes","text":"<p>name : str     Operation name: \"roughness_dw\" overlap : float     The overlapping coefficient used for calculation</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw--examples","title":"Examples","text":"<p>Calculate roughness for a signal:</p> <p>import wandas as wd signal = wd.read_wav(\"motor_noise.wav\") roughness = signal.roughness_dw(overlap=0.5) print(f\"Mean roughness: {roughness.data.mean():.2f} asper\")</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw--notes","title":"Notes","text":"<ul> <li>The output contains time-varying roughness values in asper</li> <li>For mono signals, the roughness is calculated directly</li> <li>For multi-channel signals, roughness is calculated per channel</li> <li>The method follows Daniel &amp; Weber (1997) standard</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher overlap values provide better time resolution but increase   computational cost</li> </ul>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw--references","title":"References","text":"<p>.. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:        Implementation of an optimized model.\" Acustica, 83, 113-123. .. [2] MoSQITo documentation:        https://mosqito.readthedocs.io/en/latest/</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class RoughnessDw(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\n    Calculate time-varying roughness using Daniel and Weber method.\n\n    This operation computes the roughness of audio signals according to\n    the Daniel and Weber (1997) method. It uses the MoSQITo library's\n    implementation of the standardized roughness calculation.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound. The unit is asper, where higher\n    values indicate rougher sounds.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz. The signal should be sampled at a rate appropriate\n        for the analysis (typically 44100 Hz or 48000 Hz for audio).\n    overlap : float, default=0.5\n        Overlapping coefficient for the analysis windows (0.0 to 1.0).\n        The analysis uses 200ms windows:\n        - overlap=0.5: 100ms hop size \u2192 ~10 Hz output sampling rate\n        - overlap=0.0: 200ms hop size \u2192 ~5 Hz output sampling rate\n\n    Attributes\n    ----------\n    name : str\n        Operation name: \"roughness_dw\"\n    overlap : float\n        The overlapping coefficient used for calculation\n\n    Examples\n    --------\n    Calculate roughness for a signal:\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n    &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n    &gt;&gt;&gt; print(f\"Mean roughness: {roughness.data.mean():.2f} asper\")\n\n    Notes\n    -----\n    - The output contains time-varying roughness values in asper\n    - For mono signals, the roughness is calculated directly\n    - For multi-channel signals, roughness is calculated per channel\n    - The method follows Daniel &amp; Weber (1997) standard\n    - Typical roughness values: 0-2 asper for most sounds\n    - Higher overlap values provide better time resolution but increase\n      computational cost\n\n    References\n    ----------\n    .. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n           Implementation of an optimized model.\" Acustica, 83, 113-123.\n    .. [2] MoSQITo documentation:\n           https://mosqito.readthedocs.io/en/latest/\n    \"\"\"\n\n    name = \"roughness_dw\"\n\n    def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n        \"\"\"\n        Initialize Roughness calculation operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        overlap : float, default=0.5\n            Overlapping coefficient (0.0 to 1.0)\n        \"\"\"\n        self.overlap = overlap\n        super().__init__(sampling_rate, overlap=overlap)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"\n        Validate parameters.\n\n        Raises\n        ------\n        ValueError\n            If overlap is not in [0.0, 1.0]\n        \"\"\"\n        if not 0.0 &lt;= self.overlap &lt;= 1.0:\n            raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on overlap and window size.\n\n        The Daniel &amp; Weber method uses 200ms windows. The output\n        sampling rate depends on the overlap:\n        - overlap=0.0: hop=200ms \u2192 fs=5 Hz\n        - overlap=0.5: hop=100ms \u2192 fs=10 Hz\n        - overlap=0.75: hop=50ms \u2192 fs=20 Hz\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        The output sampling rate is approximately 1 / (0.2 * (1 - overlap)) Hz.\n        \"\"\"\n        window_duration = 0.2  # 200ms window\n        hop_duration = window_duration * (1 - self.overlap)\n        output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n        return {\"sampling_rate\": output_sampling_rate}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        The roughness calculation produces a time-varying output where the\n        number of time points depends on the signal length and overlap.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, time_samples)\n        \"\"\"\n        n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n        n_samples = input_shape[-1]\n\n        # Estimate output length based on window size and overlap\n        window_samples = int(0.2 * self.sampling_rate)  # 200ms\n        hop_samples = int(window_samples * (1 - self.overlap))\n\n        if hop_samples &gt; 0:\n            estimated_time_samples = max(\n                1, (n_samples - window_samples) // hop_samples + 1\n            )\n        else:\n            estimated_time_samples = 1\n\n        return (n_channels, estimated_time_samples)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"\n        Process array to calculate roughness.\n\n        This method calculates the time-varying roughness for each channel\n        of the input signal using the Daniel and Weber method.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array with shape (channels, samples) or (samples,)\n\n        Returns\n        -------\n        NDArrayReal\n            Time-varying roughness in asper for each channel.\n            Shape: (channels, time_samples)\n\n        Notes\n        -----\n        The function processes each channel independently and returns\n        the total roughness values (R). The specific roughness per Bark\n        band (R_spec) is not returned by this operation but can be obtained\n        using the roughness_dw_spec method.\n        \"\"\"\n        logger.debug(\n            f\"Calculating roughness for signal with shape: {x.shape}, \"\n            f\"overlap: {self.overlap}\"\n        )\n\n        # Handle 1D input (single channel)\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        n_channels = x.shape[0]\n        roughness_results = []\n\n        for ch in range(n_channels):\n            channel_data = x[ch, :]\n\n            # Ensure channel_data is a contiguous 1D NumPy array\n            channel_data = np.asarray(channel_data).ravel()\n\n            # Call MoSQITo's roughness_dw function\n            # Returns: R (total roughness), R_spec (specific roughness),\n            #          bark_axis, time_axis\n            roughness_r, _, _, _ = roughness_dw_mosqito(\n                channel_data, self.sampling_rate, overlap=self.overlap\n            )\n\n            roughness_results.append(roughness_r)\n\n            logger.debug(\n                f\"Channel {ch}: Calculated roughness with \"\n                f\"{len(roughness_r)} time points, \"\n                f\"max roughness: {np.max(roughness_r):.2f} asper\"\n            )\n\n        # Stack results\n        result: NDArrayReal = np.stack(roughness_results, axis=0)\n\n        logger.debug(f\"Roughness calculation complete, output shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'roughness_dw'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>overlap = overlap</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, overlap=0.5)</code> \u00b6 <p>Initialize Roughness calculation operation.</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters.</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Update sampling rate based on overlap and window size.</p> <p>The Daniel &amp; Weber method uses 200ms windows. The output sampling rate depends on the overlap: - overlap=0.0: hop=200ms \u2192 fs=5 Hz - overlap=0.5: hop=100ms \u2192 fs=10 Hz - overlap=0.75: hop=50ms \u2192 fs=20 Hz</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <p>The roughness calculation produces a time-varying output where the number of time points depends on the signal length and overlap.</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) overlap : float, default=0.5     Overlapping coefficient (0.0 to 1.0)</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n    \"\"\"\n    Initialize Roughness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    overlap : float, default=0.5\n        Overlapping coefficient (0.0 to 1.0)\n    \"\"\"\n    self.overlap = overlap\n    super().__init__(sampling_rate, overlap=overlap)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw.validate_params--raises","title":"Raises","text":"<p>ValueError     If overlap is not in [0.0, 1.0]</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If overlap is not in [0.0, 1.0]\n    \"\"\"\n    if not 0.0 &lt;= self.overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is approximately 1 / (0.2 * (1 - overlap)) Hz.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on overlap and window size.\n\n    The Daniel &amp; Weber method uses 200ms windows. The output\n    sampling rate depends on the overlap:\n    - overlap=0.0: hop=200ms \u2192 fs=5 Hz\n    - overlap=0.5: hop=100ms \u2192 fs=10 Hz\n    - overlap=0.75: hop=50ms \u2192 fs=20 Hz\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    The output sampling rate is approximately 1 / (0.2 * (1 - overlap)) Hz.\n    \"\"\"\n    window_duration = 0.2  # 200ms window\n    hop_duration = window_duration * (1 - self.overlap)\n    output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n    return {\"sampling_rate\": output_sampling_rate}\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDw.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, time_samples)</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The roughness calculation produces a time-varying output where the\n    number of time points depends on the signal length and overlap.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, time_samples)\n    \"\"\"\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    n_samples = input_shape[-1]\n\n    # Estimate output length based on window size and overlap\n    window_samples = int(0.2 * self.sampling_rate)  # 200ms\n    hop_samples = int(window_samples * (1 - self.overlap))\n\n    if hop_samples &gt; 0:\n        estimated_time_samples = max(\n            1, (n_samples - window_samples) // hop_samples + 1\n        )\n    else:\n        estimated_time_samples = 1\n\n    return (n_channels, estimated_time_samples)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic.RoughnessDwSpec","title":"<code>RoughnessDwSpec</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Specific roughness (R_spec) operation.</p> <p>Computes per-Bark-band specific roughness over time using MoSQITo's <code>roughness_dw</code> implementation. Output is band-by-time.</p> <p>The bark_axis is retrieved dynamically from MoSQITo during initialization to ensure consistency with MoSQITo's implementation. Results are cached based on sampling_rate and overlap to avoid redundant computations.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class RoughnessDwSpec(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Specific roughness (R_spec) operation.\n\n    Computes per-Bark-band specific roughness over time using MoSQITo's\n    `roughness_dw` implementation. Output is band-by-time.\n\n    The bark_axis is retrieved dynamically from MoSQITo during initialization\n    to ensure consistency with MoSQITo's implementation. Results are cached\n    based on sampling_rate and overlap to avoid redundant computations.\n    \"\"\"\n\n    name = \"roughness_dw_spec\"\n    # Class-level cache: {(sampling_rate, overlap): bark_axis}\n    _bark_axis_cache: dict[tuple[float, float], NDArrayReal] = {}\n\n    def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n        self.overlap = overlap\n        self.validate_params()\n        # Check cache first to avoid redundant MoSQITo calls\n        cache_key = (sampling_rate, overlap)\n        if cache_key in RoughnessDwSpec._bark_axis_cache:\n            logger.debug(\n                f\"Using cached bark_axis for sampling_rate={sampling_rate}, \"\n                f\"overlap={overlap}\"\n            )\n            self._bark_axis: NDArrayReal = RoughnessDwSpec._bark_axis_cache[cache_key]\n        else:\n            # Retrieve bark_axis dynamically from MoSQITo to ensure consistency\n            # Use a minimal reference signal to get the bark_axis structure\n            logger.debug(\n                f\"Computing bark_axis from MoSQITo for sampling_rate={sampling_rate}, \"\n                f\"overlap={overlap}\"\n            )\n            reference_signal = np.zeros(\n                int(sampling_rate * 0.2)\n            )  # 200ms minimal signal\n            try:\n                _, _, bark_axis_from_mosqito, _ = roughness_dw_mosqito(\n                    reference_signal, sampling_rate, overlap=overlap\n                )\n            except Exception as e:\n                logger.error(\n                    f\"Failed to retrieve bark_axis from MoSQITo's roughness_dw: {e}\"\n                )\n                raise RuntimeError(\n                    \"Could not initialize RoughnessDwSpec: error retrieving bark_axis \"\n                    \"from MoSQITo.\"\n                ) from e\n            if bark_axis_from_mosqito is None or (\n                hasattr(bark_axis_from_mosqito, \"__len__\")\n                and len(bark_axis_from_mosqito) == 0\n            ):\n                logger.error(\n                    \"MoSQITo's roughness_dw returned an empty or None bark_axis.\"\n                )\n                raise RuntimeError(\n                    \"Could not initialize RoughnessDwSpec: MoSQITo's roughness_dw \"\n                    \"returned an empty or None bark_axis.\"\n                )\n            self._bark_axis = bark_axis_from_mosqito\n            # Cache the result for future use\n            RoughnessDwSpec._bark_axis_cache[cache_key] = bark_axis_from_mosqito\n        super().__init__(sampling_rate, overlap=overlap)\n\n    @property\n    def bark_axis(self) -&gt; NDArrayReal:\n        return self._bark_axis\n\n    def validate_params(self) -&gt; None:\n        if not 0.0 &lt;= self.overlap &lt;= 1.0:\n            raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        window_duration = 0.2\n        hop_duration = window_duration * (1 - self.overlap)\n        output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n\n        return {\"sampling_rate\": output_sampling_rate, \"bark_axis\": self._bark_axis}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        n_bark_bands = len(self._bark_axis)\n        if len(input_shape) == 1:\n            n_samples = input_shape[0]\n            n_channels = 1\n        else:\n            n_channels, n_samples = input_shape[:2]\n\n        window_samples = int(0.2 * self.sampling_rate)\n        hop_samples = int(window_samples * (1 - self.overlap))\n\n        if hop_samples &gt; 0:\n            estimated_time_samples = max(\n                1, (n_samples - window_samples) // hop_samples + 1\n            )\n        else:\n            estimated_time_samples = 1\n\n        if n_channels == 1:\n            return (n_bark_bands, estimated_time_samples)\n        return (n_channels, n_bark_bands, estimated_time_samples)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        logger.debug(\n            \"Calculating specific roughness for signal with shape: %s, overlap: %s\",\n            x.shape,\n            self.overlap,\n        )\n\n        # Ensure (n_channels, n_samples)\n        if x.ndim == 1:\n            x_proc: NDArrayReal = x.reshape(1, -1)\n        else:\n            x_proc = x\n\n        n_channels = x_proc.shape[0]\n        r_spec_list: list[NDArrayReal] = []\n\n        for ch in range(n_channels):\n            channel_data = np.asarray(x_proc[ch]).ravel()\n\n            # Call MoSQITo's roughness_dw (module-level import)\n            _, r_spec, bark_axis, _ = roughness_dw_mosqito(\n                channel_data, self.sampling_rate, overlap=self.overlap\n            )\n\n            r_spec_list.append(r_spec)\n            if self._bark_axis is None:\n                self._bark_axis = bark_axis\n\n            logger.debug(\n                \"Channel %d: calculated specific roughness shape=%s\",\n                ch,\n                r_spec.shape,\n            )\n\n        if n_channels == 1:\n            result: NDArrayReal = r_spec_list[0]\n            return result\n        return np.stack(r_spec_list, axis=0)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'roughness_dw_spec'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>overlap = overlap</code> <code>instance-attribute</code> \u00b6 <code></code> <code>bark_axis</code> <code>property</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, overlap=0.5)</code> \u00b6 Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n    self.overlap = overlap\n    self.validate_params()\n    # Check cache first to avoid redundant MoSQITo calls\n    cache_key = (sampling_rate, overlap)\n    if cache_key in RoughnessDwSpec._bark_axis_cache:\n        logger.debug(\n            f\"Using cached bark_axis for sampling_rate={sampling_rate}, \"\n            f\"overlap={overlap}\"\n        )\n        self._bark_axis: NDArrayReal = RoughnessDwSpec._bark_axis_cache[cache_key]\n    else:\n        # Retrieve bark_axis dynamically from MoSQITo to ensure consistency\n        # Use a minimal reference signal to get the bark_axis structure\n        logger.debug(\n            f\"Computing bark_axis from MoSQITo for sampling_rate={sampling_rate}, \"\n            f\"overlap={overlap}\"\n        )\n        reference_signal = np.zeros(\n            int(sampling_rate * 0.2)\n        )  # 200ms minimal signal\n        try:\n            _, _, bark_axis_from_mosqito, _ = roughness_dw_mosqito(\n                reference_signal, sampling_rate, overlap=overlap\n            )\n        except Exception as e:\n            logger.error(\n                f\"Failed to retrieve bark_axis from MoSQITo's roughness_dw: {e}\"\n            )\n            raise RuntimeError(\n                \"Could not initialize RoughnessDwSpec: error retrieving bark_axis \"\n                \"from MoSQITo.\"\n            ) from e\n        if bark_axis_from_mosqito is None or (\n            hasattr(bark_axis_from_mosqito, \"__len__\")\n            and len(bark_axis_from_mosqito) == 0\n        ):\n            logger.error(\n                \"MoSQITo's roughness_dw returned an empty or None bark_axis.\"\n            )\n            raise RuntimeError(\n                \"Could not initialize RoughnessDwSpec: MoSQITo's roughness_dw \"\n                \"returned an empty or None bark_axis.\"\n            )\n        self._bark_axis = bark_axis_from_mosqito\n        # Cache the result for future use\n        RoughnessDwSpec._bark_axis_cache[cache_key] = bark_axis_from_mosqito\n    super().__init__(sampling_rate, overlap=overlap)\n</code></pre> <code></code> <code>validate_params()</code> \u00b6 Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    if not 0.0 &lt;= self.overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n</code></pre> <code></code> <code>get_metadata_updates()</code> \u00b6 Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    window_duration = 0.2\n    hop_duration = window_duration * (1 - self.overlap)\n    output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n\n    return {\"sampling_rate\": output_sampling_rate, \"bark_axis\": self._bark_axis}\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    n_bark_bands = len(self._bark_axis)\n    if len(input_shape) == 1:\n        n_samples = input_shape[0]\n        n_channels = 1\n    else:\n        n_channels, n_samples = input_shape[:2]\n\n    window_samples = int(0.2 * self.sampling_rate)\n    hop_samples = int(window_samples * (1 - self.overlap))\n\n    if hop_samples &gt; 0:\n        estimated_time_samples = max(\n            1, (n_samples - window_samples) // hop_samples + 1\n        )\n    else:\n        estimated_time_samples = 1\n\n    if n_channels == 1:\n        return (n_bark_bands, estimated_time_samples)\n    return (n_channels, n_bark_bands, estimated_time_samples)\n</code></pre>"},{"location":"api/#wandas.processing.psychoacoustic-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.spectral","title":"<code>spectral</code>","text":""},{"location":"api/#wandas.processing.spectral-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.spectral.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.spectral-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.spectral.FFT","title":"<code>FFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>FFT (Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class FFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"FFT (Fast Fourier Transform) operation\"\"\"\n\n    name = \"fft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize FFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is None (determined by input size)\n        window : str, optional\n            Window function type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not a positive integer\n        \"\"\"\n        # Validate n_fft parameter\n        if n_fft is not None and n_fft &lt;= 0:\n            raise ValueError(\n                f\"Invalid FFT size\\n\"\n                f\"  Got: {n_fft}\\n\"\n                f\"  Expected: Positive integer &gt; 0\\n\"\n                f\"FFT size must be a positive integer.\\n\"\n                f\"Common values: 512, 1024, 2048, 4096,\\n\"\n                f\"8192 (powers of 2 are most efficient)\"\n            )\n\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n        Parameters\n        ----------\n        input_shape : tuple\n            \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n        Returns\n        -------\n        tuple\n            \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"FFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"FFT\u64cd\u4f5c\u306e\u30d7\u30ed\u30bb\u30c3\u30b5\u95a2\u6570\u3092\u4f5c\u6210\"\"\"\n        from scipy.signal import get_window\n\n        if self.n_fft is not None and x.shape[-1] &gt; self.n_fft:\n            # If n_fft is specified and input length exceeds it, truncate\n            x = x[..., : self.n_fft]\n\n        win = get_window(self.window, x.shape[-1])\n        x = x * win\n        result: NDArrayComplex = np.fft.rfft(x, n=self.n_fft, axis=-1)\n        result[..., 1:-1] *= 2.0\n        # \u7a93\u95a2\u6570\u88dc\u6b63\n        scaling_factor = np.sum(win)\n        result = result / scaling_factor\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'fft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=None, window='hann')</code> \u00b6 <p>Initialize FFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>\u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"FFT\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.FFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int, optional     FFT size, default is None (determined by input size) window : str, optional     Window function type, default is 'hann'</p>"},{"location":"api/#wandas.processing.spectral.FFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not a positive integer</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize FFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is None (determined by input size)\n    window : str, optional\n        Window function type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not a positive integer\n    \"\"\"\n    # Validate n_fft parameter\n    if n_fft is not None and n_fft &lt;= 0:\n        raise ValueError(\n            f\"Invalid FFT size\\n\"\n            f\"  Got: {n_fft}\\n\"\n            f\"  Expected: Positive integer &gt; 0\\n\"\n            f\"FFT size must be a positive integer.\\n\"\n            f\"Common values: 512, 1024, 2048, 4096,\\n\"\n            f\"8192 (powers of 2 are most efficient)\"\n        )\n\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.FFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)</p>"},{"location":"api/#wandas.processing.spectral.FFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n    Parameters\n    ----------\n    input_shape : tuple\n        \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n    Returns\n    -------\n    tuple\n        \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.IFFT","title":"<code>IFFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>IFFT (Inverse Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class IFFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"IFFT (Inverse Fast Fourier Transform) operation\"\"\"\n\n    name = \"ifft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize IFFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : Optional[int], optional\n            IFFT size, default is None (determined based on input size)\n        window : str, optional\n            Window function type, default is 'hann'\n        \"\"\"\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, freqs)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, samples)\n        \"\"\"\n        n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iFFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"Create processor function for IFFT operation\"\"\"\n        logger.debug(f\"Applying IFFT to array with shape: {x.shape}\")\n\n        # Restore frequency component scaling (remove the 2.0 multiplier applied in FFT)\n        _x = x.copy()\n        _x[..., 1:-1] /= 2.0\n\n        # Execute IFFT\n        result: NDArrayReal = np.fft.irfft(_x, n=self.n_fft, axis=-1)\n\n        # Window function correction (inverse of FFT operation)\n        from scipy.signal import get_window\n\n        win = get_window(self.window, result.shape[-1])\n\n        # Correct the FFT window function scaling\n        scaling_factor = np.sum(win) / result.shape[-1]\n        result = result / scaling_factor\n\n        logger.debug(f\"IFFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'ifft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=None, window='hann')</code> \u00b6 <p>Initialize IFFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iFFT\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.IFFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : Optional[int], optional     IFFT size, default is None (determined based on input size) window : str, optional     Window function type, default is 'hann'</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize IFFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : Optional[int], optional\n        IFFT size, default is None (determined based on input size)\n    window : str, optional\n        Window function type, default is 'hann'\n    \"\"\"\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.IFFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, freqs)</p>"},{"location":"api/#wandas.processing.spectral.IFFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, samples)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, freqs)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, samples)\n    \"\"\"\n    n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.STFT","title":"<code>STFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class STFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Short-Time Fourier Transform operation\"\"\"\n\n    name = \"stft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ):\n        \"\"\"\n        Initialize STFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"STFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",\n        )\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        n_samples = input_shape[-1]\n        n_f = len(self.SFT.f)\n        n_t = len(self.SFT.t(n_samples))\n        return (input_shape[0], n_f, n_t)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"STFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Apply SciPy STFT processing to multiple channels at once\"\"\"\n        logger.debug(f\"Applying SciPy STFT to array with shape: {x.shape}\")\n\n        # Convert 1D input to 2D\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        # Apply STFT to all channels at once\n        result: NDArrayComplex = self.SFT.stft(x)\n        result[..., 1:-1, :] *= 2.0\n        logger.debug(f\"SciPy STFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'stft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Initialize STFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"STFT\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.STFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window type, default is 'hann'</p>"},{"location":"api/#wandas.processing.spectral.STFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n):\n    \"\"\"\n    Initialize STFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"STFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",\n    )\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.spectral.STFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.spectral.STFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    n_samples = input_shape[-1]\n    n_f = len(self.SFT.f)\n    n_t = len(self.SFT.t(n_samples))\n    return (input_shape[0], n_f, n_t)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.ISTFT","title":"<code>ISTFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>Inverse Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class ISTFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"Inverse Short-Time Fourier Transform operation\"\"\"\n\n    name = \"istft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        length: int | None = None,\n    ):\n        \"\"\"\n        Initialize ISTFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n        length : int, optional\n            Length of output signal. Default is None (determined from input)\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"ISTFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.length = length\n\n        # Instantiate ShortTimeFFT for ISTFT calculation\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",  # Consistent scaling with STFT\n        )\n\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            length=length,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after ISTFT operation.\n\n        Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n        output length based on the input spectrogram dimensions and output range\n        parameters (k0, k1).\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input spectrogram shape (channels, n_freqs, n_frames)\n            where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n        Returns\n        -------\n        tuple\n            Output shape (channels, output_samples) where output_samples is the\n            reconstructed signal length determined by the output range [k0, k1).\n\n        Notes\n        -----\n        The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n        When k1 is None (default), the maximum reconstructible signal length is\n        computed as:\n\n        .. math::\n\n            q_{max} = n_{frames} + p_{min}\n\n            k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n        The output length is then:\n\n        .. math::\n\n            output\\\\_samples = k_1 - k_0\n\n        where k0 defaults to 0 and k1 defaults to k_max.\n\n        Parameters that affect the calculation:\n        - n_frames: number of time frames in the STFT\n        - p_min: minimum frame index (ShortTimeFFT property)\n        - hop: hop length (samples between frames)\n        - m_num: window length\n        - m_num_mid: window midpoint position\n        - self.length: optional length override (if set, limits output)\n\n        References\n        ----------\n        - SciPy ShortTimeFFT.istft:\n          https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n        - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        \"\"\"\n        n_channels = input_shape[0]\n        n_frames = input_shape[-1]  # time_frames\n\n        # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n        # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        q_max = n_frames + self.SFT.p_min\n        k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n        # Default parameters: k0=0, k1=None (which becomes k_max)\n        # The output length is k1 - k0 = k_max - 0 = k_max\n        k0 = 0\n        k1 = k_max\n\n        # If self.length is specified, it acts as an override to limit the output\n        if self.length is not None:\n            k1 = min(self.length, k1)\n\n        output_samples = k1 - k0\n\n        return (n_channels, output_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iSTFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"\n        Apply SciPy ISTFT processing to multiple channels at once using ShortTimeFFT\"\"\"\n        logger.debug(\n            f\"Applying SciPy ISTFT (ShortTimeFFT) to array with shape: {x.shape}\"\n        )\n\n        # Convert 2D input to 3D (assume single channel)\n        if x.ndim == 2:\n            x = x.reshape(1, *x.shape)\n\n        # Adjust scaling back if STFT applied factor of 2\n        _x = np.copy(x)\n        _x[..., 1:-1, :] /= 2.0\n\n        # Apply ISTFT using the ShortTimeFFT instance\n        result: NDArrayReal = self.SFT.istft(_x)\n\n        # Trim to desired length if specified\n        if self.length is not None:\n            result = result[..., : self.length]\n\n        logger.debug(\n            f\"ShortTimeFFT applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'istft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>length = length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', length=None)</code> \u00b6 <p>Initialize ISTFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after ISTFT operation.</p> <p>Uses the SciPy ShortTimeFFT calculation formula to compute the expected output length based on the input spectrogram dimensions and output range parameters (k0, k1).</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iSTFT\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.ISTFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window type, default is 'hann' length : int, optional     Length of output signal. Default is None (determined from input)</p>"},{"location":"api/#wandas.processing.spectral.ISTFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    length: int | None = None,\n):\n    \"\"\"\n    Initialize ISTFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n    length : int, optional\n        Length of output signal. Default is None (determined from input)\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"ISTFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.length = length\n\n    # Instantiate ShortTimeFFT for ISTFT calculation\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",  # Consistent scaling with STFT\n    )\n\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        length=length,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.spectral.ISTFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input spectrogram shape (channels, n_freqs, n_frames)     where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.</p>"},{"location":"api/#wandas.processing.spectral.ISTFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output shape (channels, output_samples) where output_samples is the     reconstructed signal length determined by the output range [k0, k1).</p>"},{"location":"api/#wandas.processing.spectral.ISTFT.calculate_output_shape--notes","title":"Notes","text":"<p>The calculation follows SciPy's ShortTimeFFT.istft() implementation. When k1 is None (default), the maximum reconstructible signal length is computed as:</p> <p>.. math::</p> <pre><code>q_{max} = n_{frames} + p_{min}\n\nk_{max} = (q_{max} - 1) \\cdot hop + m_{num} - m_{num\\_mid}\n</code></pre> <p>The output length is then:</p> <p>.. math::</p> <pre><code>output\\_samples = k_1 - k_0\n</code></pre> <p>where k0 defaults to 0 and k1 defaults to k_max.</p> <p>Parameters that affect the calculation: - n_frames: number of time frames in the STFT - p_min: minimum frame index (ShortTimeFFT property) - hop: hop length (samples between frames) - m_num: window length - m_num_mid: window midpoint position - self.length: optional length override (if set, limits output)</p>"},{"location":"api/#wandas.processing.spectral.ISTFT.calculate_output_shape--references","title":"References","text":"<ul> <li>SciPy ShortTimeFFT.istft:   https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html</li> <li>SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py</li> </ul> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after ISTFT operation.\n\n    Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n    output length based on the input spectrogram dimensions and output range\n    parameters (k0, k1).\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input spectrogram shape (channels, n_freqs, n_frames)\n        where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n    Returns\n    -------\n    tuple\n        Output shape (channels, output_samples) where output_samples is the\n        reconstructed signal length determined by the output range [k0, k1).\n\n    Notes\n    -----\n    The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n    When k1 is None (default), the maximum reconstructible signal length is\n    computed as:\n\n    .. math::\n\n        q_{max} = n_{frames} + p_{min}\n\n        k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n    The output length is then:\n\n    .. math::\n\n        output\\\\_samples = k_1 - k_0\n\n    where k0 defaults to 0 and k1 defaults to k_max.\n\n    Parameters that affect the calculation:\n    - n_frames: number of time frames in the STFT\n    - p_min: minimum frame index (ShortTimeFFT property)\n    - hop: hop length (samples between frames)\n    - m_num: window length\n    - m_num_mid: window midpoint position\n    - self.length: optional length override (if set, limits output)\n\n    References\n    ----------\n    - SciPy ShortTimeFFT.istft:\n      https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n    - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    \"\"\"\n    n_channels = input_shape[0]\n    n_frames = input_shape[-1]  # time_frames\n\n    # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n    # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    q_max = n_frames + self.SFT.p_min\n    k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n    # Default parameters: k0=0, k1=None (which becomes k_max)\n    # The output length is k1 - k0 = k_max - 0 = k_max\n    k0 = 0\n    k1 = k_max\n\n    # If self.length is specified, it acts as an override to limit the output\n    if self.length is not None:\n        k1 = min(self.length, k1)\n\n    output_samples = k1 - k0\n\n    return (n_channels, output_samples)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.Welch","title":"<code>Welch</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Welch</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Welch(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Welch\"\"\"\n\n    name = \"welch\"\n    n_fft: int\n    window: str\n    hop_length: int | None\n    win_length: int | None\n    average: str\n    detrend: str\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        average: str = \"mean\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize Welch operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str, optional\n            Window function type, default is 'hann'\n        average : str, optional\n            Averaging method, default is 'mean'\n        detrend : str, optional\n            Detrend method, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft, win_length, or hop_length are invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Welch method\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n        self.average = average\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            average=average,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"PS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for Welch operation\"\"\"\n        from scipy import signal as ss\n\n        _, result = ss.welch(\n            x,\n            nperseg=self.win_length,\n            noverlap=self.noverlap,\n            nfft=self.n_fft,\n            window=self.window,\n            average=self.average,\n            detrend=self.detrend,\n            scaling=\"spectrum\",\n        )\n\n        if not isinstance(x, np.ndarray):\n            # Trigger computation for Dask array\n            raise ValueError(\n                \"Welch operation requires a Dask array, but received a non-ndarray.\"\n            )\n        return np.array(result)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'welch'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>average = average</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', average='mean', detrend='constant')</code> \u00b6 <p>Initialize Welch operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"PS\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.Welch.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int, optional     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str, optional     Window function type, default is 'hann' average : str, optional     Averaging method, default is 'mean' detrend : str, optional     Detrend method, default is 'constant'</p>"},{"location":"api/#wandas.processing.spectral.Welch.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft, win_length, or hop_length are invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    average: str = \"mean\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize Welch operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str, optional\n        Window function type, default is 'hann'\n    average : str, optional\n        Averaging method, default is 'mean'\n    detrend : str, optional\n        Detrend method, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft, win_length, or hop_length are invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Welch method\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n    self.average = average\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        average=average,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.spectral.Welch.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.spectral.Welch.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.NOctSpectrum","title":"<code>NOctSpectrum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>N-octave spectrum operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSpectrum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"N-octave spectrum operation\"\"\"\n\n    name = \"noct_spectrum\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize N-octave spectrum\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Oct\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave spectrum\"\"\"\n        logger.debug(f\"Applying NoctSpectrum to array with shape: {x.shape}\")\n        spec, _ = noct_spectrum(\n            sig=x.T,\n            fs=self.sampling_rate,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if spec.ndim == 1:\n            # Add channel dimension for 1D\n            spec = np.expand_dims(spec, axis=0)\n        else:\n            spec = spec.T\n        logger.debug(f\"NoctSpectrum applied, returning result with shape: {spec.shape}\")\n        return np.array(spec)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'noct_spectrum'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmin = fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax = fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n = n</code> <code>instance-attribute</code> \u00b6 <code></code> <code>G = G</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fr = fr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code> \u00b6 <p>Initialize N-octave spectrum</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Oct\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.NOctSpectrum.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize N-octave spectrum\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"api/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"api/#wandas.processing.spectral.NOctSynthesis","title":"<code>NOctSynthesis</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Octave synthesis operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSynthesis(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Octave synthesis operation\"\"\"\n\n    name = \"noct_synthesis\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize octave synthesis\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Octs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave synthesis\"\"\"\n        logger.debug(f\"Applying NoctSynthesis to array with shape: {x.shape}\")\n        # Calculate n from shape[-1]\n        n = x.shape[-1]  # Calculate n from shape[-1]\n        if n % 2 == 0:\n            n = n * 2 - 1\n        else:\n            n = (n - 1) * 2\n        freqs = np.fft.rfftfreq(n, d=1 / self.sampling_rate)\n        result, _ = noct_synthesis(\n            spectrum=np.abs(x).T,\n            freqs=freqs,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        result = result.T\n        logger.debug(\n            f\"NoctSynthesis applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'noct_synthesis'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmin = fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax = fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n = n</code> <code>instance-attribute</code> \u00b6 <code></code> <code>G = G</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fr = fr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code> \u00b6 <p>Initialize octave synthesis</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Octs\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.NOctSynthesis.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize octave synthesis\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"api/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"api/#wandas.processing.spectral.Coherence","title":"<code>Coherence</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Coherence estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Coherence(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Coherence estimation operation\"\"\"\n\n    name = \"coherence\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize coherence estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Coherence\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Coh\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Processor function for coherence estimation operation\"\"\"\n        logger.debug(f\"Applying coherence estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        _, coh = ss.coherence(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayReal = coh.transpose(1, 0, 2).reshape(-1, coh.shape[-1])\n\n        logger.debug(f\"Coherence estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'coherence'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code> \u00b6 <p>Initialize coherence estimation operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Coh\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.Coherence.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant'</p>"},{"location":"api/#wandas.processing.spectral.Coherence.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize coherence estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Coherence\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.spectral.Coherence.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.spectral.Coherence.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.CSD","title":"<code>CSD</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Cross-spectral density estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class CSD(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Cross-spectral density estimation operation\"\"\"\n\n    name = \"csd\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize cross-spectral density estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"CSD\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"CSD\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for cross-spectral density estimation operation\"\"\"\n        logger.debug(f\"Applying CSD estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        # Calculate all combinations using scipy's csd function\n        _, csd_result = ss.csd(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayComplex = csd_result.transpose(1, 0, 2).reshape(\n            -1, csd_result.shape[-1]\n        )\n\n        logger.debug(f\"CSD estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'csd'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 <code></code> <code>scaling = scaling</code> <code>instance-attribute</code> \u00b6 <code></code> <code>average = average</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Initialize cross-spectral density estimation operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"CSD\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.CSD.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant' scaling : str     Type of scaling, default is 'spectrum' average : str     Method of averaging, default is 'mean'</p>"},{"location":"api/#wandas.processing.spectral.CSD.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize cross-spectral density estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"CSD\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.spectral.CSD.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.spectral.CSD.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.spectral.TransferFunction","title":"<code>TransferFunction</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Transfer function estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class TransferFunction(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Transfer function estimation operation\"\"\"\n\n    name = \"transfer_function\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize transfer function estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Transfer function\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"H\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for transfer function estimation operation\"\"\"\n        logger.debug(\n            f\"Applying transfer function estimation to array with shape: {x.shape}\"\n        )\n        from scipy import signal as ss\n\n        # Calculate cross-spectral density between all channels\n        f, p_yx = ss.csd(\n            x=x[:, np.newaxis, :],\n            y=x[np.newaxis, :, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_yx shape: (num_channels, num_channels, num_frequencies)\n\n        # Calculate power spectral density for each channel\n        f, p_xx = ss.welch(\n            x=x,\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_xx shape: (num_channels, num_frequencies)\n\n        # Calculate transfer function H(f) = P_yx / P_xx\n        h_f = p_yx / p_xx[np.newaxis, :, :]\n        result: NDArrayComplex = h_f.transpose(1, 0, 2).reshape(-1, h_f.shape[-1])\n\n        logger.debug(\n            f\"Transfer function estimation applied, result shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'transfer_function'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 <code></code> <code>scaling = scaling</code> <code>instance-attribute</code> \u00b6 <code></code> <code>average = average</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Initialize transfer function estimation operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"H\"\n</code></pre>"},{"location":"api/#wandas.processing.spectral.TransferFunction.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant' scaling : str     Type of scaling, default is 'spectrum' average : str     Method of averaging, default is 'mean'</p>"},{"location":"api/#wandas.processing.spectral.TransferFunction.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize transfer function estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Transfer function\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.spectral.TransferFunction.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.spectral.TransferFunction.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/#wandas.processing.spectral-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.stats","title":"<code>stats</code>","text":""},{"location":"api/#wandas.processing.stats-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.stats.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.stats-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.stats.ABS","title":"<code>ABS</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Absolute value operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ABS(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Absolute value operation\"\"\"\n\n    name = \"abs\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize absolute value operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"abs\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'abs'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate)</code> \u00b6 <p>Initialize absolute value operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"abs\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/#wandas.processing.stats.ABS.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize absolute value operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"api/#wandas.processing.stats.Power","title":"<code>Power</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Power operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Power(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Power operation\"\"\"\n\n    name = \"power\"\n\n    def __init__(self, sampling_rate: float, exponent: float):\n        \"\"\"\n        Initialize power operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        exponent : float\n            Power exponent\n        \"\"\"\n        super().__init__(sampling_rate)\n        self.exp = exponent\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"pow\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'power'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>exp = exponent</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, exponent)</code> \u00b6 <p>Initialize power operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"pow\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/#wandas.processing.stats.Power.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) exponent : float     Power exponent</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, exponent: float):\n    \"\"\"\n    Initialize power operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    exponent : float\n        Power exponent\n    \"\"\"\n    super().__init__(sampling_rate)\n    self.exp = exponent\n</code></pre>"},{"location":"api/#wandas.processing.stats.Sum","title":"<code>Sum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Sum calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Sum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Sum calculation\"\"\"\n\n    name = \"sum\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"sum\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.sum(axis=0, keepdims=True)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'sum'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"sum\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/#wandas.processing.stats.Mean","title":"<code>Mean</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Mean calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Mean(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Mean calculation\"\"\"\n\n    name = \"mean\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"mean\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.mean(axis=0, keepdims=True)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'mean'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"mean\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/#wandas.processing.stats.ChannelDifference","title":"<code>ChannelDifference</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Channel difference calculation operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ChannelDifference(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Channel difference calculation operation\"\"\"\n\n    name = \"channel_difference\"\n    other_channel: int\n\n    def __init__(self, sampling_rate: float, other_channel: int = 0):\n        \"\"\"\n        Initialize channel difference calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other_channel : int\n            Channel to calculate difference with, default is 0\n        \"\"\"\n        self.other_channel = other_channel\n        super().__init__(sampling_rate, other_channel=other_channel)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"diff\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        result = data - data[self.other_channel]\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'channel_difference'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>other_channel = other_channel</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, other_channel=0)</code> \u00b6 <p>Initialize channel difference calculation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"diff\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    result = data - data[self.other_channel]\n    return result\n</code></pre>"},{"location":"api/#wandas.processing.stats.ChannelDifference.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other_channel : int     Channel to calculate difference with, default is 0</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, other_channel: int = 0):\n    \"\"\"\n    Initialize channel difference calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other_channel : int\n        Channel to calculate difference with, default is 0\n    \"\"\"\n    self.other_channel = other_channel\n    super().__init__(sampling_rate, other_channel=other_channel)\n</code></pre>"},{"location":"api/#wandas.processing.stats-functions","title":"Functions","text":""},{"location":"api/#wandas.processing.temporal","title":"<code>temporal</code>","text":""},{"location":"api/#wandas.processing.temporal-attributes","title":"Attributes","text":""},{"location":"api/#wandas.processing.temporal.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.processing.temporal-classes","title":"Classes","text":""},{"location":"api/#wandas.processing.temporal.ReSampling","title":"<code>ReSampling</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Resampling operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class ReSampling(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Resampling operation\"\"\"\n\n    name = \"resampling\"\n\n    def __init__(self, sampling_rate: float, target_sr: float):\n        \"\"\"\n        Initialize resampling operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        target_sampling_rate : float\n            Target sampling rate (Hz)\n\n        Raises\n        ------\n        ValueError\n            If sampling_rate or target_sr is not positive\n        \"\"\"\n        validate_sampling_rate(sampling_rate, \"source sampling rate\")\n        validate_sampling_rate(target_sr, \"target sampling rate\")\n        super().__init__(sampling_rate, target_sr=target_sr)\n        self.target_sr = target_sr\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate to target sampling rate.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        Resampling always produces output at target_sr, regardless of input\n        sampling rate. All necessary parameters are provided at initialization.\n        \"\"\"\n        return {\"sampling_rate\": self.target_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after resampling\n        ratio = float(self.target_sr) / float(self.sampling_rate)\n        n_samples = int(np.ceil(input_shape[-1] * ratio))\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"rs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for resampling operation\"\"\"\n        logger.debug(f\"Applying resampling to array with shape: {x.shape}\")\n        result: NDArrayReal = librosa.resample(\n            x, orig_sr=self.sampling_rate, target_sr=self.target_sr\n        )\n        logger.debug(f\"Resampling applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'resampling'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>target_sr = target_sr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, target_sr)</code> \u00b6 <p>Initialize resampling operation</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Update sampling rate to target sampling rate.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"rs\"\n</code></pre>"},{"location":"api/#wandas.processing.temporal.ReSampling.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) target_sampling_rate : float     Target sampling rate (Hz)</p>"},{"location":"api/#wandas.processing.temporal.ReSampling.__init__--raises","title":"Raises","text":"<p>ValueError     If sampling_rate or target_sr is not positive</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(self, sampling_rate: float, target_sr: float):\n    \"\"\"\n    Initialize resampling operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    target_sampling_rate : float\n        Target sampling rate (Hz)\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate or target_sr is not positive\n    \"\"\"\n    validate_sampling_rate(sampling_rate, \"source sampling rate\")\n    validate_sampling_rate(target_sr, \"target sampling rate\")\n    super().__init__(sampling_rate, target_sr=target_sr)\n    self.target_sr = target_sr\n</code></pre>"},{"location":"api/#wandas.processing.temporal.ReSampling.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate</p>"},{"location":"api/#wandas.processing.temporal.ReSampling.get_metadata_updates--notes","title":"Notes","text":"<p>Resampling always produces output at target_sr, regardless of input sampling rate. All necessary parameters are provided at initialization.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate to target sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    Resampling always produces output at target_sr, regardless of input\n    sampling rate. All necessary parameters are provided at initialization.\n    \"\"\"\n    return {\"sampling_rate\": self.target_sr}\n</code></pre>"},{"location":"api/#wandas.processing.temporal.ReSampling.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.temporal.ReSampling.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after resampling\n    ratio = float(self.target_sr) / float(self.sampling_rate)\n    n_samples = int(np.ceil(input_shape[-1] * ratio))\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/#wandas.processing.temporal.Trim","title":"<code>Trim</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Trimming operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class Trim(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Trimming operation\"\"\"\n\n    name = \"trim\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        start: float,\n        end: float,\n    ):\n        \"\"\"\n        Initialize trimming operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        start : float\n            Start time for trimming (seconds)\n        end : float\n            End time for trimming (seconds)\n        \"\"\"\n        super().__init__(sampling_rate, start=start, end=end)\n        self.start = start\n        self.end = end\n        self.start_sample = int(start * sampling_rate)\n        self.end_sample = int(end * sampling_rate)\n        logger.debug(\n            f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after trimming\n        # Exclude parts where there is no signal\n        end_sample = min(self.end_sample, input_shape[-1])\n        n_samples = end_sample - self.start_sample\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"trim\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for trimming operation\"\"\"\n        logger.debug(f\"Applying trim to array with shape: {x.shape}\")\n        # Apply trimming\n        result = x[..., self.start_sample : self.end_sample]\n        logger.debug(f\"Trim applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'trim'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>start = start</code> <code>instance-attribute</code> \u00b6 <code></code> <code>end = end</code> <code>instance-attribute</code> \u00b6 <code></code> <code>start_sample = int(start * sampling_rate)</code> <code>instance-attribute</code> \u00b6 <code></code> <code>end_sample = int(end * sampling_rate)</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, start, end)</code> \u00b6 <p>Initialize trimming operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"trim\"\n</code></pre>"},{"location":"api/#wandas.processing.temporal.Trim.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) start : float     Start time for trimming (seconds) end : float     End time for trimming (seconds)</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    start: float,\n    end: float,\n):\n    \"\"\"\n    Initialize trimming operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    start : float\n        Start time for trimming (seconds)\n    end : float\n        End time for trimming (seconds)\n    \"\"\"\n    super().__init__(sampling_rate, start=start, end=end)\n    self.start = start\n    self.end = end\n    self.start_sample = int(start * sampling_rate)\n    self.end_sample = int(end * sampling_rate)\n    logger.debug(\n        f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n    )\n</code></pre>"},{"location":"api/#wandas.processing.temporal.Trim.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.temporal.Trim.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after trimming\n    # Exclude parts where there is no signal\n    end_sample = min(self.end_sample, input_shape[-1])\n    n_samples = end_sample - self.start_sample\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/#wandas.processing.temporal.FixLength","title":"<code>FixLength</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>\u4fe1\u53f7\u306e\u9577\u3055\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u8abf\u6574\u3059\u308b\u64cd\u4f5c</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class FixLength(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\u4fe1\u53f7\u306e\u9577\u3055\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u8abf\u6574\u3059\u308b\u64cd\u4f5c\"\"\"\n\n    name = \"fix_length\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        length: int | None = None,\n        duration: float | None = None,\n    ):\n        \"\"\"\n        Initialize fix length operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        length : Optional[int]\n            Target length for fixing\n        duration : Optional[float]\n            Target length for fixing\n        \"\"\"\n        if length is None:\n            if duration is None:\n                raise ValueError(\"Either length or duration must be provided.\")\n            else:\n                length = int(duration * sampling_rate)\n        self.target_length = length\n\n        super().__init__(sampling_rate, target_length=self.target_length)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        return (*input_shape[:-1], self.target_length)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"fix\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for padding operation\"\"\"\n        logger.debug(f\"Applying padding to array with shape: {x.shape}\")\n        # Apply padding\n        pad_width = self.target_length - x.shape[-1]\n        if pad_width &gt; 0:\n            result = np.pad(x, ((0, 0), (0, pad_width)), mode=\"constant\")\n        else:\n            result = x[..., : self.target_length]\n        logger.debug(f\"Padding applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'fix_length'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>target_length = length</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, length=None, duration=None)</code> \u00b6 <p>Initialize fix length operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fix\"\n</code></pre>"},{"location":"api/#wandas.processing.temporal.FixLength.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) length : Optional[int]     Target length for fixing duration : Optional[float]     Target length for fixing</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    length: int | None = None,\n    duration: float | None = None,\n):\n    \"\"\"\n    Initialize fix length operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    length : Optional[int]\n        Target length for fixing\n    duration : Optional[float]\n        Target length for fixing\n    \"\"\"\n    if length is None:\n        if duration is None:\n            raise ValueError(\"Either length or duration must be provided.\")\n        else:\n            length = int(duration * sampling_rate)\n    self.target_length = length\n\n    super().__init__(sampling_rate, target_length=self.target_length)\n</code></pre>"},{"location":"api/#wandas.processing.temporal.FixLength.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/#wandas.processing.temporal.FixLength.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    return (*input_shape[:-1], self.target_length)\n</code></pre>"},{"location":"api/#wandas.processing.temporal.RmsTrend","title":"<code>RmsTrend</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class RmsTrend(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"RMS calculation\"\"\"\n\n    name = \"rms_trend\"\n    frame_length: int\n    hop_length: int\n    Aw: bool\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        ref: list[float] | float = 1.0,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; None:\n        \"\"\"\n        Initialize RMS calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        frame_length : int\n            Frame length, default is 2048\n        hop_length : int\n            Hop length, default is 512\n        ref : Union[list[float], float]\n            Reference value(s) for dB calculation\n        dB : bool\n            Whether to convert to decibels\n        Aw : bool\n            Whether to apply A-weighting before RMS calculation\n        \"\"\"\n        self.frame_length = frame_length\n        self.hop_length = hop_length\n        self.dB = dB\n        self.Aw = Aw\n        self.ref = np.array(ref if isinstance(ref, list) else [ref])\n        super().__init__(\n            sampling_rate,\n            frame_length=frame_length,\n            hop_length=hop_length,\n            dB=dB,\n            Aw=Aw,\n            ref=self.ref,\n        )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on hop length.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate based on hop length\n\n        Notes\n        -----\n        The output sampling rate is determined by downsampling the input\n        by hop_length. All necessary parameters are provided at initialization.\n        \"\"\"\n        new_sr = self.sampling_rate / self.hop_length\n        return {\"sampling_rate\": new_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, frames)\n        \"\"\"\n        n_frames = librosa.feature.rms(\n            y=np.ones((1, input_shape[-1])),\n            frame_length=self.frame_length,\n            hop_length=self.hop_length,\n        ).shape[-1]\n        return (*input_shape[:-1], n_frames)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"RMS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for RMS calculation\"\"\"\n        logger.debug(f\"Applying RMS to array with shape: {x.shape}\")\n\n        if self.Aw:\n            # Apply A-weighting\n            _x = A_weight(x, self.sampling_rate)\n            if isinstance(_x, np.ndarray):\n                # A_weight\u304c\u30bf\u30d7\u30eb\u3092\u8fd4\u3059\u5834\u5408\u3001\u6700\u521d\u306e\u8981\u7d20\u3092\u4f7f\u7528\n                x = _x\n            elif isinstance(_x, tuple):\n                # Use the first element if A_weight returns a tuple\n                x = _x[0]\n            else:\n                raise ValueError(\"A_weighting returned an unexpected type.\")\n\n        # Calculate RMS\n        result: NDArrayReal = librosa.feature.rms(\n            y=x, frame_length=self.frame_length, hop_length=self.hop_length\n        )[..., 0, :]\n\n        if self.dB:\n            # Convert to dB\n            result = 20 * np.log10(\n                np.maximum(result / self.ref[..., np.newaxis], 1e-12)\n            )\n        #\n        logger.debug(f\"RMS applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'rms_trend'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>frame_length = frame_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>dB = dB</code> <code>instance-attribute</code> \u00b6 <code></code> <code>Aw = Aw</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ref = np.array(ref if isinstance(ref, list) else [ref])</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, frame_length=2048, hop_length=512, ref=1.0, dB=False, Aw=False)</code> \u00b6 <p>Initialize RMS calculation</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Update sampling rate based on hop length.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"RMS\"\n</code></pre>"},{"location":"api/#wandas.processing.temporal.RmsTrend.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) frame_length : int     Frame length, default is 2048 hop_length : int     Hop length, default is 512 ref : Union[list[float], float]     Reference value(s) for dB calculation dB : bool     Whether to convert to decibels Aw : bool     Whether to apply A-weighting before RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    ref: list[float] | float = 1.0,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; None:\n    \"\"\"\n    Initialize RMS calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    frame_length : int\n        Frame length, default is 2048\n    hop_length : int\n        Hop length, default is 512\n    ref : Union[list[float], float]\n        Reference value(s) for dB calculation\n    dB : bool\n        Whether to convert to decibels\n    Aw : bool\n        Whether to apply A-weighting before RMS calculation\n    \"\"\"\n    self.frame_length = frame_length\n    self.hop_length = hop_length\n    self.dB = dB\n    self.Aw = Aw\n    self.ref = np.array(ref if isinstance(ref, list) else [ref])\n    super().__init__(\n        sampling_rate,\n        frame_length=frame_length,\n        hop_length=hop_length,\n        dB=dB,\n        Aw=Aw,\n        ref=self.ref,\n    )\n</code></pre>"},{"location":"api/#wandas.processing.temporal.RmsTrend.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate based on hop length</p>"},{"location":"api/#wandas.processing.temporal.RmsTrend.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is determined by downsampling the input by hop_length. All necessary parameters are provided at initialization.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on hop length.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate based on hop length\n\n    Notes\n    -----\n    The output sampling rate is determined by downsampling the input\n    by hop_length. All necessary parameters are provided at initialization.\n    \"\"\"\n    new_sr = self.sampling_rate / self.hop_length\n    return {\"sampling_rate\": new_sr}\n</code></pre>"},{"location":"api/#wandas.processing.temporal.RmsTrend.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/#wandas.processing.temporal.RmsTrend.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, frames)</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, frames)\n    \"\"\"\n    n_frames = librosa.feature.rms(\n        y=np.ones((1, input_shape[-1])),\n        frame_length=self.frame_length,\n        hop_length=self.hop_length,\n    ).shape[-1]\n    return (*input_shape[:-1], n_frames)\n</code></pre>"},{"location":"api/#wandas.processing.temporal-functions","title":"Functions","text":""},{"location":"api/#_4","title":"\u5165\u51fa\u529b\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u5165\u51fa\u529b\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u66f8\u304d\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.io","title":"<code>wandas.io</code>","text":""},{"location":"api/#wandas.io-attributes","title":"Attributes","text":""},{"location":"api/#wandas.io.__all__","title":"<code>__all__ = ['read_wav', 'write_wav', 'load', 'save']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.io-functions","title":"Functions","text":""},{"location":"api/#wandas.io.read_wav","title":"<code>read_wav(filename, labels=None)</code>","text":"<p>Read a WAV file and create a ChannelFrame object.</p>"},{"location":"api/#wandas.io.read_wav--parameters","title":"Parameters","text":"<p>filename : str     Path to the WAV file or URL to the WAV file. labels : list of str, optional     Labels for each channel.</p>"},{"location":"api/#wandas.io.read_wav--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the audio data.</p> Source code in <code>wandas/io/wav_io.py</code> <pre><code>def read_wav(filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Read a WAV file and create a ChannelFrame object.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file or URL to the WAV file.\n    labels : list of str, optional\n        Labels for each channel.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the audio data.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304cURL\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\n    if filename.startswith(\"http://\") or filename.startswith(\"https://\"):\n        # URL\u306e\u5834\u5408\u3001requests\u3092\u4f7f\u7528\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n        response = requests.get(filename)\n        file_obj = io.BytesIO(response.content)\n        file_label = os.path.basename(filename)\n        # \u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u306f\u4f7f\u7528\u305b\u305a\u306b\u8aad\u307f\u8fbc\u3080\n        sampling_rate, data = wavfile.read(file_obj)\n    else:\n        # \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u5834\u5408\n        file_label = os.path.basename(filename)\n        # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\uff08\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4f7f\u7528\uff09\n        sampling_rate, data = wavfile.read(filename, mmap=True)\n\n    # \u30c7\u30fc\u30bf\u3092(num_channels, num_samples)\u5f62\u72b6\u306eNumPy\u914d\u5217\u306b\u5909\u63db\n    if data.ndim == 1:\n        # \u30e2\u30ce\u30e9\u30eb\uff1a(samples,) -&gt; (1, samples)\n        data = np.expand_dims(data, axis=0)\n    else:\n        # \u30b9\u30c6\u30ec\u30aa\uff1a(samples, channels) -&gt; (channels, samples)\n        data = data.T\n\n    # NumPy\u914d\u5217\u304b\u3089ChannelFrame\u3092\u4f5c\u6210\n    channel_frame = ChannelFrame.from_numpy(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=file_label,\n        ch_labels=labels,\n    )\n\n    return channel_frame\n</code></pre>"},{"location":"api/#wandas.io.write_wav","title":"<code>write_wav(filename, target, format=None)</code>","text":"<p>Write a ChannelFrame object to a WAV file.</p>"},{"location":"api/#wandas.io.write_wav--parameters","title":"Parameters","text":"<p>filename : str     Path to the WAV file. target : ChannelFrame     ChannelFrame object containing the data to write. format : str, optional     File format. If None, determined from file extension.</p>"},{"location":"api/#wandas.io.write_wav--raises","title":"Raises","text":"<p>ValueError     If target is not a ChannelFrame object.</p> Source code in <code>wandas/io/wav_io.py</code> <pre><code>def write_wav(filename: str, target: \"ChannelFrame\", format: str | None = None) -&gt; None:\n    \"\"\"\n    Write a ChannelFrame object to a WAV file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file.\n    target : ChannelFrame\n        ChannelFrame object containing the data to write.\n    format : str, optional\n        File format. If None, determined from file extension.\n\n    Raises\n    ------\n    ValueError\n        If target is not a ChannelFrame object.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    if not isinstance(target, ChannelFrame):\n        raise ValueError(\"target must be a ChannelFrame object.\")\n\n    logger.debug(f\"Saving audio data to file: {filename} (will compute now)\")\n    data = target.compute()\n    data = data.T\n    if data.shape[1] == 1:\n        data = data.squeeze(axis=1)\n    if data.dtype == float and max([np.abs(data.max()), np.abs(data.min())]) &lt; 1:\n        sf.write(\n            str(filename),\n            data,\n            int(target.sampling_rate),\n            subtype=\"FLOAT\",\n            format=format,\n        )\n    else:\n        sf.write(str(filename), data, int(target.sampling_rate), format=format)\n    logger.debug(f\"Save complete: {filename}\")\n</code></pre>"},{"location":"api/#wandas.io.load","title":"<code>load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> required <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"api/#wandas.io.save","title":"<code>save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> required <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"api/#wandas.io-modules","title":"Modules","text":""},{"location":"api/#wandas.io.readers","title":"<code>readers</code>","text":""},{"location":"api/#wandas.io.readers-attributes","title":"Attributes","text":""},{"location":"api/#wandas.io.readers.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.io.readers-classes","title":"Classes","text":""},{"location":"api/#wandas.io.readers.CSVFileInfoParams","title":"<code>CSVFileInfoParams</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for CSV file reader parameters in get_file_info.</p>"},{"location":"api/#wandas.io.readers.CSVFileInfoParams--parameters","title":"Parameters","text":"<p>delimiter : str     Delimiter character. Default is \",\". header : Optional[int]     Row number to use as header. Default is 0 (first row).     Set to None if no header. time_column : Union[int, str]     Index or name of the time column. Default is 0.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class CSVFileInfoParams(TypedDict, total=False):\n    \"\"\"Type definition for CSV file reader parameters in get_file_info.\n\n    Parameters\n    ----------\n    delimiter : str\n        Delimiter character. Default is \",\".\n    header : Optional[int]\n        Row number to use as header. Default is 0 (first row).\n        Set to None if no header.\n    time_column : Union[int, str]\n        Index or name of the time column. Default is 0.\n    \"\"\"\n\n    delimiter: str\n    header: int | None\n    time_column: int | str\n</code></pre> Attributes\u00b6 <code></code> <code>delimiter</code> <code>instance-attribute</code> \u00b6 <code></code> <code>header</code> <code>instance-attribute</code> \u00b6 <code></code> <code>time_column</code> <code>instance-attribute</code> \u00b6"},{"location":"api/#wandas.io.readers.CSVGetDataParams","title":"<code>CSVGetDataParams</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for CSV file reader parameters in get_data.</p>"},{"location":"api/#wandas.io.readers.CSVGetDataParams--parameters","title":"Parameters","text":"<p>delimiter : str     Delimiter character. Default is \",\". header : Optional[int]     Row number to use as header. Default is 0. time_column : Union[int, str]     Index or name of the time column. Default is 0.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class CSVGetDataParams(TypedDict, total=False):\n    \"\"\"Type definition for CSV file reader parameters in get_data.\n\n    Parameters\n    ----------\n    delimiter : str\n        Delimiter character. Default is \",\".\n    header : Optional[int]\n        Row number to use as header. Default is 0.\n    time_column : Union[int, str]\n        Index or name of the time column. Default is 0.\n    \"\"\"\n\n    delimiter: str\n    header: int | None\n    time_column: int | str\n</code></pre> Attributes\u00b6 <code></code> <code>delimiter</code> <code>instance-attribute</code> \u00b6 <code></code> <code>header</code> <code>instance-attribute</code> \u00b6 <code></code> <code>time_column</code> <code>instance-attribute</code> \u00b6"},{"location":"api/#wandas.io.readers.FileReader","title":"<code>FileReader</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for audio file readers.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class FileReader(ABC):\n    \"\"\"Base class for audio file readers.\"\"\"\n\n    # Class attribute for supported file extensions\n    supported_extensions: list[str] = []\n\n    @classmethod\n    @abstractmethod\n    def get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the audio file.\n\n        Args:\n            path: Path to the file.\n            **kwargs: Additional parameters specific to the file reader.\n\n        Returns:\n            Dictionary containing file information including:\n            - samplerate: Sampling rate in Hz\n            - channels: Number of channels\n            - frames: Total number of frames\n            - format: File format\n            - duration: Duration in seconds\n        \"\"\"\n        pass\n\n    @classmethod\n    @abstractmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read audio data from the file.\n\n        Args:\n            path: Path to the file.\n            channels: List of channel indices to read.\n            start_idx: Starting frame index.\n            frames: Number of frames to read.\n            **kwargs: Additional parameters specific to the file reader.\n\n        Returns:\n            Array of shape (channels, frames) containing the audio data.\n        \"\"\"\n        pass\n\n    @classmethod\n    def can_read(cls, path: str | Path) -&gt; bool:\n        \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n        ext = Path(path).suffix.lower()\n        return ext in cls.supported_extensions\n</code></pre> Attributes\u00b6 <code></code> <code>supported_extensions = []</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_file_info(path, **kwargs)</code> <code>abstractmethod</code> <code>classmethod</code> \u00b6 <p>Get basic information about the audio file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the file.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing file information including:</p> <code>dict[str, Any]</code> <ul> <li>samplerate: Sampling rate in Hz</li> </ul> <code>dict[str, Any]</code> <ul> <li>channels: Number of channels</li> </ul> <code>dict[str, Any]</code> <ul> <li>frames: Total number of frames</li> </ul> <code>dict[str, Any]</code> <ul> <li>format: File format</li> </ul> <code>dict[str, Any]</code> <ul> <li>duration: Duration in seconds</li> </ul> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\n\n    Args:\n        path: Path to the file.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Dictionary containing file information including:\n        - samplerate: Sampling rate in Hz\n        - channels: Number of channels\n        - frames: Total number of frames\n        - format: File format\n        - duration: Duration in seconds\n    \"\"\"\n    pass\n</code></pre> <code></code> <code>get_data(path, channels, start_idx, frames, **kwargs)</code> <code>abstractmethod</code> <code>classmethod</code> \u00b6 <p>Read audio data from the file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the file.</p> required <code>channels</code> <code>list[int]</code> <p>List of channel indices to read.</p> required <code>start_idx</code> <code>int</code> <p>Starting frame index.</p> required <code>frames</code> <code>int</code> <p>Number of frames to read.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ArrayLike</code> <p>Array of shape (channels, frames) containing the audio data.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\n\n    Args:\n        path: Path to the file.\n        channels: List of channel indices to read.\n        start_idx: Starting frame index.\n        frames: Number of frames to read.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Array of shape (channels, frames) containing the audio data.\n    \"\"\"\n    pass\n</code></pre> <code></code> <code>can_read(path)</code> <code>classmethod</code> \u00b6 <p>Check if this reader can handle the file based on extension.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef can_read(cls, path: str | Path) -&gt; bool:\n    \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n    ext = Path(path).suffix.lower()\n    return ext in cls.supported_extensions\n</code></pre>"},{"location":"api/#wandas.io.readers.SoundFileReader","title":"<code>SoundFileReader</code>","text":"<p>               Bases: <code>FileReader</code></p> <p>Audio file reader using SoundFile library.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class SoundFileReader(FileReader):\n    \"\"\"Audio file reader using SoundFile library.\"\"\"\n\n    # SoundFile supported formats\n    supported_extensions = [\".wav\", \".flac\", \".ogg\", \".aiff\", \".aif\", \".snd\"]\n\n    @classmethod\n    def get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the audio file.\"\"\"\n        info = sf.info(str(path))\n        return {\n            \"samplerate\": info.samplerate,\n            \"channels\": info.channels,\n            \"frames\": info.frames,\n            \"format\": info.format,\n            \"subtype\": info.subtype,\n            \"duration\": info.frames / info.samplerate,\n        }\n\n    @classmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read audio data from the file.\"\"\"\n        logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n        with sf.SoundFile(str(path)) as f:\n            if start_idx &gt; 0:\n                f.seek(start_idx)\n            data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n            # Select requested channels\n            if len(channels) &lt; f.channels:\n                data = data[:, channels]\n\n            # Transpose to get (channels, samples) format\n            result: ArrayLike = data.T\n            if not isinstance(result, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n\n        _shape = result.shape\n        logger.debug(f\"File read complete, returning data with shape {_shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>supported_extensions = ['.wav', '.flac', '.ogg', '.aiff', '.aif', '.snd']</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_file_info(path, **kwargs)</code> <code>classmethod</code> \u00b6 <p>Get basic information about the audio file.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\"\"\"\n    info = sf.info(str(path))\n    return {\n        \"samplerate\": info.samplerate,\n        \"channels\": info.channels,\n        \"frames\": info.frames,\n        \"format\": info.format,\n        \"subtype\": info.subtype,\n        \"duration\": info.frames / info.samplerate,\n    }\n</code></pre> <code></code> <code>get_data(path, channels, start_idx, frames, **kwargs)</code> <code>classmethod</code> \u00b6 <p>Read audio data from the file.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\"\"\"\n    logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n    with sf.SoundFile(str(path)) as f:\n        if start_idx &gt; 0:\n            f.seek(start_idx)\n        data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n        # Select requested channels\n        if len(channels) &lt; f.channels:\n            data = data[:, channels]\n\n        # Transpose to get (channels, samples) format\n        result: ArrayLike = data.T\n        if not isinstance(result, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"File read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"api/#wandas.io.readers.CSVFileReader","title":"<code>CSVFileReader</code>","text":"<p>               Bases: <code>FileReader</code></p> <p>CSV file reader for time series data.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class CSVFileReader(FileReader):\n    \"\"\"CSV file reader for time series data.\"\"\"\n\n    # CSV supported formats\n    supported_extensions = [\".csv\"]\n\n    @classmethod\n    def get_file_info(\n        cls,\n        path: str | Path,\n        **kwargs: Any,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the CSV file.\n\n        Parameters\n        ----------\n        path : Union[str, Path]\n            Path to the CSV file.\n        **kwargs : Any\n            Additional parameters for CSV reading. Supported parameters:\n\n            - delimiter : str, default=\",\"\n                Delimiter character.\n            - header : Optional[int], default=0\n                Row number to use as header. Set to None if no header.\n            - time_column : Union[int, str], default=0\n                Index or name of the time column.\n\n        Returns\n        -------\n        dict[str, Any]\n            Dictionary containing file information including:\n            - samplerate: Estimated sampling rate in Hz\n            - channels: Number of data channels (excluding time column)\n            - frames: Total number of frames\n            - format: \"CSV\"\n            - duration: Duration in seconds (or None if cannot be calculated)\n            - ch_labels: List of channel labels\n\n        Notes\n        -----\n        This method accepts CSV-specific parameters through kwargs.\n        See CSVFileInfoParams for supported parameter types.\n        \"\"\"\n        # Extract parameters with defaults\n        delimiter: str = kwargs.get(\"delimiter\", \",\")\n        header: int | None = kwargs.get(\"header\", 0)\n        time_column: int | str = kwargs.get(\"time_column\", 0)\n\n        # Read first few lines to determine structure\n        df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n        # Estimate sampling rate from first column (assuming it's time)\n        try:\n            # Get time column as Series\n            if isinstance(time_column, str):\n                time_series = df[time_column]\n            else:\n                time_series = df.iloc[:, time_column]\n            time_values = np.array(time_series.values)\n            if len(time_values) &gt; 1:\n                # Use round() instead of int() to handle floating-point precision issues\n                estimated_sr = round(1 / np.mean(np.diff(time_values)))\n            else:\n                estimated_sr = 0  # Cannot determine from single row\n        except Exception:\n            estimated_sr = 0  # Default if can't calculate\n\n        frames = df.shape[0]\n        duration = frames / estimated_sr if estimated_sr &gt; 0 else None\n\n        # Return file info\n        return {\n            \"samplerate\": estimated_sr,\n            \"channels\": df.shape[1] - 1,  # Assuming first column is time\n            \"frames\": frames,\n            \"format\": \"CSV\",\n            \"duration\": duration,\n            \"ch_labels\": df.columns[1:].tolist(),  # Assuming first column is time\n        }\n\n    @classmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read data from the CSV file.\n\n        Parameters\n        ----------\n        path : Union[str, Path]\n            Path to the CSV file.\n        channels : list[int]\n            List of channel indices to read.\n        start_idx : int\n            Starting frame index.\n        frames : int\n            Number of frames to read.\n        **kwargs : Any\n            Additional parameters for CSV reading. Supported parameters:\n\n            - delimiter : str, default=\",\"\n                Delimiter character.\n            - header : Optional[int], default=0\n                Row number to use as header.\n            - time_column : Union[int, str], default=0\n                Index or name of the time column.\n\n        Returns\n        -------\n        ArrayLike\n            Array of shape (channels, frames) containing the data.\n\n        Notes\n        -----\n        This method accepts CSV-specific parameters through kwargs.\n        See CSVGetDataParams for supported parameter types.\n        \"\"\"\n        # Extract parameters with defaults\n        time_column: int | str = kwargs.get(\"time_column\", 0)\n        delimiter: str = kwargs.get(\"delimiter\", \",\")\n        header: int | None = kwargs.get(\"header\", 0)\n\n        logger.debug(f\"Reading CSV data from {path} starting at {start_idx}\")\n\n        # Read the CSV file\n        df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n        # Remove time column\n        df = df.drop(\n            columns=[time_column]\n            if isinstance(time_column, str)\n            else df.columns[time_column]\n        )\n\n        # Select requested channels - adjust indices to account for time column removal\n        if channels:\n            try:\n                data_df = df.iloc[:, channels]\n            except IndexError:\n                raise ValueError(f\"Requested channels {channels} out of range\")\n        else:\n            data_df = df\n\n        # Handle start_idx and frames for partial reading\n        end_idx = start_idx + frames if frames &gt; 0 else None\n        data_df = data_df.iloc[start_idx:end_idx]\n\n        # Convert to numpy array and transpose to (channels, samples) format\n        result = data_df.values.T\n\n        if not isinstance(result, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n\n        _shape = result.shape\n        logger.debug(f\"CSV read complete, returning data with shape {_shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>supported_extensions = ['.csv']</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_file_info(path, **kwargs)</code> <code>classmethod</code> \u00b6 <p>Get basic information about the CSV file.</p> <code></code> <code>get_data(path, channels, start_idx, frames, **kwargs)</code> <code>classmethod</code> \u00b6 <p>Read data from the CSV file.</p>"},{"location":"api/#wandas.io.readers.CSVFileReader.get_file_info--parameters","title":"Parameters","text":"<p>path : Union[str, Path]     Path to the CSV file. **kwargs : Any     Additional parameters for CSV reading. Supported parameters:</p> <pre><code>- delimiter : str, default=\",\"\n    Delimiter character.\n- header : Optional[int], default=0\n    Row number to use as header. Set to None if no header.\n- time_column : Union[int, str], default=0\n    Index or name of the time column.\n</code></pre>"},{"location":"api/#wandas.io.readers.CSVFileReader.get_file_info--returns","title":"Returns","text":"<p>dict[str, Any]     Dictionary containing file information including:     - samplerate: Estimated sampling rate in Hz     - channels: Number of data channels (excluding time column)     - frames: Total number of frames     - format: \"CSV\"     - duration: Duration in seconds (or None if cannot be calculated)     - ch_labels: List of channel labels</p>"},{"location":"api/#wandas.io.readers.CSVFileReader.get_file_info--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVFileInfoParams for supported parameter types.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(\n    cls,\n    path: str | Path,\n    **kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header. Set to None if no header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing file information including:\n        - samplerate: Estimated sampling rate in Hz\n        - channels: Number of data channels (excluding time column)\n        - frames: Total number of frames\n        - format: \"CSV\"\n        - duration: Duration in seconds (or None if cannot be calculated)\n        - ch_labels: List of channel labels\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVFileInfoParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n\n    # Read first few lines to determine structure\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Estimate sampling rate from first column (assuming it's time)\n    try:\n        # Get time column as Series\n        if isinstance(time_column, str):\n            time_series = df[time_column]\n        else:\n            time_series = df.iloc[:, time_column]\n        time_values = np.array(time_series.values)\n        if len(time_values) &gt; 1:\n            # Use round() instead of int() to handle floating-point precision issues\n            estimated_sr = round(1 / np.mean(np.diff(time_values)))\n        else:\n            estimated_sr = 0  # Cannot determine from single row\n    except Exception:\n        estimated_sr = 0  # Default if can't calculate\n\n    frames = df.shape[0]\n    duration = frames / estimated_sr if estimated_sr &gt; 0 else None\n\n    # Return file info\n    return {\n        \"samplerate\": estimated_sr,\n        \"channels\": df.shape[1] - 1,  # Assuming first column is time\n        \"frames\": frames,\n        \"format\": \"CSV\",\n        \"duration\": duration,\n        \"ch_labels\": df.columns[1:].tolist(),  # Assuming first column is time\n    }\n</code></pre>"},{"location":"api/#wandas.io.readers.CSVFileReader.get_data--parameters","title":"Parameters","text":"<p>path : Union[str, Path]     Path to the CSV file. channels : list[int]     List of channel indices to read. start_idx : int     Starting frame index. frames : int     Number of frames to read. **kwargs : Any     Additional parameters for CSV reading. Supported parameters:</p> <pre><code>- delimiter : str, default=\",\"\n    Delimiter character.\n- header : Optional[int], default=0\n    Row number to use as header.\n- time_column : Union[int, str], default=0\n    Index or name of the time column.\n</code></pre>"},{"location":"api/#wandas.io.readers.CSVFileReader.get_data--returns","title":"Returns","text":"<p>ArrayLike     Array of shape (channels, frames) containing the data.</p>"},{"location":"api/#wandas.io.readers.CSVFileReader.get_data--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVGetDataParams for supported parameter types.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read data from the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    channels : list[int]\n        List of channel indices to read.\n    start_idx : int\n        Starting frame index.\n    frames : int\n        Number of frames to read.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    ArrayLike\n        Array of shape (channels, frames) containing the data.\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVGetDataParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n\n    logger.debug(f\"Reading CSV data from {path} starting at {start_idx}\")\n\n    # Read the CSV file\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Remove time column\n    df = df.drop(\n        columns=[time_column]\n        if isinstance(time_column, str)\n        else df.columns[time_column]\n    )\n\n    # Select requested channels - adjust indices to account for time column removal\n    if channels:\n        try:\n            data_df = df.iloc[:, channels]\n        except IndexError:\n            raise ValueError(f\"Requested channels {channels} out of range\")\n    else:\n        data_df = df\n\n    # Handle start_idx and frames for partial reading\n    end_idx = start_idx + frames if frames &gt; 0 else None\n    data_df = data_df.iloc[start_idx:end_idx]\n\n    # Convert to numpy array and transpose to (channels, samples) format\n    result = data_df.values.T\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"CSV read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"api/#wandas.io.readers-functions","title":"Functions","text":""},{"location":"api/#wandas.io.readers.get_file_reader","title":"<code>get_file_reader(path)</code>","text":"<p>Get an appropriate file reader for the given path.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>def get_file_reader(path: str | Path) -&gt; FileReader:\n    \"\"\"Get an appropriate file reader for the given path.\"\"\"\n    path_str = str(path)\n    ext = Path(path).suffix.lower()\n\n    # Try each reader in order\n    for reader in _file_readers:\n        if ext in reader.__class__.supported_extensions:\n            logger.debug(f\"Using {reader.__class__.__name__} for {path_str}\")\n            return reader\n\n    # If no reader found, raise error\n    raise ValueError(f\"No suitable file reader found for {path_str}\")\n</code></pre>"},{"location":"api/#wandas.io.readers.register_file_reader","title":"<code>register_file_reader(reader_class)</code>","text":"<p>Register a new file reader.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>def register_file_reader(reader_class: type) -&gt; None:\n    \"\"\"Register a new file reader.\"\"\"\n    reader = reader_class()\n    _file_readers.append(reader)\n    logger.debug(f\"Registered new file reader: {reader_class.__name__}\")\n</code></pre>"},{"location":"api/#wandas.io.wav_io","title":"<code>wav_io</code>","text":""},{"location":"api/#wandas.io.wav_io-attributes","title":"Attributes","text":""},{"location":"api/#wandas.io.wav_io.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.io.wav_io-classes","title":"Classes","text":""},{"location":"api/#wandas.io.wav_io-functions","title":"Functions","text":""},{"location":"api/#wandas.io.wav_io.read_wav","title":"<code>read_wav(filename, labels=None)</code>","text":"<p>Read a WAV file and create a ChannelFrame object.</p>"},{"location":"api/#wandas.io.wav_io.read_wav--parameters","title":"Parameters","text":"<p>filename : str     Path to the WAV file or URL to the WAV file. labels : list of str, optional     Labels for each channel.</p>"},{"location":"api/#wandas.io.wav_io.read_wav--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the audio data.</p> Source code in <code>wandas/io/wav_io.py</code> <pre><code>def read_wav(filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Read a WAV file and create a ChannelFrame object.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file or URL to the WAV file.\n    labels : list of str, optional\n        Labels for each channel.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the audio data.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304cURL\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\n    if filename.startswith(\"http://\") or filename.startswith(\"https://\"):\n        # URL\u306e\u5834\u5408\u3001requests\u3092\u4f7f\u7528\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n        response = requests.get(filename)\n        file_obj = io.BytesIO(response.content)\n        file_label = os.path.basename(filename)\n        # \u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u306f\u4f7f\u7528\u305b\u305a\u306b\u8aad\u307f\u8fbc\u3080\n        sampling_rate, data = wavfile.read(file_obj)\n    else:\n        # \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u5834\u5408\n        file_label = os.path.basename(filename)\n        # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\uff08\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4f7f\u7528\uff09\n        sampling_rate, data = wavfile.read(filename, mmap=True)\n\n    # \u30c7\u30fc\u30bf\u3092(num_channels, num_samples)\u5f62\u72b6\u306eNumPy\u914d\u5217\u306b\u5909\u63db\n    if data.ndim == 1:\n        # \u30e2\u30ce\u30e9\u30eb\uff1a(samples,) -&gt; (1, samples)\n        data = np.expand_dims(data, axis=0)\n    else:\n        # \u30b9\u30c6\u30ec\u30aa\uff1a(samples, channels) -&gt; (channels, samples)\n        data = data.T\n\n    # NumPy\u914d\u5217\u304b\u3089ChannelFrame\u3092\u4f5c\u6210\n    channel_frame = ChannelFrame.from_numpy(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=file_label,\n        ch_labels=labels,\n    )\n\n    return channel_frame\n</code></pre>"},{"location":"api/#wandas.io.wav_io.write_wav","title":"<code>write_wav(filename, target, format=None)</code>","text":"<p>Write a ChannelFrame object to a WAV file.</p>"},{"location":"api/#wandas.io.wav_io.write_wav--parameters","title":"Parameters","text":"<p>filename : str     Path to the WAV file. target : ChannelFrame     ChannelFrame object containing the data to write. format : str, optional     File format. If None, determined from file extension.</p>"},{"location":"api/#wandas.io.wav_io.write_wav--raises","title":"Raises","text":"<p>ValueError     If target is not a ChannelFrame object.</p> Source code in <code>wandas/io/wav_io.py</code> <pre><code>def write_wav(filename: str, target: \"ChannelFrame\", format: str | None = None) -&gt; None:\n    \"\"\"\n    Write a ChannelFrame object to a WAV file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file.\n    target : ChannelFrame\n        ChannelFrame object containing the data to write.\n    format : str, optional\n        File format. If None, determined from file extension.\n\n    Raises\n    ------\n    ValueError\n        If target is not a ChannelFrame object.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    if not isinstance(target, ChannelFrame):\n        raise ValueError(\"target must be a ChannelFrame object.\")\n\n    logger.debug(f\"Saving audio data to file: {filename} (will compute now)\")\n    data = target.compute()\n    data = data.T\n    if data.shape[1] == 1:\n        data = data.squeeze(axis=1)\n    if data.dtype == float and max([np.abs(data.max()), np.abs(data.min())]) &lt; 1:\n        sf.write(\n            str(filename),\n            data,\n            int(target.sampling_rate),\n            subtype=\"FLOAT\",\n            format=format,\n        )\n    else:\n        sf.write(str(filename), data, int(target.sampling_rate), format=format)\n    logger.debug(f\"Save complete: {filename}\")\n</code></pre>"},{"location":"api/#wandas.io.wdf_io","title":"<code>wdf_io</code>","text":"<p>WDF (Wandas Data File) I/O module for saving and loading ChannelFrame objects.</p> <p>This module provides functionality to save and load ChannelFrame objects in the WDF (Wandas Data File) format, which is based on HDF5. The format preserves all metadata including sampling rate, channel labels, units, and frame metadata.</p>"},{"location":"api/#wandas.io.wdf_io-attributes","title":"Attributes","text":""},{"location":"api/#wandas.io.wdf_io.da_from_array","title":"<code>da_from_array = da.from_array</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.io.wdf_io.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.io.wdf_io.WDF_FORMAT_VERSION","title":"<code>WDF_FORMAT_VERSION = '0.1'</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.io.wdf_io-classes","title":"Classes","text":""},{"location":"api/#wandas.io.wdf_io-functions","title":"Functions","text":""},{"location":"api/#wandas.io.wdf_io.save","title":"<code>save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> required <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"api/#wandas.io.wdf_io.load","title":"<code>load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> required <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"api/#_5","title":"\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u88dc\u52a9\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.utils","title":"<code>wandas.utils</code>","text":""},{"location":"api/#wandas.utils-attributes","title":"Attributes","text":""},{"location":"api/#wandas.utils.__all__","title":"<code>__all__ = ['filter_kwargs', 'accepted_kwargs', 'validate_sampling_rate']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils-functions","title":"Functions","text":""},{"location":"api/#wandas.utils.accepted_kwargs","title":"<code>accepted_kwargs(func)</code>","text":"<p>Get the set of explicit keyword arguments accepted by a function and whether it accepts **kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The function to inspect.</p> required <p>Returns:</p> Type Description <code>set[str]</code> <p>A tuple containing:</p> <code>bool</code> <ul> <li>set[str]: Set of explicit keyword argument names accepted by func.</li> </ul> <code>tuple[set[str], bool]</code> <ul> <li>bool: Whether the function accepts variable keyword arguments (**kwargs).</li> </ul> Source code in <code>wandas/utils/introspection.py</code> <pre><code>def accepted_kwargs(func: Callable[..., Any]) -&gt; tuple[set[str], bool]:\n    \"\"\"\n    Get the set of explicit keyword arguments accepted by\n    a function and whether it accepts **kwargs.\n\n    Args:\n        func: The function to inspect.\n\n    Returns:\n        A tuple containing:\n        - set[str]: Set of explicit keyword argument names accepted by func.\n        - bool: Whether the function accepts variable keyword arguments (**kwargs).\n    \"\"\"\n    # \u30e2\u30c3\u30af\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n    if hasattr(func, \"__module__\") and func.__module__ == \"unittest.mock\":\n        return set(), True\n    try:\n        params = signature(func).parameters.values()\n\n        # \u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u5f15\u6570\u3092\u53ce\u96c6\n        explicit_kwargs = {\n            p.name\n            for p in params\n            if p.kind in (Parameter.POSITIONAL_OR_KEYWORD, Parameter.KEYWORD_ONLY)\n        }\n\n        # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\n        has_var_kwargs = any(p.kind is Parameter.VAR_KEYWORD for p in params)\n\n        return explicit_kwargs, has_var_kwargs\n    except (ValueError, TypeError):\n        # \u30b7\u30b0\u30cd\u30c1\u30e3\u3092\u53d6\u5f97\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n        return set(), True\n</code></pre>"},{"location":"api/#wandas.utils.filter_kwargs","title":"<code>filter_kwargs(func, kwargs, *, strict_mode=False)</code>","text":"<p>Filter keyword arguments to only those accepted by the function.</p> <p>This function examines the signature of <code>func</code> and returns a dictionary containing only the key-value pairs from <code>kwargs</code> that are valid keyword arguments for <code>func</code>.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The function to filter keyword arguments for.</p> required <code>kwargs</code> <code>Mapping[str, Any]</code> <p>The keyword arguments to filter.</p> required <code>strict_mode</code> <code>bool</code> <p>If True, only explicitly defined parameters are passed even when the function accepts kwargs. If False (default), all parameters are passed to functions that accept kwargs, but a warning is issued for parameters not explicitly defined.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary containing only the key-value pairs that are valid for <code>func</code>.</p> Source code in <code>wandas/utils/introspection.py</code> <pre><code>def filter_kwargs(\n    func: Callable[..., Any],\n    kwargs: Mapping[str, Any],\n    *,\n    strict_mode: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Filter keyword arguments to only those accepted by the function.\n\n    This function examines the signature of `func` and returns a dictionary\n    containing only the key-value pairs from `kwargs` that are valid keyword\n    arguments for `func`.\n\n    Args:\n        func: The function to filter keyword arguments for.\n        kwargs: The keyword arguments to filter.\n        strict_mode: If True, only explicitly defined parameters are passed even when\n            the function accepts **kwargs. If False (default), all parameters are\n            passed to functions that accept **kwargs, but a warning is issued for\n            parameters not explicitly defined.\n\n    Returns:\n        A dictionary containing only the key-value pairs that are valid for `func`.\n    \"\"\"\n    explicit_params, accepts_var_kwargs = accepted_kwargs(func)\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u306a\u3044\u5834\u5408\u3001\u307e\u305f\u306f strict_mode \u304c True \u306e\u5834\u5408\u306f\u3001\n    # \u660e\u793a\u7684\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n    if not accepts_var_kwargs or strict_mode:\n        filtered = {k: v for k, v in kwargs.items() if k in explicit_params}\n        return filtered\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u5834\u5408\uff08strict_mode\u304cFalse\u306e\u5834\u5408\uff09\u306f\u5168\u30ad\u30fc\u3092\u8a31\u53ef\n    # \u305f\u3060\u3057\u3001\u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u306a\u3044\u30ad\u30fc\u306b\u306f\u8b66\u544a\u3092\u51fa\u3059\n    unknown = set(kwargs) - explicit_params\n    if unknown:\n        warnings.warn(\n            f\"Implicit kwargs for {func.__name__}: {unknown}\",\n            UserWarning,\n            stacklevel=2,\n        )\n    return dict(kwargs)\n</code></pre>"},{"location":"api/#wandas.utils.validate_sampling_rate","title":"<code>validate_sampling_rate(sampling_rate, param_name='sampling_rate')</code>","text":"<p>Validate that sampling rate is positive.</p>"},{"location":"api/#wandas.utils.validate_sampling_rate--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz to validate. param_name : str, default=\"sampling_rate\"     Name of the parameter being validated (for error messages).</p>"},{"location":"api/#wandas.utils.validate_sampling_rate--raises","title":"Raises","text":"<p>ValueError     If sampling_rate is not positive (i.e., &lt;= 0).</p>"},{"location":"api/#wandas.utils.validate_sampling_rate--examples","title":"Examples","text":"<p>validate_sampling_rate(44100)  # No error validate_sampling_rate(0)  # Raises ValueError validate_sampling_rate(-100)  # Raises ValueError</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def validate_sampling_rate(\n    sampling_rate: float, param_name: str = \"sampling_rate\"\n) -&gt; None:\n    \"\"\"\n    Validate that sampling rate is positive.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz to validate.\n    param_name : str, default=\"sampling_rate\"\n        Name of the parameter being validated (for error messages).\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate is not positive (i.e., &lt;= 0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; validate_sampling_rate(44100)  # No error\n    &gt;&gt;&gt; validate_sampling_rate(0)  # Raises ValueError\n    &gt;&gt;&gt; validate_sampling_rate(-100)  # Raises ValueError\n    \"\"\"\n    if sampling_rate &lt;= 0:\n        raise ValueError(\n            f\"Invalid {param_name}\\n\"\n            f\"  Got: {sampling_rate} Hz\\n\"\n            f\"  Expected: Positive value &gt; 0\\n\"\n            f\"Sampling rate represents samples per second and must be positive.\\n\"\n            f\"Common values: 8000, 16000, 22050, 44100, 48000 Hz\"\n        )\n</code></pre>"},{"location":"api/#wandas.utils-modules","title":"Modules","text":""},{"location":"api/#wandas.utils.frame_dataset","title":"<code>frame_dataset</code>","text":""},{"location":"api/#wandas.utils.frame_dataset-attributes","title":"Attributes","text":""},{"location":"api/#wandas.utils.frame_dataset.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.frame_dataset.FrameType","title":"<code>FrameType = ChannelFrame | SpectrogramFrame</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.frame_dataset.F","title":"<code>F = TypeVar('F', bound=FrameType)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.frame_dataset.F_out","title":"<code>F_out = TypeVar('F_out', bound=FrameType)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.frame_dataset-classes","title":"Classes","text":""},{"location":"api/#wandas.utils.frame_dataset.LazyFrame","title":"<code>LazyFrame</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[F]</code></p> <p>A class that encapsulates a frame and its loading state.</p> <p>Attributes:</p> Name Type Description <code>file_path</code> <code>Path</code> <p>File path associated with the frame</p> <code>frame</code> <code>F | None</code> <p>Loaded frame object (None if not loaded)</p> <code>is_loaded</code> <code>bool</code> <p>Flag indicating if the frame is loaded</p> <code>load_attempted</code> <code>bool</code> <p>Flag indicating if loading was attempted (for error detection)</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>@dataclass\nclass LazyFrame(Generic[F]):\n    \"\"\"\n    A class that encapsulates a frame and its loading state.\n\n    Attributes:\n        file_path: File path associated with the frame\n        frame: Loaded frame object (None if not loaded)\n        is_loaded: Flag indicating if the frame is loaded\n        load_attempted: Flag indicating if loading was attempted (for error detection)\n    \"\"\"\n\n    file_path: Path\n    frame: F | None = None\n    is_loaded: bool = False\n    load_attempted: bool = False\n\n    def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n        \"\"\"\n        Ensures the frame is loaded, loading it if necessary.\n\n        Args:\n            loader: Function to load a frame from a file path\n\n        Returns:\n            The loaded frame, or None if loading failed\n        \"\"\"\n        # Return the current frame if already loaded\n        if self.is_loaded:\n            return self.frame\n\n        # Attempt to load if not loaded yet\n        try:\n            self.load_attempted = True\n            self.frame = loader(self.file_path)\n            self.is_loaded = True\n            return self.frame\n        except Exception as e:\n            logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n            self.is_loaded = True  # Loading was attempted\n            self.frame = None\n            return None\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the frame state.\n        \"\"\"\n        self.frame = None\n        self.is_loaded = False\n        self.load_attempted = False\n</code></pre> Attributes\u00b6 <code></code> <code>file_path</code> <code>instance-attribute</code> \u00b6 <code></code> <code>frame = None</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>is_loaded = False</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>load_attempted = False</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(file_path, frame=None, is_loaded=False, load_attempted=False)</code> \u00b6 <code></code> <code>ensure_loaded(loader)</code> \u00b6 <p>Ensures the frame is loaded, loading it if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>loader</code> <code>Callable[[Path], F | None]</code> <p>Function to load a frame from a file path</p> required <p>Returns:</p> Type Description <code>F | None</code> <p>The loaded frame, or None if loading failed</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n    \"\"\"\n    Ensures the frame is loaded, loading it if necessary.\n\n    Args:\n        loader: Function to load a frame from a file path\n\n    Returns:\n        The loaded frame, or None if loading failed\n    \"\"\"\n    # Return the current frame if already loaded\n    if self.is_loaded:\n        return self.frame\n\n    # Attempt to load if not loaded yet\n    try:\n        self.load_attempted = True\n        self.frame = loader(self.file_path)\n        self.is_loaded = True\n        return self.frame\n    except Exception as e:\n        logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n        self.is_loaded = True  # Loading was attempted\n        self.frame = None\n        return None\n</code></pre> <code></code> <code>reset()</code> \u00b6 <p>Reset the frame state.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the frame state.\n    \"\"\"\n    self.frame = None\n    self.is_loaded = False\n    self.load_attempted = False\n</code></pre>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset","title":"<code>FrameDataset</code>","text":"<p>               Bases: <code>Generic[F]</code>, <code>ABC</code></p> <p>Abstract base dataset class for processing files in a folder. Includes lazy loading capability to efficiently handle large datasets. Subclasses handle specific frame types (ChannelFrame, SpectrogramFrame, etc.).</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class FrameDataset(Generic[F], ABC):\n    \"\"\"\n    Abstract base dataset class for processing files in a folder.\n    Includes lazy loading capability to efficiently handle large datasets.\n    Subclasses handle specific frame types (ChannelFrame, SpectrogramFrame, etc.).\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], F | None] | None = None,\n    ):\n        self.folder_path = Path(folder_path)\n        if source_dataset is None and not self.folder_path.exists():\n            raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n        self.sampling_rate = sampling_rate\n        self.signal_length = signal_length\n        self.file_extensions = file_extensions or [\".wav\"]\n        self._recursive = recursive\n        self._lazy_loading = lazy_loading\n\n        # Changed to a list of LazyFrame\n        self._lazy_frames: list[LazyFrame[F]] = []\n\n        self._source_dataset = source_dataset\n        self._transform = transform\n\n        if self._source_dataset:\n            self._initialize_from_source()\n        else:\n            self._initialize_from_folder()\n\n    def _initialize_from_source(self) -&gt; None:\n        \"\"\"Initialize from a source dataset.\"\"\"\n        if self._source_dataset is None:\n            return\n\n        # Copy file paths from source\n        file_paths = self._source_dataset._get_file_paths()\n        self._lazy_frames = [LazyFrame(file_path) for file_path in file_paths]\n\n        # Inherit other properties\n        self.sampling_rate = self.sampling_rate or self._source_dataset.sampling_rate\n        self.signal_length = self.signal_length or self._source_dataset.signal_length\n        self.file_extensions = (\n            self.file_extensions or self._source_dataset.file_extensions\n        )\n        self._recursive = self._source_dataset._recursive\n        self.folder_path = self._source_dataset.folder_path\n\n    def _initialize_from_folder(self) -&gt; None:\n        \"\"\"Initialize from a folder.\"\"\"\n        self._discover_files()\n        if not self._lazy_loading:\n            self._load_all_files()\n\n    def _discover_files(self) -&gt; None:\n        \"\"\"Discover files in the folder and store them in a list of LazyFrame.\"\"\"\n        file_paths = []\n        for ext in self.file_extensions:\n            pattern = f\"**/*{ext}\" if self._recursive else f\"*{ext}\"\n            file_paths.extend(\n                sorted(p for p in self.folder_path.glob(pattern) if p.is_file())\n            )\n\n        # Remove duplicates and sort\n        file_paths = sorted(list(set(file_paths)))\n\n        # Create a list of LazyFrame\n        self._lazy_frames = [LazyFrame(file_path) for file_path in file_paths]\n\n    def _load_all_files(self) -&gt; None:\n        \"\"\"Load all files.\"\"\"\n        for i in tqdm(range(len(self._lazy_frames)), desc=\"Loading/transforming\"):\n            try:\n                self._ensure_loaded(i)\n            except Exception as e:\n                filepath = self._lazy_frames[i].file_path\n                logger.warning(\n                    f\"Failed to load/transform index {i} ({filepath}): {str(e)}\"\n                )\n        self._lazy_loading = False\n\n    @abstractmethod\n    def _load_file(self, file_path: Path) -&gt; F | None:\n        \"\"\"Abstract method to load a frame from a file.\"\"\"\n        pass\n\n    def _load_from_source(self, index: int) -&gt; F | None:\n        \"\"\"Load a frame from the source dataset and transform it if necessary.\"\"\"\n        if self._source_dataset is None or self._transform is None:\n            return None\n\n        source_frame = self._source_dataset._ensure_loaded(index)\n        if source_frame is None:\n            return None\n\n        try:\n            return self._transform(source_frame)\n        except Exception as e:\n            logger.warning(f\"Failed to transform index {index}: {str(e)}\")\n            return None\n\n    def _ensure_loaded(self, index: int) -&gt; F | None:\n        \"\"\"Ensure the frame at the given index is loaded.\"\"\"\n        if not (0 &lt;= index &lt; len(self._lazy_frames)):\n            raise IndexError(\n                f\"Index {index} is out of range (0-{len(self._lazy_frames) - 1})\"\n            )\n\n        lazy_frame = self._lazy_frames[index]\n\n        # Return if already loaded\n        if lazy_frame.is_loaded:\n            return lazy_frame.frame\n\n        try:\n            # Convert from source dataset\n            if self._transform and self._source_dataset:\n                lazy_frame.load_attempted = True\n                frame = self._load_from_source(index)\n                lazy_frame.frame = frame\n                lazy_frame.is_loaded = True\n                return frame\n            # Load directly from file\n            else:\n                return lazy_frame.ensure_loaded(self._load_file)\n        except Exception as e:\n            f_path = lazy_frame.file_path\n            logger.error(\n                f\"Failed to load or initialize index {index} ({f_path}): {str(e)}\"\n            )\n            lazy_frame.frame = None\n            lazy_frame.is_loaded = True\n            lazy_frame.load_attempted = True\n            return None\n\n    def _get_file_paths(self) -&gt; list[Path]:\n        \"\"\"Get a list of file paths.\"\"\"\n        return [lazy_frame.file_path for lazy_frame in self._lazy_frames]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of files in the dataset.\"\"\"\n        return len(self._lazy_frames)\n\n    def get_by_label(self, label: str) -&gt; F | None:\n        \"\"\"\n        Get a frame by its label (filename).\n\n        Parameters\n        ----------\n        label : str\n            The filename (label) to search for (e.g., 'sample_1.wav').\n\n        Returns\n        -------\n        Optional[F]\n            The frame if found, otherwise None.\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n        &gt;&gt;&gt; if frame:\n        ...     print(frame.label)\n        \"\"\"\n        # Keep for backward compatibility: return the first match but emit\n        # a DeprecationWarning recommending `get_all_by_label`.\n        all_matches = self.get_all_by_label(label)\n        if len(all_matches) &gt; 0:\n            warnings.warn(\n                \"get_by_label() returns the first matching frame and is deprecated; \"\n                \"use get_all_by_label() to obtain all matches.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return all_matches[0]\n        return None\n\n    def get_all_by_label(self, label: str) -&gt; list[F]:\n        \"\"\"\n        Get all frames matching the given label (filename).\n\n        Parameters\n        ----------\n        label : str\n            The filename (label) to search for (e.g., 'sample_1.wav').\n\n        Returns\n        -------\n        list[F]\n            A list of frames matching the label.\n            If none are found, returns an empty list.\n\n        Notes\n        -----\n        - Search is performed against the filename portion only (i.e. Path.name).\n        - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n        \"\"\"\n        matches: list[F] = []\n        for i, lazy_frame in enumerate(self._lazy_frames):\n            if lazy_frame.file_path.name == label:\n                loaded = self._ensure_loaded(i)\n                if loaded is not None:\n                    matches.append(loaded)\n        return matches\n\n    @overload\n    def __getitem__(self, key: int) -&gt; F | None: ...\n\n    @overload\n    def __getitem__(self, key: str) -&gt; list[F]: ...\n\n    def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n        \"\"\"\n        Get the frame by index (int) or label (str).\n\n        Parameters\n        ----------\n        key : int or str\n            Index (int) or filename/label (str).\n\n        Returns\n        -------\n        Optional[F] or list[F]\n            If `key` is an int, returns the frame or None. If `key` is a str,\n            returns a list of matching frames (may be empty).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame = dataset[0]  # by index\n        &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n        \"\"\"\n        if isinstance(key, int):\n            return self._ensure_loaded(key)\n        if isinstance(key, str):\n            # pandas-like behaviour: return all matches for the label as a list\n            return self.get_all_by_label(key)\n        raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n\n    @overload\n    def apply(self, func: Callable[[F], F_out | None]) -&gt; \"FrameDataset[F_out]\": ...\n\n    @overload\n    def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\": ...\n\n    def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n        \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n        new_dataset = type(self)(\n            folder_path=str(self.folder_path),\n            lazy_loading=True,\n            source_dataset=self,\n            transform=func,\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            recursive=self._recursive,\n        )\n        return cast(\"FrameDataset[Any]\", new_dataset)\n\n    def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n        \"\"\"Save processed frames to files.\"\"\"\n        raise NotImplementedError(\"The save method is not currently implemented.\")\n\n    def sample(\n        self,\n        n: int | None = None,\n        ratio: float | None = None,\n        seed: int | None = None,\n    ) -&gt; \"FrameDataset[F]\":\n        \"\"\"Get a sample from the dataset.\"\"\"\n        if seed is not None:\n            random.seed(seed)\n\n        total = len(self._lazy_frames)\n        if total == 0:\n            return type(self)(\n                str(self.folder_path),\n                sampling_rate=self.sampling_rate,\n                signal_length=self.signal_length,\n                file_extensions=self.file_extensions,\n                lazy_loading=self._lazy_loading,\n                recursive=self._recursive,\n            )\n\n        # Determine sample size\n        if n is None and ratio is None:\n            n = max(1, min(10, int(total * 0.1)))\n        elif n is None and ratio is not None:\n            n = max(1, int(total * ratio))\n        elif n is not None:\n            n = max(1, n)\n        else:\n            n = 1\n\n        n = min(n, total)\n\n        # Randomly select indices\n        sampled_indices = sorted(random.sample(range(total), n))\n\n        return _SampledFrameDataset(self, sampled_indices)\n\n    def get_metadata(self) -&gt; dict[str, Any]:\n        \"\"\"Get metadata for the dataset.\"\"\"\n        actual_sr: int | float | None = self.sampling_rate\n        frame_type_name = \"Unknown\"\n\n        # Count loaded frames\n        loaded_count = sum(\n            1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n        )\n\n        # Get metadata from the first frame (if possible)\n        first_frame: F | None = None\n        if len(self._lazy_frames) &gt; 0:\n            try:\n                if self._lazy_frames[0].is_loaded:\n                    first_frame = self._lazy_frames[0].frame\n\n                if first_frame:\n                    actual_sr = getattr(\n                        first_frame, \"sampling_rate\", self.sampling_rate\n                    )\n                    frame_type_name = type(first_frame).__name__\n            except Exception as e:\n                logger.warning(\n                    f\"Error accessing the first frame during metadata retrieval: {e}\"\n                )\n\n        return {\n            \"folder_path\": str(self.folder_path),\n            \"file_count\": len(self._lazy_frames),\n            \"loaded_count\": loaded_count,\n            \"target_sampling_rate\": self.sampling_rate,\n            \"actual_sampling_rate\": actual_sr,\n            \"signal_length\": self.signal_length,\n            \"file_extensions\": self.file_extensions,\n            \"lazy_loading\": self._lazy_loading,\n            \"recursive\": self._recursive,\n            \"frame_type\": frame_type_name,\n            \"has_transform\": self._transform is not None,\n            \"is_sampled\": isinstance(self, _SampledFrameDataset),\n        }\n</code></pre> Attributes\u00b6 <code></code> <code>folder_path = Path(folder_path)</code> <code>instance-attribute</code> \u00b6 <code></code> <code>sampling_rate = sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>signal_length = signal_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>file_extensions = file_extensions or ['.wav']</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code> \u00b6 Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], F | None] | None = None,\n):\n    self.folder_path = Path(folder_path)\n    if source_dataset is None and not self.folder_path.exists():\n        raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n    self.sampling_rate = sampling_rate\n    self.signal_length = signal_length\n    self.file_extensions = file_extensions or [\".wav\"]\n    self._recursive = recursive\n    self._lazy_loading = lazy_loading\n\n    # Changed to a list of LazyFrame\n    self._lazy_frames: list[LazyFrame[F]] = []\n\n    self._source_dataset = source_dataset\n    self._transform = transform\n\n    if self._source_dataset:\n        self._initialize_from_source()\n    else:\n        self._initialize_from_folder()\n</code></pre> <code></code> <code>__len__()</code> \u00b6 <p>Return the number of files in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of files in the dataset.\"\"\"\n    return len(self._lazy_frames)\n</code></pre> <code></code> <code>get_by_label(label)</code> \u00b6 <p>Get a frame by its label (filename).</p> <code></code> <code>get_all_by_label(label)</code> \u00b6 <p>Get all frames matching the given label (filename).</p> <code></code> <code>__getitem__(key)</code> \u00b6 <pre><code>__getitem__(key: int) -&gt; F | None\n</code></pre><pre><code>__getitem__(key: str) -&gt; list[F]\n</code></pre> <p>Get the frame by index (int) or label (str).</p> <code></code> <code>apply(func)</code> \u00b6 <pre><code>apply(func: Callable[[F], F_out | None]) -&gt; FrameDataset[F_out]\n</code></pre><pre><code>apply(func: Callable[[F], Any | None]) -&gt; FrameDataset[Any]\n</code></pre> <p>Apply a function to the entire dataset to create a new dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n    \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n    new_dataset = type(self)(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=func,\n        sampling_rate=self.sampling_rate,\n        signal_length=self.signal_length,\n        file_extensions=self.file_extensions,\n        recursive=self._recursive,\n    )\n    return cast(\"FrameDataset[Any]\", new_dataset)\n</code></pre> <code></code> <code>save(output_folder, filename_prefix='')</code> \u00b6 <p>Save processed frames to files.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n    \"\"\"Save processed frames to files.\"\"\"\n    raise NotImplementedError(\"The save method is not currently implemented.\")\n</code></pre> <code></code> <code>sample(n=None, ratio=None, seed=None)</code> \u00b6 <p>Get a sample from the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def sample(\n    self,\n    n: int | None = None,\n    ratio: float | None = None,\n    seed: int | None = None,\n) -&gt; \"FrameDataset[F]\":\n    \"\"\"Get a sample from the dataset.\"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    total = len(self._lazy_frames)\n    if total == 0:\n        return type(self)(\n            str(self.folder_path),\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            lazy_loading=self._lazy_loading,\n            recursive=self._recursive,\n        )\n\n    # Determine sample size\n    if n is None and ratio is None:\n        n = max(1, min(10, int(total * 0.1)))\n    elif n is None and ratio is not None:\n        n = max(1, int(total * ratio))\n    elif n is not None:\n        n = max(1, n)\n    else:\n        n = 1\n\n    n = min(n, total)\n\n    # Randomly select indices\n    sampled_indices = sorted(random.sample(range(total), n))\n\n    return _SampledFrameDataset(self, sampled_indices)\n</code></pre> <code></code> <code>get_metadata()</code> \u00b6 <p>Get metadata for the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_metadata(self) -&gt; dict[str, Any]:\n    \"\"\"Get metadata for the dataset.\"\"\"\n    actual_sr: int | float | None = self.sampling_rate\n    frame_type_name = \"Unknown\"\n\n    # Count loaded frames\n    loaded_count = sum(\n        1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n    )\n\n    # Get metadata from the first frame (if possible)\n    first_frame: F | None = None\n    if len(self._lazy_frames) &gt; 0:\n        try:\n            if self._lazy_frames[0].is_loaded:\n                first_frame = self._lazy_frames[0].frame\n\n            if first_frame:\n                actual_sr = getattr(\n                    first_frame, \"sampling_rate\", self.sampling_rate\n                )\n                frame_type_name = type(first_frame).__name__\n        except Exception as e:\n            logger.warning(\n                f\"Error accessing the first frame during metadata retrieval: {e}\"\n            )\n\n    return {\n        \"folder_path\": str(self.folder_path),\n        \"file_count\": len(self._lazy_frames),\n        \"loaded_count\": loaded_count,\n        \"target_sampling_rate\": self.sampling_rate,\n        \"actual_sampling_rate\": actual_sr,\n        \"signal_length\": self.signal_length,\n        \"file_extensions\": self.file_extensions,\n        \"lazy_loading\": self._lazy_loading,\n        \"recursive\": self._recursive,\n        \"frame_type\": frame_type_name,\n        \"has_transform\": self._transform is not None,\n        \"is_sampled\": isinstance(self, _SampledFrameDataset),\n    }\n</code></pre>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.get_by_label--parameters","title":"Parameters","text":"<p>label : str     The filename (label) to search for (e.g., 'sample_1.wav').</p>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.get_by_label--returns","title":"Returns","text":"<p>Optional[F]     The frame if found, otherwise None.</p>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.get_by_label--examples","title":"Examples","text":"<p>frame = dataset.get_by_label(\"sample_1.wav\") if frame: ...     print(frame.label)</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_by_label(self, label: str) -&gt; F | None:\n    \"\"\"\n    Get a frame by its label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    Optional[F]\n        The frame if found, otherwise None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n    &gt;&gt;&gt; if frame:\n    ...     print(frame.label)\n    \"\"\"\n    # Keep for backward compatibility: return the first match but emit\n    # a DeprecationWarning recommending `get_all_by_label`.\n    all_matches = self.get_all_by_label(label)\n    if len(all_matches) &gt; 0:\n        warnings.warn(\n            \"get_by_label() returns the first matching frame and is deprecated; \"\n            \"use get_all_by_label() to obtain all matches.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return all_matches[0]\n    return None\n</code></pre>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--parameters","title":"Parameters","text":"<p>label : str     The filename (label) to search for (e.g., 'sample_1.wav').</p>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--returns","title":"Returns","text":"<p>list[F]     A list of frames matching the label.     If none are found, returns an empty list.</p>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--notes","title":"Notes","text":"<ul> <li>Search is performed against the filename portion only (i.e. Path.name).</li> <li>Each matched frame will be loaded (triggering lazy load) via <code>_ensure_loaded</code>.</li> </ul> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_all_by_label(self, label: str) -&gt; list[F]:\n    \"\"\"\n    Get all frames matching the given label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    list[F]\n        A list of frames matching the label.\n        If none are found, returns an empty list.\n\n    Notes\n    -----\n    - Search is performed against the filename portion only (i.e. Path.name).\n    - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n    \"\"\"\n    matches: list[F] = []\n    for i, lazy_frame in enumerate(self._lazy_frames):\n        if lazy_frame.file_path.name == label:\n            loaded = self._ensure_loaded(i)\n            if loaded is not None:\n                matches.append(loaded)\n    return matches\n</code></pre>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.__getitem__--parameters","title":"Parameters","text":"<p>key : int or str     Index (int) or filename/label (str).</p>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.__getitem__--returns","title":"Returns","text":"<p>Optional[F] or list[F]     If <code>key</code> is an int, returns the frame or None. If <code>key</code> is a str,     returns a list of matching frames (may be empty).</p>"},{"location":"api/#wandas.utils.frame_dataset.FrameDataset.__getitem__--examples","title":"Examples","text":"<p>frame = dataset[0]  # by index frames = dataset[\"sample_1.wav\"]  # list of matches by filename</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n    \"\"\"\n    Get the frame by index (int) or label (str).\n\n    Parameters\n    ----------\n    key : int or str\n        Index (int) or filename/label (str).\n\n    Returns\n    -------\n    Optional[F] or list[F]\n        If `key` is an int, returns the frame or None. If `key` is a str,\n        returns a list of matching frames (may be empty).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset[0]  # by index\n    &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n    \"\"\"\n    if isinstance(key, int):\n        return self._ensure_loaded(key)\n    if isinstance(key, str):\n        # pandas-like behaviour: return all matches for the label as a list\n        return self.get_all_by_label(key)\n    raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n</code></pre>"},{"location":"api/#wandas.utils.frame_dataset.ChannelFrameDataset","title":"<code>ChannelFrameDataset</code>","text":"<p>               Bases: <code>FrameDataset[ChannelFrame]</code></p> <p>Dataset class for handling audio files as ChannelFrames in a folder.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class ChannelFrameDataset(FrameDataset[ChannelFrame]):\n    \"\"\"\n    Dataset class for handling audio files as ChannelFrames in a folder.\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], ChannelFrame | None] | None = None,\n    ):\n        _file_extensions = file_extensions or [\n            \".wav\",\n            \".mp3\",\n            \".flac\",\n            \".csv\",\n        ]\n\n        super().__init__(\n            folder_path=folder_path,\n            sampling_rate=sampling_rate,\n            signal_length=signal_length,\n            file_extensions=_file_extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n            source_dataset=source_dataset,\n            transform=transform,\n        )\n\n    def _load_file(self, file_path: Path) -&gt; ChannelFrame | None:\n        \"\"\"Load an audio file and return a ChannelFrame.\"\"\"\n        try:\n            frame = ChannelFrame.from_file(file_path)\n            if self.sampling_rate and frame.sampling_rate != self.sampling_rate:\n                logger.info(\n                    f\"Resampling file {file_path.name} ({frame.sampling_rate} Hz) to \"\n                    f\"dataset rate ({self.sampling_rate} Hz).\"\n                )\n                frame = frame.resampling(target_sr=self.sampling_rate)\n            return frame\n        except Exception as e:\n            logger.error(f\"Failed to load or initialize file {file_path}: {str(e)}\")\n            return None\n\n    def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Resample all frames in the dataset.\"\"\"\n\n        def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.resampling(target_sr=target_sr)\n            except Exception as e:\n                logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n                return None\n\n        new_dataset = self.apply(_resample_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Trim all frames in the dataset.\"\"\"\n\n        def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.trim(start=start, end=end)\n            except Exception as e:\n                logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n                return None\n\n        new_dataset = self.apply(_trim_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Normalize all frames in the dataset.\"\"\"\n\n        def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.normalize(**kwargs)\n            except Exception as e:\n                logger.warning(f\"Normalization error ({kwargs}): {e}\")\n                return None\n\n        new_dataset = self.apply(_normalize_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def stft(\n        self,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrameDataset\":\n        \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n        _hop = hop_length or n_fft // 4\n\n        def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.stft(\n                    n_fft=n_fft,\n                    hop_length=_hop,\n                    win_length=win_length,\n                    window=window,\n                )\n            except Exception as e:\n                logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n                return None\n\n        new_dataset = SpectrogramFrameDataset(\n            folder_path=str(self.folder_path),\n            lazy_loading=True,\n            source_dataset=self,\n            transform=_stft_func,\n            sampling_rate=self.sampling_rate,\n        )\n        return new_dataset\n\n    @classmethod\n    def from_folder(\n        cls,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        file_extensions: list[str] | None = None,\n        recursive: bool = False,\n        lazy_loading: bool = True,\n    ) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n        extensions = (\n            file_extensions\n            if file_extensions is not None\n            else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n        )\n\n        return cls(\n            folder_path,\n            sampling_rate=sampling_rate,\n            file_extensions=extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n        )\n</code></pre> Functions\u00b6 <code></code> <code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code> \u00b6 Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], ChannelFrame | None] | None = None,\n):\n    _file_extensions = file_extensions or [\n        \".wav\",\n        \".mp3\",\n        \".flac\",\n        \".csv\",\n    ]\n\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=_file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre> <code></code> <code>resample(target_sr)</code> \u00b6 <p>Resample all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Resample all frames in the dataset.\"\"\"\n\n    def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.resampling(target_sr=target_sr)\n        except Exception as e:\n            logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n            return None\n\n    new_dataset = self.apply(_resample_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre> <code></code> <code>trim(start, end)</code> \u00b6 <p>Trim all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Trim all frames in the dataset.\"\"\"\n\n    def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.trim(start=start, end=end)\n        except Exception as e:\n            logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n            return None\n\n    new_dataset = self.apply(_trim_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre> <code></code> <code>normalize(**kwargs)</code> \u00b6 <p>Normalize all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Normalize all frames in the dataset.\"\"\"\n\n    def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.normalize(**kwargs)\n        except Exception as e:\n            logger.warning(f\"Normalization error ({kwargs}): {e}\")\n            return None\n\n    new_dataset = self.apply(_normalize_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre> <code></code> <code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Apply STFT to all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def stft(\n    self,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrameDataset\":\n    \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n    _hop = hop_length or n_fft // 4\n\n    def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.stft(\n                n_fft=n_fft,\n                hop_length=_hop,\n                win_length=win_length,\n                window=window,\n            )\n        except Exception as e:\n            logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n            return None\n\n    new_dataset = SpectrogramFrameDataset(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=_stft_func,\n        sampling_rate=self.sampling_rate,\n    )\n    return new_dataset\n</code></pre> <code></code> <code>from_folder(folder_path, sampling_rate=None, file_extensions=None, recursive=False, lazy_loading=True)</code> <code>classmethod</code> \u00b6 <p>Class method to create a ChannelFrameDataset from a folder.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>@classmethod\ndef from_folder(\n    cls,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    file_extensions: list[str] | None = None,\n    recursive: bool = False,\n    lazy_loading: bool = True,\n) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n    extensions = (\n        file_extensions\n        if file_extensions is not None\n        else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n    )\n\n    return cls(\n        folder_path,\n        sampling_rate=sampling_rate,\n        file_extensions=extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n    )\n</code></pre>"},{"location":"api/#wandas.utils.frame_dataset.SpectrogramFrameDataset","title":"<code>SpectrogramFrameDataset</code>","text":"<p>               Bases: <code>FrameDataset[SpectrogramFrame]</code></p> <p>Dataset class for handling spectrogram data as SpectrogramFrames. Expected to be generated mainly as a result of ChannelFrameDataset.stft().</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class SpectrogramFrameDataset(FrameDataset[SpectrogramFrame]):\n    \"\"\"\n    Dataset class for handling spectrogram data as SpectrogramFrames.\n    Expected to be generated mainly as a result of ChannelFrameDataset.stft().\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n    ):\n        super().__init__(\n            folder_path=folder_path,\n            sampling_rate=sampling_rate,\n            signal_length=signal_length,\n            file_extensions=file_extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n            source_dataset=source_dataset,\n            transform=transform,\n        )\n\n    def _load_file(self, file_path: Path) -&gt; SpectrogramFrame | None:\n        \"\"\"Direct loading from files is not currently supported.\"\"\"\n        logger.warning(\n            \"No method defined for directly loading SpectrogramFrames. Normally \"\n            \"created from ChannelFrameDataset.stft().\"\n        )\n        raise NotImplementedError(\n            \"No method defined for directly loading SpectrogramFrames\"\n        )\n\n    def plot(self, index: int, **kwargs: Any) -&gt; None:\n        \"\"\"Plot the spectrogram at the specified index.\"\"\"\n        try:\n            frame = self._ensure_loaded(index)\n\n            if frame is None:\n                logger.warning(\n                    f\"Cannot plot index {index} as it failed to load/transform.\"\n                )\n                return\n\n            plot_method = getattr(frame, \"plot\", None)\n            if callable(plot_method):\n                plot_method(**kwargs)\n            else:\n                logger.warning(\n                    f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                    f\"have a plot method implemented.\"\n                )\n        except Exception as e:\n            logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre> Functions\u00b6 <code></code> <code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code> \u00b6 Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n):\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre> <code></code> <code>plot(index, **kwargs)</code> \u00b6 <p>Plot the spectrogram at the specified index.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def plot(self, index: int, **kwargs: Any) -&gt; None:\n    \"\"\"Plot the spectrogram at the specified index.\"\"\"\n    try:\n        frame = self._ensure_loaded(index)\n\n        if frame is None:\n            logger.warning(\n                f\"Cannot plot index {index} as it failed to load/transform.\"\n            )\n            return\n\n        plot_method = getattr(frame, \"plot\", None)\n        if callable(plot_method):\n            plot_method(**kwargs)\n        else:\n            logger.warning(\n                f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                f\"have a plot method implemented.\"\n            )\n    except Exception as e:\n        logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre>"},{"location":"api/#wandas.utils.generate_sample","title":"<code>generate_sample</code>","text":""},{"location":"api/#wandas.utils.generate_sample-classes","title":"Classes","text":""},{"location":"api/#wandas.utils.generate_sample-functions","title":"Functions","text":""},{"location":"api/#wandas.utils.generate_sample.generate_sin","title":"<code>generate_sin(freqs=1000, sampling_rate=16000, duration=1.0, label=None)</code>","text":"<p>Generate sample sine wave signals.</p>"},{"location":"api/#wandas.utils.generate_sample.generate_sin--parameters","title":"Parameters","text":"<p>freqs : float or list of float, default=1000     Frequency of the sine wave(s) in Hz.     If multiple frequencies are specified, multiple channels will be created. sampling_rate : int, default=16000     Sampling rate in Hz. duration : float, default=1.0     Duration of the signal in seconds. label : str, optional     Label for the entire signal.</p>"},{"location":"api/#wandas.utils.generate_sample.generate_sin--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the sine wave(s).</p> Source code in <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    # \u76f4\u63a5\u3001generate_sin_lazy\u95a2\u6570\u3092\u547c\u3073\u51fa\u3059\n    return generate_sin_lazy(\n        freqs=freqs, sampling_rate=sampling_rate, duration=duration, label=label\n    )\n</code></pre>"},{"location":"api/#wandas.utils.generate_sample.generate_sin_lazy","title":"<code>generate_sin_lazy(freqs=1000, sampling_rate=16000, duration=1.0, label=None)</code>","text":"<p>Generate sample sine wave signals using lazy computation.</p>"},{"location":"api/#wandas.utils.generate_sample.generate_sin_lazy--parameters","title":"Parameters","text":"<p>freqs : float or list of float, default=1000     Frequency of the sine wave(s) in Hz.     If multiple frequencies are specified, multiple channels will be created. sampling_rate : int, default=16000     Sampling rate in Hz. duration : float, default=1.0     Duration of the signal in seconds. label : str, optional     Label for the entire signal.</p>"},{"location":"api/#wandas.utils.generate_sample.generate_sin_lazy--returns","title":"Returns","text":"<p>ChannelFrame     Lazy ChannelFrame object containing the sine wave(s).</p> Source code in <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin_lazy(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals using lazy computation.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        Lazy ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    label = label or \"Generated Sin\"\n    t = np.linspace(0, duration, int(sampling_rate * duration), endpoint=False)\n\n    _freqs: list[float]\n    if isinstance(freqs, float):\n        _freqs = [freqs]\n    elif isinstance(freqs, list):\n        _freqs = freqs\n    else:\n        raise ValueError(\"freqs must be a float or a list of floats.\")\n\n    channels = []\n    labels = []\n    for idx, freq in enumerate(_freqs):\n        data = np.sin(2 * np.pi * freq * t)\n        labels.append(f\"Channel {idx + 1}\")\n        channels.append(data)\n    return ChannelFrame.from_numpy(\n        data=np.array(channels),\n        label=label,\n        sampling_rate=sampling_rate,\n        ch_labels=labels,\n    )\n</code></pre>"},{"location":"api/#wandas.utils.introspection","title":"<code>introspection</code>","text":"<p>Utilities for runtime signature introspection.</p>"},{"location":"api/#wandas.utils.introspection-attributes","title":"Attributes","text":""},{"location":"api/#wandas.utils.introspection.__all__","title":"<code>__all__ = ['accepted_kwargs', 'filter_kwargs']</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.introspection-functions","title":"Functions","text":""},{"location":"api/#wandas.utils.introspection.accepted_kwargs","title":"<code>accepted_kwargs(func)</code>","text":"<p>Get the set of explicit keyword arguments accepted by a function and whether it accepts **kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The function to inspect.</p> required <p>Returns:</p> Type Description <code>set[str]</code> <p>A tuple containing:</p> <code>bool</code> <ul> <li>set[str]: Set of explicit keyword argument names accepted by func.</li> </ul> <code>tuple[set[str], bool]</code> <ul> <li>bool: Whether the function accepts variable keyword arguments (**kwargs).</li> </ul> Source code in <code>wandas/utils/introspection.py</code> <pre><code>def accepted_kwargs(func: Callable[..., Any]) -&gt; tuple[set[str], bool]:\n    \"\"\"\n    Get the set of explicit keyword arguments accepted by\n    a function and whether it accepts **kwargs.\n\n    Args:\n        func: The function to inspect.\n\n    Returns:\n        A tuple containing:\n        - set[str]: Set of explicit keyword argument names accepted by func.\n        - bool: Whether the function accepts variable keyword arguments (**kwargs).\n    \"\"\"\n    # \u30e2\u30c3\u30af\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n    if hasattr(func, \"__module__\") and func.__module__ == \"unittest.mock\":\n        return set(), True\n    try:\n        params = signature(func).parameters.values()\n\n        # \u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u5f15\u6570\u3092\u53ce\u96c6\n        explicit_kwargs = {\n            p.name\n            for p in params\n            if p.kind in (Parameter.POSITIONAL_OR_KEYWORD, Parameter.KEYWORD_ONLY)\n        }\n\n        # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\n        has_var_kwargs = any(p.kind is Parameter.VAR_KEYWORD for p in params)\n\n        return explicit_kwargs, has_var_kwargs\n    except (ValueError, TypeError):\n        # \u30b7\u30b0\u30cd\u30c1\u30e3\u3092\u53d6\u5f97\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n        return set(), True\n</code></pre>"},{"location":"api/#wandas.utils.introspection.filter_kwargs","title":"<code>filter_kwargs(func, kwargs, *, strict_mode=False)</code>","text":"<p>Filter keyword arguments to only those accepted by the function.</p> <p>This function examines the signature of <code>func</code> and returns a dictionary containing only the key-value pairs from <code>kwargs</code> that are valid keyword arguments for <code>func</code>.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The function to filter keyword arguments for.</p> required <code>kwargs</code> <code>Mapping[str, Any]</code> <p>The keyword arguments to filter.</p> required <code>strict_mode</code> <code>bool</code> <p>If True, only explicitly defined parameters are passed even when the function accepts kwargs. If False (default), all parameters are passed to functions that accept kwargs, but a warning is issued for parameters not explicitly defined.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary containing only the key-value pairs that are valid for <code>func</code>.</p> Source code in <code>wandas/utils/introspection.py</code> <pre><code>def filter_kwargs(\n    func: Callable[..., Any],\n    kwargs: Mapping[str, Any],\n    *,\n    strict_mode: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Filter keyword arguments to only those accepted by the function.\n\n    This function examines the signature of `func` and returns a dictionary\n    containing only the key-value pairs from `kwargs` that are valid keyword\n    arguments for `func`.\n\n    Args:\n        func: The function to filter keyword arguments for.\n        kwargs: The keyword arguments to filter.\n        strict_mode: If True, only explicitly defined parameters are passed even when\n            the function accepts **kwargs. If False (default), all parameters are\n            passed to functions that accept **kwargs, but a warning is issued for\n            parameters not explicitly defined.\n\n    Returns:\n        A dictionary containing only the key-value pairs that are valid for `func`.\n    \"\"\"\n    explicit_params, accepts_var_kwargs = accepted_kwargs(func)\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u306a\u3044\u5834\u5408\u3001\u307e\u305f\u306f strict_mode \u304c True \u306e\u5834\u5408\u306f\u3001\n    # \u660e\u793a\u7684\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n    if not accepts_var_kwargs or strict_mode:\n        filtered = {k: v for k, v in kwargs.items() if k in explicit_params}\n        return filtered\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u5834\u5408\uff08strict_mode\u304cFalse\u306e\u5834\u5408\uff09\u306f\u5168\u30ad\u30fc\u3092\u8a31\u53ef\n    # \u305f\u3060\u3057\u3001\u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u306a\u3044\u30ad\u30fc\u306b\u306f\u8b66\u544a\u3092\u51fa\u3059\n    unknown = set(kwargs) - explicit_params\n    if unknown:\n        warnings.warn(\n            f\"Implicit kwargs for {func.__name__}: {unknown}\",\n            UserWarning,\n            stacklevel=2,\n        )\n    return dict(kwargs)\n</code></pre>"},{"location":"api/#wandas.utils.types","title":"<code>types</code>","text":""},{"location":"api/#wandas.utils.types-attributes","title":"Attributes","text":""},{"location":"api/#wandas.utils.types.Real","title":"<code>Real = np.number[Any]</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.types.Complex","title":"<code>Complex = np.complexfloating[Any, Any]</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.types.NDArrayReal","title":"<code>NDArrayReal = npt.NDArray[Real]</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.types.NDArrayComplex","title":"<code>NDArrayComplex = npt.NDArray[Complex]</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.utils.util","title":"<code>util</code>","text":""},{"location":"api/#wandas.utils.util-attributes","title":"Attributes","text":""},{"location":"api/#wandas.utils.util-functions","title":"Functions","text":""},{"location":"api/#wandas.utils.util.validate_sampling_rate","title":"<code>validate_sampling_rate(sampling_rate, param_name='sampling_rate')</code>","text":"<p>Validate that sampling rate is positive.</p>"},{"location":"api/#wandas.utils.util.validate_sampling_rate--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz to validate. param_name : str, default=\"sampling_rate\"     Name of the parameter being validated (for error messages).</p>"},{"location":"api/#wandas.utils.util.validate_sampling_rate--raises","title":"Raises","text":"<p>ValueError     If sampling_rate is not positive (i.e., &lt;= 0).</p>"},{"location":"api/#wandas.utils.util.validate_sampling_rate--examples","title":"Examples","text":"<p>validate_sampling_rate(44100)  # No error validate_sampling_rate(0)  # Raises ValueError validate_sampling_rate(-100)  # Raises ValueError</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def validate_sampling_rate(\n    sampling_rate: float, param_name: str = \"sampling_rate\"\n) -&gt; None:\n    \"\"\"\n    Validate that sampling rate is positive.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz to validate.\n    param_name : str, default=\"sampling_rate\"\n        Name of the parameter being validated (for error messages).\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate is not positive (i.e., &lt;= 0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; validate_sampling_rate(44100)  # No error\n    &gt;&gt;&gt; validate_sampling_rate(0)  # Raises ValueError\n    &gt;&gt;&gt; validate_sampling_rate(-100)  # Raises ValueError\n    \"\"\"\n    if sampling_rate &lt;= 0:\n        raise ValueError(\n            f\"Invalid {param_name}\\n\"\n            f\"  Got: {sampling_rate} Hz\\n\"\n            f\"  Expected: Positive value &gt; 0\\n\"\n            f\"Sampling rate represents samples per second and must be positive.\\n\"\n            f\"Common values: 8000, 16000, 22050, 44100, 48000 Hz\"\n        )\n</code></pre>"},{"location":"api/#wandas.utils.util.unit_to_ref","title":"<code>unit_to_ref(unit)</code>","text":"<p>Convert unit to reference value.</p>"},{"location":"api/#wandas.utils.util.unit_to_ref--parameters","title":"Parameters","text":"<p>unit : str     Unit string.</p>"},{"location":"api/#wandas.utils.util.unit_to_ref--returns","title":"Returns","text":"<p>float     Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).     For other units, returns 1.0.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def unit_to_ref(unit: str) -&gt; float:\n    \"\"\"\n    Convert unit to reference value.\n\n    Parameters\n    ----------\n    unit : str\n        Unit string.\n\n    Returns\n    -------\n    float\n        Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).\n        For other units, returns 1.0.\n    \"\"\"\n    if unit == \"Pa\":\n        return 2e-5\n\n    else:\n        return 1.0\n</code></pre>"},{"location":"api/#wandas.utils.util.calculate_rms","title":"<code>calculate_rms(wave)</code>","text":"<p>Calculate the root mean square of the wave.</p>"},{"location":"api/#wandas.utils.util.calculate_rms--parameters","title":"Parameters","text":"<p>wave : NDArrayReal     Input waveform data. Can be multi-channel (shape: [channels, samples])     or single channel (shape: [samples]).</p>"},{"location":"api/#wandas.utils.util.calculate_rms--returns","title":"Returns","text":"<p>Union[float, NDArray[np.float64]]     RMS value(s). For multi-channel input, returns an array of RMS values,     one per channel. For single-channel input, returns a single RMS value.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def calculate_rms(wave: \"NDArrayReal\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the root mean square of the wave.\n\n    Parameters\n    ----------\n    wave : NDArrayReal\n        Input waveform data. Can be multi-channel (shape: [channels, samples])\n        or single channel (shape: [samples]).\n\n    Returns\n    -------\n    Union[float, NDArray[np.float64]]\n        RMS value(s). For multi-channel input, returns an array of RMS values,\n        one per channel. For single-channel input, returns a single RMS value.\n    \"\"\"\n    # Calculate RMS considering axis (over the last dimension)\n    axis_to_use = -1 if wave.ndim &gt; 1 else None\n    rms_values: NDArrayReal = np.sqrt(\n        np.mean(np.square(wave), axis=axis_to_use, keepdims=True)\n    )\n    return rms_values\n</code></pre>"},{"location":"api/#wandas.utils.util.calculate_desired_noise_rms","title":"<code>calculate_desired_noise_rms(clean_rms, snr)</code>","text":"<p>Calculate the desired noise RMS based on clean signal RMS and target SNR.</p>"},{"location":"api/#wandas.utils.util.calculate_desired_noise_rms--parameters","title":"Parameters","text":"<p>clean_rms : \"NDArrayReal\"     RMS value(s) of the clean signal.     Can be a single value or an array for multi-channel. snr : float     Target Signal-to-Noise Ratio in dB.</p>"},{"location":"api/#wandas.utils.util.calculate_desired_noise_rms--returns","title":"Returns","text":"<p>\"NDArrayReal\"     Desired noise RMS value(s) to achieve the target SNR.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def calculate_desired_noise_rms(clean_rms: \"NDArrayReal\", snr: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the desired noise RMS based on clean signal RMS and target SNR.\n\n    Parameters\n    ----------\n    clean_rms : \"NDArrayReal\"\n        RMS value(s) of the clean signal.\n        Can be a single value or an array for multi-channel.\n    snr : float\n        Target Signal-to-Noise Ratio in dB.\n\n    Returns\n    -------\n    \"NDArrayReal\"\n        Desired noise RMS value(s) to achieve the target SNR.\n    \"\"\"\n    a = snr / 20\n    noise_rms = clean_rms / (10**a)\n    return noise_rms\n</code></pre>"},{"location":"api/#wandas.utils.util.amplitude_to_db","title":"<code>amplitude_to_db(amplitude, ref)</code>","text":"<p>Convert amplitude to decibel.</p>"},{"location":"api/#wandas.utils.util.amplitude_to_db--parameters","title":"Parameters","text":"<p>amplitude : NDArrayReal     Input amplitude data. ref : float     Reference value for conversion.</p>"},{"location":"api/#wandas.utils.util.amplitude_to_db--returns","title":"Returns","text":"<p>NDArrayReal     Amplitude data converted to decibels.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def amplitude_to_db(amplitude: \"NDArrayReal\", ref: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Convert amplitude to decibel.\n\n    Parameters\n    ----------\n    amplitude : NDArrayReal\n        Input amplitude data.\n    ref : float\n        Reference value for conversion.\n\n    Returns\n    -------\n    NDArrayReal\n        Amplitude data converted to decibels.\n    \"\"\"\n    db: NDArrayReal = librosa.amplitude_to_db(\n        np.abs(amplitude), ref=ref, amin=1e-15, top_db=None\n    )\n    return db\n</code></pre>"},{"location":"api/#wandas.utils.util.level_trigger","title":"<code>level_trigger(data, level, offset=0, hold=1)</code>","text":"<p>Find points where the signal crosses the specified level from below.</p>"},{"location":"api/#wandas.utils.util.level_trigger--parameters","title":"Parameters","text":"<p>data : NDArrayReal     Input signal data. level : float     Threshold level for triggering. offset : int, default=0     Offset to add to trigger points. hold : int, default=1     Minimum number of samples between successive trigger points.</p>"},{"location":"api/#wandas.utils.util.level_trigger--returns","title":"Returns","text":"<p>list of int     List of sample indices where the signal crosses the level.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def level_trigger(\n    data: \"NDArrayReal\", level: float, offset: int = 0, hold: int = 1\n) -&gt; list[int]:\n    \"\"\"\n    Find points where the signal crosses the specified level from below.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    level : float\n        Threshold level for triggering.\n    offset : int, default=0\n        Offset to add to trigger points.\n    hold : int, default=1\n        Minimum number of samples between successive trigger points.\n\n    Returns\n    -------\n    list of int\n        List of sample indices where the signal crosses the level.\n    \"\"\"\n    trig_point: list[int] = []\n\n    sig_len = len(data)\n    diff = np.diff(np.sign(data - level))\n    level_point = np.where(diff &gt; 0)[0]\n    level_point = level_point[(level_point + hold) &lt; sig_len]\n\n    if len(level_point) == 0:\n        return list()\n\n    last_point = level_point[0]\n    trig_point.append(last_point + offset)\n    for i in level_point:\n        if (last_point + hold) &lt; i:\n            trig_point.append(i + offset)\n            last_point = i\n\n    return trig_point\n</code></pre>"},{"location":"api/#wandas.utils.util.cut_sig","title":"<code>cut_sig(data, point_list, cut_len, taper_rate=0, dc_cut=False)</code>","text":"<p>Cut segments from signal at specified points.</p>"},{"location":"api/#wandas.utils.util.cut_sig--parameters","title":"Parameters","text":"<p>data : NDArrayReal     Input signal data. point_list : list of int     List of starting points for cutting. cut_len : int     Length of each segment to cut. taper_rate : float, default=0     Taper rate for Tukey window applied to segments.     A value of 0 means no tapering, 1 means full tapering. dc_cut : bool, default=False     Whether to remove DC component (mean) from segments.</p>"},{"location":"api/#wandas.utils.util.cut_sig--returns","title":"Returns","text":"<p>NDArrayReal     Array containing cut segments with shape (n_segments, cut_len).</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def cut_sig(\n    data: \"NDArrayReal\",\n    point_list: list[int],\n    cut_len: int,\n    taper_rate: float = 0,\n    dc_cut: bool = False,\n) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Cut segments from signal at specified points.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    point_list : list of int\n        List of starting points for cutting.\n    cut_len : int\n        Length of each segment to cut.\n    taper_rate : float, default=0\n        Taper rate for Tukey window applied to segments.\n        A value of 0 means no tapering, 1 means full tapering.\n    dc_cut : bool, default=False\n        Whether to remove DC component (mean) from segments.\n\n    Returns\n    -------\n    NDArrayReal\n        Array containing cut segments with shape (n_segments, cut_len).\n    \"\"\"\n    length = len(data)\n    point_list_ = [p for p in point_list if p &gt;= 0 and p + cut_len &lt;= length]\n    trial: NDArrayReal = np.zeros((len(point_list_), cut_len))\n\n    for i, v in enumerate(point_list_):\n        trial[i] = data[v : v + cut_len]\n        if dc_cut:\n            trial[i] = trial[i] - trial[i].mean()\n\n    win: NDArrayReal = tukey(cut_len, taper_rate).astype(trial.dtype)[np.newaxis, :]\n    trial = trial * win\n    return trial\n</code></pre>"},{"location":"api/#_6","title":"\u53ef\u8996\u5316\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u53ef\u8996\u5316\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u30c7\u30fc\u30bf\u306e\u8996\u899a\u5316\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.visualization","title":"<code>wandas.visualization</code>","text":""},{"location":"api/#wandas.visualization-modules","title":"Modules","text":""},{"location":"api/#wandas.visualization.plotting","title":"<code>plotting</code>","text":""},{"location":"api/#wandas.visualization.plotting-attributes","title":"Attributes","text":""},{"location":"api/#wandas.visualization.plotting.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.visualization.plotting.TFrame","title":"<code>TFrame = TypeVar('TFrame', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/#wandas.visualization.plotting-classes","title":"Classes","text":""},{"location":"api/#wandas.visualization.plotting.PlotStrategy","title":"<code>PlotStrategy</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TFrame]</code></p> <p>Base class for plotting strategies</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class PlotStrategy(abc.ABC, Generic[TFrame]):\n    \"\"\"Base class for plotting strategies\"\"\"\n\n    name: ClassVar[str]\n\n    @abc.abstractmethod\n    def channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass\n\n    @abc.abstractmethod\n    def plot(\n        self,\n        bf: TFrame,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Implementation of plotting\"\"\"\n        pass\n</code></pre> Attributes\u00b6 <code></code> <code>name</code> <code>class-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax)</code> <code>abstractmethod</code> \u00b6 <p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> <code>abstractmethod</code> \u00b6 <p>Implementation of plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef plot(\n    self,\n    bf: TFrame,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of plotting\"\"\"\n    pass\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.WaveformPlotStrategy","title":"<code>WaveformPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['ChannelFrame']</code></p> <p>Strategy for waveform plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class WaveformPlotStrategy(PlotStrategy[\"ChannelFrame\"]):\n    \"\"\"Strategy for waveform plotting\"\"\"\n\n    name = \"waveform\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.plot(x, y, **kwargs)\n        ax.set_ylabel(\"Amplitude\")\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"ChannelFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Waveform plotting\"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n        xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(\n            Line2D,\n            kwargs,\n            strict_mode=True,\n        )\n        ax_set = filter_kwargs(\n            Axes.set,\n            kwargs,\n            strict_mode=True,\n        )\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        data = bf.data\n        data = _reshape_to_2d(data)\n        if overlay:\n            if ax is None:\n                fig, ax = plt.subplots(figsize=(10, 4))\n\n            self.channel_plot(\n                bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n            )\n            ax.set(\n                ylabel=ylabel,\n                title=title or bf.label or \"Channel Data\",\n                xlabel=xlabel,\n                **ax_set,\n            )\n            if ax is None:\n                fig.suptitle(title or bf.label or None)\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n                )\n                ax_i.set(\n                    ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                    title=ch_meta.label,\n                    **ax_set,\n                )\n\n            axes_list[-1].set(\n                xlabel=\"Time [s]\",\n            )\n            fig.suptitle(title or bf.label or \"Channel Data\")\n\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'waveform'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.set_ylabel(\"Amplitude\")\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Waveform plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Waveform plotting\"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n    xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(\n        Line2D,\n        kwargs,\n        strict_mode=True,\n    )\n    ax_set = filter_kwargs(\n        Axes.set,\n        kwargs,\n        strict_mode=True,\n    )\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    data = bf.data\n    data = _reshape_to_2d(data)\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(10, 4))\n\n        self.channel_plot(\n            bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n        )\n        ax.set(\n            ylabel=ylabel,\n            title=title or bf.label or \"Channel Data\",\n            xlabel=xlabel,\n            **ax_set,\n        )\n        if ax is None:\n            fig.suptitle(title or bf.label or None)\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n            )\n            ax_i.set(\n                ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                title=ch_meta.label,\n                **ax_set,\n            )\n\n        axes_list[-1].set(\n            xlabel=\"Time [s]\",\n        )\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.FrequencyPlotStrategy","title":"<code>FrequencyPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectralFrame']</code></p> <p>Strategy for frequency domain plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class FrequencyPlotStrategy(PlotStrategy[\"SpectralFrame\"]):\n    \"\"\"Strategy for frequency domain plotting\"\"\"\n\n    name = \"frequency\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.plot(x, y, **kwargs)\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"SpectralFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Frequency domain plotting\"\"\"\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n        if (\n            len(bf.operation_history) &gt; 0\n            and bf.operation_history[-1][\"operation\"] == \"coherence\"\n        ):\n            unit = \"\"\n            data = bf.magnitude\n            ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n        else:\n            if is_aw:\n                unit = \"dBA\"\n                data = bf.dBA\n            else:\n                unit = \"dB\"\n                data = bf.dB\n            ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n        data = _reshape_to_2d(data)\n        xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                _, ax = plt.subplots(figsize=(10, 4))\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,\n                label=bf.labels,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax.set(\n                ylabel=ylabel,\n                xlabel=xlabel,\n                title=title or bf.label or \"Channel Data\",\n                **ax_set,\n            )\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    label=ch_meta.label,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(\n                    ylabel=ylabel,\n                    title=ch_meta.label,\n                    xlabel=xlabel,\n                    **ax_set,\n                )\n            axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n            fig.suptitle(title or bf.label or \"Channel Data\")\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'frequency'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Frequency domain plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Frequency domain plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    data = _reshape_to_2d(data)\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=title or bf.label or \"Channel Data\",\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.NOctPlotStrategy","title":"<code>NOctPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['NOctFrame']</code></p> <p>Strategy for N-octave band analysis plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class NOctPlotStrategy(PlotStrategy[\"NOctFrame\"]):\n    \"\"\"Strategy for N-octave band analysis plotting\"\"\"\n\n    name = \"noct\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.step(x, y, **kwargs)\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"NOctFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"N-octave band analysis plotting\"\"\"\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n\n        if is_aw:\n            unit = \"dBrA\"\n            data = bf.dBA\n        else:\n            unit = \"dBr\"\n            data = bf.dB\n        data = _reshape_to_2d(data)\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n        xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                _, ax = plt.subplots(figsize=(10, 4))\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,\n                label=bf.labels,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n            actual_title = title if title else (bf.label or default_title)\n            ax.set(\n                ylabel=ylabel,\n                xlabel=xlabel,\n                title=actual_title,\n                **ax_set,\n            )\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    label=ch_meta.label,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(\n                    ylabel=ylabel,\n                    title=ch_meta.label,\n                    xlabel=xlabel,\n                    **ax_set,\n                )\n            axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n            fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'noct'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.step(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>N-octave band analysis plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"NOctFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"N-octave band analysis plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n\n    if is_aw:\n        unit = \"dBrA\"\n        data = bf.dBA\n    else:\n        unit = \"dBr\"\n        data = bf.dB\n    data = _reshape_to_2d(data)\n    ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n        actual_title = title if title else (bf.label or default_title)\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=actual_title,\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.SpectrogramPlotStrategy","title":"<code>SpectrogramPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectrogramFrame']</code></p> <p>Strategy for spectrogram plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class SpectrogramPlotStrategy(PlotStrategy[\"SpectrogramFrame\"]):\n    \"\"\"Strategy for spectrogram plotting\"\"\"\n\n    name = \"spectrogram\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass\n\n    def plot(\n        self,\n        bf: \"SpectrogramFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Spectrogram plotting\"\"\"\n        # Explicit overlay mode is not supported for spectrograms\n        if overlay:\n            raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n        # If an Axes is provided, allow drawing into it only for single-channel frames\n        if ax is not None and bf.n_channels &gt; 1:\n            raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n        kwargs = kwargs or {}\n\n        is_aw = kwargs.pop(\"Aw\", False)\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        data = _reshape_spectrogram_data(data)\n        specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n        ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n        cmap = kwargs.pop(\"cmap\", \"jet\")\n        vmin = kwargs.pop(\"vmin\", None)\n        vmax = kwargs.pop(\"vmax\", None)\n\n        if ax is not None:\n            img = display.specshow(\n                data=data[0],\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                cmap=cmap,\n                ax=ax,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax.set(\n                title=title or bf.label or \"Spectrogram\",\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n\n            fig = ax.figure\n            if fig is not None:\n                try:\n                    cbar = fig.colorbar(img, ax=ax)\n                    cbar.set_label(f\"Spectrum level [{unit}]\")\n                except (ValueError, AttributeError) as e:\n                    # Handle case where img doesn't have proper colorbar properties\n                    logger.warning(\n                        f\"Failed to create colorbar for spectrogram: \"\n                        f\"{type(e).__name__}: {e}\"\n                    )\n            return ax\n\n        else:\n            # Create a new figure if ax is None\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n            )\n            if not isinstance(fig, Figure):\n                raise ValueError(\"fig must be a matplotlib Figure object.\")\n            # Convert axs to array if it is a single Axes object\n            if not isinstance(axs, np.ndarray):\n                axs = np.array([axs])\n\n            for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n                img = display.specshow(\n                    data=channel_data,\n                    sr=bf.sampling_rate,\n                    hop_length=bf.hop_length,\n                    n_fft=bf.n_fft,\n                    win_length=bf.win_length,\n                    x_axis=\"time\",\n                    y_axis=\"linear\",\n                    ax=ax_i,\n                    cmap=cmap,\n                    vmin=vmin,\n                    vmax=vmax,\n                    **specshow_kwargs,\n                )\n                ax_i.set(\n                    title=ch_meta.label,\n                    ylabel=\"Frequency [Hz]\",\n                    xlabel=\"Time [s]\",\n                    **ax_set_kwargs,\n                )\n                try:\n                    cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                    cbar.set_label(f\"Spectrum level [{unit}]\")\n                except (ValueError, AttributeError) as e:\n                    # Handle case where img doesn't have proper colorbar properties\n                    logger.warning(\n                        f\"Failed to create colorbar for spectrogram: \"\n                        f\"{type(e).__name__}: {e}\"\n                    )\n                fig.suptitle(title or \"Spectrogram Data\")\n            plt.tight_layout()\n            plt.show()\n\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'spectrogram'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Spectrogram plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectrogramFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Spectrogram plotting\"\"\"\n    # Explicit overlay mode is not supported for spectrograms\n    if overlay:\n        raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n    # If an Axes is provided, allow drawing into it only for single-channel frames\n    if ax is not None and bf.n_channels &gt; 1:\n        raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n    kwargs = kwargs or {}\n\n    is_aw = kwargs.pop(\"Aw\", False)\n    if is_aw:\n        unit = \"dBA\"\n        data = bf.dBA\n    else:\n        unit = \"dB\"\n        data = bf.dB\n    data = _reshape_spectrogram_data(data)\n    specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n    ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n\n    if ax is not None:\n        img = display.specshow(\n            data=data[0],\n            sr=bf.sampling_rate,\n            hop_length=bf.hop_length,\n            n_fft=bf.n_fft,\n            win_length=bf.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            cmap=cmap,\n            ax=ax,\n            vmin=vmin,\n            vmax=vmax,\n            **specshow_kwargs,\n        )\n        ax.set(\n            title=title or bf.label or \"Spectrogram\",\n            ylabel=\"Frequency [Hz]\",\n            xlabel=\"Time [s]\",\n            **ax_set_kwargs,\n        )\n\n        fig = ax.figure\n        if fig is not None:\n            try:\n                cbar = fig.colorbar(img, ax=ax)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n        return ax\n\n    else:\n        # Create a new figure if ax is None\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n        )\n        if not isinstance(fig, Figure):\n            raise ValueError(\"fig must be a matplotlib Figure object.\")\n        # Convert axs to array if it is a single Axes object\n        if not isinstance(axs, np.ndarray):\n            axs = np.array([axs])\n\n        for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n            img = display.specshow(\n                data=channel_data,\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                ax=ax_i,\n                cmap=cmap,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax_i.set(\n                title=ch_meta.label,\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n            try:\n                cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n            fig.suptitle(title or \"Spectrogram Data\")\n        plt.tight_layout()\n        plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.DescribePlotStrategy","title":"<code>DescribePlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['ChannelFrame']</code></p> <p>Strategy for visualizing ChannelFrame data with describe plot</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class DescribePlotStrategy(PlotStrategy[\"ChannelFrame\"]):\n    \"\"\"Strategy for visualizing ChannelFrame data with describe plot\"\"\"\n\n    name = \"describe\"\n\n    def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass  # This method is not used for describe plot\n\n    def plot(\n        self,\n        bf: \"ChannelFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n        fmin = kwargs.pop(\"fmin\", 0)\n        fmax = kwargs.pop(\"fmax\", None)\n        cmap = kwargs.pop(\"cmap\", \"jet\")\n        vmin = kwargs.pop(\"vmin\", None)\n        vmax = kwargs.pop(\"vmax\", None)\n        xlim = kwargs.pop(\"xlim\", None)\n        ylim = kwargs.pop(\"ylim\", None)\n        is_aw = kwargs.pop(\"Aw\", False)\n        waveform = kwargs.pop(\"waveform\", {})\n        spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n        gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n        gs.update(wspace=0.2)\n\n        fig = plt.figure(figsize=(12, 6))\n        fig.subplots_adjust(wspace=0.0001)\n\n        # First subplot (Time Plot)\n        ax_1 = fig.add_subplot(gs[0])\n        bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n        ax_1.set(**waveform)\n        ax_1.legend().set_visible(False)\n        ax_1.set(xlabel=\"\", title=\"\")\n\n        # Second subplot (STFT Plot)\n        ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n        stft_ch = bf.stft()\n        if is_aw:\n            unit = \"dBA\"\n            channel_data = stft_ch.dBA\n        else:\n            unit = \"dB\"\n            channel_data = stft_ch.dB\n        if channel_data.ndim == 3:\n            channel_data = channel_data[0]\n        # Get the maximum value of the data and round it to a convenient value\n        if vmax is None:\n            data_max = np.nanmax(channel_data)\n            # Round to a convenient number with increments of 10, 5, or 2\n            for step in [10, 5, 2]:\n                rounded_max = np.ceil(data_max / step) * step\n                if rounded_max &gt;= data_max:\n                    vmax = rounded_max\n                    vmin = vmax - 180\n                    break\n        img = display.specshow(\n            data=channel_data,\n            sr=bf.sampling_rate,\n            hop_length=stft_ch.hop_length,\n            n_fft=stft_ch.n_fft,\n            win_length=stft_ch.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            ax=ax_2,\n            fmin=fmin,\n            fmax=fmax,\n            cmap=cmap,\n            vmin=vmin,\n            vmax=vmax,\n        )\n        ax_2.set(xlim=xlim, ylim=ylim)\n\n        # Third subplot\n        ax_3 = fig.add_subplot(gs[1])\n        ax_3.axis(\"off\")\n\n        # Fourth subplot (Welch Plot)\n        ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n        welch_ch = bf.welch()\n        if is_aw:\n            unit = \"dBA\"\n            data_db = welch_ch.dBA\n        else:\n            unit = \"dB\"\n            data_db = welch_ch.dB\n        ax_4.plot(data_db.T, welch_ch.freqs.T)\n        ax_4.grid(True)\n        ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n        cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n        cbar.set_label(unit)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'describe'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass  # This method is not used for describe plot\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Implementation of describe method for visualizing ChannelFrame data</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n    fmin = kwargs.pop(\"fmin\", 0)\n    fmax = kwargs.pop(\"fmax\", None)\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n    xlim = kwargs.pop(\"xlim\", None)\n    ylim = kwargs.pop(\"ylim\", None)\n    is_aw = kwargs.pop(\"Aw\", False)\n    waveform = kwargs.pop(\"waveform\", {})\n    spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n    gs.update(wspace=0.2)\n\n    fig = plt.figure(figsize=(12, 6))\n    fig.subplots_adjust(wspace=0.0001)\n\n    # First subplot (Time Plot)\n    ax_1 = fig.add_subplot(gs[0])\n    bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n    ax_1.set(**waveform)\n    ax_1.legend().set_visible(False)\n    ax_1.set(xlabel=\"\", title=\"\")\n\n    # Second subplot (STFT Plot)\n    ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n    stft_ch = bf.stft()\n    if is_aw:\n        unit = \"dBA\"\n        channel_data = stft_ch.dBA\n    else:\n        unit = \"dB\"\n        channel_data = stft_ch.dB\n    if channel_data.ndim == 3:\n        channel_data = channel_data[0]\n    # Get the maximum value of the data and round it to a convenient value\n    if vmax is None:\n        data_max = np.nanmax(channel_data)\n        # Round to a convenient number with increments of 10, 5, or 2\n        for step in [10, 5, 2]:\n            rounded_max = np.ceil(data_max / step) * step\n            if rounded_max &gt;= data_max:\n                vmax = rounded_max\n                vmin = vmax - 180\n                break\n    img = display.specshow(\n        data=channel_data,\n        sr=bf.sampling_rate,\n        hop_length=stft_ch.hop_length,\n        n_fft=stft_ch.n_fft,\n        win_length=stft_ch.win_length,\n        x_axis=\"time\",\n        y_axis=\"linear\",\n        ax=ax_2,\n        fmin=fmin,\n        fmax=fmax,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n    ax_2.set(xlim=xlim, ylim=ylim)\n\n    # Third subplot\n    ax_3 = fig.add_subplot(gs[1])\n    ax_3.axis(\"off\")\n\n    # Fourth subplot (Welch Plot)\n    ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n    welch_ch = bf.welch()\n    if is_aw:\n        unit = \"dBA\"\n        data_db = welch_ch.dBA\n    else:\n        unit = \"dB\"\n        data_db = welch_ch.dB\n    ax_4.plot(data_db.T, welch_ch.freqs.T)\n    ax_4.grid(True)\n    ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n    cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n    cbar.set_label(unit)\n    fig.suptitle(title or bf.label or \"Channel Data\")\n\n    return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.MatrixPlotStrategy","title":"<code>MatrixPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectralFrame']</code></p> <p>Strategy for displaying relationships between channels in matrix format</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class MatrixPlotStrategy(PlotStrategy[\"SpectralFrame\"]):\n    \"\"\"Strategy for displaying relationships between channels in matrix format\"\"\"\n\n    name = \"matrix\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        title: str | None = None,\n        ylabel: str = \"\",\n        xlabel: str = \"Frequency [Hz]\",\n        alpha: float = 0,\n        **kwargs: Any,\n    ) -&gt; None:\n        ax.plot(x, y, **kwargs)\n        ax.grid(True)\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.set_title(title or \"\")\n\n    def plot(\n        self,\n        bf: \"SpectralFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n        if (\n            len(bf.operation_history) &gt; 0\n            and bf.operation_history[-1][\"operation\"] == \"coherence\"\n        ):\n            unit = \"\"\n            data = bf.magnitude\n            ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n        else:\n            if is_aw:\n                unit = \"dBA\"\n                data = bf.dBA\n            else:\n                unit = \"dB\"\n                data = bf.dB\n            ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n        data = _reshape_to_2d(data)\n\n        xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        num_channels = bf.n_channels\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n            else:\n                fig = ax.figure\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n                title=title or bf.label or \"Spectral Data\",\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax.set(**ax_set)\n            if fig is not None:\n                fig.suptitle(title or bf.label or \"Spectral Data\")\n            if ax.figure != fig:  # Only show if we created the figure\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_rows = int(np.ceil(np.sqrt(num_channels)))\n            fig, axs = plt.subplots(\n                num_rows,\n                num_rows,\n                figsize=(3 * num_rows, 3 * num_rows),\n                sharex=True,\n                sharey=True,\n            )\n            if isinstance(axs, np.ndarray):\n                axes_list = axs.flatten().tolist()\n            elif isinstance(axs, list):\n                import itertools\n\n                axes_list = list(itertools.chain.from_iterable(axs))\n            else:\n                axes_list = [axs]\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    title=ch_meta.label,\n                    ylabel=ylabel,\n                    xlabel=xlabel,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(**ax_set)\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n            plt.tight_layout()\n            plt.show()\n            return _return_axes_iterator(fig.axes)\n\n        raise NotImplementedError()\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'matrix'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, title=None, ylabel='', xlabel='Frequency [Hz]', alpha=0, **kwargs)</code> \u00b6 Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    title: str | None = None,\n    ylabel: str = \"\",\n    xlabel: str = \"Frequency [Hz]\",\n    alpha: float = 0,\n    **kwargs: Any,\n) -&gt; None:\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_title(title or \"\")\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n    data = _reshape_to_2d(data)\n\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    num_channels = bf.n_channels\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n        else:\n            fig = ax.figure\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n            title=title or bf.label or \"Spectral Data\",\n            ylabel=ylabel,\n            xlabel=xlabel,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(**ax_set)\n        if fig is not None:\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n        if ax.figure != fig:  # Only show if we created the figure\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_rows = int(np.ceil(np.sqrt(num_channels)))\n        fig, axs = plt.subplots(\n            num_rows,\n            num_rows,\n            figsize=(3 * num_rows, 3 * num_rows),\n            sharex=True,\n            sharey=True,\n        )\n        if isinstance(axs, np.ndarray):\n            axes_list = axs.flatten().tolist()\n        elif isinstance(axs, list):\n            import itertools\n\n            axes_list = list(itertools.chain.from_iterable(axs))\n        else:\n            axes_list = [axs]\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                title=ch_meta.label,\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(**ax_set)\n        fig.suptitle(title or bf.label or \"Spectral Data\")\n        plt.tight_layout()\n        plt.show()\n        return _return_axes_iterator(fig.axes)\n\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/#wandas.visualization.plotting-functions","title":"Functions","text":""},{"location":"api/#wandas.visualization.plotting.register_plot_strategy","title":"<code>register_plot_strategy(strategy_cls)</code>","text":"<p>Register a new plot strategy from a class</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def register_plot_strategy(strategy_cls: type) -&gt; None:\n    \"\"\"Register a new plot strategy from a class\"\"\"\n    if not issubclass(strategy_cls, PlotStrategy):\n        raise TypeError(\"Strategy class must inherit from PlotStrategy.\")\n    if inspect.isabstract(strategy_cls):\n        raise TypeError(\"Cannot register abstract PlotStrategy class.\")\n    _plot_strategies[strategy_cls.name] = strategy_cls\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.get_plot_strategy","title":"<code>get_plot_strategy(name)</code>","text":"<p>Get plot strategy by name</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def get_plot_strategy(name: str) -&gt; type[PlotStrategy[Any]]:\n    \"\"\"Get plot strategy by name\"\"\"\n    if name not in _plot_strategies:\n        raise ValueError(f\"Unknown plot type: {name}\")\n    return _plot_strategies[name]\n</code></pre>"},{"location":"api/#wandas.visualization.plotting.create_operation","title":"<code>create_operation(name, **params)</code>","text":"<p>Create operation instance from operation name and parameters</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def create_operation(name: str, **params: Any) -&gt; PlotStrategy[Any]:\n    \"\"\"Create operation instance from operation name and parameters\"\"\"\n    operation_class = get_plot_strategy(name)\n    return operation_class(**params)\n</code></pre>"},{"location":"api/#wandas.visualization.types","title":"<code>types</code>","text":"<p>Type definitions for visualization parameters.</p>"},{"location":"api/#wandas.visualization.types-classes","title":"Classes","text":""},{"location":"api/#wandas.visualization.types.WaveformConfig","title":"<code>WaveformConfig</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration for waveform plot in describe view.</p> <p>This corresponds to the time-domain plot shown at the top of the describe view.</p> Source code in <code>wandas/visualization/types.py</code> <pre><code>class WaveformConfig(TypedDict, total=False):\n    \"\"\"Configuration for waveform plot in describe view.\n\n    This corresponds to the time-domain plot shown at the top of the\n    describe view.\n    \"\"\"\n\n    xlabel: str\n    ylabel: str\n    xlim: tuple[float, float]\n    ylim: tuple[float, float]\n</code></pre> Attributes\u00b6 <code></code> <code>xlabel</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ylabel</code> <code>instance-attribute</code> \u00b6 <code></code> <code>xlim</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ylim</code> <code>instance-attribute</code> \u00b6"},{"location":"api/#wandas.visualization.types.SpectralConfig","title":"<code>SpectralConfig</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration for spectral plot in describe view.</p> <p>This corresponds to the frequency-domain plot (Welch) shown on the right side.</p> Source code in <code>wandas/visualization/types.py</code> <pre><code>class SpectralConfig(TypedDict, total=False):\n    \"\"\"Configuration for spectral plot in describe view.\n\n    This corresponds to the frequency-domain plot (Welch) shown on the\n    right side.\n    \"\"\"\n\n    xlabel: str\n    ylabel: str\n    xlim: tuple[float, float]\n    ylim: tuple[float, float]\n</code></pre> Attributes\u00b6 <code></code> <code>xlabel</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ylabel</code> <code>instance-attribute</code> \u00b6 <code></code> <code>xlim</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ylim</code> <code>instance-attribute</code> \u00b6"},{"location":"api/#wandas.visualization.types.DescribeParams","title":"<code>DescribeParams</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters for the describe visualization method.</p> <p>This visualization creates a comprehensive view with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>Attributes:</p> Name Type Description <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency</p> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots.</p> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots.</p> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>waveform</code> <code>WaveformConfig</code> <p>Additional configuration dict for waveform subplot.</p> <code>spectral</code> <code>SpectralConfig</code> <p>Additional configuration dict for spectral subplot.</p> <code>normalize</code> <code>bool</code> <p>Normalize audio data for playback. Default: True</p> <code>is_close</code> <code>bool</code> <p>Close the figure after displaying. Default: True</p> <p>Deprecated (for backward compatibility):     axis_config: Old configuration format.         Use specific parameters instead.     cbar_config: Old colorbar configuration. Use vmin/vmax instead.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n</code></pre> Source code in <code>wandas/visualization/types.py</code> <pre><code>class DescribeParams(TypedDict, total=False):\n    \"\"\"Parameters for the describe visualization method.\n\n    This visualization creates a comprehensive view with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Attributes:\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency\n        cmap: Colormap for the spectrogram. Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n        Aw: Apply A-weighting to the frequency analysis. Default: False\n        waveform: Additional configuration dict for waveform subplot.\n        spectral: Additional configuration dict for spectral subplot.\n        normalize: Normalize audio data for playback. Default: True\n        is_close: Close the figure after displaying. Default: True\n\n    Deprecated (for backward compatibility):\n        axis_config: Old configuration format.\n            Use specific parameters instead.\n        cbar_config: Old colorbar configuration. Use vmin/vmax instead.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n    \"\"\"\n\n    # Spectrogram parameters\n    fmin: float\n    fmax: float | None\n    cmap: str\n    vmin: float | None\n    vmax: float | None\n\n    # Axis limits\n    xlim: tuple[float, float] | None\n    ylim: tuple[float, float] | None\n\n    # Weighting\n    Aw: bool\n\n    # Subplot configurations\n    waveform: WaveformConfig\n    spectral: SpectralConfig\n\n    # Display options\n    normalize: bool\n    is_close: bool\n\n    # Deprecated (backward compatibility)\n    axis_config: dict[str, Any]\n    cbar_config: dict[str, Any]\n</code></pre> Attributes\u00b6 <code></code> <code>fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cmap</code> <code>instance-attribute</code> \u00b6 <code></code> <code>vmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>vmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>xlim</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ylim</code> <code>instance-attribute</code> \u00b6 <code></code> <code>Aw</code> <code>instance-attribute</code> \u00b6 <code></code> <code>waveform</code> <code>instance-attribute</code> \u00b6 <code></code> <code>spectral</code> <code>instance-attribute</code> \u00b6 <code></code> <code>normalize</code> <code>instance-attribute</code> \u00b6 <code></code> <code>is_close</code> <code>instance-attribute</code> \u00b6 <code></code> <code>axis_config</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cbar_config</code> <code>instance-attribute</code> \u00b6"},{"location":"api/#_7","title":"\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u3068\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/#wandas.datasets","title":"<code>wandas.datasets</code>","text":""},{"location":"api/#wandas.datasets-modules","title":"Modules","text":""},{"location":"api/#wandas.datasets.sample_data","title":"<code>sample_data</code>","text":""},{"location":"api/#wandas.datasets.sample_data-attributes","title":"Attributes","text":""},{"location":"api/#wandas.datasets.sample_data-functions","title":"Functions","text":""},{"location":"api/#wandas.datasets.sample_data.load_sample_signal","title":"<code>load_sample_signal(frequency=5.0, sampling_rate=100, duration=1.0)</code>","text":"<p>Generate a sample sine wave signal.</p>"},{"location":"api/#wandas.datasets.sample_data.load_sample_signal--parameters","title":"Parameters","text":"<p>frequency : float, default=5.0     Frequency of the signal in Hz. sampling_rate : int, default=100     Sampling rate in Hz. duration : float, default=1.0     Duration of the signal in seconds.</p>"},{"location":"api/#wandas.datasets.sample_data.load_sample_signal--returns","title":"Returns","text":"<p>NDArrayReal     Signal data as a NumPy array.</p> Source code in <code>wandas/datasets/sample_data.py</code> <pre><code>def load_sample_signal(\n    frequency: float = 5.0, sampling_rate: int = 100, duration: float = 1.0\n) -&gt; NDArrayReal:\n    \"\"\"\n    Generate a sample sine wave signal.\n\n    Parameters\n    ----------\n    frequency : float, default=5.0\n        Frequency of the signal in Hz.\n    sampling_rate : int, default=100\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n\n    Returns\n    -------\n    NDArrayReal\n        Signal data as a NumPy array.\n    \"\"\"\n    num_samples = int(sampling_rate * duration)\n    t = np.arange(num_samples) / sampling_rate\n    signal: NDArrayReal = np.sin(2 * np.pi * frequency * t, dtype=np.float64)\n    return signal\n</code></pre>"},{"location":"api/core/","title":"\u30b3\u30a2\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.core</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u57fa\u76e4\u3068\u306a\u308b\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/core/#baseframe","title":"BaseFrame","text":"<p>BaseFrame\u306f\u3059\u3079\u3066\u306eWandas\u30d5\u30ec\u30fc\u30e0\u306e\u57fa\u5e95\u30af\u30e9\u30b9\u3067\u3059\u3002\u3053\u308c\u306f\u57fa\u672c\u7684\u306a\u30c7\u30fc\u30bf\u69cb\u9020\u3068\u64cd\u4f5c\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame","title":"<code>wandas.core.base_frame.BaseFrame</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>Abstract base class for all signal frame types.</p> <p>This class provides the common interface and functionality for all frame types used in signal processing. It implements basic operations like indexing, iteration, and data manipulation that are shared across all frame types.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The signal data to process. Must be a dask array. sampling_rate : float     The sampling rate of the signal in Hz. label : str, optional     A label for the frame. If not provided, defaults to \"unnamed_frame\". metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata | dict], optional     Metadata for each channel in the frame. Can be ChannelMetadata objects     or dicts that will be validated by Pydantic. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame--attributes","title":"Attributes","text":"<p>sampling_rate : float     The sampling rate of the signal in Hz. label : str     The label of the frame. metadata : dict     Additional metadata for the frame. operation_history : list[dict]     History of operations performed on this frame.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>class BaseFrame(ABC, Generic[T]):\n    \"\"\"\n    Abstract base class for all signal frame types.\n\n    This class provides the common interface and functionality for all frame types\n    used in signal processing. It implements basic operations like indexing, iteration,\n    and data manipulation that are shared across all frame types.\n\n    Parameters\n    ----------\n    data : DaArray\n        The signal data to process. Must be a dask array.\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str, optional\n        A label for the frame. If not provided, defaults to \"unnamed_frame\".\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata | dict], optional\n        Metadata for each channel in the frame. Can be ChannelMetadata objects\n        or dicts that will be validated by Pydantic.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str\n        The label of the frame.\n    metadata : dict\n        Additional metadata for the frame.\n    operation_history : list[dict]\n        History of operations performed on this frame.\n    \"\"\"\n\n    _data: DaArray\n    sampling_rate: float\n    label: str\n    metadata: dict[str, Any]\n    operation_history: list[dict[str, Any]]\n    _channel_metadata: list[ChannelMetadata]\n    _previous: Optional[\"BaseFrame[Any]\"]\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ):\n        self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n        if self._data.ndim == 1:\n            self._data = self._data.reshape((1, -1))\n        self.sampling_rate = sampling_rate\n        self.label = label or \"unnamed_frame\"\n        self.metadata = metadata or {}\n        self.operation_history = operation_history or []\n        self._previous = previous\n\n        if channel_metadata:\n            # Pydantic handles both ChannelMetadata objects and dicts\n            def _to_channel_metadata(\n                ch: ChannelMetadata | dict[str, Any], index: int\n            ) -&gt; ChannelMetadata:\n                if isinstance(ch, ChannelMetadata):\n                    return copy.deepcopy(ch)\n                elif isinstance(ch, dict):\n                    try:\n                        return ChannelMetadata(**ch)\n                    except ValidationError as e:\n                        raise ValueError(\n                            f\"Invalid channel_metadata at index {index}\\n\"\n                            f\"  Got: {ch}\\n\"\n                            f\"  Validation error: {e}\\n\"\n                            f\"Ensure all dict keys match ChannelMetadata fields \"\n                            f\"(label, unit, ref, extra) and have correct types.\"\n                        ) from e\n                else:\n                    raise TypeError(\n                        f\"Invalid type in channel_metadata at index {index}\\n\"\n                        f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                        f\"  Expected: ChannelMetadata or dict\\n\"\n                        f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                    )\n\n            self._channel_metadata = [\n                _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n                for i, ch in enumerate(channel_metadata)\n            ]\n        else:\n            self._channel_metadata = [\n                ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n                for i in range(self._n_channels)\n            ]\n\n        try:\n            # Display information for newer dask versions\n            logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n            logger.debug(\n                f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n            )\n        except Exception as e:\n            logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n\n    @property\n    @abstractmethod\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n\n    @property\n    def n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return self._n_channels\n\n    @property\n    def channels(self) -&gt; list[ChannelMetadata]:\n        \"\"\"Property to access channel metadata.\"\"\"\n        return self._channel_metadata\n\n    @property\n    def previous(self) -&gt; Optional[\"BaseFrame[Any]\"]:\n        \"\"\"\n        Returns the previous frame.\n        \"\"\"\n        return self._previous\n\n    def get_channel(\n        self: S,\n        channel_idx: int\n        | list[int]\n        | tuple[int, ...]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index.\n\n        Parameters\n        ----------\n        channel_idx : int or sequence of int\n            Single channel index or sequence of channel indices.\n            Supports negative indices (e.g., -1 for the last channel).\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n        &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n        &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n        &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n        \"\"\"\n        if isinstance(channel_idx, int):\n            # Convert single channel to a list.\n            channel_idx_list: list[int] = [channel_idx]\n        else:\n            channel_idx_list = list(channel_idx)\n\n        new_data = self._data[channel_idx_list]\n        new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Returns the number of channels.\n        \"\"\"\n        return len(self._channel_metadata)\n\n    def __iter__(self: S) -&gt; Iterator[S]:\n        for idx in range(len(self)):\n            yield self[idx]\n\n    def __getitem__(\n        self: S,\n        key: int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index, label, or advanced indexing.\n\n        This method supports multiple indexing patterns similar to NumPy and pandas:\n\n        - Single channel by index: `frame[0]`\n        - Single channel by label: `frame[\"ch0\"]`\n        - Slice of channels: `frame[0:3]`\n        - Multiple channels by indices: `frame[[0, 2, 5]]`\n        - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n        - NumPy integer array: `frame[np.array([0, 2])]`\n        - Boolean mask: `frame[mask]` where mask is a boolean array\n        - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n        Parameters\n        ----------\n        key : int, str, slice, list, tuple, or ndarray\n            - int: Single channel index (supports negative indexing)\n            - str: Single channel label\n            - slice: Range of channels\n            - list[int]: Multiple channel indices\n            - list[str]: Multiple channel labels\n            - tuple: Multidimensional indexing (channel_key, time_key, ...)\n            - ndarray[int]: NumPy array of channel indices\n            - ndarray[bool]: Boolean mask for channel selection\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Raises\n        ------\n        ValueError\n            If the key length is invalid for the shape or if boolean mask\n            length doesn't match number of channels.\n        IndexError\n            If the channel index is out of range.\n        TypeError\n            If the key type is invalid or list contains mixed types.\n        KeyError\n            If a channel label is not found.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Single channel selection\n        &gt;&gt;&gt; frame[0]  # First channel\n        &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n        &gt;&gt;&gt; frame[-1]  # Last channel\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Multiple channel selection\n        &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n        &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n        &gt;&gt;&gt; frame[0:3]  # Slice\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # NumPy array indexing\n        &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n        &gt;&gt;&gt; mask = np.array([True, False, True])\n        &gt;&gt;&gt; frame[mask]  # Boolean mask\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Time slicing (multidimensional)\n        &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n        &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n        \"\"\"\n\n        # Single index (int)\n        if isinstance(key, numbers.Integral):\n            # Ensure we pass a plain Python int to satisfy the type checker\n            return self.get_channel(int(key))\n\n        # Single label (str)\n        if isinstance(key, str):\n            index = self.label2index(key)\n            return self.get_channel(index)\n\n        # Phase 2: NumPy array support (bool mask and int array)\n        if isinstance(key, np.ndarray):\n            if key.dtype == bool or key.dtype == np.bool_:\n                # Boolean mask\n                if len(key) != self.n_channels:\n                    raise ValueError(\n                        f\"Boolean mask length {len(key)} does not match \"\n                        f\"number of channels {self.n_channels}\"\n                    )\n                indices = np.where(key)[0]\n                return self.get_channel(indices)\n            elif np.issubdtype(key.dtype, np.integer):\n                # Integer array\n                return self.get_channel(key)\n            else:\n                raise TypeError(\n                    f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n                )\n\n        # Phase 1: List support (int or str)\n        if isinstance(key, list):\n            if len(key) == 0:\n                raise ValueError(\"Cannot index with an empty list\")\n\n            # Check if all elements are strings\n            if all(isinstance(k, str) for k in key):\n                # Multiple labels - type narrowing for mypy\n                str_list = cast(list[str], key)\n                indices_from_labels = [self.label2index(label) for label in str_list]\n                return self.get_channel(indices_from_labels)\n\n            # Check if all elements are integers\n            elif all(isinstance(k, int | np.integer) for k in key):\n                # Multiple indices - convert to list[int] for type safety\n                int_list = [int(k) for k in key]\n                return self.get_channel(int_list)\n\n            else:\n                raise TypeError(\n                    f\"List must contain all str or all int, got mixed types: \"\n                    f\"{[type(k).__name__ for k in key]}\"\n                )\n\n        # Tuple: multidimensional indexing\n        if isinstance(key, tuple):\n            return self._handle_multidim_indexing(key)\n\n        # Slice\n        if isinstance(key, slice):\n            new_data = self._data[key]\n            new_channel_metadata = self._channel_metadata[key]\n            if isinstance(new_channel_metadata, ChannelMetadata):\n                new_channel_metadata = [new_channel_metadata]\n            return self._create_new_instance(\n                data=new_data,\n                operation_history=self.operation_history,\n                channel_metadata=new_channel_metadata,\n            )\n\n        raise TypeError(\n            f\"Invalid key type: {type(key).__name__}. \"\n            f\"Expected int, str, slice, list, tuple, or ndarray.\"\n        )\n\n    def _handle_multidim_indexing(\n        self: S,\n        key: tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ],\n    ) -&gt; S:\n        \"\"\"\n        Handle multidimensional indexing (channel + time axis).\n\n        Parameters\n        ----------\n        key : tuple\n            Tuple of indices where the first element selects channels\n            and subsequent elements select along other dimensions (e.g., time).\n\n        Returns\n        -------\n        S\n            New instance with selected channels and time range.\n\n        Raises\n        ------\n        ValueError\n            If the key length exceeds the data dimensions.\n        \"\"\"\n        if len(key) &gt; self._data.ndim:\n            raise ValueError(f\"Invalid key length: {len(key)} for shape {self.shape}\")\n\n        # First element: channel selection\n        channel_key = key[0]\n        time_keys = key[1:] if len(key) &gt; 1 else ()\n\n        # Select channels first (recursively call __getitem__)\n        if isinstance(channel_key, list | np.ndarray):\n            selected = self[channel_key]\n        elif isinstance(channel_key, int | str | slice):\n            selected = self[channel_key]\n        else:\n            raise TypeError(\n                f\"Invalid channel key type in tuple: {type(channel_key).__name__}\"\n            )\n\n        # Apply time indexing if present\n        if time_keys:\n            new_data = selected._data[(slice(None),) + time_keys]\n            return selected._create_new_instance(\n                data=new_data,\n                operation_history=selected.operation_history,\n                channel_metadata=selected._channel_metadata,\n            )\n\n        return selected\n\n    def label2index(self, label: str) -&gt; int:\n        \"\"\"\n        Get the index from a channel label.\n\n        Parameters\n        ----------\n        label : str\n            Channel label.\n\n        Returns\n        -------\n        int\n            Corresponding index.\n\n        Raises\n        ------\n        KeyError\n            If the channel label is not found.\n        \"\"\"\n        for idx, ch in enumerate(self._channel_metadata):\n            if ch.label == label:\n                return idx\n        raise KeyError(f\"Channel label '{label}' not found.\")\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        _shape: tuple[int, ...] = self._data.shape\n        if _shape[0] == 1:\n            return _shape[1:]\n        return _shape\n\n    @property\n    def data(self) -&gt; T:\n        \"\"\"\n        Returns the computed data.\n        Calculation is executed the first time this is accessed.\n        \"\"\"\n        data = self.compute()\n        if self.n_channels == 1:\n            return data.squeeze(axis=0)\n        return data\n\n    @property\n    def labels(self) -&gt; list[str]:\n        \"\"\"Get a list of all channel labels.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def compute(self) -&gt; T:\n        \"\"\"\n        Compute and return the data.\n        This method materializes lazily computed data into a concrete NumPy array.\n\n        Returns\n        -------\n        NDArrayReal\n            The computed data.\n\n        Raises\n        ------\n        ValueError\n            If the computed result is not a NumPy array.\n        \"\"\"\n        logger.debug(\n            \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n        )\n        result = self._data.compute()\n\n        if not isinstance(result, np.ndarray):\n            raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n        logger.debug(f\"Computation complete, result shape: {result.shape}\")\n        return cast(T, result)\n\n    @abstractmethod\n    def plot(\n        self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the data\"\"\"\n        pass\n\n    def persist(self: S) -&gt; S:\n        \"\"\"Persist the data in memory\"\"\"\n        persisted_data = self._data.persist()\n        return self._create_new_instance(data=persisted_data)\n\n    @abstractmethod\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Abstract method for derived classes to provide\n        additional initialization arguments.\n        \"\"\"\n        pass\n\n    def _create_new_instance(self: S, data: DaArray, **kwargs: Any) -&gt; S:\n        \"\"\"\n        Create a new channel instance based on an existing channel.\n        Keyword arguments can override or extend the original attributes.\n        \"\"\"\n\n        sampling_rate = kwargs.pop(\"sampling_rate\", self.sampling_rate)\n        # if not isinstance(sampling_rate, int):\n        #     raise TypeError(\"Sampling rate must be an integer\")\n\n        label = kwargs.pop(\"label\", self.label)\n        if not isinstance(label, str):\n            raise TypeError(\"Label must be a string\")\n\n        metadata = kwargs.pop(\"metadata\", copy.deepcopy(self.metadata))\n        if not isinstance(metadata, dict):\n            raise TypeError(\"Metadata must be a dictionary\")\n\n        channel_metadata = kwargs.pop(\n            \"channel_metadata\", copy.deepcopy(self._channel_metadata)\n        )\n        if not isinstance(channel_metadata, list):\n            raise TypeError(\"Channel metadata must be a list\")\n\n        # Get additional initialization arguments from derived classes\n        additional_kwargs = self._get_additional_init_kwargs()\n        kwargs.update(additional_kwargs)\n\n        return type(self)(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            channel_metadata=channel_metadata,\n            previous=self,\n            **kwargs,\n        )\n\n    def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n        \"\"\"Implicit conversion to NumPy array\"\"\"\n        result = self.compute()\n        if dtype is not None:\n            return result.astype(dtype)\n        return result\n\n    def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n        \"\"\"\n        Visualize the computation graph and save it to a file.\n\n        This method creates a visual representation of the Dask computation graph.\n        In Jupyter notebooks, it returns an IPython.display.Image object that\n        will be displayed inline. In other environments, it saves the graph to\n        a file and returns None.\n\n        Parameters\n        ----------\n        filename : str, optional\n            Output filename for the graph image. If None, a unique filename\n            is generated using UUID. The file is saved in the current working\n            directory.\n\n        Returns\n        -------\n        IPython.display.Image or None\n            In Jupyter environments: Returns an IPython.display.Image object\n            that can be displayed inline.\n            In other environments: Returns None after saving the graph to file.\n            Returns None if visualization fails.\n\n        Notes\n        -----\n        This method requires graphviz to be installed on your system:\n        - Ubuntu/Debian: `sudo apt-get install graphviz`\n        - macOS: `brew install graphviz`\n        - Windows: Download from https://graphviz.org/download/\n\n        The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n        making it easier to understand the processing pipeline.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n        &gt;&gt;&gt; # In Jupyter: displays graph inline\n        &gt;&gt;&gt; processed.visualize_graph()\n        &gt;&gt;&gt; # Save to specific file\n        &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n        See Also\n        --------\n        debug_info : Print detailed debug information about the frame\n        \"\"\"\n        try:\n            filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n            return self._data.visualize(filename=filename)\n        except Exception as e:\n            logger.warning(f\"Failed to visualize the graph: {e}\")\n            return None\n\n    @abstractmethod\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"Basic implementation of binary operations\"\"\"\n        # Basic logic\n        # Actual implementation is left to derived classes\n        pass\n\n    def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Addition operator\"\"\"\n        return self._binary_op(other, lambda x, y: x + y, \"+\")\n\n    def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Subtraction operator\"\"\"\n        return self._binary_op(other, lambda x, y: x - y, \"-\")\n\n    def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Multiplication operator\"\"\"\n        return self._binary_op(other, lambda x, y: x * y, \"*\")\n\n    def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Division operator\"\"\"\n        return self._binary_op(other, lambda x, y: x / y, \"/\")\n\n    def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Power operator\"\"\"\n        return self._binary_op(other, lambda x, y: x**y, \"**\")\n\n    def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply a named operation.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters to pass to the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        # Apply the operation through abstract method\n        return self._apply_operation_impl(operation_name, **params)\n\n    @abstractmethod\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"Implementation of operation application\"\"\"\n        pass\n\n    def _relabel_channels(\n        self,\n        operation_name: str,\n        display_name: str | None = None,\n    ) -&gt; list[ChannelMetadata]:\n        \"\"\"\n        Update channel labels to reflect applied operation.\n\n        This method creates new channel metadata with labels that include\n        the operation name, making it easier to track processing history\n        and distinguish frames in plots.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation (e.g., \"normalize\", \"lowpass_filter\")\n        display_name : str, optional\n            Display name for the operation. If None, uses operation_name.\n            This allows operations to provide custom, more readable labels.\n\n        Returns\n        -------\n        list[ChannelMetadata]\n            New channel metadata with updated labels.\n            Original metadata is deep-copied and only labels are modified.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Original label: \"ch0\"\n        &gt;&gt;&gt; # After normalize: \"normalize(ch0)\"\n        &gt;&gt;&gt; # After chained ops: \"lowpass_filter(normalize(ch0))\"\n\n        Notes\n        -----\n        Labels are nested for chained operations, allowing full\n        traceability of the processing pipeline.\n        \"\"\"\n        display = display_name or operation_name\n        new_metadata = []\n        for ch in self._channel_metadata:\n            # All channel metadata are ChannelMetadata objects at this point\n            new_ch = ch.model_copy(deep=True)\n            new_ch.label = f\"{display}({ch.label})\"\n            new_metadata.append(new_ch)\n        return new_metadata\n\n    def debug_info(self) -&gt; None:\n        \"\"\"Output detailed debug information\"\"\"\n        logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n        logger.debug(f\"Label: {self.label}\")\n        logger.debug(f\"Shape: {self.shape}\")\n        logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n        logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n        self._debug_info_impl()\n        logger.debug(\"=== End Debug Info ===\")\n\n    def print_operation_history(self) -&gt; None:\n        \"\"\"\n        Print the operation history to standard output in a readable format.\n\n        This method writes a human-friendly representation of the\n        `operation_history` list to stdout. Each operation is printed on its\n        own line with an index, the operation name (if available), and the\n        parameters used.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf.print_operation_history()\n        1: normalize {}\n        2: low_pass_filter {'cutoff': 1000}\n        \"\"\"\n        if not self.operation_history:\n            print(\"Operation history: &lt;empty&gt;\")\n            return\n\n        print(f\"Operation history ({len(self.operation_history)}):\")\n        for i, record in enumerate(self.operation_history, start=1):\n            # record is expected to be a dict with at least a 'operation' key\n            op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n            # Copy params for display - exclude the 'operation'/'name' keys\n            params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n            print(f\"{i}: {op_name} {params}\")\n\n    def to_numpy(self) -&gt; T:\n        \"\"\"Convert the frame data to a NumPy array.\n\n        This method computes the Dask array and returns it as a concrete NumPy array.\n        The returned array has the same shape as the frame's data.\n\n        Returns\n        -------\n        T\n            NumPy array containing the frame data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; data = cf.to_numpy()\n        &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n        \"\"\"\n        return self.data\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"Convert the frame data to a pandas DataFrame.\n\n        This method provides a common implementation for converting frame data\n        to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame with appropriate index and columns.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; df = cf.to_dataframe()\n        &gt;&gt;&gt; print(df.head())\n        \"\"\"\n        # Get data as numpy array\n        data = self.to_numpy()\n\n        # Get column names from subclass\n        columns = self._get_dataframe_columns()\n\n        # Get index from subclass\n        index = self._get_dataframe_index()\n\n        # Create DataFrame\n        if data.ndim == 1:\n            # Single channel case - reshape to 2D\n            df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n        else:\n            # Multi-channel case - transpose to (n_samples, n_channels)\n            df = pd.DataFrame(data.T, columns=columns, index=index)\n\n        return df\n\n    @abstractmethod\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get column names for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate column names for the DataFrame.\n\n        Returns\n        -------\n        list[str]\n            List of column names.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get index for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate index for the DataFrame based on the frame type.\n\n        Returns\n        -------\n        pd.Index\n            Index for the DataFrame.\n        \"\"\"\n        pass\n\n    def _debug_info_impl(self) -&gt; None:\n        \"\"\"Implement derived class-specific debug information\"\"\"\n        pass\n\n    def _print_operation_history(self) -&gt; None:\n        \"\"\"Print the operation history information.\n\n        This is a helper method for info() implementations to display\n        the number of operations applied to the frame in a consistent format.\n        \"\"\"\n        if self.operation_history:\n            print(f\"  Operations Applied: {len(self.operation_history)}\")\n        else:\n            print(\"  Operations Applied: None\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame-attributes","title":"Attributes","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.sampling_rate","title":"<code>sampling_rate = sampling_rate</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.label","title":"<code>label = label or 'unnamed_frame'</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.metadata","title":"<code>metadata = metadata or {}</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.operation_history","title":"<code>operation_history = operation_history or []</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.n_channels","title":"<code>n_channels</code>  <code>property</code>","text":"<p>Returns the number of channels.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.channels","title":"<code>channels</code>  <code>property</code>","text":"<p>Property to access channel metadata.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.previous","title":"<code>previous</code>  <code>property</code>","text":"<p>Returns the previous frame.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.shape","title":"<code>shape</code>  <code>property</code>","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.data","title":"<code>data</code>  <code>property</code>","text":"<p>Returns the computed data. Calculation is executed the first time this is accessed.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.labels","title":"<code>labels</code>  <code>property</code>","text":"<p>Get a list of all channel labels.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame-functions","title":"Functions","text":""},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n):\n    self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n    if self._data.ndim == 1:\n        self._data = self._data.reshape((1, -1))\n    self.sampling_rate = sampling_rate\n    self.label = label or \"unnamed_frame\"\n    self.metadata = metadata or {}\n    self.operation_history = operation_history or []\n    self._previous = previous\n\n    if channel_metadata:\n        # Pydantic handles both ChannelMetadata objects and dicts\n        def _to_channel_metadata(\n            ch: ChannelMetadata | dict[str, Any], index: int\n        ) -&gt; ChannelMetadata:\n            if isinstance(ch, ChannelMetadata):\n                return copy.deepcopy(ch)\n            elif isinstance(ch, dict):\n                try:\n                    return ChannelMetadata(**ch)\n                except ValidationError as e:\n                    raise ValueError(\n                        f\"Invalid channel_metadata at index {index}\\n\"\n                        f\"  Got: {ch}\\n\"\n                        f\"  Validation error: {e}\\n\"\n                        f\"Ensure all dict keys match ChannelMetadata fields \"\n                        f\"(label, unit, ref, extra) and have correct types.\"\n                    ) from e\n            else:\n                raise TypeError(\n                    f\"Invalid type in channel_metadata at index {index}\\n\"\n                    f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                    f\"  Expected: ChannelMetadata or dict\\n\"\n                    f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                )\n\n        self._channel_metadata = [\n            _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n            for i, ch in enumerate(channel_metadata)\n        ]\n    else:\n        self._channel_metadata = [\n            ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n            for i in range(self._n_channels)\n        ]\n\n    try:\n        # Display information for newer dask versions\n        logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n        logger.debug(\n            f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n        )\n    except Exception as e:\n        logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.get_channel","title":"<code>get_channel(channel_idx)</code>","text":"<p>Get channel(s) by index.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.get_channel--parameters","title":"Parameters","text":"<p>channel_idx : int or sequence of int     Single channel index or sequence of channel indices.     Supports negative indices (e.g., -1 for the last channel).</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.get_channel--returns","title":"Returns","text":"<p>S     New instance containing the selected channel(s).</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.get_channel--examples","title":"Examples","text":"<p>frame.get_channel(0)  # Single channel frame.get_channel([0, 2, 3])  # Multiple channels frame.get_channel((-1, -2))  # Last two channels frame.get_channel(np.array([1, 2]))  # NumPy array of indices</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def get_channel(\n    self: S,\n    channel_idx: int\n    | list[int]\n    | tuple[int, ...]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index.\n\n    Parameters\n    ----------\n    channel_idx : int or sequence of int\n        Single channel index or sequence of channel indices.\n        Supports negative indices (e.g., -1 for the last channel).\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n    &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n    &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n    &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n    \"\"\"\n    if isinstance(channel_idx, int):\n        # Convert single channel to a list.\n        channel_idx_list: list[int] = [channel_idx]\n    else:\n        channel_idx_list = list(channel_idx)\n\n    new_data = self._data[channel_idx_list]\n    new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n    return self._create_new_instance(\n        data=new_data,\n        operation_history=self.operation_history,\n        channel_metadata=new_channel_metadata,\n    )\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of channels.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of channels.\n    \"\"\"\n    return len(self._channel_metadata)\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__iter__","title":"<code>__iter__()</code>","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __iter__(self: S) -&gt; Iterator[S]:\n    for idx in range(len(self)):\n        yield self[idx]\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get channel(s) by index, label, or advanced indexing.</p> <p>This method supports multiple indexing patterns similar to NumPy and pandas:</p> <ul> <li>Single channel by index: <code>frame[0]</code></li> <li>Single channel by label: <code>frame[\"ch0\"]</code></li> <li>Slice of channels: <code>frame[0:3]</code></li> <li>Multiple channels by indices: <code>frame[[0, 2, 5]]</code></li> <li>Multiple channels by labels: <code>frame[[\"ch0\", \"ch2\"]]</code></li> <li>NumPy integer array: <code>frame[np.array([0, 2])]</code></li> <li>Boolean mask: <code>frame[mask]</code> where mask is a boolean array</li> <li>Multidimensional indexing: <code>frame[0, 100:200]</code> (channel + time)</li> </ul>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--parameters","title":"Parameters","text":"<p>key : int, str, slice, list, tuple, or ndarray     - int: Single channel index (supports negative indexing)     - str: Single channel label     - slice: Range of channels     - list[int]: Multiple channel indices     - list[str]: Multiple channel labels     - tuple: Multidimensional indexing (channel_key, time_key, ...)     - ndarray[int]: NumPy array of channel indices     - ndarray[bool]: Boolean mask for channel selection</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--returns","title":"Returns","text":"<p>S     New instance containing the selected channel(s).</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--raises","title":"Raises","text":"<p>ValueError     If the key length is invalid for the shape or if boolean mask     length doesn't match number of channels. IndexError     If the channel index is out of range. TypeError     If the key type is invalid or list contains mixed types. KeyError     If a channel label is not found.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--examples","title":"Examples","text":"Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __getitem__(\n    self: S,\n    key: int\n    | str\n    | slice\n    | list[int]\n    | list[str]\n    | tuple[\n        int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n        ...,\n    ]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index, label, or advanced indexing.\n\n    This method supports multiple indexing patterns similar to NumPy and pandas:\n\n    - Single channel by index: `frame[0]`\n    - Single channel by label: `frame[\"ch0\"]`\n    - Slice of channels: `frame[0:3]`\n    - Multiple channels by indices: `frame[[0, 2, 5]]`\n    - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n    - NumPy integer array: `frame[np.array([0, 2])]`\n    - Boolean mask: `frame[mask]` where mask is a boolean array\n    - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n    Parameters\n    ----------\n    key : int, str, slice, list, tuple, or ndarray\n        - int: Single channel index (supports negative indexing)\n        - str: Single channel label\n        - slice: Range of channels\n        - list[int]: Multiple channel indices\n        - list[str]: Multiple channel labels\n        - tuple: Multidimensional indexing (channel_key, time_key, ...)\n        - ndarray[int]: NumPy array of channel indices\n        - ndarray[bool]: Boolean mask for channel selection\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Raises\n    ------\n    ValueError\n        If the key length is invalid for the shape or if boolean mask\n        length doesn't match number of channels.\n    IndexError\n        If the channel index is out of range.\n    TypeError\n        If the key type is invalid or list contains mixed types.\n    KeyError\n        If a channel label is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Single channel selection\n    &gt;&gt;&gt; frame[0]  # First channel\n    &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n    &gt;&gt;&gt; frame[-1]  # Last channel\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Multiple channel selection\n    &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n    &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n    &gt;&gt;&gt; frame[0:3]  # Slice\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # NumPy array indexing\n    &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n    &gt;&gt;&gt; mask = np.array([True, False, True])\n    &gt;&gt;&gt; frame[mask]  # Boolean mask\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Time slicing (multidimensional)\n    &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n    &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n    \"\"\"\n\n    # Single index (int)\n    if isinstance(key, numbers.Integral):\n        # Ensure we pass a plain Python int to satisfy the type checker\n        return self.get_channel(int(key))\n\n    # Single label (str)\n    if isinstance(key, str):\n        index = self.label2index(key)\n        return self.get_channel(index)\n\n    # Phase 2: NumPy array support (bool mask and int array)\n    if isinstance(key, np.ndarray):\n        if key.dtype == bool or key.dtype == np.bool_:\n            # Boolean mask\n            if len(key) != self.n_channels:\n                raise ValueError(\n                    f\"Boolean mask length {len(key)} does not match \"\n                    f\"number of channels {self.n_channels}\"\n                )\n            indices = np.where(key)[0]\n            return self.get_channel(indices)\n        elif np.issubdtype(key.dtype, np.integer):\n            # Integer array\n            return self.get_channel(key)\n        else:\n            raise TypeError(\n                f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n            )\n\n    # Phase 1: List support (int or str)\n    if isinstance(key, list):\n        if len(key) == 0:\n            raise ValueError(\"Cannot index with an empty list\")\n\n        # Check if all elements are strings\n        if all(isinstance(k, str) for k in key):\n            # Multiple labels - type narrowing for mypy\n            str_list = cast(list[str], key)\n            indices_from_labels = [self.label2index(label) for label in str_list]\n            return self.get_channel(indices_from_labels)\n\n        # Check if all elements are integers\n        elif all(isinstance(k, int | np.integer) for k in key):\n            # Multiple indices - convert to list[int] for type safety\n            int_list = [int(k) for k in key]\n            return self.get_channel(int_list)\n\n        else:\n            raise TypeError(\n                f\"List must contain all str or all int, got mixed types: \"\n                f\"{[type(k).__name__ for k in key]}\"\n            )\n\n    # Tuple: multidimensional indexing\n    if isinstance(key, tuple):\n        return self._handle_multidim_indexing(key)\n\n    # Slice\n    if isinstance(key, slice):\n        new_data = self._data[key]\n        new_channel_metadata = self._channel_metadata[key]\n        if isinstance(new_channel_metadata, ChannelMetadata):\n            new_channel_metadata = [new_channel_metadata]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    raise TypeError(\n        f\"Invalid key type: {type(key).__name__}. \"\n        f\"Expected int, str, slice, list, tuple, or ndarray.\"\n    )\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--single-channel-selection","title":"Single channel selection","text":"<p>frame[0]  # First channel frame[\"acc_x\"]  # By label frame[-1]  # Last channel</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--multiple-channel-selection","title":"Multiple channel selection","text":"<p>frame[[0, 2, 5]]  # Multiple indices frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels frame[0:3]  # Slice</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--numpy-array-indexing","title":"NumPy array indexing","text":"<p>frame[np.array([0, 2, 4])]  # Integer array mask = np.array([True, False, True]) frame[mask]  # Boolean mask</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__getitem__--time-slicing-multidimensional","title":"Time slicing (multidimensional)","text":"<p>frame[0, 100:200]  # Channel 0, samples 100-200 frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.label2index","title":"<code>label2index(label)</code>","text":"<p>Get the index from a channel label.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.label2index--parameters","title":"Parameters","text":"<p>label : str     Channel label.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.label2index--returns","title":"Returns","text":"<p>int     Corresponding index.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.label2index--raises","title":"Raises","text":"<p>KeyError     If the channel label is not found.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n\n    Parameters\n    ----------\n    label : str\n        Channel label.\n\n    Returns\n    -------\n    int\n        Corresponding index.\n\n    Raises\n    ------\n    KeyError\n        If the channel label is not found.\n    \"\"\"\n    for idx, ch in enumerate(self._channel_metadata):\n        if ch.label == label:\n            return idx\n    raise KeyError(f\"Channel label '{label}' not found.\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.compute","title":"<code>compute()</code>","text":"<p>Compute and return the data. This method materializes lazily computed data into a concrete NumPy array.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.compute--returns","title":"Returns","text":"<p>NDArrayReal     The computed data.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.compute--raises","title":"Raises","text":"<p>ValueError     If the computed result is not a NumPy array.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def compute(self) -&gt; T:\n    \"\"\"\n    Compute and return the data.\n    This method materializes lazily computed data into a concrete NumPy array.\n\n    Returns\n    -------\n    NDArrayReal\n        The computed data.\n\n    Raises\n    ------\n    ValueError\n        If the computed result is not a NumPy array.\n    \"\"\"\n    logger.debug(\n        \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n    )\n    result = self._data.compute()\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n    logger.debug(f\"Computation complete, result shape: {result.shape}\")\n    return cast(T, result)\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.plot","title":"<code>plot(plot_type='default', ax=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Plot the data</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>@abstractmethod\ndef plot(\n    self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the data\"\"\"\n    pass\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.persist","title":"<code>persist()</code>","text":"<p>Persist the data in memory</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def persist(self: S) -&gt; S:\n    \"\"\"Persist the data in memory\"\"\"\n    persisted_data = self._data.persist()\n    return self._create_new_instance(data=persisted_data)\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__array__","title":"<code>__array__(dtype=None)</code>","text":"<p>Implicit conversion to NumPy array</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n    \"\"\"Implicit conversion to NumPy array\"\"\"\n    result = self.compute()\n    if dtype is not None:\n        return result.astype(dtype)\n    return result\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph","title":"<code>visualize_graph(filename=None)</code>","text":"<p>Visualize the computation graph and save it to a file.</p> <p>This method creates a visual representation of the Dask computation graph. In Jupyter notebooks, it returns an IPython.display.Image object that will be displayed inline. In other environments, it saves the graph to a file and returns None.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--parameters","title":"Parameters","text":"<p>filename : str, optional     Output filename for the graph image. If None, a unique filename     is generated using UUID. The file is saved in the current working     directory.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--returns","title":"Returns","text":"<p>IPython.display.Image or None     In Jupyter environments: Returns an IPython.display.Image object     that can be displayed inline.     In other environments: Returns None after saving the graph to file.     Returns None if visualization fails.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--notes","title":"Notes","text":"<p>This method requires graphviz to be installed on your system: - Ubuntu/Debian: <code>sudo apt-get install graphviz</code> - macOS: <code>brew install graphviz</code> - Windows: Download from https://graphviz.org/download/</p> <p>The graph displays operation names (e.g., 'normalize', 'lowpass_filter') making it easier to understand the processing pipeline.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"audio.wav\") processed = signal.normalize().low_pass_filter(cutoff=1000)</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--in-jupyter-displays-graph-inline","title":"In Jupyter: displays graph inline","text":"<p>processed.visualize_graph()</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--save-to-specific-file","title":"Save to specific file","text":"<p>processed.visualize_graph(\"my_graph.png\")</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--see-also","title":"See Also","text":"<p>debug_info : Print detailed debug information about the frame</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n    \"\"\"\n    Visualize the computation graph and save it to a file.\n\n    This method creates a visual representation of the Dask computation graph.\n    In Jupyter notebooks, it returns an IPython.display.Image object that\n    will be displayed inline. In other environments, it saves the graph to\n    a file and returns None.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Output filename for the graph image. If None, a unique filename\n        is generated using UUID. The file is saved in the current working\n        directory.\n\n    Returns\n    -------\n    IPython.display.Image or None\n        In Jupyter environments: Returns an IPython.display.Image object\n        that can be displayed inline.\n        In other environments: Returns None after saving the graph to file.\n        Returns None if visualization fails.\n\n    Notes\n    -----\n    This method requires graphviz to be installed on your system:\n    - Ubuntu/Debian: `sudo apt-get install graphviz`\n    - macOS: `brew install graphviz`\n    - Windows: Download from https://graphviz.org/download/\n\n    The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n    making it easier to understand the processing pipeline.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n    &gt;&gt;&gt; # In Jupyter: displays graph inline\n    &gt;&gt;&gt; processed.visualize_graph()\n    &gt;&gt;&gt; # Save to specific file\n    &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n    See Also\n    --------\n    debug_info : Print detailed debug information about the frame\n    \"\"\"\n    try:\n        filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n        return self._data.visualize(filename=filename)\n    except Exception as e:\n        logger.warning(f\"Failed to visualize the graph: {e}\")\n        return None\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__add__","title":"<code>__add__(other)</code>","text":"<p>Addition operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Addition operator\"\"\"\n    return self._binary_op(other, lambda x, y: x + y, \"+\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtraction operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Subtraction operator\"\"\"\n    return self._binary_op(other, lambda x, y: x - y, \"-\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiplication operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Multiplication operator\"\"\"\n    return self._binary_op(other, lambda x, y: x * y, \"*\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Division operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Division operator\"\"\"\n    return self._binary_op(other, lambda x, y: x / y, \"/\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.__pow__","title":"<code>__pow__(other)</code>","text":"<p>Power operator</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Power operator\"\"\"\n    return self._binary_op(other, lambda x, y: x**y, \"**\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.apply_operation","title":"<code>apply_operation(operation_name, **params)</code>","text":"<p>Apply a named operation.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.apply_operation--parameters","title":"Parameters","text":"<p>operation_name : str     Name of the operation to apply. **params : Any     Parameters to pass to the operation.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.apply_operation--returns","title":"Returns","text":"<p>S     A new instance with the operation applied.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n    \"\"\"\n    Apply a named operation.\n\n    Parameters\n    ----------\n    operation_name : str\n        Name of the operation to apply.\n    **params : Any\n        Parameters to pass to the operation.\n\n    Returns\n    -------\n    S\n        A new instance with the operation applied.\n    \"\"\"\n    # Apply the operation through abstract method\n    return self._apply_operation_impl(operation_name, **params)\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.debug_info","title":"<code>debug_info()</code>","text":"<p>Output detailed debug information</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def debug_info(self) -&gt; None:\n    \"\"\"Output detailed debug information\"\"\"\n    logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n    logger.debug(f\"Label: {self.label}\")\n    logger.debug(f\"Shape: {self.shape}\")\n    logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n    logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n    self._debug_info_impl()\n    logger.debug(\"=== End Debug Info ===\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.print_operation_history","title":"<code>print_operation_history()</code>","text":"<p>Print the operation history to standard output in a readable format.</p> <p>This method writes a human-friendly representation of the <code>operation_history</code> list to stdout. Each operation is printed on its own line with an index, the operation name (if available), and the parameters used.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.print_operation_history--examples","title":"Examples","text":"<p>cf.print_operation_history() 1: normalize {} 2: low_pass_filter {'cutoff': 1000}</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def print_operation_history(self) -&gt; None:\n    \"\"\"\n    Print the operation history to standard output in a readable format.\n\n    This method writes a human-friendly representation of the\n    `operation_history` list to stdout. Each operation is printed on its\n    own line with an index, the operation name (if available), and the\n    parameters used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf.print_operation_history()\n    1: normalize {}\n    2: low_pass_filter {'cutoff': 1000}\n    \"\"\"\n    if not self.operation_history:\n        print(\"Operation history: &lt;empty&gt;\")\n        return\n\n    print(f\"Operation history ({len(self.operation_history)}):\")\n    for i, record in enumerate(self.operation_history, start=1):\n        # record is expected to be a dict with at least a 'operation' key\n        op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n        # Copy params for display - exclude the 'operation'/'name' keys\n        params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n        print(f\"{i}: {op_name} {params}\")\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Convert the frame data to a NumPy array.</p> <p>This method computes the Dask array and returns it as a concrete NumPy array. The returned array has the same shape as the frame's data.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.to_numpy--returns","title":"Returns","text":"<p>T     NumPy array containing the frame data.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.to_numpy--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") data = cf.to_numpy() print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def to_numpy(self) -&gt; T:\n    \"\"\"Convert the frame data to a NumPy array.\n\n    This method computes the Dask array and returns it as a concrete NumPy array.\n    The returned array has the same shape as the frame's data.\n\n    Returns\n    -------\n    T\n        NumPy array containing the frame data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; data = cf.to_numpy()\n    &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n    \"\"\"\n    return self.data\n</code></pre>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert the frame data to a pandas DataFrame.</p> <p>This method provides a common implementation for converting frame data to pandas DataFrame. Subclasses can override this method for custom behavior.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.to_dataframe--returns","title":"Returns","text":"<p>pd.DataFrame     DataFrame with appropriate index and columns.</p>"},{"location":"api/core/#wandas.core.base_frame.BaseFrame.to_dataframe--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") df = cf.to_dataframe() print(df.head())</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"Convert the frame data to a pandas DataFrame.\n\n    This method provides a common implementation for converting frame data\n    to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with appropriate index and columns.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; df = cf.to_dataframe()\n    &gt;&gt;&gt; print(df.head())\n    \"\"\"\n    # Get data as numpy array\n    data = self.to_numpy()\n\n    # Get column names from subclass\n    columns = self._get_dataframe_columns()\n\n    # Get index from subclass\n    index = self._get_dataframe_index()\n\n    # Create DataFrame\n    if data.ndim == 1:\n        # Single channel case - reshape to 2D\n        df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n    else:\n        # Multi-channel case - transpose to (n_samples, n_channels)\n        df = pd.DataFrame(data.T, columns=columns, index=index)\n\n    return df\n</code></pre>"},{"location":"api/core/#channelmetadata","title":"ChannelMetadata","text":"<p>ChannelMetadata\u30af\u30e9\u30b9\u306f\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u306b\u95a2\u9023\u3059\u308b\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002</p>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata","title":"<code>wandas.core.metadata.ChannelMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data class for storing channel metadata</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>class ChannelMetadata(BaseModel):\n    \"\"\"\n    Data class for storing channel metadata\n    \"\"\"\n\n    label: str = \"\"\n    unit: str = \"\"\n    ref: float = 1.0\n    # Additional metadata for extensibility\n    extra: dict[str, Any] = Field(default_factory=dict)\n\n    def __init__(self, **data: Any):\n        super().__init__(**data)\n        # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n        if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n            self.ref = unit_to_ref(self.unit)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n        super().__setattr__(name, value)\n        # Only proceed if unit is being set to a non-empty value\n        if name == \"unit\" and value and isinstance(value, str):\n            super().__setattr__(\"ref\", unit_to_ref(value))\n\n    @property\n    def label_value(self) -&gt; str:\n        \"\"\"Get the label value\"\"\"\n        return self.label\n\n    @property\n    def unit_value(self) -&gt; str:\n        \"\"\"Get the unit value\"\"\"\n        return self.unit\n\n    @property\n    def ref_value(self) -&gt; float:\n        \"\"\"Get the ref value\"\"\"\n        return self.ref\n\n    @property\n    def extra_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get the extra metadata dictionary\"\"\"\n        return self.extra\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Provide dictionary-like behavior\"\"\"\n        if key == \"label\":\n            return self.label\n        elif key == \"unit\":\n            return self.unit\n        elif key == \"ref\":\n            return self.ref\n        else:\n            return self.extra.get(key)\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        \"\"\"Provide dictionary-like behavior\"\"\"\n        if key == \"label\":\n            self.label = value\n        elif key == \"unit\":\n            self.unit = value\n            self.ref = unit_to_ref(value)\n        elif key == \"ref\":\n            self.ref = value\n        else:\n            self.extra[key] = value\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert to JSON format\"\"\"\n        json_data: str = self.model_dump_json(indent=4)\n        return json_data\n\n    @classmethod\n    def from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n        \"\"\"Convert from JSON format\"\"\"\n        root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n        return root_model\n</code></pre>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata-attributes","title":"Attributes","text":""},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.label","title":"<code>label = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.unit","title":"<code>unit = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.ref","title":"<code>ref = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.extra","title":"<code>extra = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.label_value","title":"<code>label_value</code>  <code>property</code>","text":"<p>Get the label value</p>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.unit_value","title":"<code>unit_value</code>  <code>property</code>","text":"<p>Get the unit value</p>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.ref_value","title":"<code>ref_value</code>  <code>property</code>","text":"<p>Get the ref value</p>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.extra_data","title":"<code>extra_data</code>  <code>property</code>","text":"<p>Get the extra metadata dictionary</p>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata-functions","title":"Functions","text":""},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.__init__","title":"<code>__init__(**data)</code>","text":"Source code in <code>wandas/core/metadata.py</code> <pre><code>def __init__(self, **data: Any):\n    super().__init__(**data)\n    # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n    if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n        self.ref = unit_to_ref(self.unit)\n</code></pre>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.__setattr__","title":"<code>__setattr__(name, value)</code>","text":"<p>Override setattr to update ref when unit is changed directly</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n    super().__setattr__(name, value)\n    # Only proceed if unit is being set to a non-empty value\n    if name == \"unit\" and value and isinstance(value, str):\n        super().__setattr__(\"ref\", unit_to_ref(value))\n</code></pre>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Provide dictionary-like behavior</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        return self.label\n    elif key == \"unit\":\n        return self.unit\n    elif key == \"ref\":\n        return self.ref\n    else:\n        return self.extra.get(key)\n</code></pre>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Provide dictionary-like behavior</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def __setitem__(self, key: str, value: Any) -&gt; None:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        self.label = value\n    elif key == \"unit\":\n        self.unit = value\n        self.ref = unit_to_ref(value)\n    elif key == \"ref\":\n        self.ref = value\n    else:\n        self.extra[key] = value\n</code></pre>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.to_json","title":"<code>to_json()</code>","text":"<p>Convert to JSON format</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert to JSON format\"\"\"\n    json_data: str = self.model_dump_json(indent=4)\n    return json_data\n</code></pre>"},{"location":"api/core/#wandas.core.metadata.ChannelMetadata.from_json","title":"<code>from_json(json_data)</code>  <code>classmethod</code>","text":"<p>Convert from JSON format</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n    \"\"\"Convert from JSON format\"\"\"\n    root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n    return root_model\n</code></pre>"},{"location":"api/datasets/","title":"\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.datasets</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u30c6\u30b9\u30c8\u3084\u30c7\u30e2\u306b\u4f7f\u7528\u3067\u304d\u308b\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/datasets/#_2","title":"\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf","text":"<p>\u30c6\u30b9\u30c8\u3084\u30c7\u30e2\u3067\u4f7f\u7528\u3067\u304d\u308b\u30b5\u30f3\u30d7\u30eb\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/datasets/#wandas.datasets.sample_data","title":"<code>wandas.datasets.sample_data</code>","text":""},{"location":"api/datasets/#wandas.datasets.sample_data-attributes","title":"Attributes","text":""},{"location":"api/datasets/#wandas.datasets.sample_data-functions","title":"Functions","text":""},{"location":"api/datasets/#wandas.datasets.sample_data.load_sample_signal","title":"<code>load_sample_signal(frequency=5.0, sampling_rate=100, duration=1.0)</code>","text":"<p>Generate a sample sine wave signal.</p>"},{"location":"api/datasets/#wandas.datasets.sample_data.load_sample_signal--parameters","title":"Parameters","text":"<p>frequency : float, default=5.0     Frequency of the signal in Hz. sampling_rate : int, default=100     Sampling rate in Hz. duration : float, default=1.0     Duration of the signal in seconds.</p>"},{"location":"api/datasets/#wandas.datasets.sample_data.load_sample_signal--returns","title":"Returns","text":"<p>NDArrayReal     Signal data as a NumPy array.</p> Source code in <code>wandas/datasets/sample_data.py</code> <pre><code>def load_sample_signal(\n    frequency: float = 5.0, sampling_rate: int = 100, duration: float = 1.0\n) -&gt; NDArrayReal:\n    \"\"\"\n    Generate a sample sine wave signal.\n\n    Parameters\n    ----------\n    frequency : float, default=5.0\n        Frequency of the signal in Hz.\n    sampling_rate : int, default=100\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n\n    Returns\n    -------\n    NDArrayReal\n        Signal data as a NumPy array.\n    \"\"\"\n    num_samples = int(sampling_rate * duration)\n    t = np.arange(num_samples) / sampling_rate\n    signal: NDArrayReal = np.sin(2 * np.pi * frequency * t, dtype=np.float64)\n    return signal\n</code></pre>"},{"location":"api/frames/","title":"\u30d5\u30ec\u30fc\u30e0\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.frames</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u306e\u64cd\u4f5c\u3068\u8868\u73fe\u306e\u305f\u3081\u306e\u69d8\u3005\u306a\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u30af\u30e9\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/frames/#channelframe","title":"ChannelFrame","text":"<p>ChannelFrame\u306f\u6642\u9593\u9818\u57df\u306e\u6ce2\u5f62\u30c7\u30fc\u30bf\u3092\u6271\u3046\u305f\u3081\u306e\u57fa\u672c\u7684\u306a\u30d5\u30ec\u30fc\u30e0\u3067\u3059\u3002</p>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame","title":"<code>wandas.frames.channel.ChannelFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code>, <code>ChannelProcessingMixin</code>, <code>ChannelTransformMixin</code></p> <p>Channel-based data frame for handling audio signals and time series data.</p> <p>This frame represents channel-based data such as audio signals and time series data, with each channel containing data samples in the time domain.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>class ChannelFrame(\n    BaseFrame[NDArrayReal], ChannelProcessingMixin, ChannelTransformMixin\n):\n    \"\"\"Channel-based data frame for handling audio signals and time series data.\n\n    This frame represents channel-based data such as audio signals and time series data,\n    with each channel containing data samples in the time domain.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: DaskArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a ChannelFrame.\n\n        Args:\n            data: Dask array containing channel data.\n            Shape should be (n_channels, n_samples).\n            sampling_rate: The sampling rate of the data in Hz.\n                Must be a positive value.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Raises:\n            ValueError: If data has more than 2 dimensions, or if\n                sampling_rate is not positive.\n        \"\"\"\n        # Validate sampling rate\n        validate_sampling_rate(sampling_rate)\n\n        # Validate and reshape data\n        if data.ndim == 1:\n            data = da.reshape(data, (1, -1))\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Invalid data shape for ChannelFrame\\n\"\n                f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n                f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n                f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n                f\"  (1, n_samples).\\n\"\n                f\"For higher-dimensional data, reshape it before creating\\n\"\n                f\"  ChannelFrame:\\n\"\n                f\"  Example: data.reshape(n_channels, -1)\"\n            )\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"Get time array for the signal.\n\n        The time array represents the start time of each sample, calculated as\n        sample_index / sampling_rate. This provides a uniform, evenly-spaced\n        time axis that is consistent across all frame types in wandas.\n\n        For frames resulting from windowed analysis operations (e.g., FFT,\n        loudness, roughness), each time point corresponds to the start of\n        the analysis window, not the center. This differs from some libraries\n        (e.g., MoSQITo) which use window center times, but does not affect\n        the calculated values themselves.\n\n        Returns:\n            Array of time points in seconds, starting from 0.0.\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; time = signal.time\n            &gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n            &gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n        \"\"\"\n        return np.arange(self.n_samples) / self.sampling_rate\n\n    @property\n    def n_samples(self) -&gt; int:\n        \"\"\"Returns the number of samples.\"\"\"\n        n: int = self._data.shape[-1]\n        return n\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Returns the duration in seconds.\"\"\"\n        return self.n_samples / self.sampling_rate\n\n    @property\n    def rms(self) -&gt; NDArrayReal:\n        \"\"\"Calculate RMS (Root Mean Square) value for each channel.\n\n        Returns:\n            Array of RMS values, one per channel.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; rms_values = cf.rms\n            &gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n            &gt;&gt;&gt; # Select channels with RMS &gt; threshold\n            &gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n        \"\"\"\n        # Convert to a concrete NumPy ndarray to satisfy numpy.mean typing\n        # and to ensure dask arrays are materialized for this operation.\n        rms_values = da.sqrt((self._data**2).mean(axis=1))\n        return np.array(rms_values.compute())\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the ChannelFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - Duration\n        - Number of samples\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.info()\n        Channels: 2\n        Sampling rate: 44100 Hz\n        Duration: 1.0 s\n        Samples: 44100\n        Channel labels: ['ch0', 'ch1']\n        \"\"\"\n        print(\"ChannelFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  Duration: {self.duration:.1f} s\")\n        print(f\"  Samples: {self.n_samples}\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        # Get metadata updates from operation\n        metadata_updates = operation.get_metadata_updates()\n\n        # Update channel labels to reflect the operation\n        display_name = operation.get_display_name()\n        new_channel_metadata = self._relabel_channels(operation_name, display_name)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # Apply metadata updates (including sampling_rate if specified)\n        creation_params: dict[str, Any] = {\n            \"data\": processed_data,\n            \"metadata\": new_metadata,\n            \"operation_history\": new_history,\n            \"channel_metadata\": new_channel_metadata,\n        }\n        creation_params.update(metadata_updates)\n\n        return self._create_new_instance(**creation_params)\n\n    def _binary_op(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal | DaskArray\",\n        op: Callable[[\"DaskArray\", Any], \"DaskArray\"],\n        symbol: str,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Common implementation for binary operations\n        - utilizing dask's lazy evaluation.\n\n        Args:\n            other: Right operand for the operation.\n            op: Function to execute the operation (e.g., lambda a, b: a + b).\n            symbol: Symbolic representation of the operation (e.g., '+').\n\n        Returns:\n            A new channel containing the operation result (lazy execution).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, ChannelFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Perform operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Merge channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Perform operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # Operand display string\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n                previous=self,\n            )\n\n    def add(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal\",\n        snr: float | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add another signal or value to the current signal.\n\n        If SNR is specified, performs addition with consideration for\n        signal-to-noise ratio.\n\n        Args:\n            other: Signal or value to add.\n            snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n                other signal based on this SNR.\n                self is treated as the signal, and other as the noise.\n\n        Returns:\n            A new channel frame containing the addition result (lazy execution).\n        \"\"\"\n        logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n        if isinstance(other, ChannelFrame):\n            # Check if sampling rates match\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n        elif isinstance(other, np.ndarray):\n            other = ChannelFrame.from_numpy(\n                other, self.sampling_rate, label=\"array_data\"\n            )\n        elif isinstance(other, int | float):\n            return self + other\n        else:\n            raise TypeError(\n                \"Addition target with SNR must be a ChannelFrame or \"\n                f\"NumPy array: {type(other)}\"\n            )\n\n        # If SNR is specified, adjust the length of the other signal\n        if other.duration != self.duration:\n            other = other.fix_length(length=self.n_samples)\n\n        if snr is None:\n            return self + other\n        return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n\n    def plot(\n        self,\n        plot_type: str = \"waveform\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the frame data.\n\n        Args:\n            plot_type: Type of plot. Default is \"waveform\".\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot. If None, uses the frame label.\n            overlay: Whether to overlay all channels on a single plot (True)\n                or create separate subplots for each channel (False).\n            xlabel: Label for the x-axis. If None, uses default based on plot type.\n            ylabel: Label for the y-axis. If None, uses default based on plot type.\n            alpha: Transparency level for the plot lines (0.0 to 1.0).\n            xlim: Limits for the x-axis as (min, max) tuple.\n            ylim: Limits for the y-axis as (min, max) tuple.\n            **kwargs: Additional matplotlib Line2D parameters\n                (e.g., color, linewidth, linestyle).\n                These are passed to the underlying matplotlib plot functions.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic plot\n            &gt;&gt;&gt; cf.plot()\n            &gt;&gt;&gt; # Overlay all channels\n            &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n        \"\"\"\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        from ..visualization.plotting import create_operation\n\n        plot_strategy = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def rms_plot(\n        self,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = True,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Generate an RMS plot.\n\n        Args:\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot.\n            overlay: Whether to overlay the plot on the existing axis.\n            Aw: Apply A-weighting.\n            **kwargs: Additional arguments passed to the plot() method.\n                Accepts the same arguments as plot() including xlabel, ylabel,\n                alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic RMS plot\n            &gt;&gt;&gt; cf.rms_plot()\n            &gt;&gt;&gt; # With A-weighting\n            &gt;&gt;&gt; cf.rms_plot(Aw=True)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n        \"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n        rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n        return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n\n    def describe(\n        self,\n        normalize: bool = True,\n        is_close: bool = True,\n        *,\n        fmin: float = 0,\n        fmax: float | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        waveform: dict[str, Any] | None = None,\n        spectral: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Display visual and audio representation of the frame.\n\n        This method creates a comprehensive visualization with three plots:\n        1. Time-domain waveform (top)\n        2. Spectrogram (bottom-left)\n        3. Frequency spectrum via Welch method (bottom-right)\n\n        Args:\n            normalize: Whether to normalize the audio data for playback.\n                Default: True\n            is_close: Whether to close the figure after displaying.\n                Default: True\n            fmin: Minimum frequency to display in the spectrogram (Hz).\n                Default: 0\n            fmax: Maximum frequency to display in the spectrogram (Hz).\n                Default: Nyquist frequency (sampling_rate / 2)\n            cmap: Colormap for the spectrogram.\n                Default: 'jet'\n            vmin: Minimum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            vmax: Maximum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            xlim: Time axis limits (seconds) for all time-based plots.\n                Format: (start_time, end_time)\n            ylim: Frequency axis limits (Hz) for frequency-based plots.\n                Format: (min_freq, max_freq)\n            Aw: Apply A-weighting to the frequency analysis.\n                Default: False\n            waveform: Additional configuration dict for waveform subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            spectral: Additional configuration dict for spectral subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            **kwargs: Deprecated parameters for backward compatibility only.\n                - axis_config: Old configuration format (use waveform/spectral instead)\n                - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic usage\n            &gt;&gt;&gt; cf.describe()\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom frequency range\n            &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom color scale\n            &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # A-weighted analysis\n            &gt;&gt;&gt; cf.describe(Aw=True)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom time range\n            &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom waveform subplot settings\n            &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n        \"\"\"\n        # Prepare kwargs with explicit parameters\n        plot_kwargs: dict[str, Any] = {\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"xlim\": xlim,\n            \"ylim\": ylim,\n            \"Aw\": Aw,\n            \"waveform\": waveform or {},\n            \"spectral\": spectral or {},\n        }\n        # Merge with additional kwargs\n        plot_kwargs.update(kwargs)\n\n        if \"axis_config\" in plot_kwargs:\n            logger.warning(\n                \"axis_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            axis_config = plot_kwargs[\"axis_config\"]\n            if \"time_plot\" in axis_config:\n                plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n            if \"freq_plot\" in axis_config:\n                if \"xlim\" in axis_config[\"freq_plot\"]:\n                    vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                    plot_kwargs[\"vmin\"] = vlim[0]\n                    plot_kwargs[\"vmax\"] = vlim[1]\n                if \"ylim\" in axis_config[\"freq_plot\"]:\n                    ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                    plot_kwargs[\"ylim\"] = ylim_config\n\n        if \"cbar_config\" in plot_kwargs:\n            logger.warning(\n                \"cbar_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            cbar_config = plot_kwargs[\"cbar_config\"]\n            if \"vmin\" in cbar_config:\n                plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n            if \"vmax\" in cbar_config:\n                plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n        for ch in self:\n            ax: Axes\n            _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n            if isinstance(_ax, Iterator):\n                ax = next(iter(_ax))\n            elif isinstance(_ax, Axes):\n                ax = _ax\n            else:\n                raise TypeError(\n                    f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n                )\n            # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n            display(ax.figure)\n            if is_close:\n                plt.close(getattr(ax, \"figure\", None))\n            display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayReal,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        ch_labels: list[str] | None = None,\n        ch_units: list[str] | str | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing channel data.\n            sampling_rate: The sampling rate in Hz.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            ch_labels: Labels for each channel.\n            ch_units: Units for each channel.\n\n        Returns:\n            A new ChannelFrame containing the NumPy data.\n        \"\"\"\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n\n        # Convert NumPy array to dask array\n        dask_data = da_from_array(data)\n        cf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=label or \"numpy_data\",\n        )\n        if metadata is not None:\n            cf.metadata = metadata\n        if ch_labels is not None:\n            if len(ch_labels) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel labels does not match the number of channels\"\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        if ch_units is not None:\n            if isinstance(ch_units, str):\n                ch_units = [ch_units] * cf.n_channels\n\n            if len(ch_units) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel units does not match the number of channels\"\n                )\n            for i in range(len(ch_units)):\n                cf._channel_metadata[i].unit = ch_units[i]\n\n        return cf\n\n    @classmethod\n    def from_ndarray(\n        cls,\n        array: NDArrayReal,\n        sampling_rate: float,\n        labels: list[str] | None = None,\n        unit: list[str] | str | None = None,\n        frame_label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        This method is deprecated. Use from_numpy instead.\n\n        Args:\n            array: Signal data. Each row corresponds to a channel.\n            sampling_rate: Sampling rate (Hz).\n            labels: Labels for each channel.\n            unit: Unit of the signal.\n            frame_label: Label for the frame.\n            metadata: Optional metadata dictionary.\n\n        Returns:\n            A new ChannelFrame containing the data.\n        \"\"\"\n        # Redirect to from_numpy for compatibility\n        # However, from_ndarray is deprecated\n        logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n        return cls.from_numpy(\n            data=array,\n            sampling_rate=sampling_rate,\n            label=frame_label,\n            metadata=metadata,\n            ch_labels=labels,\n            ch_units=unit,\n        )\n\n    @classmethod\n    def from_file(\n        cls,\n        path: str | Path,\n        channel: int | list[int] | None = None,\n        start: float | None = None,\n        end: float | None = None,\n        chunk_size: int | None = None,\n        ch_labels: list[str] | None = None,\n        # CSV-specific parameters\n        time_column: int | str = 0,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from an audio file.\n\n        Args:\n            path: Path to the audio file.\n            channel: Channel(s) to load.\n            start: Start time in seconds.\n            end: End time in seconds.\n            chunk_size: Chunk size for processing.\n                Specifies the splitting size for lazy processing.\n            ch_labels: Labels for each channel.\n            time_column: For CSV files, index or name of the time column.\n                Default is 0 (first column).\n            delimiter: For CSV files, delimiter character. Default is \",\".\n            header: For CSV files, row number to use as header.\n                Default is 0 (first row). Set to None if no header.\n\n        Returns:\n            A new ChannelFrame containing the loaded audio data.\n\n        Raises:\n            ValueError: If channel specification is invalid.\n            TypeError: If channel parameter type is invalid.\n            FileNotFoundError: If the file doesn't exist at the specified path.\n                Error message includes absolute path, current directory, and\n                troubleshooting suggestions.\n\n        Examples:\n            &gt;&gt;&gt; # Load WAV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n            &gt;&gt;&gt; # Load specific channels\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n            &gt;&gt;&gt; # Load CSV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\n            ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n            ... )\n        \"\"\"\n        from .channel import ChannelFrame\n\n        path = Path(path)\n        if not path.exists():\n            raise FileNotFoundError(\n                f\"Audio file not found\\n\"\n                f\"  Path: {path.absolute()}\\n\"\n                f\"  Current directory: {Path.cwd()}\\n\"\n                f\"Please check:\\n\"\n                f\"  - File path is correct\\n\"\n                f\"  - File exists at the specified location\\n\"\n                f\"  - You have read permissions for the file\"\n            )\n\n        # Get file reader\n        reader = get_file_reader(path)\n\n        # Build kwargs for reader\n        reader_kwargs: dict[str, Any] = {}\n        if path.suffix.lower() == \".csv\":\n            reader_kwargs[\"time_column\"] = time_column\n            reader_kwargs[\"delimiter\"] = delimiter\n            if header is not None:\n                reader_kwargs[\"header\"] = header\n\n        # Get file info\n        info = reader.get_file_info(path, **reader_kwargs)\n        sr = info[\"samplerate\"]\n        n_channels = info[\"channels\"]\n        n_frames = info[\"frames\"]\n        ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n        logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n        # Channel selection processing\n        all_channels = list(range(n_channels))\n\n        if channel is None:\n            channels_to_load = all_channels\n            logger.debug(f\"Will load all channels: {channels_to_load}\")\n        elif isinstance(channel, int):\n            if channel &lt; 0 or channel &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n            channels_to_load = [channel]\n            logger.debug(f\"Will load single channel: {channel}\")\n        elif isinstance(channel, list | tuple):\n            for ch in channel:\n                if ch &lt; 0 or ch &gt;= n_channels:\n                    raise ValueError(\n                        f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                    )\n            channels_to_load = list(channel)\n            logger.debug(f\"Will load specific channels: {channels_to_load}\")\n        else:\n            raise TypeError(\"channel must be int, list, or None\")\n\n        # Index calculation\n        start_idx = 0 if start is None else max(0, int(start * sr))\n        end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n        frames_to_read = end_idx - start_idx\n\n        logger.debug(\n            f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n            f\"start_idx={start_idx}, end_idx={end_idx}\"\n        )\n\n        # Settings for lazy loading\n        expected_shape = (len(channels_to_load), frames_to_read)\n\n        # Define the loading function using the file reader\n        def _load_audio() -&gt; NDArrayReal:\n            logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n            # Use the reader to get audio data with parameters\n            out = reader.get_data(\n                path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n            )\n            if not isinstance(out, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n            return out\n\n        logger.debug(\n            f\"Creating delayed dask task with expected shape: {expected_shape}\"\n        )\n\n        # Create delayed operation\n        delayed_data = dask_delayed(_load_audio)()\n        logger.debug(\"Wrapping delayed function in dask array\")\n\n        # Create dask array from delayed computation\n        dask_array = da_from_delayed(\n            delayed_data, shape=expected_shape, dtype=np.float32\n        )\n\n        if chunk_size is not None:\n            if chunk_size &lt;= 0:\n                raise ValueError(\"Chunk size must be a positive integer\")\n            logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n            dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n        logger.debug(\n            \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n        )\n\n        cf = ChannelFrame(\n            data=dask_array,\n            sampling_rate=sr,\n            label=path.stem,\n            metadata={\n                \"filename\": str(path),\n            },\n        )\n        if ch_labels is not None:\n            if len(ch_labels) != len(cf):\n                raise ValueError(\n                    \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        return cf\n\n    @classmethod\n    def read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a WAV file.\n\n        Args:\n            filename: Path to the WAV file.\n            labels: Labels to set for each channel.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(filename, ch_labels=labels)\n        return cf\n\n    @classmethod\n    def read_csv(\n        cls,\n        filename: str,\n        time_column: int | str = 0,\n        labels: list[str] | None = None,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a CSV file.\n\n        Args:\n            filename: Path to the CSV file.\n            time_column: Index or name of the time column.\n            labels: Labels to set for each channel.\n            delimiter: Delimiter character.\n            header: Row number to use as header.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n\n        Examples:\n            &gt;&gt;&gt; # Read CSV with default settings\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n            &gt;&gt;&gt; # Read CSV with custom delimiter\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n            &gt;&gt;&gt; # Read CSV without header\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(\n            filename,\n            ch_labels=labels,\n            time_column=time_column,\n            delimiter=delimiter,\n            header=header,\n        )\n        return cf\n\n    def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n        \"\"\"Save the audio data to a WAV file.\n\n        Args:\n            path: Path to save the file.\n            format: File format. If None, determined from file extension.\n        \"\"\"\n        from wandas.io.wav_io import write_wav\n\n        write_wav(str(path), self, format=format)\n\n    def save(\n        self,\n        path: str | Path,\n        *,\n        format: str = \"hdf5\",\n        compress: str | None = \"gzip\",\n        overwrite: bool = False,\n        dtype: str | np.dtype[Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n        This saves the complete frame including all channel data and metadata\n        in a format that can be loaded back with full fidelity.\n\n        Args:\n            path: Path to save the file. '.wdf' extension will be added if not present.\n            format: Format to use (currently only 'hdf5' is supported)\n            compress: Compression method ('gzip' by default, None for no compression)\n            overwrite: Whether to overwrite existing file\n            dtype: Optional data type conversion before saving (e.g. 'float32')\n\n        Raises:\n            FileExistsError: If the file exists and overwrite=False.\n            NotImplementedError: For unsupported formats.\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import save as wdf_save\n\n        wdf_save(\n            self,\n            path,\n            format=format,\n            compress=compress,\n            overwrite=overwrite,\n            dtype=dtype,\n        )\n\n    @classmethod\n    def load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n        \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n        This loads data saved with the save() method, preserving all channel data,\n        metadata, labels, and units.\n\n        Args:\n            path: Path to the WDF file\n            format: Format of the file (currently only 'hdf5' is supported)\n\n        Returns:\n            A new ChannelFrame with all data and metadata loaded\n\n        Raises:\n            FileNotFoundError: If the file doesn't exist\n            NotImplementedError: For unsupported formats\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import load as wdf_load\n\n        return wdf_load(path, format=format)\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"Provide additional initialization arguments required for ChannelFrame.\"\"\"\n        return {}\n\n    def add_channel(\n        self,\n        data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n        label: str | None = None,\n        align: str = \"strict\",\n        suffix_on_dup: str | None = None,\n        inplace: bool = False,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add a new channel to the frame.\n\n        Args:\n            data: Data to add as a new channel. Can be:\n                - numpy array (1D or 2D)\n                - dask array (1D or 2D)\n                - ChannelFrame (channels will be added)\n            label: Label for the new channel. If None, generates a default label.\n                Ignored when data is a ChannelFrame (uses its channel labels).\n            align: How to handle length mismatches:\n                - \"strict\": Raise error if lengths don't match\n                - \"pad\": Pad shorter data with zeros\n                - \"truncate\": Truncate longer data to match\n            suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n            inplace: If True, modifies the frame in place.\n                Otherwise returns a new frame.\n\n        Returns:\n            Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n        Raises:\n            ValueError: If data length doesn't match and align=\"strict\",\n                or if label is duplicate and suffix_on_dup is None.\n            TypeError: If data type is not supported.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Add a numpy array as a new channel\n            &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n            &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n            &gt;&gt;&gt; # Add another ChannelFrame's channels\n            &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n            &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n        \"\"\"\n        # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n        if isinstance(data, ChannelFrame):\n            if self.sampling_rate != data.sampling_rate:\n                raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n            if data.n_samples != self.n_samples:\n                if align == \"pad\":\n                    pad_len = self.n_samples - data.n_samples\n                    arr = data._data\n                    if pad_len &gt; 0:\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                    else:\n                        arr = arr[:, : self.n_samples]\n                elif align == \"truncate\":\n                    arr = data._data[:, : self.n_samples]\n                    if arr.shape[1] &lt; self.n_samples:\n                        pad_len = self.n_samples - arr.shape[1]\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                else:\n                    raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n            else:\n                arr = data._data\n            labels = [ch.label for ch in self._channel_metadata]\n            new_labels = []\n            new_metadata_list = []\n            for chmeta in data._channel_metadata:\n                new_label = chmeta.label\n                if new_label in labels or new_label in new_labels:\n                    if suffix_on_dup:\n                        new_label += suffix_on_dup\n                    else:\n                        raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n                new_labels.append(new_label)\n                # Copy the entire channel_metadata and update only the label\n                new_ch_meta = chmeta.model_copy(deep=True)\n                new_ch_meta.label = new_label\n                new_metadata_list.append(new_ch_meta)\n            new_data = concatenate([self._data, arr], axis=0)\n\n            new_chmeta = self._channel_metadata + new_metadata_list\n            if inplace:\n                self._data = new_data\n                self._channel_metadata = new_chmeta\n                return self\n            else:\n                return ChannelFrame(\n                    data=new_data,\n                    sampling_rate=self.sampling_rate,\n                    label=self.label,\n                    metadata=self.metadata,\n                    operation_history=self.operation_history,\n                    channel_metadata=new_chmeta,\n                    previous=self,\n                )\n        if isinstance(data, np.ndarray):\n            arr = from_array(data.reshape(1, -1))\n        elif isinstance(data, DaskArray):\n            arr = data[None, ...] if data.ndim == 1 else data\n            if arr.shape[0] != 1:\n                arr = arr.reshape((1, -1))\n        else:\n            raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n        if arr.shape[1] != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - arr.shape[1]\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = arr[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        labels = [ch.label for ch in self._channel_metadata]\n        new_label = label or f\"ch{len(labels)}\"\n        if new_label in labels:\n            if suffix_on_dup:\n                new_label += suffix_on_dup\n            else:\n                raise ValueError(\"label\u91cd\u8907\")\n        new_data = concatenate([self._data, arr], axis=0)\n        from ..core.metadata import ChannelMetadata\n\n        new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n        if isinstance(key, int):\n            if not (0 &lt;= key &lt; self.n_channels):\n                raise IndexError(f\"index {key} out of range\")\n            idx = key\n        else:\n            labels = [ch.label for ch in self._channel_metadata]\n            if key not in labels:\n                raise KeyError(f\"label {key} not found\")\n            idx = labels.index(key)\n        new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n        new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get time index for DataFrame.\"\"\"\n        return pd.Index(self.time, name=\"time\")\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame-attributes","title":"Attributes","text":""},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.time","title":"<code>time</code>  <code>property</code>","text":"<p>Get time array for the signal.</p> <p>The time array represents the start time of each sample, calculated as sample_index / sampling_rate. This provides a uniform, evenly-spaced time axis that is consistent across all frame types in wandas.</p> <p>For frames resulting from windowed analysis operations (e.g., FFT, loudness, roughness), each time point corresponds to the start of the analysis window, not the center. This differs from some libraries (e.g., MoSQITo) which use window center times, but does not affect the calculated values themselves.</p> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Array of time points in seconds, starting from 0.0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; time = signal.time\n&gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n&gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.n_samples","title":"<code>n_samples</code>  <code>property</code>","text":"<p>Returns the number of samples.</p>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.duration","title":"<code>duration</code>  <code>property</code>","text":"<p>Returns the duration in seconds.</p>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.rms","title":"<code>rms</code>  <code>property</code>","text":"<p>Calculate RMS (Root Mean Square) value for each channel.</p> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Array of RMS values, one per channel.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; rms_values = cf.rms\n&gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n&gt;&gt;&gt; # Select channels with RMS &gt; threshold\n&gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame-functions","title":"Functions","text":""},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a ChannelFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Array</code> <p>Dask array containing channel data.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate of the data in Hz. Must be a positive value.</p> required <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data has more than 2 dimensions, or if sampling_rate is not positive.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def __init__(\n    self,\n    data: DaskArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a ChannelFrame.\n\n    Args:\n        data: Dask array containing channel data.\n        Shape should be (n_channels, n_samples).\n        sampling_rate: The sampling rate of the data in Hz.\n            Must be a positive value.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Raises:\n        ValueError: If data has more than 2 dimensions, or if\n            sampling_rate is not positive.\n    \"\"\"\n    # Validate sampling rate\n    validate_sampling_rate(sampling_rate)\n\n    # Validate and reshape data\n    if data.ndim == 1:\n        data = da.reshape(data, (1, -1))\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Invalid data shape for ChannelFrame\\n\"\n            f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n            f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n            f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n            f\"  (1, n_samples).\\n\"\n            f\"For higher-dimensional data, reshape it before creating\\n\"\n            f\"  ChannelFrame:\\n\"\n            f\"  Example: data.reshape(n_channels, -1)\"\n        )\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.info","title":"<code>info()</code>","text":"<p>Display comprehensive information about the ChannelFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - Duration - Number of samples - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.info--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.info() Channels: 2 Sampling rate: 44100 Hz Duration: 1.0 s Samples: 44100 Channel labels: ['ch0', 'ch1']</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the ChannelFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - Duration\n    - Number of samples\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; cf.info()\n    Channels: 2\n    Sampling rate: 44100 Hz\n    Duration: 1.0 s\n    Samples: 44100\n    Channel labels: ['ch0', 'ch1']\n    \"\"\"\n    print(\"ChannelFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  Duration: {self.duration:.1f} s\")\n    print(f\"  Samples: {self.n_samples}\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.add","title":"<code>add(other, snr=None)</code>","text":"<p>Add another signal or value to the current signal.</p> <p>If SNR is specified, performs addition with consideration for signal-to-noise ratio.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ChannelFrame | int | float | NDArrayReal</code> <p>Signal or value to add.</p> required <code>snr</code> <code>float | None</code> <p>Signal-to-noise ratio (dB). If specified, adjusts the scale of the other signal based on this SNR. self is treated as the signal, and other as the noise.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new channel frame containing the addition result (lazy execution).</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def add(\n    self,\n    other: \"ChannelFrame | int | float | NDArrayReal\",\n    snr: float | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add another signal or value to the current signal.\n\n    If SNR is specified, performs addition with consideration for\n    signal-to-noise ratio.\n\n    Args:\n        other: Signal or value to add.\n        snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n            other signal based on this SNR.\n            self is treated as the signal, and other as the noise.\n\n    Returns:\n        A new channel frame containing the addition result (lazy execution).\n    \"\"\"\n    logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n    if isinstance(other, ChannelFrame):\n        # Check if sampling rates match\n        if self.sampling_rate != other.sampling_rate:\n            raise ValueError(\n                \"Sampling rates do not match. Cannot perform operation.\"\n            )\n\n    elif isinstance(other, np.ndarray):\n        other = ChannelFrame.from_numpy(\n            other, self.sampling_rate, label=\"array_data\"\n        )\n    elif isinstance(other, int | float):\n        return self + other\n    else:\n        raise TypeError(\n            \"Addition target with SNR must be a ChannelFrame or \"\n            f\"NumPy array: {type(other)}\"\n        )\n\n    # If SNR is specified, adjust the length of the other signal\n    if other.duration != self.duration:\n        other = other.fix_length(length=self.n_samples)\n\n    if snr is None:\n        return self + other\n    return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.plot","title":"<code>plot(plot_type='waveform', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, **kwargs)</code>","text":"<p>Plot the frame data.</p> <p>Parameters:</p> Name Type Description Default <code>plot_type</code> <code>str</code> <p>Type of plot. Default is \"waveform\".</p> <code>'waveform'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot. If None, uses the frame label.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay all channels on a single plot (True) or create separate subplots for each channel (False).</p> <code>False</code> <code>xlabel</code> <code>str | None</code> <p>Label for the x-axis. If None, uses default based on plot type.</p> <code>None</code> <code>ylabel</code> <code>str | None</code> <p>Label for the y-axis. If None, uses default based on plot type.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level for the plot lines (0.0 to 1.0).</p> <code>1.0</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Limits for the x-axis as (min, max) tuple.</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Limits for the y-axis as (min, max) tuple.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional matplotlib Line2D parameters (e.g., color, linewidth, linestyle). These are passed to the underlying matplotlib plot functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic plot\n&gt;&gt;&gt; cf.plot()\n&gt;&gt;&gt; # Overlay all channels\n&gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"waveform\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the frame data.\n\n    Args:\n        plot_type: Type of plot. Default is \"waveform\".\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot. If None, uses the frame label.\n        overlay: Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel: Label for the x-axis. If None, uses default based on plot type.\n        ylabel: Label for the y-axis. If None, uses default based on plot type.\n        alpha: Transparency level for the plot lines (0.0 to 1.0).\n        xlim: Limits for the x-axis as (min, max) tuple.\n        ylim: Limits for the y-axis as (min, max) tuple.\n        **kwargs: Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n            These are passed to the underlying matplotlib plot functions.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic plot\n        &gt;&gt;&gt; cf.plot()\n        &gt;&gt;&gt; # Overlay all channels\n        &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n    \"\"\"\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    from ..visualization.plotting import create_operation\n\n    plot_strategy = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.rms_plot","title":"<code>rms_plot(ax=None, title=None, overlay=True, Aw=False, **kwargs)</code>","text":"<p>Generate an RMS plot.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay the plot on the existing axis.</p> <code>True</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the plot() method. Accepts the same arguments as plot() including xlabel, ylabel, alpha, xlim, ylim, and matplotlib Line2D parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic RMS plot\n&gt;&gt;&gt; cf.rms_plot()\n&gt;&gt;&gt; # With A-weighting\n&gt;&gt;&gt; cf.rms_plot(Aw=True)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def rms_plot(\n    self,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = True,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Generate an RMS plot.\n\n    Args:\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot.\n        overlay: Whether to overlay the plot on the existing axis.\n        Aw: Apply A-weighting.\n        **kwargs: Additional arguments passed to the plot() method.\n            Accepts the same arguments as plot() including xlabel, ylabel,\n            alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic RMS plot\n        &gt;&gt;&gt; cf.rms_plot()\n        &gt;&gt;&gt; # With A-weighting\n        &gt;&gt;&gt; cf.rms_plot(Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n    \"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n    rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n    return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.describe","title":"<code>describe(normalize=True, is_close=True, *, fmin=0, fmax=None, cmap='jet', vmin=None, vmax=None, xlim=None, ylim=None, Aw=False, waveform=None, spectral=None, **kwargs)</code>","text":"<p>Display visual and audio representation of the frame.</p> <p>This method creates a comprehensive visualization with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>Parameters:</p> Name Type Description Default <code>normalize</code> <code>bool</code> <p>Whether to normalize the audio data for playback. Default: True</p> <code>True</code> <code>is_close</code> <code>bool</code> <p>Whether to close the figure after displaying. Default: True</p> <code>True</code> <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>0</code> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency (sampling_rate / 2)</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>'jet'</code> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots. Format: (start_time, end_time)</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots. Format: (min_freq, max_freq)</p> <code>None</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>False</code> <code>waveform</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for waveform subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>spectral</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for spectral subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Deprecated parameters for backward compatibility only. - axis_config: Old configuration format (use waveform/spectral instead) - cbar_config: Old colorbar configuration (use vmin/vmax instead)</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom waveform subplot settings\n&gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def describe(\n    self,\n    normalize: bool = True,\n    is_close: bool = True,\n    *,\n    fmin: float = 0,\n    fmax: float | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    waveform: dict[str, Any] | None = None,\n    spectral: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Display visual and audio representation of the frame.\n\n    This method creates a comprehensive visualization with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Args:\n        normalize: Whether to normalize the audio data for playback.\n            Default: True\n        is_close: Whether to close the figure after displaying.\n            Default: True\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency (sampling_rate / 2)\n        cmap: Colormap for the spectrogram.\n            Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n            Format: (start_time, end_time)\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n            Format: (min_freq, max_freq)\n        Aw: Apply A-weighting to the frequency analysis.\n            Default: False\n        waveform: Additional configuration dict for waveform subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        spectral: Additional configuration dict for spectral subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        **kwargs: Deprecated parameters for backward compatibility only.\n            - axis_config: Old configuration format (use waveform/spectral instead)\n            - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom waveform subplot settings\n        &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n    \"\"\"\n    # Prepare kwargs with explicit parameters\n    plot_kwargs: dict[str, Any] = {\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"xlim\": xlim,\n        \"ylim\": ylim,\n        \"Aw\": Aw,\n        \"waveform\": waveform or {},\n        \"spectral\": spectral or {},\n    }\n    # Merge with additional kwargs\n    plot_kwargs.update(kwargs)\n\n    if \"axis_config\" in plot_kwargs:\n        logger.warning(\n            \"axis_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        axis_config = plot_kwargs[\"axis_config\"]\n        if \"time_plot\" in axis_config:\n            plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n        if \"freq_plot\" in axis_config:\n            if \"xlim\" in axis_config[\"freq_plot\"]:\n                vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                plot_kwargs[\"vmin\"] = vlim[0]\n                plot_kwargs[\"vmax\"] = vlim[1]\n            if \"ylim\" in axis_config[\"freq_plot\"]:\n                ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                plot_kwargs[\"ylim\"] = ylim_config\n\n    if \"cbar_config\" in plot_kwargs:\n        logger.warning(\n            \"cbar_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        cbar_config = plot_kwargs[\"cbar_config\"]\n        if \"vmin\" in cbar_config:\n            plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n        if \"vmax\" in cbar_config:\n            plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n    for ch in self:\n        ax: Axes\n        _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n        if isinstance(_ax, Iterator):\n            ax = next(iter(_ax))\n        elif isinstance(_ax, Axes):\n            ax = _ax\n        else:\n            raise TypeError(\n                f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n            )\n        # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n        display(ax.figure)\n        if is_close:\n            plt.close(getattr(ax, \"figure\", None))\n        display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.from_numpy","title":"<code>from_numpy(data, sampling_rate, label=None, metadata=None, ch_labels=None, ch_units=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayReal</code> <p>NumPy array containing channel data.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> required <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>ch_units</code> <code>list[str] | str | None</code> <p>Units for each channel.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the NumPy data.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayReal,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    ch_labels: list[str] | None = None,\n    ch_units: list[str] | str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing channel data.\n        sampling_rate: The sampling rate in Hz.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        ch_labels: Labels for each channel.\n        ch_units: Units for each channel.\n\n    Returns:\n        A new ChannelFrame containing the NumPy data.\n    \"\"\"\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n\n    # Convert NumPy array to dask array\n    dask_data = da_from_array(data)\n    cf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        label=label or \"numpy_data\",\n    )\n    if metadata is not None:\n        cf.metadata = metadata\n    if ch_labels is not None:\n        if len(ch_labels) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel labels does not match the number of channels\"\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    if ch_units is not None:\n        if isinstance(ch_units, str):\n            ch_units = [ch_units] * cf.n_channels\n\n        if len(ch_units) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel units does not match the number of channels\"\n            )\n        for i in range(len(ch_units)):\n            cf._channel_metadata[i].unit = ch_units[i]\n\n    return cf\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.from_ndarray","title":"<code>from_ndarray(array, sampling_rate, labels=None, unit=None, frame_label=None, metadata=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>This method is deprecated. Use from_numpy instead.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArrayReal</code> <p>Signal data. Each row corresponds to a channel.</p> required <code>sampling_rate</code> <code>float</code> <p>Sampling rate (Hz).</p> required <code>labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>unit</code> <code>list[str] | str | None</code> <p>Unit of the signal.</p> <code>None</code> <code>frame_label</code> <code>str | None</code> <p>Label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_ndarray(\n    cls,\n    array: NDArrayReal,\n    sampling_rate: float,\n    labels: list[str] | None = None,\n    unit: list[str] | str | None = None,\n    frame_label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    This method is deprecated. Use from_numpy instead.\n\n    Args:\n        array: Signal data. Each row corresponds to a channel.\n        sampling_rate: Sampling rate (Hz).\n        labels: Labels for each channel.\n        unit: Unit of the signal.\n        frame_label: Label for the frame.\n        metadata: Optional metadata dictionary.\n\n    Returns:\n        A new ChannelFrame containing the data.\n    \"\"\"\n    # Redirect to from_numpy for compatibility\n    # However, from_ndarray is deprecated\n    logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n    return cls.from_numpy(\n        data=array,\n        sampling_rate=sampling_rate,\n        label=frame_label,\n        metadata=metadata,\n        ch_labels=labels,\n        ch_units=unit,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.from_file","title":"<code>from_file(path, channel=None, start=None, end=None, chunk_size=None, ch_labels=None, time_column=0, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from an audio file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the audio file.</p> required <code>channel</code> <code>int | list[int] | None</code> <p>Channel(s) to load.</p> <code>None</code> <code>start</code> <code>float | None</code> <p>Start time in seconds.</p> <code>None</code> <code>end</code> <code>float | None</code> <p>End time in seconds.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Chunk size for processing. Specifies the splitting size for lazy processing.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>time_column</code> <code>int | str</code> <p>For CSV files, index or name of the time column. Default is 0 (first column).</p> <code>0</code> <code>delimiter</code> <code>str</code> <p>For CSV files, delimiter character. Default is \",\".</p> <code>','</code> <code>header</code> <code>int | None</code> <p>For CSV files, row number to use as header. Default is 0 (first row). Set to None if no header.</p> <code>0</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the loaded audio data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If channel specification is invalid.</p> <code>TypeError</code> <p>If channel parameter type is invalid.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist at the specified path. Error message includes absolute path, current directory, and troubleshooting suggestions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load WAV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n&gt;&gt;&gt; # Load specific channels\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n&gt;&gt;&gt; # Load CSV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\n...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n... )\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    channel: int | list[int] | None = None,\n    start: float | None = None,\n    end: float | None = None,\n    chunk_size: int | None = None,\n    ch_labels: list[str] | None = None,\n    # CSV-specific parameters\n    time_column: int | str = 0,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from an audio file.\n\n    Args:\n        path: Path to the audio file.\n        channel: Channel(s) to load.\n        start: Start time in seconds.\n        end: End time in seconds.\n        chunk_size: Chunk size for processing.\n            Specifies the splitting size for lazy processing.\n        ch_labels: Labels for each channel.\n        time_column: For CSV files, index or name of the time column.\n            Default is 0 (first column).\n        delimiter: For CSV files, delimiter character. Default is \",\".\n        header: For CSV files, row number to use as header.\n            Default is 0 (first row). Set to None if no header.\n\n    Returns:\n        A new ChannelFrame containing the loaded audio data.\n\n    Raises:\n        ValueError: If channel specification is invalid.\n        TypeError: If channel parameter type is invalid.\n        FileNotFoundError: If the file doesn't exist at the specified path.\n            Error message includes absolute path, current directory, and\n            troubleshooting suggestions.\n\n    Examples:\n        &gt;&gt;&gt; # Load WAV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n        &gt;&gt;&gt; # Load specific channels\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n        &gt;&gt;&gt; # Load CSV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\n        ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n        ... )\n    \"\"\"\n    from .channel import ChannelFrame\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Audio file not found\\n\"\n            f\"  Path: {path.absolute()}\\n\"\n            f\"  Current directory: {Path.cwd()}\\n\"\n            f\"Please check:\\n\"\n            f\"  - File path is correct\\n\"\n            f\"  - File exists at the specified location\\n\"\n            f\"  - You have read permissions for the file\"\n        )\n\n    # Get file reader\n    reader = get_file_reader(path)\n\n    # Build kwargs for reader\n    reader_kwargs: dict[str, Any] = {}\n    if path.suffix.lower() == \".csv\":\n        reader_kwargs[\"time_column\"] = time_column\n        reader_kwargs[\"delimiter\"] = delimiter\n        if header is not None:\n            reader_kwargs[\"header\"] = header\n\n    # Get file info\n    info = reader.get_file_info(path, **reader_kwargs)\n    sr = info[\"samplerate\"]\n    n_channels = info[\"channels\"]\n    n_frames = info[\"frames\"]\n    ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n    logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n    # Channel selection processing\n    all_channels = list(range(n_channels))\n\n    if channel is None:\n        channels_to_load = all_channels\n        logger.debug(f\"Will load all channels: {channels_to_load}\")\n    elif isinstance(channel, int):\n        if channel &lt; 0 or channel &gt;= n_channels:\n            raise ValueError(\n                f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n            )\n        channels_to_load = [channel]\n        logger.debug(f\"Will load single channel: {channel}\")\n    elif isinstance(channel, list | tuple):\n        for ch in channel:\n            if ch &lt; 0 or ch &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n        channels_to_load = list(channel)\n        logger.debug(f\"Will load specific channels: {channels_to_load}\")\n    else:\n        raise TypeError(\"channel must be int, list, or None\")\n\n    # Index calculation\n    start_idx = 0 if start is None else max(0, int(start * sr))\n    end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n    frames_to_read = end_idx - start_idx\n\n    logger.debug(\n        f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n        f\"start_idx={start_idx}, end_idx={end_idx}\"\n    )\n\n    # Settings for lazy loading\n    expected_shape = (len(channels_to_load), frames_to_read)\n\n    # Define the loading function using the file reader\n    def _load_audio() -&gt; NDArrayReal:\n        logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n        # Use the reader to get audio data with parameters\n        out = reader.get_data(\n            path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n        )\n        if not isinstance(out, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n        return out\n\n    logger.debug(\n        f\"Creating delayed dask task with expected shape: {expected_shape}\"\n    )\n\n    # Create delayed operation\n    delayed_data = dask_delayed(_load_audio)()\n    logger.debug(\"Wrapping delayed function in dask array\")\n\n    # Create dask array from delayed computation\n    dask_array = da_from_delayed(\n        delayed_data, shape=expected_shape, dtype=np.float32\n    )\n\n    if chunk_size is not None:\n        if chunk_size &lt;= 0:\n            raise ValueError(\"Chunk size must be a positive integer\")\n        logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n        dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n    logger.debug(\n        \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n    )\n\n    cf = ChannelFrame(\n        data=dask_array,\n        sampling_rate=sr,\n        label=path.stem,\n        metadata={\n            \"filename\": str(path),\n        },\n    )\n    if ch_labels is not None:\n        if len(ch_labels) != len(cf):\n            raise ValueError(\n                \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    return cf\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.read_wav","title":"<code>read_wav(filename, labels=None)</code>  <code>classmethod</code>","text":"<p>Utility method to read a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the WAV file.</p> required <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a WAV file.\n\n    Args:\n        filename: Path to the WAV file.\n        labels: Labels to set for each channel.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(filename, ch_labels=labels)\n    return cf\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.read_csv","title":"<code>read_csv(filename, time_column=0, labels=None, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Utility method to read a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> required <code>time_column</code> <code>int | str</code> <p>Index or name of the time column.</p> <code>0</code> <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>Delimiter character.</p> <code>','</code> <code>header</code> <code>int | None</code> <p>Row number to use as header.</p> <code>0</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Read CSV with default settings\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n&gt;&gt;&gt; # Read CSV with custom delimiter\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n&gt;&gt;&gt; # Read CSV without header\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_csv(\n    cls,\n    filename: str,\n    time_column: int | str = 0,\n    labels: list[str] | None = None,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a CSV file.\n\n    Args:\n        filename: Path to the CSV file.\n        time_column: Index or name of the time column.\n        labels: Labels to set for each channel.\n        delimiter: Delimiter character.\n        header: Row number to use as header.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n\n    Examples:\n        &gt;&gt;&gt; # Read CSV with default settings\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n        &gt;&gt;&gt; # Read CSV with custom delimiter\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n        &gt;&gt;&gt; # Read CSV without header\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(\n        filename,\n        ch_labels=labels,\n        time_column=time_column,\n        delimiter=delimiter,\n        header=header,\n    )\n    return cf\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.to_wav","title":"<code>to_wav(path, format=None)</code>","text":"<p>Save the audio data to a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to save the file.</p> required <code>format</code> <code>str | None</code> <p>File format. If None, determined from file extension.</p> <code>None</code> Source code in <code>wandas/frames/channel.py</code> <pre><code>def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n    \"\"\"Save the audio data to a WAV file.\n\n    Args:\n        path: Path to save the file.\n        format: File format. If None, determined from file extension.\n    \"\"\"\n    from wandas.io.wav_io import write_wav\n\n    write_wav(str(path), self, format=format)\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.save","title":"<code>save(path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save the ChannelFrame to a WDF (Wandas Data File) format.</p> <p>This saves the complete frame including all channel data and metadata in a format that can be loaded back with full fidelity.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Example <p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.save(\"audio_analysis.wdf\")</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>def save(\n    self,\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n    This saves the complete frame including all channel data and metadata\n    in a format that can be loaded back with full fidelity.\n\n    Args:\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import save as wdf_save\n\n    wdf_save(\n        self,\n        path,\n        format=format,\n        compress=compress,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.load","title":"<code>load(path, *, format='hdf5')</code>  <code>classmethod</code>","text":"<p>Load a ChannelFrame from a WDF (Wandas Data File) file.</p> <p>This loads data saved with the save() method, preserving all channel data, metadata, labels, and units.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file</p> required <code>format</code> <code>str</code> <p>Format of the file (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame with all data and metadata loaded</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>NotImplementedError</code> <p>For unsupported formats</p> Example <p>cf = ChannelFrame.load(\"audio_analysis.wdf\")</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n    This loads data saved with the save() method, preserving all channel data,\n    metadata, labels, and units.\n\n    Args:\n        path: Path to the WDF file\n        format: Format of the file (currently only 'hdf5' is supported)\n\n    Returns:\n        A new ChannelFrame with all data and metadata loaded\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        NotImplementedError: For unsupported formats\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import load as wdf_load\n\n    return wdf_load(path, format=format)\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.add_channel","title":"<code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False)</code>","text":"<p>Add a new channel to the frame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray[Any, Any] | Array | ChannelFrame</code> <p>Data to add as a new channel. Can be: - numpy array (1D or 2D) - dask array (1D or 2D) - ChannelFrame (channels will be added)</p> required <code>label</code> <code>str | None</code> <p>Label for the new channel. If None, generates a default label. Ignored when data is a ChannelFrame (uses its channel labels).</p> <code>None</code> <code>align</code> <code>str</code> <p>How to handle length mismatches: - \"strict\": Raise error if lengths don't match - \"pad\": Pad shorter data with zeros - \"truncate\": Truncate longer data to match</p> <code>'strict'</code> <code>suffix_on_dup</code> <code>str | None</code> <p>Suffix to add to duplicate labels. If None, raises error.</p> <code>None</code> <code>inplace</code> <code>bool</code> <p>If True, modifies the frame in place. Otherwise returns a new frame.</p> <code>False</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>Modified ChannelFrame (self if inplace=True, new frame otherwise).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data length doesn't match and align=\"strict\", or if label is duplicate and suffix_on_dup is None.</p> <code>TypeError</code> <p>If data type is not supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Add a numpy array as a new channel\n&gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n&gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n&gt;&gt;&gt; # Add another ChannelFrame's channels\n&gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n&gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n</code></pre> Source code in <code>wandas/frames/channel.py</code> <pre><code>def add_channel(\n    self,\n    data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n    label: str | None = None,\n    align: str = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add a new channel to the frame.\n\n    Args:\n        data: Data to add as a new channel. Can be:\n            - numpy array (1D or 2D)\n            - dask array (1D or 2D)\n            - ChannelFrame (channels will be added)\n        label: Label for the new channel. If None, generates a default label.\n            Ignored when data is a ChannelFrame (uses its channel labels).\n        align: How to handle length mismatches:\n            - \"strict\": Raise error if lengths don't match\n            - \"pad\": Pad shorter data with zeros\n            - \"truncate\": Truncate longer data to match\n        suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n        inplace: If True, modifies the frame in place.\n            Otherwise returns a new frame.\n\n    Returns:\n        Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n    Raises:\n        ValueError: If data length doesn't match and align=\"strict\",\n            or if label is duplicate and suffix_on_dup is None.\n        TypeError: If data type is not supported.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Add a numpy array as a new channel\n        &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n        &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n        &gt;&gt;&gt; # Add another ChannelFrame's channels\n        &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n        &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n    \"\"\"\n    # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n    if isinstance(data, ChannelFrame):\n        if self.sampling_rate != data.sampling_rate:\n            raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n        if data.n_samples != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - data.n_samples\n                arr = data._data\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = data._data[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        else:\n            arr = data._data\n        labels = [ch.label for ch in self._channel_metadata]\n        new_labels = []\n        new_metadata_list = []\n        for chmeta in data._channel_metadata:\n            new_label = chmeta.label\n            if new_label in labels or new_label in new_labels:\n                if suffix_on_dup:\n                    new_label += suffix_on_dup\n                else:\n                    raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n            new_labels.append(new_label)\n            # Copy the entire channel_metadata and update only the label\n            new_ch_meta = chmeta.model_copy(deep=True)\n            new_ch_meta.label = new_label\n            new_metadata_list.append(new_ch_meta)\n        new_data = concatenate([self._data, arr], axis=0)\n\n        new_chmeta = self._channel_metadata + new_metadata_list\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n    if isinstance(data, np.ndarray):\n        arr = from_array(data.reshape(1, -1))\n    elif isinstance(data, DaskArray):\n        arr = data[None, ...] if data.ndim == 1 else data\n        if arr.shape[0] != 1:\n            arr = arr.reshape((1, -1))\n    else:\n        raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n    if arr.shape[1] != self.n_samples:\n        if align == \"pad\":\n            pad_len = self.n_samples - arr.shape[1]\n            if pad_len &gt; 0:\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n            else:\n                arr = arr[:, : self.n_samples]\n        elif align == \"truncate\":\n            arr = arr[:, : self.n_samples]\n            if arr.shape[1] &lt; self.n_samples:\n                pad_len = self.n_samples - arr.shape[1]\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n        else:\n            raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n    labels = [ch.label for ch in self._channel_metadata]\n    new_label = label or f\"ch{len(labels)}\"\n    if new_label in labels:\n        if suffix_on_dup:\n            new_label += suffix_on_dup\n        else:\n            raise ValueError(\"label\u91cd\u8907\")\n    new_data = concatenate([self._data, arr], axis=0)\n    from ..core.metadata import ChannelMetadata\n\n    new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"api/frames/#wandas.frames.channel.ChannelFrame.remove_channel","title":"<code>remove_channel(key, inplace=False)</code>","text":"Source code in <code>wandas/frames/channel.py</code> <pre><code>def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n    if isinstance(key, int):\n        if not (0 &lt;= key &lt; self.n_channels):\n            raise IndexError(f\"index {key} out of range\")\n        idx = key\n    else:\n        labels = [ch.label for ch in self._channel_metadata]\n        if key not in labels:\n            raise KeyError(f\"label {key} not found\")\n        idx = labels.index(key)\n    new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n    new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"api/frames/#spectralframe","title":"SpectralFrame","text":"<p>SpectralFrame\u306f\u5468\u6ce2\u6570\u9818\u57df\u306e\u30c7\u30fc\u30bf\u3092\u6271\u3046\u305f\u3081\u306e\u30d5\u30ec\u30fc\u30e0\u3067\u3059\u3002</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame","title":"<code>wandas.frames.spectral.SpectralFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayComplex]</code></p> <p>Class for handling frequency-domain signal data.</p> <p>This class represents spectral data, providing methods for spectral analysis, manipulation, and visualization. It handles complex-valued frequency domain data obtained through operations like FFT.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The spectral data. Must be a dask array with shape:     - (channels, frequency_bins) for multi-channel data     - (frequency_bins,) for single-channel data, which will be       reshaped to (1, frequency_bins) sampling_rate : float     The sampling rate of the original time-domain signal in Hz. n_fft : int     The FFT size used to generate this spectral data. window : str, default=\"hann\"     The window function used in the FFT. label : str, optional     A label for the frame. metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel in the frame. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame--attributes","title":"Attributes","text":"<p>magnitude : NDArrayReal     The magnitude spectrum of the data. phase : NDArrayReal     The phase spectrum in radians. unwrapped_phase : NDArrayReal     The unwrapped phase spectrum in radians. power : NDArrayReal     The power spectrum (magnitude squared). dB : NDArrayReal     The spectrum in decibels relative to channel reference values. dBA : NDArrayReal     The A-weighted spectrum in decibels. freqs : NDArrayReal     The frequency axis values in Hz.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame--examples","title":"Examples","text":"<p>Create a SpectralFrame from FFT:</p> <p>signal = ChannelFrame.from_numpy(data, sampling_rate=44100) spectrum = signal.fft(n_fft=2048)</p> <p>Plot the magnitude spectrum:</p> <p>spectrum.plot()</p> <p>Perform binary operations:</p> <p>scaled = spectrum * 2.0 summed = spectrum1 + spectrum2  # Must have matching sampling rates</p> <p>Convert back to time domain:</p> <p>time_signal = spectrum.ifft()</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame--notes","title":"Notes","text":"<ul> <li>All operations are performed lazily using dask arrays for efficient memory usage.</li> <li>Binary operations (+, -, *, /) can be performed between SpectralFrames or with   scalar values.</li> <li>The class maintains the processing history and metadata through all operations.</li> </ul> Source code in <code>wandas/frames/spectral.py</code> <pre><code>class SpectralFrame(BaseFrame[NDArrayComplex]):\n    \"\"\"\n    Class for handling frequency-domain signal data.\n\n    This class represents spectral data, providing methods for spectral analysis,\n    manipulation, and visualization. It handles complex-valued frequency domain data\n    obtained through operations like FFT.\n\n    Parameters\n    ----------\n    data : DaArray\n        The spectral data. Must be a dask array with shape:\n        - (channels, frequency_bins) for multi-channel data\n        - (frequency_bins,) for single-channel data, which will be\n          reshaped to (1, frequency_bins)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    n_fft : int\n        The FFT size used to generate this spectral data.\n    window : str, default=\"hann\"\n        The window function used in the FFT.\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    magnitude : NDArrayReal\n        The magnitude spectrum of the data.\n    phase : NDArrayReal\n        The phase spectrum in radians.\n    unwrapped_phase : NDArrayReal\n        The unwrapped phase spectrum in radians.\n    power : NDArrayReal\n        The power spectrum (magnitude squared).\n    dB : NDArrayReal\n        The spectrum in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrum in decibels.\n    freqs : NDArrayReal\n        The frequency axis values in Hz.\n\n    Examples\n    --------\n    Create a SpectralFrame from FFT:\n    &gt;&gt;&gt; signal = ChannelFrame.from_numpy(data, sampling_rate=44100)\n    &gt;&gt;&gt; spectrum = signal.fft(n_fft=2048)\n\n    Plot the magnitude spectrum:\n    &gt;&gt;&gt; spectrum.plot()\n\n    Perform binary operations:\n    &gt;&gt;&gt; scaled = spectrum * 2.0\n    &gt;&gt;&gt; summed = spectrum1 + spectrum2  # Must have matching sampling rates\n\n    Convert back to time domain:\n    &gt;&gt;&gt; time_signal = spectrum.ifft()\n\n    Notes\n    -----\n    - All operations are performed lazily using dask arrays for efficient memory usage.\n    - Binary operations (+, -, *, /) can be performed between SpectralFrames or with\n      scalar values.\n    - The class maintains the processing history and metadata through all operations.\n    \"\"\"\n\n    n_fft: int\n    window: str\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        n_fft: int,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: BaseFrame[Any] | None = None,\n    ) -&gt; None:\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def magnitude(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the magnitude spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The absolute values of the complex spectrum.\n        \"\"\"\n        return np.abs(self.data)\n\n    @property\n    def phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the phase spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The phase angles of the complex spectrum in radians.\n        \"\"\"\n        return np.angle(self.data)\n\n    @property\n    def unwrapped_phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the unwrapped phase spectrum.\n\n        The unwrapped phase removes discontinuities of 2\u03c0 radians, providing\n        continuous phase values across frequency bins.\n\n        Returns\n        -------\n        NDArrayReal\n            The unwrapped phase angles of the complex spectrum in radians.\n        \"\"\"\n        return np.unwrap(np.angle(self.data))\n\n    @property\n    def power(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the power spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The squared magnitude spectrum.\n        \"\"\"\n        return self.magnitude**2\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrum in decibels.\n\n        The reference values are taken from channel metadata. If no reference\n        is specified, uses 1.0.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrum in dB relative to channel references.\n        \"\"\"\n        mag: NDArrayReal = self.magnitude\n        ref_values: NDArrayReal = np.array([ch.ref for ch in self._channel_metadata])\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(mag / ref_values[:, np.newaxis], 1e-12)\n        )\n\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrum in decibels.\n\n        Applies A-weighting filter to the spectrum for better correlation with\n        perceived loudness.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrum in dB.\n        \"\"\"\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels.\n        \"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the frequency axis values in Hz.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of frequency values corresponding to each frequency bin.\n        \"\"\"\n        return np.fft.rfftfreq(self.n_fft, 1.0 / self.sampling_rate)\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Implementation of operation application for spectral data.\n\n        This internal method handles the application of various operations to\n        spectral data, maintaining lazy evaluation through dask.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters for the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n        return self._create_new_instance(\n            data=processed_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n        )\n\n    def _binary_op(\n        self,\n        other: (\n            SpectralFrame\n            | int\n            | float\n            | complex\n            | NDArrayComplex\n            | NDArrayReal\n            | DaArray\n        ),\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; SpectralFrame:\n        \"\"\"\n        Common implementation for binary operations.\n\n        This method handles binary operations between SpectralFrames and various types\n        of operands, maintaining lazy evaluation through dask arrays.\n\n        Parameters\n        ----------\n        other : Union[SpectralFrame, int, float, complex,\n                        NDArrayComplex, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation (e.g., lambda a, b: a + b)\n        symbol : str\n            String representation of the operation (e.g., '+')\n\n        Returns\n        -------\n        SpectralFrame\n            A new SpectralFrame containing the result of the operation.\n\n        Raises\n        ------\n        ValueError\n            If attempting to operate with a SpectralFrame\n            with a different sampling rate.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, SpectralFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Directly operate on dask arrays (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Combine channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return SpectralFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly to dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # String representation of operand for display\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, complex):\n                other_str = f\"complex({other.real}, {other.imag})\"\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return SpectralFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n            )\n\n    def plot(\n        self,\n        plot_type: str = \"frequency\",\n        ax: Axes | None = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"\n        Plot the spectral data using various visualization strategies.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"frequency\"\n            Type of plot to create. Options include:\n            - \"frequency\": Standard frequency plot\n            - \"matrix\": Matrix plot for comparing channels\n            - Other types as defined by available plot strategies\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses the frame label.\n        overlay : bool, default=False\n            Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel : str, optional\n            Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n        ylabel : str, optional\n            Label for the y-axis. If None, uses default based on data type.\n        alpha : float, default=1.0\n            Transparency level for the plot lines (0.0 to 1.0).\n        xlim : tuple[float, float], optional\n            Limits for the x-axis as (min, max) tuple.\n        ylim : tuple[float, float], optional\n            Limits for the y-axis as (min, max) tuple.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the data.\n        **kwargs : dict\n            Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; spectrum = cf.fft()\n        &gt;&gt;&gt; # Basic frequency plot\n        &gt;&gt;&gt; spectrum.plot()\n        &gt;&gt;&gt; # Overlay with A-weighting\n        &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def ifft(self) -&gt; ChannelFrame:\n        \"\"\"\n        Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n        This method transforms the frequency-domain data back to the time domain using\n        the inverse FFT operation. The window function used in the forward FFT is\n        taken into account to ensure proper reconstruction.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the time-domain signal.\n        \"\"\"\n        from ..processing import IFFT, create_operation\n        from .channel import ChannelFrame\n\n        params = {\"n_fft\": self.n_fft, \"window\": self.window}\n        operation_name = \"ifft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"IFFT\", operation)\n        # Apply processing to data\n        time_series = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Create new instance\n        return ChannelFrame(\n            data=time_series,\n            sampling_rate=self.sampling_rate,\n            label=f\"ifft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Provide additional initialization arguments required for SpectralFrame.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments for SpectralFrame.\n        \"\"\"\n        return {\n            \"n_fft\": self.n_fft,\n            \"window\": self.window,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; pd.Index[Any]:\n        \"\"\"Get frequency index for DataFrame.\"\"\"\n        return pd.Index(self.freqs, name=\"frequency\")\n\n    def noct_synthesis(\n        self,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; NOctFrame:\n        \"\"\"\n        Synthesize N-octave band spectrum.\n\n        This method combines frequency components into N-octave bands according to\n        standard acoustical band definitions. This is commonly used in noise and\n        vibration analysis.\n\n        Parameters\n        ----------\n        fmin : float\n            Lower frequency bound in Hz.\n        fmax : float\n            Upper frequency bound in Hz.\n        n : int, default=3\n            Number of bands per octave (e.g., 3 for third-octave bands).\n        G : int, default=10\n            Reference band number.\n        fr : int, default=1000\n            Reference frequency in Hz.\n\n        Returns\n        -------\n        NOctFrame\n            A new NOctFrame containing the N-octave band spectrum.\n\n        Raises\n        ------\n        ValueError\n            If the sampling rate is not 48000 Hz, which is required for this operation.\n        \"\"\"\n        if self.sampling_rate != 48000:\n            raise ValueError(\n                \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n            )\n        from ..processing import NOctSynthesis\n        from .noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_synthesis\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSynthesis\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_synthesis\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def plot_matrix(\n        self,\n        plot_type: str = \"matrix\",\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"\n        Plot channel relationships in matrix format.\n\n        This method creates a matrix plot showing relationships between channels,\n        such as coherence, transfer functions, or cross-spectral density.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"matrix\"\n            Type of matrix plot to create.\n        **kwargs : dict\n            Additional plot parameters:\n            - vmin, vmax: Color scale limits\n            - cmap: Colormap name\n            - title: Plot title\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot.\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, **kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the SpectralFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - FFT size\n        - Frequency range\n        - Number of frequency bins\n        - Frequency resolution (\u0394F)\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; spectrum = cf.fft()\n        &gt;&gt;&gt; spectrum.info()\n        SpectralFrame Information:\n          Channels: 2\n          Sampling rate: 44100 Hz\n          FFT size: 2048\n          Frequency range: 0.0 - 22050.0 Hz\n          Frequency bins: 1025\n          Frequency resolution (\u0394F): 21.5 Hz\n          Channel labels: ['ch0', 'ch1']\n          Operations Applied: 1\n        \"\"\"\n        # Calculate frequency resolution (\u0394F)\n        delta_f = self.sampling_rate / self.n_fft\n\n        print(\"SpectralFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  FFT size: {self.n_fft}\")\n        print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n        print(f\"  Frequency bins: {len(self.freqs)}\")\n        print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame-attributes","title":"Attributes","text":""},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.magnitude","title":"<code>magnitude</code>  <code>property</code>","text":"<p>Get the magnitude spectrum.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.magnitude--returns","title":"Returns","text":"<p>NDArrayReal     The absolute values of the complex spectrum.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.phase","title":"<code>phase</code>  <code>property</code>","text":"<p>Get the phase spectrum.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.phase--returns","title":"Returns","text":"<p>NDArrayReal     The phase angles of the complex spectrum in radians.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.unwrapped_phase","title":"<code>unwrapped_phase</code>  <code>property</code>","text":"<p>Get the unwrapped phase spectrum.</p> <p>The unwrapped phase removes discontinuities of 2\u03c0 radians, providing continuous phase values across frequency bins.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.unwrapped_phase--returns","title":"Returns","text":"<p>NDArrayReal     The unwrapped phase angles of the complex spectrum in radians.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.power","title":"<code>power</code>  <code>property</code>","text":"<p>Get the power spectrum.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.power--returns","title":"Returns","text":"<p>NDArrayReal     The squared magnitude spectrum.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.dB","title":"<code>dB</code>  <code>property</code>","text":"<p>Get the spectrum in decibels.</p> <p>The reference values are taken from channel metadata. If no reference is specified, uses 1.0.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.dB--returns","title":"Returns","text":"<p>NDArrayReal     The spectrum in dB relative to channel references.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.dBA","title":"<code>dBA</code>  <code>property</code>","text":"<p>Get the A-weighted spectrum in decibels.</p> <p>Applies A-weighting filter to the spectrum for better correlation with perceived loudness.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.dBA--returns","title":"Returns","text":"<p>NDArrayReal     The A-weighted spectrum in dB.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.freqs","title":"<code>freqs</code>  <code>property</code>","text":"<p>Get the frequency axis values in Hz.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.freqs--returns","title":"Returns","text":"<p>NDArrayReal     Array of frequency values corresponding to each frequency bin.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame-functions","title":"Functions","text":""},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.__init__","title":"<code>__init__(data, sampling_rate, n_fft, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"Source code in <code>wandas/frames/spectral.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: BaseFrame[Any] | None = None,\n) -&gt; None:\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot","title":"<code>plot(plot_type='frequency', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, Aw=False, **kwargs)</code>","text":"<p>Plot the spectral data using various visualization strategies.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"frequency\"     Type of plot to create. Options include:     - \"frequency\": Standard frequency plot     - \"matrix\": Matrix plot for comparing channels     - Other types as defined by available plot strategies ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. title : str, optional     Title for the plot. If None, uses the frame label. overlay : bool, default=False     Whether to overlay all channels on a single plot (True)     or create separate subplots for each channel (False). xlabel : str, optional     Label for the x-axis. If None, uses default \"Frequency [Hz]\". ylabel : str, optional     Label for the y-axis. If None, uses default based on data type. alpha : float, default=1.0     Transparency level for the plot lines (0.0 to 1.0). xlim : tuple[float, float], optional     Limits for the x-axis as (min, max) tuple. ylim : tuple[float, float], optional     Limits for the y-axis as (min, max) tuple. Aw : bool, default=False     Whether to apply A-weighting to the data. **kwargs : dict     Additional matplotlib Line2D parameters     (e.g., color, linewidth, linestyle).</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot, or an iterator of axes     for multi-plot outputs.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot--examples","title":"Examples","text":"<p>spectrum = cf.fft()</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"frequency\",\n    ax: Axes | None = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot the spectral data using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"frequency\"\n        Type of plot to create. Options include:\n        - \"frequency\": Standard frequency plot\n        - \"matrix\": Matrix plot for comparing channels\n        - Other types as defined by available plot strategies\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; # Basic frequency plot\n    &gt;&gt;&gt; spectrum.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot--basic-frequency-plot","title":"Basic frequency plot","text":"<p>spectrum.plot()</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot--overlay-with-a-weighting","title":"Overlay with A-weighting","text":"<p>spectrum.plot(overlay=True, Aw=True)</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot--custom-styling","title":"Custom styling","text":"<p>spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.ifft","title":"<code>ifft()</code>","text":"<p>Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.</p> <p>This method transforms the frequency-domain data back to the time domain using the inverse FFT operation. The window function used in the forward FFT is taken into account to ensure proper reconstruction.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.ifft--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the time-domain signal.</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def ifft(self) -&gt; ChannelFrame:\n    \"\"\"\n    Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n    This method transforms the frequency-domain data back to the time domain using\n    the inverse FFT operation. The window function used in the forward FFT is\n    taken into account to ensure proper reconstruction.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the time-domain signal.\n    \"\"\"\n    from ..processing import IFFT, create_operation\n    from .channel import ChannelFrame\n\n    params = {\"n_fft\": self.n_fft, \"window\": self.window}\n    operation_name = \"ifft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"IFFT\", operation)\n    # Apply processing to data\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Create new instance\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"ifft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.noct_synthesis","title":"<code>noct_synthesis(fmin, fmax, n=3, G=10, fr=1000)</code>","text":"<p>Synthesize N-octave band spectrum.</p> <p>This method combines frequency components into N-octave bands according to standard acoustical band definitions. This is commonly used in noise and vibration analysis.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.noct_synthesis--parameters","title":"Parameters","text":"<p>fmin : float     Lower frequency bound in Hz. fmax : float     Upper frequency bound in Hz. n : int, default=3     Number of bands per octave (e.g., 3 for third-octave bands). G : int, default=10     Reference band number. fr : int, default=1000     Reference frequency in Hz.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.noct_synthesis--returns","title":"Returns","text":"<p>NOctFrame     A new NOctFrame containing the N-octave band spectrum.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.noct_synthesis--raises","title":"Raises","text":"<p>ValueError     If the sampling rate is not 48000 Hz, which is required for this operation.</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def noct_synthesis(\n    self,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; NOctFrame:\n    \"\"\"\n    Synthesize N-octave band spectrum.\n\n    This method combines frequency components into N-octave bands according to\n    standard acoustical band definitions. This is commonly used in noise and\n    vibration analysis.\n\n    Parameters\n    ----------\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number.\n    fr : int, default=1000\n        Reference frequency in Hz.\n\n    Returns\n    -------\n    NOctFrame\n        A new NOctFrame containing the N-octave band spectrum.\n\n    Raises\n    ------\n    ValueError\n        If the sampling rate is not 48000 Hz, which is required for this operation.\n    \"\"\"\n    if self.sampling_rate != 48000:\n        raise ValueError(\n            \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n        )\n    from ..processing import NOctSynthesis\n    from .noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_synthesis\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n    from ..processing import create_operation\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSynthesis\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_synthesis\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot_matrix","title":"<code>plot_matrix(plot_type='matrix', **kwargs)</code>","text":"<p>Plot channel relationships in matrix format.</p> <p>This method creates a matrix plot showing relationships between channels, such as coherence, transfer functions, or cross-spectral density.</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot_matrix--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"matrix\"     Type of matrix plot to create. **kwargs : dict     Additional plot parameters:     - vmin, vmax: Color scale limits     - cmap: Colormap name     - title: Plot title</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.plot_matrix--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot.</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def plot_matrix(\n    self,\n    plot_type: str = \"matrix\",\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot channel relationships in matrix format.\n\n    This method creates a matrix plot showing relationships between channels,\n    such as coherence, transfer functions, or cross-spectral density.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"matrix\"\n        Type of matrix plot to create.\n    **kwargs : dict\n        Additional plot parameters:\n        - vmin, vmax: Color scale limits\n        - cmap: Colormap name\n        - title: Plot title\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, **kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.info","title":"<code>info()</code>","text":"<p>Display comprehensive information about the SpectralFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - FFT size - Frequency range - Number of frequency bins - Frequency resolution (\u0394F) - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p>"},{"location":"api/frames/#wandas.frames.spectral.SpectralFrame.info--examples","title":"Examples","text":"<p>spectrum = cf.fft() spectrum.info() SpectralFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> Source code in <code>wandas/frames/spectral.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectralFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; spectrum.info()\n    SpectralFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F)\n    delta_f = self.sampling_rate / self.n_fft\n\n    print(\"SpectralFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {len(self.freqs)}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/frames/#spectrogramframe","title":"SpectrogramFrame","text":"<p>SpectrogramFrame\u306f\u6642\u9593-\u5468\u6ce2\u6570\u9818\u57df\uff08\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\uff09\u306e\u30c7\u30fc\u30bf\u3092\u6271\u3046\u30d5\u30ec\u30fc\u30e0\u3067\u3059\u3002</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame","title":"<code>wandas.frames.spectrogram.SpectrogramFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayComplex]</code></p> <p>Class for handling time-frequency domain data (spectrograms).</p> <p>This class represents spectrogram data obtained through Short-Time Fourier Transform (STFT) or similar time-frequency analysis methods. It provides methods for visualization, manipulation, and conversion back to time domain.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The spectrogram data. Must be a dask array with shape:     - (channels, frequency_bins, time_frames) for multi-channel data     - (frequency_bins, time_frames) for single-channel data, which will be       reshaped to (1, frequency_bins, time_frames) sampling_rate : float     The sampling rate of the original time-domain signal in Hz. n_fft : int     The FFT size used to generate this spectrogram. hop_length : int     Number of samples between successive frames. win_length : int, optional     The window length in samples. If None, defaults to n_fft. window : str, default=\"hann\"     The window function to use (e.g., \"hann\", \"hamming\", \"blackman\"). label : str, optional     A label for the frame. metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel in the frame. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame--attributes","title":"Attributes","text":"<p>magnitude : NDArrayReal     The magnitude spectrogram. phase : NDArrayReal     The phase spectrogram in radians. power : NDArrayReal     The power spectrogram. dB : NDArrayReal     The spectrogram in decibels relative to channel reference values. dBA : NDArrayReal     The A-weighted spectrogram in decibels. n_frames : int     Number of time frames. n_freq_bins : int     Number of frequency bins. freqs : NDArrayReal     The frequency axis values in Hz. times : NDArrayReal     The time axis values in seconds.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame--examples","title":"Examples","text":"<p>Create a spectrogram from a time-domain signal:</p> <p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512)</p> <p>Extract a specific time frame:</p> <p>frame_at_1s = spectrogram.get_frame_at(int(1.0 * sampling_rate / hop_length))</p> <p>Convert back to time domain:</p> <p>reconstructed = spectrogram.to_channel_frame()</p> <p>Plot the spectrogram:</p> <p>spectrogram.plot()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>class SpectrogramFrame(BaseFrame[NDArrayComplex]):\n    \"\"\"\n    Class for handling time-frequency domain data (spectrograms).\n\n    This class represents spectrogram data obtained through\n    Short-Time Fourier Transform (STFT)\n    or similar time-frequency analysis methods. It provides methods for visualization,\n    manipulation, and conversion back to time domain.\n\n    Parameters\n    ----------\n    data : DaArray\n        The spectrogram data. Must be a dask array with shape:\n        - (channels, frequency_bins, time_frames) for multi-channel data\n        - (frequency_bins, time_frames) for single-channel data, which will be\n          reshaped to (1, frequency_bins, time_frames)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    n_fft : int\n        The FFT size used to generate this spectrogram.\n    hop_length : int\n        Number of samples between successive frames.\n    win_length : int, optional\n        The window length in samples. If None, defaults to n_fft.\n    window : str, default=\"hann\"\n        The window function to use (e.g., \"hann\", \"hamming\", \"blackman\").\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    magnitude : NDArrayReal\n        The magnitude spectrogram.\n    phase : NDArrayReal\n        The phase spectrogram in radians.\n    power : NDArrayReal\n        The power spectrogram.\n    dB : NDArrayReal\n        The spectrogram in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrogram in decibels.\n    n_frames : int\n        Number of time frames.\n    n_freq_bins : int\n        Number of frequency bins.\n    freqs : NDArrayReal\n        The frequency axis values in Hz.\n    times : NDArrayReal\n        The time axis values in seconds.\n\n    Examples\n    --------\n    Create a spectrogram from a time-domain signal:\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n\n    Extract a specific time frame:\n    &gt;&gt;&gt; frame_at_1s = spectrogram.get_frame_at(int(1.0 * sampling_rate / hop_length))\n\n    Convert back to time domain:\n    &gt;&gt;&gt; reconstructed = spectrogram.to_channel_frame()\n\n    Plot the spectrogram:\n    &gt;&gt;&gt; spectrogram.plot()\n    \"\"\"\n\n    n_fft: int\n    hop_length: int\n    win_length: int\n    window: str\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        n_fft: int,\n        hop_length: int,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        if data.ndim == 2:\n            data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n        elif data.ndim != 3:\n            raise ValueError(\n                f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n            )\n        if not data.shape[-2] == n_fft // 2 + 1:\n            raise ValueError(\n                f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n            )\n\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.win_length = win_length if win_length is not None else n_fft\n        self.window = window\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def magnitude(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the magnitude spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The absolute values of the complex spectrogram.\n        \"\"\"\n        return np.abs(self.data)\n\n    @property\n    def phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the phase spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The phase angles of the complex spectrogram in radians.\n        \"\"\"\n        return np.angle(self.data)\n\n    @property\n    def power(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the power spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The squared magnitude of the complex spectrogram.\n        \"\"\"\n        return np.abs(self.data) ** 2\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrogram in decibels relative to each channel's reference value.\n\n        The reference value for each channel is specified in its metadata.\n        A minimum value of -120 dB is enforced to avoid numerical issues.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrogram in decibels.\n        \"\"\"\n        # dB\u898f\u5b9a\u5024\u3092_channel_metadata\u304b\u3089\u53ce\u96c6\n        ref = np.array([ch.ref for ch in self._channel_metadata])\n        # dB\u5909\u63db\n        # 0\u9664\u7b97\u3092\u907f\u3051\u308b\u305f\u3081\u306b\u3001\u6700\u5927\u5024\u30681e-12\u306e\u3044\u305a\u308c\u304b\u3092\u4f7f\u7528\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(self.magnitude / ref[..., np.newaxis, np.newaxis], 1e-12)\n        )\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrogram in decibels.\n\n        A-weighting applies a frequency-dependent weighting filter that approximates\n        the human ear's response. This is particularly useful for analyzing noise\n        and acoustic measurements.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrogram in decibels.\n        \"\"\"\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted[:, np.newaxis]  # \u5468\u6ce2\u6570\u8ef8\u306b\u6cbf\u3063\u3066\u30d6\u30ed\u30fc\u30c9\u30ad\u30e3\u30b9\u30c8\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels.\n        \"\"\"\n        return int(self._data.shape[-3])\n\n    @property\n    def n_frames(self) -&gt; int:\n        \"\"\"\n        Get the number of time frames.\n\n        Returns\n        -------\n        int\n            The number of time frames in the spectrogram.\n        \"\"\"\n        return self.shape[-1]\n\n    @property\n    def n_freq_bins(self) -&gt; int:\n        \"\"\"\n        Get the number of frequency bins.\n\n        Returns\n        -------\n        int\n            The number of frequency bins (n_fft // 2 + 1).\n        \"\"\"\n        return self.shape[-2]\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the frequency axis values in Hz.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of frequency values corresponding to each frequency bin.\n        \"\"\"\n        return np.fft.rfftfreq(self.n_fft, 1.0 / self.sampling_rate)\n\n    @property\n    def times(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the time axis values in seconds.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of time values corresponding to each time frame.\n        \"\"\"\n        return np.arange(self.n_frames) * self.hop_length / self.sampling_rate\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Implementation of operation application for spectrogram data.\n\n        This internal method handles the application of various operations to\n        spectrogram data, maintaining lazy evaluation through dask.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters for the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from wandas.processing import create_operation\n\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        processed_data = operation.process(self._data)\n\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n        return self._create_new_instance(\n            data=processed_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n        )\n\n    def _binary_op(\n        self,\n        other: Union[\n            \"SpectrogramFrame\",\n            int,\n            float,\n            complex,\n            NDArrayComplex,\n            NDArrayReal,\n            \"DaArray\",\n        ],\n        op: Callable[[\"DaArray\", Any], \"DaArray\"],\n        symbol: str,\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"\n        Common implementation for binary operations.\n\n        This method handles binary operations between\n        SpectrogramFrames and various types\n        of operands, maintaining lazy evaluation through dask arrays.\n\n        Parameters\n        ----------\n        other : Union[SpectrogramFrame, int, float, complex,\n            NDArrayComplex, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation (e.g., lambda a, b: a + b)\n        symbol : str\n            String representation of the operation (e.g., '+')\n\n        Returns\n        -------\n        SpectrogramFrame\n            A new SpectrogramFrame containing the result of the operation.\n\n        Raises\n        ------\n        ValueError\n            If attempting to operate with a SpectrogramFrame\n            with a different sampling rate.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        if isinstance(other, SpectrogramFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u304c\u4e00\u81f4\u3057\u3066\u3044\u307e\u305b\u3093\u3002\u6f14\u7b97\u3067\u304d\u307e\u305b\u3093\u3002\"\n                )\n\n            result_data = op(self._data, other._data)\n\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return SpectrogramFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                hop_length=self.hop_length,\n                win_length=self.win_length,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n        else:\n            result_data = op(self._data, other)\n\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, complex):\n                other_str = f\"complex({other.real}, {other.imag})\"\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return SpectrogramFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                hop_length=self.hop_length,\n                win_length=self.win_length,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n            )\n\n    def plot(\n        self,\n        plot_type: str = \"spectrogram\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        fmin: float = 0,\n        fmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the spectrogram using various visualization strategies.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"spectrogram\"\n            Type of plot to create.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses the frame label.\n        cmap : str, default=\"jet\"\n            Colormap name for the spectrogram visualization.\n        vmin : float, optional\n            Minimum value for colormap scaling (dB). Auto-calculated if None.\n        vmax : float, optional\n            Maximum value for colormap scaling (dB). Auto-calculated if None.\n        fmin : float, default=0\n            Minimum frequency to display (Hz).\n        fmax : float, optional\n            Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n        xlim : tuple[float, float], optional\n            Time axis limits as (start_time, end_time) in seconds.\n        ylim : tuple[float, float], optional\n            Frequency axis limits as (min_freq, max_freq) in Hz.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the spectrogram.\n        **kwargs : dict\n            Additional keyword arguments passed to librosa.display.specshow().\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; stft = cf.stft()\n        &gt;&gt;&gt; # Basic spectrogram\n        &gt;&gt;&gt; stft.plot()\n        &gt;&gt;&gt; # Custom color scale and frequency range\n        &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n        &gt;&gt;&gt; # A-weighted spectrogram\n        &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n        plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def plot_Aw(  # noqa: N802\n        self,\n        plot_type: str = \"spectrogram\",\n        ax: Optional[\"Axes\"] = None,\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the A-weighted spectrogram.\n\n        A convenience method that calls plot() with Aw=True, applying A-weighting\n        to the spectrogram before plotting.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"spectrogram\"\n            Type of plot to create.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        **kwargs : dict\n            Additional keyword arguments passed to plot().\n            Accepts all parameters from plot() except Aw (which is set to True).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot.\n\n        Examples\n        --------\n        &gt;&gt;&gt; stft = cf.stft()\n        &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n        &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n        \"\"\"\n        return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n\n    def abs(self) -&gt; \"SpectrogramFrame\":\n        \"\"\"\n        Compute the absolute value (magnitude) of the complex spectrogram.\n\n        This method calculates the magnitude of each complex value in the\n        spectrogram, converting the complex-valued data to real-valued magnitude data.\n        The result is stored in a new SpectrogramFrame with complex dtype to maintain\n        compatibility with other spectrogram operations.\n\n        Returns\n        -------\n        SpectrogramFrame\n            A new SpectrogramFrame containing the magnitude values as complex numbers\n            (with zero imaginary parts).\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n        &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n        &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n        \"\"\"\n        logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n        # Compute the absolute value using dask for lazy evaluation\n        magnitude_data = da.absolute(self._data)\n\n        # Update operation history\n        operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[\"abs\"] = {}\n\n        logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n        return SpectrogramFrame(\n            data=magnitude_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=self.n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=self.window,\n            label=f\"abs({self.label})\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n        \"\"\"\n        Extract spectral data at a specific time frame.\n\n        Parameters\n        ----------\n        time_idx : int\n            Index of the time frame to extract.\n\n        Returns\n        -------\n        SpectralFrame\n            A new SpectralFrame containing the spectral data at the specified time.\n\n        Raises\n        ------\n        IndexError\n            If time_idx is out of range.\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n\n        if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n            raise IndexError(\n                f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n            )\n\n        frame_data = self._data[..., time_idx]\n\n        return SpectralFrame(\n            data=frame_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=self.n_fft,\n            window=self.window,\n            label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def to_channel_frame(self) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Convert the spectrogram back to time domain using inverse STFT.\n\n        This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n        reconstruct the time-domain signal from the spectrogram.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the reconstructed time-domain signal.\n\n        See Also\n        --------\n        istft : Alias for this method with more intuitive naming.\n        \"\"\"\n        from wandas.frames.channel import ChannelFrame\n        from wandas.processing import ISTFT, create_operation\n\n        params = {\n            \"n_fft\": self.n_fft,\n            \"hop_length\": self.hop_length,\n            \"win_length\": self.win_length,\n            \"window\": self.window,\n        }\n        operation_name = \"istft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"ISTFT\", operation)\n        # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n        time_series = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n        return ChannelFrame(\n            data=time_series,\n            sampling_rate=self.sampling_rate,\n            label=f\"istft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def istft(self) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Convert the spectrogram back to time domain using inverse STFT.\n\n        This is an alias for `to_channel_frame()` with a more intuitive name.\n        It performs an inverse Short-Time Fourier Transform (ISTFT) to\n        reconstruct the time-domain signal from the spectrogram.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the reconstructed time-domain signal.\n\n        See Also\n        --------\n        to_channel_frame : The underlying implementation.\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; reconstructed = spectrogram.istft()\n        \"\"\"\n        return self.to_channel_frame()\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get additional initialization arguments for SpectrogramFrame.\n\n        This internal method provides the additional initialization arguments\n        required by SpectrogramFrame beyond those required by BaseFrame.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments.\n        \"\"\"\n        return {\n            \"n_fft\": self.n_fft,\n            \"hop_length\": self.hop_length,\n            \"win_length\": self.win_length,\n            \"window\": self.window,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"DataFrame index is not supported for SpectrogramFrame.\"\"\"\n        raise NotImplementedError(\n            \"DataFrame index is not supported for SpectrogramFrame.\"\n        )\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n        SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n        which cannot be directly converted to a 2D DataFrame. Consider using\n        get_frame_at() to extract a specific time frame as a SpectralFrame,\n        then convert that to a DataFrame.\n\n        Raises\n        ------\n        NotImplementedError\n            Always raised as DataFrame conversion is not supported.\n        \"\"\"\n        raise NotImplementedError(\n            \"DataFrame conversion is not supported for SpectrogramFrame. \"\n            \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n            \"then convert that to a DataFrame.\"\n        )\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - FFT size\n        - Hop length\n        - Window length\n        - Window function\n        - Frequency range\n        - Number of frequency bins\n        - Frequency resolution (\u0394F)\n        - Number of time frames\n        - Time resolution (\u0394T)\n        - Total duration\n        - Channel labels\n        - Number of operations applied\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; spectrogram.info()\n        SpectrogramFrame Information:\n          Channels: 2\n          Sampling rate: 44100 Hz\n          FFT size: 2048\n          Hop length: 512 samples\n          Window length: 2048 samples\n          Window: hann\n          Frequency range: 0.0 - 22050.0 Hz\n          Frequency bins: 1025\n          Frequency resolution (\u0394F): 21.5 Hz\n          Time frames: 100\n          Time resolution (\u0394T): 11.6 ms\n          Total duration: 1.16 s\n          Channel labels: ['ch0', 'ch1']\n          Operations Applied: 1\n        \"\"\"\n        # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n        delta_f = self.sampling_rate / self.n_fft\n        delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n        total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n        print(\"SpectrogramFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  FFT size: {self.n_fft}\")\n        print(f\"  Hop length: {self.hop_length} samples\")\n        print(f\"  Window length: {self.win_length} samples\")\n        print(f\"  Window: {self.window}\")\n        print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n        print(f\"  Frequency bins: {self.n_freq_bins}\")\n        print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n        print(f\"  Time frames: {self.n_frames}\")\n        print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n        print(f\"  Total duration: {total_duration:.2f} s\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayComplex,\n        sampling_rate: float,\n        n_fft: int,\n        hop_length: int,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing spectrogram data.\n                Shape should be (n_channels, n_freq_bins, n_time_frames) or\n                (n_freq_bins, n_time_frames) for single channel.\n            sampling_rate: The sampling rate in Hz.\n            n_fft: The FFT size used to generate this spectrogram.\n            hop_length: Number of samples between successive frames.\n            win_length: The window length in samples. If None, defaults to n_fft.\n            window: The window function used (e.g., \"hann\", \"hamming\").\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Returns:\n            A new SpectrogramFrame containing the NumPy data.\n        \"\"\"\n\n        # Convert NumPy array to dask array\n        dask_data = da.from_array(data)\n        sf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            label=label or \"numpy_spectrogram\",\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n        return sf\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame-attributes","title":"Attributes","text":""},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.hop_length","title":"<code>hop_length = hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.win_length","title":"<code>win_length = win_length if win_length is not None else n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.magnitude","title":"<code>magnitude</code>  <code>property</code>","text":"<p>Get the magnitude spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.magnitude--returns","title":"Returns","text":"<p>NDArrayReal     The absolute values of the complex spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.phase","title":"<code>phase</code>  <code>property</code>","text":"<p>Get the phase spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.phase--returns","title":"Returns","text":"<p>NDArrayReal     The phase angles of the complex spectrogram in radians.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.power","title":"<code>power</code>  <code>property</code>","text":"<p>Get the power spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.power--returns","title":"Returns","text":"<p>NDArrayReal     The squared magnitude of the complex spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.dB","title":"<code>dB</code>  <code>property</code>","text":"<p>Get the spectrogram in decibels relative to each channel's reference value.</p> <p>The reference value for each channel is specified in its metadata. A minimum value of -120 dB is enforced to avoid numerical issues.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.dB--returns","title":"Returns","text":"<p>NDArrayReal     The spectrogram in decibels.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.dBA","title":"<code>dBA</code>  <code>property</code>","text":"<p>Get the A-weighted spectrogram in decibels.</p> <p>A-weighting applies a frequency-dependent weighting filter that approximates the human ear's response. This is particularly useful for analyzing noise and acoustic measurements.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.dBA--returns","title":"Returns","text":"<p>NDArrayReal     The A-weighted spectrogram in decibels.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.n_frames","title":"<code>n_frames</code>  <code>property</code>","text":"<p>Get the number of time frames.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.n_frames--returns","title":"Returns","text":"<p>int     The number of time frames in the spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.n_freq_bins","title":"<code>n_freq_bins</code>  <code>property</code>","text":"<p>Get the number of frequency bins.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.n_freq_bins--returns","title":"Returns","text":"<p>int     The number of frequency bins (n_fft // 2 + 1).</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.freqs","title":"<code>freqs</code>  <code>property</code>","text":"<p>Get the frequency axis values in Hz.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.freqs--returns","title":"Returns","text":"<p>NDArrayReal     Array of frequency values corresponding to each frequency bin.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.times","title":"<code>times</code>  <code>property</code>","text":"<p>Get the time axis values in seconds.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.times--returns","title":"Returns","text":"<p>NDArrayReal     Array of time values corresponding to each time frame.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame-functions","title":"Functions","text":""},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.__init__","title":"<code>__init__(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    if data.ndim == 2:\n        data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n    elif data.ndim != 3:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n        )\n    if not data.shape[-2] == n_fft // 2 + 1:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n        )\n\n    self.n_fft = n_fft\n    self.hop_length = hop_length\n    self.win_length = win_length if win_length is not None else n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot","title":"<code>plot(plot_type='spectrogram', ax=None, title=None, cmap='jet', vmin=None, vmax=None, fmin=0, fmax=None, xlim=None, ylim=None, Aw=False, **kwargs)</code>","text":"<p>Plot the spectrogram using various visualization strategies.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"spectrogram\"     Type of plot to create. ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. title : str, optional     Title for the plot. If None, uses the frame label. cmap : str, default=\"jet\"     Colormap name for the spectrogram visualization. vmin : float, optional     Minimum value for colormap scaling (dB). Auto-calculated if None. vmax : float, optional     Maximum value for colormap scaling (dB). Auto-calculated if None. fmin : float, default=0     Minimum frequency to display (Hz). fmax : float, optional     Maximum frequency to display (Hz). If None, uses Nyquist frequency. xlim : tuple[float, float], optional     Time axis limits as (start_time, end_time) in seconds. ylim : tuple[float, float], optional     Frequency axis limits as (min_freq, max_freq) in Hz. Aw : bool, default=False     Whether to apply A-weighting to the spectrogram. **kwargs : dict     Additional keyword arguments passed to librosa.display.specshow().</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot, or an iterator of axes     for multi-plot outputs.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--examples","title":"Examples","text":"<p>stft = cf.stft()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    fmin: float = 0,\n    fmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the spectrogram using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    cmap : str, default=\"jet\"\n        Colormap name for the spectrogram visualization.\n    vmin : float, optional\n        Minimum value for colormap scaling (dB). Auto-calculated if None.\n    vmax : float, optional\n        Maximum value for colormap scaling (dB). Auto-calculated if None.\n    fmin : float, default=0\n        Minimum frequency to display (Hz).\n    fmax : float, optional\n        Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n    xlim : tuple[float, float], optional\n        Time axis limits as (start_time, end_time) in seconds.\n    ylim : tuple[float, float], optional\n        Frequency axis limits as (min_freq, max_freq) in Hz.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the spectrogram.\n    **kwargs : dict\n        Additional keyword arguments passed to librosa.display.specshow().\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # Basic spectrogram\n    &gt;&gt;&gt; stft.plot()\n    &gt;&gt;&gt; # Custom color scale and frequency range\n    &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n    &gt;&gt;&gt; # A-weighted spectrogram\n    &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n    plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--basic-spectrogram","title":"Basic spectrogram","text":"<p>stft.plot()</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--custom-color-scale-and-frequency-range","title":"Custom color scale and frequency range","text":"<p>stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--a-weighted-spectrogram","title":"A-weighted spectrogram","text":"<p>stft.plot(Aw=True, cmap=\"viridis\")</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw","title":"<code>plot_Aw(plot_type='spectrogram', ax=None, **kwargs)</code>","text":"<p>Plot the A-weighted spectrogram.</p> <p>A convenience method that calls plot() with Aw=True, applying A-weighting to the spectrogram before plotting.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"spectrogram\"     Type of plot to create. ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. **kwargs : dict     Additional keyword arguments passed to plot().     Accepts all parameters from plot() except Aw (which is set to True).</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--examples","title":"Examples","text":"<p>stft = cf.stft()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def plot_Aw(  # noqa: N802\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the A-weighted spectrogram.\n\n    A convenience method that calls plot() with Aw=True, applying A-weighting\n    to the spectrogram before plotting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    **kwargs : dict\n        Additional keyword arguments passed to plot().\n        Accepts all parameters from plot() except Aw (which is set to True).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n    &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n    \"\"\"\n    return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--a-weighted-spectrogram-with-custom-settings","title":"A-weighted spectrogram with custom settings","text":"<p>stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.abs","title":"<code>abs()</code>","text":"<p>Compute the absolute value (magnitude) of the complex spectrogram.</p> <p>This method calculates the magnitude of each complex value in the spectrogram, converting the complex-valued data to real-valued magnitude data. The result is stored in a new SpectrogramFrame with complex dtype to maintain compatibility with other spectrogram operations.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.abs--returns","title":"Returns","text":"<p>SpectrogramFrame     A new SpectrogramFrame containing the magnitude values as complex numbers     (with zero imaginary parts).</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.abs--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) magnitude_spectrogram = spectrogram.abs()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def abs(self) -&gt; \"SpectrogramFrame\":\n    \"\"\"\n    Compute the absolute value (magnitude) of the complex spectrogram.\n\n    This method calculates the magnitude of each complex value in the\n    spectrogram, converting the complex-valued data to real-valued magnitude data.\n    The result is stored in a new SpectrogramFrame with complex dtype to maintain\n    compatibility with other spectrogram operations.\n\n    Returns\n    -------\n    SpectrogramFrame\n        A new SpectrogramFrame containing the magnitude values as complex numbers\n        (with zero imaginary parts).\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n    &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n    &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n    \"\"\"\n    logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n    # Compute the absolute value using dask for lazy evaluation\n    magnitude_data = da.absolute(self._data)\n\n    # Update operation history\n    operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n    new_history = self.operation_history.copy()\n    new_history.append(operation_metadata)\n    new_metadata = {**self.metadata}\n    new_metadata[\"abs\"] = {}\n\n    logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n    return SpectrogramFrame(\n        data=magnitude_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=self.window,\n        label=f\"abs({self.label})\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.abs--the-magnitude-can-be-accessed-via-the-magnitude-property-or-data","title":"The magnitude can be accessed via the magnitude property or data","text":"<p>print(magnitude_spectrogram.magnitude.shape)</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at","title":"<code>get_frame_at(time_idx)</code>","text":"<p>Extract spectral data at a specific time frame.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--parameters","title":"Parameters","text":"<p>time_idx : int     Index of the time frame to extract.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--returns","title":"Returns","text":"<p>SpectralFrame     A new SpectralFrame containing the spectral data at the specified time.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--raises","title":"Raises","text":"<p>IndexError     If time_idx is out of range.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n    \"\"\"\n    Extract spectral data at a specific time frame.\n\n    Parameters\n    ----------\n    time_idx : int\n        Index of the time frame to extract.\n\n    Returns\n    -------\n    SpectralFrame\n        A new SpectralFrame containing the spectral data at the specified time.\n\n    Raises\n    ------\n    IndexError\n        If time_idx is out of range.\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n\n    if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n        raise IndexError(\n            f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n        )\n\n    frame_data = self._data[..., time_idx]\n\n    return SpectralFrame(\n        data=frame_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        window=self.window,\n        label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame","title":"<code>to_channel_frame()</code>","text":"<p>Convert the spectrogram back to time domain using inverse STFT.</p> <p>This method performs an inverse Short-Time Fourier Transform (ISTFT) to reconstruct the time-domain signal from the spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the reconstructed time-domain signal.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame--see-also","title":"See Also","text":"<p>istft : Alias for this method with more intuitive naming.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def to_channel_frame(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    istft : Alias for this method with more intuitive naming.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n    from wandas.processing import ISTFT, create_operation\n\n    params = {\n        \"n_fft\": self.n_fft,\n        \"hop_length\": self.hop_length,\n        \"win_length\": self.win_length,\n        \"window\": self.window,\n    }\n    operation_name = \"istft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"ISTFT\", operation)\n    # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n    )\n\n    # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"istft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.istft","title":"<code>istft()</code>","text":"<p>Convert the spectrogram back to time domain using inverse STFT.</p> <p>This is an alias for <code>to_channel_frame()</code> with a more intuitive name. It performs an inverse Short-Time Fourier Transform (ISTFT) to reconstruct the time-domain signal from the spectrogram.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.istft--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the reconstructed time-domain signal.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.istft--see-also","title":"See Also","text":"<p>to_channel_frame : The underlying implementation.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.istft--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) reconstructed = spectrogram.istft()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def istft(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This is an alias for `to_channel_frame()` with a more intuitive name.\n    It performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    to_channel_frame : The underlying implementation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; reconstructed = spectrogram.istft()\n    \"\"\"\n    return self.to_channel_frame()\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>DataFrame conversion is not supported for SpectrogramFrame.</p> <p>SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames) which cannot be directly converted to a 2D DataFrame. Consider using get_frame_at() to extract a specific time frame as a SpectralFrame, then convert that to a DataFrame.</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n    SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n    which cannot be directly converted to a 2D DataFrame. Consider using\n    get_frame_at() to extract a specific time frame as a SpectralFrame,\n    then convert that to a DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for SpectrogramFrame. \"\n        \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n        \"then convert that to a DataFrame.\"\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.info","title":"<code>info()</code>","text":"<p>Display comprehensive information about the SpectrogramFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - FFT size - Hop length - Window length - Window function - Frequency range - Number of frequency bins - Frequency resolution (\u0394F) - Number of time frames - Time resolution (\u0394T) - Total duration - Channel labels - Number of operations applied</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.info--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) spectrogram.info() SpectrogramFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Hop length: 512 samples   Window length: 2048 samples   Window: hann   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Time frames: 100   Time resolution (\u0394T): 11.6 ms   Total duration: 1.16 s   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Hop length\n    - Window length\n    - Window function\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Number of time frames\n    - Time resolution (\u0394T)\n    - Total duration\n    - Channel labels\n    - Number of operations applied\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; spectrogram.info()\n    SpectrogramFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Hop length: 512 samples\n      Window length: 2048 samples\n      Window: hann\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Time frames: 100\n      Time resolution (\u0394T): 11.6 ms\n      Total duration: 1.16 s\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n    delta_f = self.sampling_rate / self.n_fft\n    delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n    total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n    print(\"SpectrogramFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Hop length: {self.hop_length} samples\")\n    print(f\"  Window length: {self.win_length} samples\")\n    print(f\"  Window: {self.window}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {self.n_freq_bins}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Time frames: {self.n_frames}\")\n    print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n    print(f\"  Total duration: {total_duration:.2f} s\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"api/frames/#wandas.frames.spectrogram.SpectrogramFrame.from_numpy","title":"<code>from_numpy(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>  <code>classmethod</code>","text":"<p>Create a SpectrogramFrame from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayComplex</code> <p>NumPy array containing spectrogram data. Shape should be (n_channels, n_freq_bins, n_time_frames) or (n_freq_bins, n_time_frames) for single channel.</p> required <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> required <code>n_fft</code> <code>int</code> <p>The FFT size used to generate this spectrogram.</p> required <code>hop_length</code> <code>int</code> <p>Number of samples between successive frames.</p> required <code>win_length</code> <code>int | None</code> <p>The window length in samples. If None, defaults to n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>The window function used (e.g., \"hann\", \"hamming\").</p> <code>'hann'</code> <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpectrogramFrame</code> <p>A new SpectrogramFrame containing the NumPy data.</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayComplex,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing spectrogram data.\n            Shape should be (n_channels, n_freq_bins, n_time_frames) or\n            (n_freq_bins, n_time_frames) for single channel.\n        sampling_rate: The sampling rate in Hz.\n        n_fft: The FFT size used to generate this spectrogram.\n        hop_length: Number of samples between successive frames.\n        win_length: The window length in samples. If None, defaults to n_fft.\n        window: The window function used (e.g., \"hann\", \"hamming\").\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Returns:\n        A new SpectrogramFrame containing the NumPy data.\n    \"\"\"\n\n    # Convert NumPy array to dask array\n    dask_data = da.from_array(data)\n    sf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        label=label or \"numpy_spectrogram\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n    return sf\n</code></pre>"},{"location":"api/frames/#noctframe","title":"NOctFrame","text":"<p>NOctFrame\u306f\u30aa\u30af\u30bf\u30fc\u30d6\u30d0\u30f3\u30c9\u89e3\u6790\u306e\u305f\u3081\u306e\u30d5\u30ec\u30fc\u30e0\u30af\u30e9\u30b9\u3067\u3059\u3002</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame","title":"<code>wandas.frames.noct.NOctFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code></p> <p>Class for handling N-octave band analysis data.</p> <p>This class represents frequency data analyzed in fractional octave bands, typically used in acoustic and vibration analysis. It handles real-valued data representing energy or power in each frequency band, following standard acoustical band definitions.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame--parameters","title":"Parameters","text":"<p>data : DaArray     The N-octave band data. Must be a dask array with shape:     - (channels, frequency_bins) for multi-channel data     - (frequency_bins,) for single-channel data, which will be       reshaped to (1, frequency_bins) sampling_rate : float     The sampling rate of the original time-domain signal in Hz. fmin : float, default=0     Lower frequency bound in Hz. fmax : float, default=0     Upper frequency bound in Hz. n : int, default=3     Number of bands per octave (e.g., 3 for third-octave bands). G : int, default=10     Reference band number according to IEC 61260-1:2014. fr : int, default=1000     Reference frequency in Hz, typically 1000 Hz for acoustic analysis. label : str, optional     A label for the frame. metadata : dict, optional     Additional metadata for the frame. operation_history : list[dict], optional     History of operations performed on this frame. channel_metadata : list[ChannelMetadata], optional     Metadata for each channel in the frame. previous : BaseFrame, optional     The frame that this frame was derived from.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame--attributes","title":"Attributes","text":"<p>freqs : NDArrayReal     The center frequencies of each band in Hz, calculated according to     the standard fractional octave band definitions. dB : NDArrayReal     The spectrum in decibels relative to channel reference values. dBA : NDArrayReal     The A-weighted spectrum in decibels, applying frequency weighting     for better correlation with perceived loudness. fmin : float     Lower frequency bound in Hz. fmax : float     Upper frequency bound in Hz. n : int     Number of bands per octave. G : int     Reference band number. fr : int     Reference frequency in Hz.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame--examples","title":"Examples","text":"<p>Create an N-octave band spectrum from a time-domain signal:</p> <p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrum = signal.noct_spectrum(fmin=20, fmax=20000, n=3)</p> <p>Plot the N-octave band spectrum:</p> <p>spectrum.plot()</p> <p>Plot with A-weighting applied:</p> <p>spectrum.plot(Aw=True)</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame--notes","title":"Notes","text":"<ul> <li>Binary operations (addition, multiplication, etc.) are not currently   supported for N-octave band data.</li> <li>The actual frequency bands are determined by the parameters n, G, and fr   according to IEC 61260-1:2014 standard for fractional octave band filters.</li> <li>The class follows acoustic standards for band definitions and analysis,   making it suitable for noise measurements and sound level analysis.</li> <li>A-weighting is available for better correlation with human hearing   perception, following IEC 61672-1:2013.</li> </ul> Source code in <code>wandas/frames/noct.py</code> <pre><code>class NOctFrame(BaseFrame[NDArrayReal]):\n    \"\"\"\n    Class for handling N-octave band analysis data.\n\n    This class represents frequency data analyzed in fractional octave bands,\n    typically used in acoustic and vibration analysis. It handles real-valued\n    data representing energy or power in each frequency band, following standard\n    acoustical band definitions.\n\n    Parameters\n    ----------\n    data : DaArray\n        The N-octave band data. Must be a dask array with shape:\n        - (channels, frequency_bins) for multi-channel data\n        - (frequency_bins,) for single-channel data, which will be\n          reshaped to (1, frequency_bins)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    fmin : float, default=0\n        Lower frequency bound in Hz.\n    fmax : float, default=0\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number according to IEC 61260-1:2014.\n    fr : int, default=1000\n        Reference frequency in Hz, typically 1000 Hz for acoustic analysis.\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    freqs : NDArrayReal\n        The center frequencies of each band in Hz, calculated according to\n        the standard fractional octave band definitions.\n    dB : NDArrayReal\n        The spectrum in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrum in decibels, applying frequency weighting\n        for better correlation with perceived loudness.\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int\n        Number of bands per octave.\n    G : int\n        Reference band number.\n    fr : int\n        Reference frequency in Hz.\n\n    Examples\n    --------\n    Create an N-octave band spectrum from a time-domain signal:\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrum = signal.noct_spectrum(fmin=20, fmax=20000, n=3)\n\n    Plot the N-octave band spectrum:\n    &gt;&gt;&gt; spectrum.plot()\n\n    Plot with A-weighting applied:\n    &gt;&gt;&gt; spectrum.plot(Aw=True)\n\n    Notes\n    -----\n    - Binary operations (addition, multiplication, etc.) are not currently\n      supported for N-octave band data.\n    - The actual frequency bands are determined by the parameters n, G, and fr\n      according to IEC 61260-1:2014 standard for fractional octave band filters.\n    - The class follows acoustic standards for band definitions and analysis,\n      making it suitable for noise measurements and sound level analysis.\n    - A-weighting is available for better correlation with human hearing\n      perception, following IEC 61672-1:2013.\n    \"\"\"\n\n    fmin: float\n    fmax: float\n    n: int\n    G: int\n    fr: int\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        fmin: float = 0,\n        fmax: float = 0,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a NOctFrame instance.\n\n        Sets up N-octave band analysis parameters and prepares the frame for\n        storing band-filtered data. Data shape is validated to ensure compatibility\n        with N-octave band analysis.\n\n        See class docstring for parameter descriptions.\n        \"\"\"\n        self.n = n\n        self.G = G\n        self.fr = fr\n        self.fmin = fmin\n        self.fmax = fmax\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrum in decibels relative to each channel's reference value.\n\n        The reference value for each channel is specified in its metadata.\n        A minimum value of -120 dB is enforced to avoid numerical issues.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrum in decibels. Shape matches the input data shape:\n            (channels, frequency_bins).\n        \"\"\"\n        # Collect dB reference values from _channel_metadata\n        ref = np.array([ch.ref for ch in self._channel_metadata])\n        # Convert to dB\n        # Use either the maximum value or 1e-12 to avoid division by zero\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(self.data / ref[..., np.newaxis], 1e-12)\n        )\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrum in decibels.\n\n        A-weighting applies a frequency-dependent weighting filter that approximates\n        the human ear's response to different frequencies. This is particularly useful\n        for analyzing noise and acoustic measurements as it provides a better\n        correlation with perceived loudness.\n\n        The weighting is applied according to IEC 61672-1:2013 standard.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrum in decibels. Shape matches the input data shape:\n            (channels, frequency_bins).\n        \"\"\"\n        # Collect dB reference values from _channel_metadata\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels in the N-octave band data.\n        \"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the center frequencies of each band in Hz.\n\n        These frequencies are calculated based on the N-octave band parameters\n        (n, G, fr) and the frequency bounds (fmin, fmax) according to\n        IEC 61260-1:2014 standard for fractional octave band filters.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of center frequencies for each frequency band.\n\n        Raises\n        ------\n        ValueError\n            If the center frequencies cannot be calculated or the result\n            is not a numpy array.\n        \"\"\"\n        _, freqs = _center_freq(\n            fmax=self.fmax,\n            fmin=self.fmin,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if isinstance(freqs, np.ndarray):\n            return freqs\n        else:\n            raise ValueError(\"freqs is not numpy array.\")\n\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"\n        Binary operations are not currently supported for N-octave band data.\n\n        Parameters\n        ----------\n        other : Union[S, int, float, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation.\n        symbol : str\n            String representation of the operation (e.g., '+', '-', '*', '/').\n\n        Raises\n        ------\n        NotImplementedError\n            Always raises this error as operations are not implemented\n            for N-octave band data.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Operation {symbol} is not implemented for NOctFrame.\"\n        )\n        return self\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply operations using lazy evaluation.\n        \"\"\"\n        # Apply operations using lazy evaluation\n        raise NotImplementedError(\n            f\"Operation {operation_name} is not implemented for NOctFrame.\"\n        )\n        return self\n\n    def plot(\n        self,\n        plot_type: str = \"noct\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the N-octave band data using various visualization strategies.\n\n        Supports standard plotting configurations for acoustic analysis,\n        including decibel scales and A-weighting.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"noct\"\n            Type of plot to create. The default \"noct\" type creates a step plot\n            suitable for displaying N-octave band data.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses a default title with band specification.\n        overlay : bool, default=False\n            Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel : str, optional\n            Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n        ylabel : str, optional\n            Label for the y-axis. If None, uses default based on data type.\n        alpha : float, default=1.0\n            Transparency level for the plot lines (0.0 to 1.0).\n        xlim : tuple[float, float], optional\n            Limits for the x-axis as (min, max) tuple.\n        ylim : tuple[float, float], optional\n            Limits for the y-axis as (min, max) tuple.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the data.\n        **kwargs : dict\n            Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; noct = spectrum.noct(n=3)\n        &gt;&gt;&gt; # Basic 1/3-octave plot\n        &gt;&gt;&gt; noct.plot()\n        &gt;&gt;&gt; # Overlay with A-weighting\n        &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get additional initialization arguments for NOctFrame.\n\n        This internal method provides the additional initialization arguments\n        required by NOctFrame beyond those required by BaseFrame. These include\n        the N-octave band analysis parameters that define the frequency bands.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments specific to NOctFrame:\n            - n: Number of bands per octave\n            - G: Reference band number\n            - fr: Reference frequency\n            - fmin: Lower frequency bound\n            - fmax: Upper frequency bound\n        \"\"\"\n        return {\n            \"n\": self.n,\n            \"G\": self.G,\n            \"fr\": self.fr,\n            \"fmin\": self.fmin,\n            \"fmax\": self.fmax,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get frequency index for DataFrame.\"\"\"\n        return pd.Index(self.freqs, name=\"frequency\")\n</code></pre>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame-attributes","title":"Attributes","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.n","title":"<code>n = n</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.G","title":"<code>G = G</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.fr","title":"<code>fr = fr</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.fmin","title":"<code>fmin = fmin</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.fmax","title":"<code>fmax = fmax</code>  <code>instance-attribute</code>","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.dB","title":"<code>dB</code>  <code>property</code>","text":"<p>Get the spectrum in decibels relative to each channel's reference value.</p> <p>The reference value for each channel is specified in its metadata. A minimum value of -120 dB is enforced to avoid numerical issues.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.dB--returns","title":"Returns","text":"<p>NDArrayReal     The spectrum in decibels. Shape matches the input data shape:     (channels, frequency_bins).</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.dBA","title":"<code>dBA</code>  <code>property</code>","text":"<p>Get the A-weighted spectrum in decibels.</p> <p>A-weighting applies a frequency-dependent weighting filter that approximates the human ear's response to different frequencies. This is particularly useful for analyzing noise and acoustic measurements as it provides a better correlation with perceived loudness.</p> <p>The weighting is applied according to IEC 61672-1:2013 standard.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.dBA--returns","title":"Returns","text":"<p>NDArrayReal     The A-weighted spectrum in decibels. Shape matches the input data shape:     (channels, frequency_bins).</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.freqs","title":"<code>freqs</code>  <code>property</code>","text":"<p>Get the center frequencies of each band in Hz.</p> <p>These frequencies are calculated based on the N-octave band parameters (n, G, fr) and the frequency bounds (fmin, fmax) according to IEC 61260-1:2014 standard for fractional octave band filters.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.freqs--returns","title":"Returns","text":"<p>NDArrayReal     Array of center frequencies for each frequency band.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.freqs--raises","title":"Raises","text":"<p>ValueError     If the center frequencies cannot be calculated or the result     is not a numpy array.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame-functions","title":"Functions","text":""},{"location":"api/frames/#wandas.frames.noct.NOctFrame.__init__","title":"<code>__init__(data, sampling_rate, fmin=0, fmax=0, n=3, G=10, fr=1000, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a NOctFrame instance.</p> <p>Sets up N-octave band analysis parameters and prepares the frame for storing band-filtered data. Data shape is validated to ensure compatibility with N-octave band analysis.</p> <p>See class docstring for parameter descriptions.</p> Source code in <code>wandas/frames/noct.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    fmin: float = 0,\n    fmax: float = 0,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a NOctFrame instance.\n\n    Sets up N-octave band analysis parameters and prepares the frame for\n    storing band-filtered data. Data shape is validated to ensure compatibility\n    with N-octave band analysis.\n\n    See class docstring for parameter descriptions.\n    \"\"\"\n    self.n = n\n    self.G = G\n    self.fr = fr\n    self.fmin = fmin\n    self.fmax = fmax\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot","title":"<code>plot(plot_type='noct', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, Aw=False, **kwargs)</code>","text":"<p>Plot the N-octave band data using various visualization strategies.</p> <p>Supports standard plotting configurations for acoustic analysis, including decibel scales and A-weighting.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot--parameters","title":"Parameters","text":"<p>plot_type : str, default=\"noct\"     Type of plot to create. The default \"noct\" type creates a step plot     suitable for displaying N-octave band data. ax : matplotlib.axes.Axes, optional     Axes to plot on. If None, creates new axes. title : str, optional     Title for the plot. If None, uses a default title with band specification. overlay : bool, default=False     Whether to overlay all channels on a single plot (True)     or create separate subplots for each channel (False). xlabel : str, optional     Label for the x-axis. If None, uses default \"Center frequency [Hz]\". ylabel : str, optional     Label for the y-axis. If None, uses default based on data type. alpha : float, default=1.0     Transparency level for the plot lines (0.0 to 1.0). xlim : tuple[float, float], optional     Limits for the x-axis as (min, max) tuple. ylim : tuple[float, float], optional     Limits for the y-axis as (min, max) tuple. Aw : bool, default=False     Whether to apply A-weighting to the data. **kwargs : dict     Additional matplotlib Line2D parameters     (e.g., color, linewidth, linestyle).</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot, or an iterator of axes     for multi-plot outputs.</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot--examples","title":"Examples","text":"<p>noct = spectrum.noct(n=3)</p> Source code in <code>wandas/frames/noct.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"noct\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the N-octave band data using various visualization strategies.\n\n    Supports standard plotting configurations for acoustic analysis,\n    including decibel scales and A-weighting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"noct\"\n        Type of plot to create. The default \"noct\" type creates a step plot\n        suitable for displaying N-octave band data.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses a default title with band specification.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; noct = spectrum.noct(n=3)\n    &gt;&gt;&gt; # Basic 1/3-octave plot\n    &gt;&gt;&gt; noct.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot--basic-13-octave-plot","title":"Basic 1/3-octave plot","text":"<p>noct.plot()</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot--overlay-with-a-weighting","title":"Overlay with A-weighting","text":"<p>noct.plot(overlay=True, Aw=True)</p>"},{"location":"api/frames/#wandas.frames.noct.NOctFrame.plot--custom-styling","title":"Custom styling","text":"<p>noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)</p>"},{"location":"api/frames/#mixins","title":"Mixins","text":"<p>\u30d5\u30ec\u30fc\u30e0\u306e\u6a5f\u80fd\u3092\u62e1\u5f35\u3059\u308b\u305f\u3081\u306e\u30df\u30c3\u30af\u30b9\u30a4\u30f3\u3067\u3059\u3002</p>"},{"location":"api/frames/#channelprocessingmixin","title":"ChannelProcessingMixin","text":""},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin","title":"<code>wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin</code>","text":"<p>Mixin that provides methods related to signal processing.</p> <p>This mixin provides processing methods applied to audio signals and other time-series data, such as signal processing filters and transformation operations.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>class ChannelProcessingMixin:\n    \"\"\"Mixin that provides methods related to signal processing.\n\n    This mixin provides processing methods applied to audio signals and\n    other time-series data, such as signal processing filters and\n    transformation operations.\n    \"\"\"\n\n    def high_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a high-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def low_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a low-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def band_pass_filter(\n        self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a band-pass filter to the signal.\n\n        Args:\n            low_cutoff: Lower cutoff frequency (Hz)\n            high_cutoff: Higher cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n            f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"bandpass_filter\",\n            low_cutoff=low_cutoff,\n            high_cutoff=high_cutoff,\n            order=order,\n        )\n        return cast(T_Processing, result)\n\n    def normalize(\n        self: T_Processing,\n        norm: float | None = float(\"inf\"),\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Normalize signal levels using librosa.util.normalize.\n\n        This method normalizes the signal amplitude according to the specified norm.\n\n        Args:\n            norm: Norm type. Default is np.inf (maximum absolute value normalization).\n                Supported values:\n                - np.inf: Maximum absolute value normalization\n                - -np.inf: Minimum absolute value normalization\n                - 0: Peak normalization\n                - float: Lp norm\n                - None: No normalization\n            axis: Axis along which to normalize. Default is -1 (time axis).\n                - -1: Normalize along time axis (each channel independently)\n                - None: Global normalization across all axes\n                - int: Normalize along specified axis\n            threshold: Threshold below which values are considered zero.\n                If None, no threshold is applied.\n            fill: Value to fill when the norm is zero.\n                If None, the zero vector remains zero.\n\n        Returns:\n            New ChannelFrame containing the normalized signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n            &gt;&gt;&gt; normalized = signal.normalize()\n            &gt;&gt;&gt; # Global normalization across all channels\n            &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n            &gt;&gt;&gt; # L2 normalization\n            &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n        \"\"\"\n        logger.debug(\n            f\"Setting up normalize: norm={norm}, axis={axis}, \"\n            f\"threshold={threshold}, fill={fill} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        return cast(T_Processing, result)\n\n    def remove_dc(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Remove DC component (DC offset) from the signal.\n\n        This method removes the DC (direct current) component by subtracting\n        the mean value from each channel. This is equivalent to centering the\n        signal around zero.\n\n        Returns:\n            New ChannelFrame with DC component removed\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; # Create signal with DC offset\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n            &gt;&gt;&gt; # Remove DC offset\n            &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n            &gt;&gt;&gt; # Verify DC removal\n            &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n        Notes:\n            - This operation is performed per channel\n            - Equivalent to applying a high-pass filter with very low cutoff\n            - Useful for removing sensor drift or measurement offset\n        \"\"\"\n        logger.debug(\"Setting up DC removal (lazy)\")\n        result = self.apply_operation(\"remove_dc\")\n        return cast(T_Processing, result)\n\n    def a_weighting(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Apply A-weighting filter to the signal.\n\n        A-weighting adjusts the frequency response to approximate human\n        auditory perception, according to the IEC 61672-1:2013 standard.\n\n        Returns:\n            New ChannelFrame containing the A-weighted signal\n        \"\"\"\n        result = self.apply_operation(\"a_weighting\")\n        return cast(T_Processing, result)\n\n    def abs(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Compute the absolute value of the signal.\n\n        Returns:\n            New ChannelFrame containing the absolute values\n        \"\"\"\n        result = self.apply_operation(\"abs\")\n        return cast(T_Processing, result)\n\n    def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n        \"\"\"Compute the power of the signal.\n\n        Args:\n            exponent: Exponent to raise the signal to. Default is 2.0.\n\n        Returns:\n            New ChannelFrame containing the powered signal\n        \"\"\"\n        result = self.apply_operation(\"power\", exponent=exponent)\n        return cast(T_Processing, result)\n\n    def _reduce_channels(self: T_Processing, op: str) -&gt; T_Processing:\n        \"\"\"Helper to reduce all channels with the given operation ('sum' or 'mean').\"\"\"\n        if op == \"sum\":\n            reduced_data = self._data.sum(axis=0, keepdims=True)\n            label = \"sum\"\n        elif op == \"mean\":\n            reduced_data = self._data.mean(axis=0, keepdims=True)\n            label = \"mean\"\n        else:\n            raise ValueError(f\"Unsupported reduction operation: {op}\")\n\n        units = [ch.unit for ch in self._channel_metadata]\n        if all(u == units[0] for u in units):\n            reduced_unit = units[0]\n        else:\n            reduced_unit = \"\"\n\n        reduced_extra = {\"source_extras\": [ch.extra for ch in self._channel_metadata]}\n        new_channel_metadata = [\n            ChannelMetadata(\n                label=label,\n                unit=reduced_unit,\n                extra=reduced_extra,\n            )\n        ]\n        new_history = (\n            self.operation_history.copy() if hasattr(self, \"operation_history\") else []\n        )\n        new_history.append({\"operation\": op})\n        new_metadata = self.metadata.copy() if hasattr(self, \"metadata\") else {}\n        result = self._create_new_instance(\n            data=reduced_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=new_channel_metadata,\n        )\n        return result\n\n    def sum(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Sum all channels.\n\n        Returns:\n            A new ChannelFrame with summed signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n\n    def mean(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Average all channels.\n\n        Returns:\n            A new ChannelFrame with averaged signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n\n    def trim(\n        self: T_Processing,\n        start: float = 0,\n        end: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Trim the signal to the specified time range.\n\n        Args:\n            start: Start time (seconds)\n            end: End time (seconds)\n\n        Returns:\n            New ChannelFrame containing the trimmed signal\n\n        Raises:\n            ValueError: If end time is earlier than start time\n        \"\"\"\n        if end is None:\n            end = self.duration\n        if start &gt; end:\n            raise ValueError(\"start must be less than end\")\n        result = self.apply_operation(\"trim\", start=start, end=end)\n        return cast(T_Processing, result)\n\n    def fix_length(\n        self: T_Processing,\n        length: int | None = None,\n        duration: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Adjust the signal to the specified length.\n\n        Args:\n            duration: Signal length in seconds\n            length: Signal length in samples\n\n        Returns:\n            New ChannelFrame containing the adjusted signal\n        \"\"\"\n\n        result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n        return cast(T_Processing, result)\n\n    def rms_trend(\n        self: T_Processing,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; T_Processing:\n        \"\"\"Compute the RMS trend of the signal.\n\n        This method calculates the root mean square value over a sliding window.\n\n        Args:\n            frame_length: Size of the sliding window in samples. Default is 2048.\n            hop_length: Hop length between windows in samples. Default is 512.\n            dB: Whether to return RMS values in decibels. Default is False.\n            Aw: Whether to apply A-weighting. Default is False.\n\n        Returns:\n            New ChannelFrame containing the RMS trend\n        \"\"\"\n        # Access _channel_metadata to retrieve reference values\n        frame = cast(ProcessingFrameProtocol, self)\n\n        # Ensure _channel_metadata exists before referencing\n        ref_values = []\n        if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n            ref_values = [ch.ref for ch in frame._channel_metadata]\n\n        result = self.apply_operation(\n            \"rms_trend\",\n            frame_length=frame_length,\n            hop_length=hop_length,\n            ref=ref_values,\n            dB=dB,\n            Aw=Aw,\n        )\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def channel_difference(\n        self: T_Processing, other_channel: int | str = 0\n    ) -&gt; T_Processing:\n        \"\"\"Compute the difference between channels.\n\n        Args:\n            other_channel: Index or label of the reference channel. Default is 0.\n\n        Returns:\n            New ChannelFrame containing the channel difference\n        \"\"\"\n        # label2index is a method of BaseFrame\n        if isinstance(other_channel, str):\n            if hasattr(self, \"label2index\"):\n                other_channel = self.label2index(other_channel)\n\n        result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n        return cast(T_Processing, result)\n\n    def resampling(\n        self: T_Processing,\n        target_sr: float,\n        **kwargs: Any,\n    ) -&gt; T_Processing:\n        \"\"\"Resample audio data.\n\n        Args:\n            target_sr: Target sampling rate (Hz)\n            **kwargs: Additional resampling parameters\n\n        Returns:\n            Resampled ChannelFrame\n        \"\"\"\n        return cast(\n            T_Processing,\n            self.apply_operation(\n                \"resampling\",\n                target_sr=target_sr,\n                **kwargs,\n            ),\n        )\n\n    def hpss_harmonic(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract harmonic components using HPSS\n         (Harmonic-Percussive Source Separation).\n\n        This method separates the harmonic (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n            n_fft: Size of FFT window.\n            hop_length: Hop length for STFT.\n            win_length: Window length for STFT.\n            window: Window type for STFT.\n            center: If True, center the frames.\n            pad_mode: Padding mode for STFT.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_harmonic\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def hpss_percussive(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract percussive components using HPSS\n        (Harmonic-Percussive Source Separation).\n\n        This method separates the percussive (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_percussive\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n        \"\"\"\n        Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of non-stationary signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            New ChannelFrame containing time-varying loudness values in sones.\n            Each channel is processed independently.\n            The output sampling rate is adjusted based on the loudness\n            calculation time resolution (typically ~500 Hz for 2ms steps).\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate loudness for a signal:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n        Notes:\n            - The output contains time-varying loudness values in sones\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - The time resolution is approximately 2ms (determined by the algorithm)\n            - For multi-channel signals, loudness is calculated per channel\n            - The output sampling rate is updated to reflect the time resolution\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 2ms analysis step. This differs slightly from the MoSQITo\n            library, which uses the center time of each step. For example:\n\n            - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n            - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n            The difference is very small (~1ms) and does not affect the loudness\n            values themselves. This design choice ensures consistency with\n            wandas's time axis convention across all frame types.\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n        \"\"\"\n        Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of stationary (steady) signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        This method is suitable for analyzing steady sounds such as fan noise,\n        constant machinery sounds, or other stationary signals.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            Loudness values in sones, one per channel. Shape: (n_channels,)\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate steady-state loudness for a fan noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n            &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n        Notes:\n            - Returns a 1D array with one loudness value per channel\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - For multi-channel signals, loudness is calculated independently\n              per channel\n            - This method is designed for stationary signals (constant sounds)\n            - For time-varying signals, use loudness_zwtv() instead\n            - Similar to the rms property, returns NDArrayReal for consistency\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        # Treat self as a ProcessingFrameProtocol so mypy understands\n        # where sampling_rate and data come from.\n        from wandas.processing.psychoacoustic import LoudnessZwst\n        from wandas.utils.types import NDArrayReal\n\n        # Create operation instance\n        operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n        # Get data (triggers computation if lazy)\n        data = self.data\n\n        # Ensure data is 2D (n_channels, n_samples)\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        # Process the array using the public API and materialize to NumPy\n        result = operation.process_array(data).compute()\n\n        # Squeeze to get 1D array (n_channels,)\n        loudness_values: NDArrayReal = result.squeeze()\n\n        # Ensure it's 1D even for single channel\n        if loudness_values.ndim == 0:\n            loudness_values = loudness_values.reshape(1)\n\n        return loudness_values\n\n    def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n        \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n        Roughness is a psychoacoustic metric that quantifies the perceived\n        harshness or roughness of a sound, measured in asper. This method\n        implements the Daniel &amp; Weber (1997) standard calculation.\n\n        The calculation follows the standard formula:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            New ChannelFrame containing time-varying roughness values in asper.\n            The output sampling rate depends on the overlap parameter.\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Calculate roughness for a motor noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n            &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n            &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n            Analyze roughness statistics:\n            &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n            &gt;&gt;&gt; max_roughness = roughness.data.max()\n            &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n            &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n            Compare before and after modification:\n            &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n            &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n            &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n            &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n        Notes:\n            - Returns a ChannelFrame with time-varying roughness values\n            - Typical roughness values: 0-2 asper for most sounds\n            - Higher values indicate rougher, harsher sounds\n            - For multi-channel signals, roughness is calculated independently\n              per channel\n            - This is the standard-compliant total roughness (R)\n            - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 200ms analysis window. This differs from the MoSQITo library,\n            which uses the center time of each window. For example:\n\n            - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n            - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n            The difference is constant (half the window duration = 100ms) and\n            does not affect the roughness values themselves. This design choice\n            ensures consistency with wandas's time axis convention across all\n            frame types.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n        logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n        result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n        return cast(T_Processing, result)\n\n    def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n        \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n        This method returns detailed roughness analysis data organized by\n        Bark frequency bands over time, allowing for frequency-specific\n        roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n        The relationship between total roughness and specific roughness:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            RoughnessFrame containing:\n                - data: Specific roughness by Bark band, shape (47, n_time)\n                        for mono or (n_channels, 47, n_time) for multi-channel\n                - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n                - time: Time axis for each analysis frame\n                - overlap: Overlap coefficient used\n                - plot(): Method for Bark-Time heatmap visualization\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Analyze frequency-specific roughness:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n            &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Plot Bark-Time heatmap\n            &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Find dominant Bark band\n            &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n            &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n            &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Extract specific Bark band time series\n            &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n            &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Verify standard formula\n            &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n            &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n        Notes:\n            - Returns a RoughnessFrame (not ChannelFrame)\n            - Contains 47 Bark bands from 0.5 to 23.5 Bark\n            - Each Bark band corresponds to a critical band of hearing\n            - Useful for identifying which frequencies contribute most to roughness\n            - The specific roughness can be integrated to obtain total roughness\n            - For simple time-series analysis, use roughness_dw() instead\n\n            **Time axis convention:**\n            The time axis represents the start time of each 200ms analysis\n            window, consistent with roughness_dw() and other wandas methods.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n\n        params = {\"overlap\": overlap}\n        operation_name = \"roughness_dw_spec\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance via factory\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing lazily to self._data (Dask)\n        r_spec_dask = operation.process(self._data)\n\n        # Get metadata updates (sampling rate, bark_axis)\n        metadata_updates = operation.get_metadata_updates()\n\n        # Build metadata and history\n        new_metadata = {**self.metadata, **params}\n        new_history = [\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ]\n\n        # Extract bark_axis with proper type handling\n        bark_axis_value = metadata_updates.get(\"bark_axis\")\n        if bark_axis_value is None:\n            raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n        # Create RoughnessFrame. operation.get_metadata_updates() should provide\n        # sampling_rate and bark_axis\n        roughness_frame = RoughnessFrame(\n            data=r_spec_dask,\n            sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n            bark_axis=bark_axis_value,\n            overlap=overlap,\n            label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=cast(\"BaseFrame[NDArrayReal]\", self),\n        )\n\n        logger.debug(\n            \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n            operation_name,\n            r_spec_dask.shape,\n            roughness_frame.sampling_rate,\n        )\n\n        return roughness_frame\n\n    def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n        \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n        This method applies a symmetric fade-in and fade-out envelope to the signal\n        using a Tukey (tapered cosine) window. The fade duration is the same for\n        both the beginning and end of the signal.\n\n        Args:\n            fade_ms: Fade duration in milliseconds for each end of the signal.\n                The total fade duration is 2 * fade_ms. Default is 50 ms.\n                Must be positive and less than half the signal duration.\n\n        Returns:\n            New ChannelFrame containing the faded signal\n\n        Raises:\n            ValueError: If fade_ms is negative or too long for the signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n            &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n            &gt;&gt;&gt; # Apply very short fade (almost no effect)\n            &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n        Notes:\n            - Uses SciPy's Tukey window for smooth fade transitions\n            - Fade is applied symmetrically to both ends of the signal\n            - The Tukey window alpha parameter is computed automatically\n              based on the fade duration and signal length\n            - For multi-channel signals, the same fade envelope is applied\n              to all channels\n            - Lazy evaluation is preserved - computation occurs only when needed\n        \"\"\"\n        logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n        result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n        return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin-functions","title":"Functions","text":""},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.high_pass_filter","title":"<code>high_pass_filter(cutoff, order=4)</code>","text":"<p>Apply a high-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def high_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a high-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.low_pass_filter","title":"<code>low_pass_filter(cutoff, order=4)</code>","text":"<p>Apply a low-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def low_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a low-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.band_pass_filter","title":"<code>band_pass_filter(low_cutoff, high_cutoff, order=4)</code>","text":"<p>Apply a band-pass filter to the signal.</p> <p>Parameters:</p> Name Type Description Default <code>low_cutoff</code> <code>float</code> <p>Lower cutoff frequency (Hz)</p> required <code>high_cutoff</code> <code>float</code> <p>Higher cutoff frequency (Hz)</p> required <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame after filter application</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def band_pass_filter(\n    self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a band-pass filter to the signal.\n\n    Args:\n        low_cutoff: Lower cutoff frequency (Hz)\n        high_cutoff: Higher cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n        f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"bandpass_filter\",\n        low_cutoff=low_cutoff,\n        high_cutoff=high_cutoff,\n        order=order,\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.normalize","title":"<code>normalize(norm=float('inf'), axis=-1, threshold=None, fill=None)</code>","text":"<p>Normalize signal levels using librosa.util.normalize.</p> <p>This method normalizes the signal amplitude according to the specified norm.</p> <p>Parameters:</p> Name Type Description Default <code>norm</code> <code>float | None</code> <p>Norm type. Default is np.inf (maximum absolute value normalization). Supported values: - np.inf: Maximum absolute value normalization - -np.inf: Minimum absolute value normalization - 0: Peak normalization - float: Lp norm - None: No normalization</p> <code>float('inf')</code> <code>axis</code> <code>int | None</code> <p>Axis along which to normalize. Default is -1 (time axis). - -1: Normalize along time axis (each channel independently) - None: Global normalization across all axes - int: Normalize along specified axis</p> <code>-1</code> <code>threshold</code> <code>float | None</code> <p>Threshold below which values are considered zero. If None, no threshold is applied.</p> <code>None</code> <code>fill</code> <code>bool | None</code> <p>Value to fill when the norm is zero. If None, the zero vector remains zero.</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the normalized signal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n&gt;&gt;&gt; normalized = signal.normalize()\n&gt;&gt;&gt; # Global normalization across all channels\n&gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n&gt;&gt;&gt; # L2 normalization\n&gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n</code></pre> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def normalize(\n    self: T_Processing,\n    norm: float | None = float(\"inf\"),\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n) -&gt; T_Processing:\n    \"\"\"Normalize signal levels using librosa.util.normalize.\n\n    This method normalizes the signal amplitude according to the specified norm.\n\n    Args:\n        norm: Norm type. Default is np.inf (maximum absolute value normalization).\n            Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Peak normalization\n            - float: Lp norm\n            - None: No normalization\n        axis: Axis along which to normalize. Default is -1 (time axis).\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold: Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill: Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n    Returns:\n        New ChannelFrame containing the normalized signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n        &gt;&gt;&gt; normalized = signal.normalize()\n        &gt;&gt;&gt; # Global normalization across all channels\n        &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n        &gt;&gt;&gt; # L2 normalization\n        &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n    \"\"\"\n    logger.debug(\n        f\"Setting up normalize: norm={norm}, axis={axis}, \"\n        f\"threshold={threshold}, fill={fill} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.remove_dc","title":"<code>remove_dc()</code>","text":"<p>Remove DC component (DC offset) from the signal.</p> <p>This method removes the DC (direct current) component by subtracting the mean value from each channel. This is equivalent to centering the signal around zero.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame with DC component removed</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create signal with DC offset\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n&gt;&gt;&gt; # Remove DC offset\n&gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n&gt;&gt;&gt; # Verify DC removal\n&gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n</code></pre> Notes <ul> <li>This operation is performed per channel</li> <li>Equivalent to applying a high-pass filter with very low cutoff</li> <li>Useful for removing sensor drift or measurement offset</li> </ul> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def remove_dc(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This method removes the DC (direct current) component by subtracting\n    the mean value from each channel. This is equivalent to centering the\n    signal around zero.\n\n    Returns:\n        New ChannelFrame with DC component removed\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # Create signal with DC offset\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n        &gt;&gt;&gt; # Remove DC offset\n        &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n        &gt;&gt;&gt; # Verify DC removal\n        &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n    Notes:\n        - This operation is performed per channel\n        - Equivalent to applying a high-pass filter with very low cutoff\n        - Useful for removing sensor drift or measurement offset\n    \"\"\"\n    logger.debug(\"Setting up DC removal (lazy)\")\n    result = self.apply_operation(\"remove_dc\")\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.a_weighting","title":"<code>a_weighting()</code>","text":"<p>Apply A-weighting filter to the signal.</p> <p>A-weighting adjusts the frequency response to approximate human auditory perception, according to the IEC 61672-1:2013 standard.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the A-weighted signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def a_weighting(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Apply A-weighting filter to the signal.\n\n    A-weighting adjusts the frequency response to approximate human\n    auditory perception, according to the IEC 61672-1:2013 standard.\n\n    Returns:\n        New ChannelFrame containing the A-weighted signal\n    \"\"\"\n    result = self.apply_operation(\"a_weighting\")\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.abs","title":"<code>abs()</code>","text":"<p>Compute the absolute value of the signal.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the absolute values</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def abs(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Compute the absolute value of the signal.\n\n    Returns:\n        New ChannelFrame containing the absolute values\n    \"\"\"\n    result = self.apply_operation(\"abs\")\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.power","title":"<code>power(exponent=2.0)</code>","text":"<p>Compute the power of the signal.</p> <p>Parameters:</p> Name Type Description Default <code>exponent</code> <code>float</code> <p>Exponent to raise the signal to. Default is 2.0.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the powered signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n    \"\"\"Compute the power of the signal.\n\n    Args:\n        exponent: Exponent to raise the signal to. Default is 2.0.\n\n    Returns:\n        New ChannelFrame containing the powered signal\n    \"\"\"\n    result = self.apply_operation(\"power\", exponent=exponent)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.sum","title":"<code>sum()</code>","text":"<p>Sum all channels.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame with summed signal.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def sum(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Sum all channels.\n\n    Returns:\n        A new ChannelFrame with summed signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.mean","title":"<code>mean()</code>","text":"<p>Average all channels.</p> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame with averaged signal.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def mean(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Average all channels.\n\n    Returns:\n        A new ChannelFrame with averaged signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.trim","title":"<code>trim(start=0, end=None)</code>","text":"<p>Trim the signal to the specified time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float</code> <p>Start time (seconds)</p> <code>0</code> <code>end</code> <code>float | None</code> <p>End time (seconds)</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the trimmed signal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If end time is earlier than start time</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def trim(\n    self: T_Processing,\n    start: float = 0,\n    end: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Trim the signal to the specified time range.\n\n    Args:\n        start: Start time (seconds)\n        end: End time (seconds)\n\n    Returns:\n        New ChannelFrame containing the trimmed signal\n\n    Raises:\n        ValueError: If end time is earlier than start time\n    \"\"\"\n    if end is None:\n        end = self.duration\n    if start &gt; end:\n        raise ValueError(\"start must be less than end\")\n    result = self.apply_operation(\"trim\", start=start, end=end)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.fix_length","title":"<code>fix_length(length=None, duration=None)</code>","text":"<p>Adjust the signal to the specified length.</p> <p>Parameters:</p> Name Type Description Default <code>duration</code> <code>float | None</code> <p>Signal length in seconds</p> <code>None</code> <code>length</code> <code>int | None</code> <p>Signal length in samples</p> <code>None</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the adjusted signal</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fix_length(\n    self: T_Processing,\n    length: int | None = None,\n    duration: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Adjust the signal to the specified length.\n\n    Args:\n        duration: Signal length in seconds\n        length: Signal length in samples\n\n    Returns:\n        New ChannelFrame containing the adjusted signal\n    \"\"\"\n\n    result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.rms_trend","title":"<code>rms_trend(frame_length=2048, hop_length=512, dB=False, Aw=False)</code>","text":"<p>Compute the RMS trend of the signal.</p> <p>This method calculates the root mean square value over a sliding window.</p> <p>Parameters:</p> Name Type Description Default <code>frame_length</code> <code>int</code> <p>Size of the sliding window in samples. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int</code> <p>Hop length between windows in samples. Default is 512.</p> <code>512</code> <code>dB</code> <code>bool</code> <p>Whether to return RMS values in decibels. Default is False.</p> <code>False</code> <code>Aw</code> <code>bool</code> <p>Whether to apply A-weighting. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the RMS trend</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def rms_trend(\n    self: T_Processing,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; T_Processing:\n    \"\"\"Compute the RMS trend of the signal.\n\n    This method calculates the root mean square value over a sliding window.\n\n    Args:\n        frame_length: Size of the sliding window in samples. Default is 2048.\n        hop_length: Hop length between windows in samples. Default is 512.\n        dB: Whether to return RMS values in decibels. Default is False.\n        Aw: Whether to apply A-weighting. Default is False.\n\n    Returns:\n        New ChannelFrame containing the RMS trend\n    \"\"\"\n    # Access _channel_metadata to retrieve reference values\n    frame = cast(ProcessingFrameProtocol, self)\n\n    # Ensure _channel_metadata exists before referencing\n    ref_values = []\n    if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n        ref_values = [ch.ref for ch in frame._channel_metadata]\n\n    result = self.apply_operation(\n        \"rms_trend\",\n        frame_length=frame_length,\n        hop_length=hop_length,\n        ref=ref_values,\n        dB=dB,\n        Aw=Aw,\n    )\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.channel_difference","title":"<code>channel_difference(other_channel=0)</code>","text":"<p>Compute the difference between channels.</p> <p>Parameters:</p> Name Type Description Default <code>other_channel</code> <code>int | str</code> <p>Index or label of the reference channel. Default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the channel difference</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def channel_difference(\n    self: T_Processing, other_channel: int | str = 0\n) -&gt; T_Processing:\n    \"\"\"Compute the difference between channels.\n\n    Args:\n        other_channel: Index or label of the reference channel. Default is 0.\n\n    Returns:\n        New ChannelFrame containing the channel difference\n    \"\"\"\n    # label2index is a method of BaseFrame\n    if isinstance(other_channel, str):\n        if hasattr(self, \"label2index\"):\n            other_channel = self.label2index(other_channel)\n\n    result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.resampling","title":"<code>resampling(target_sr, **kwargs)</code>","text":"<p>Resample audio data.</p> <p>Parameters:</p> Name Type Description Default <code>target_sr</code> <code>float</code> <p>Target sampling rate (Hz)</p> required <code>**kwargs</code> <code>Any</code> <p>Additional resampling parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>Resampled ChannelFrame</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def resampling(\n    self: T_Processing,\n    target_sr: float,\n    **kwargs: Any,\n) -&gt; T_Processing:\n    \"\"\"Resample audio data.\n\n    Args:\n        target_sr: Target sampling rate (Hz)\n        **kwargs: Additional resampling parameters\n\n    Returns:\n        Resampled ChannelFrame\n    \"\"\"\n    return cast(\n        T_Processing,\n        self.apply_operation(\n            \"resampling\",\n            target_sr=target_sr,\n            **kwargs,\n        ),\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.hpss_harmonic","title":"<code>hpss_harmonic(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code>","text":"<p>Extract harmonic components using HPSS  (Harmonic-Percussive Source Separation).</p> <p>This method separates the harmonic (tonal) components from the signal.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <code>n_fft</code> <code>int</code> <p>Size of FFT window.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Hop length for STFT.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length for STFT.</p> <code>None</code> <code>window</code> <code>_WindowSpec</code> <p>Window type for STFT.</p> <code>'hann'</code> <code>center</code> <code>bool</code> <p>If True, center the frames.</p> <code>True</code> <code>pad_mode</code> <code>_PadModeSTFT</code> <p>Padding mode for STFT.</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_harmonic(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract harmonic components using HPSS\n     (Harmonic-Percussive Source Separation).\n\n    This method separates the harmonic (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n        n_fft: Size of FFT window.\n        hop_length: Hop length for STFT.\n        win_length: Window length for STFT.\n        window: Window type for STFT.\n        center: If True, center the frames.\n        pad_mode: Padding mode for STFT.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_harmonic\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.hpss_percussive","title":"<code>hpss_percussive(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code>","text":"<p>Extract percussive components using HPSS (Harmonic-Percussive Source Separation).</p> <p>This method separates the percussive (tonal) components from the signal.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_percussive(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract percussive components using HPSS\n    (Harmonic-Percussive Source Separation).\n\n    This method separates the percussive (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_percussive\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.loudness_zwtv","title":"<code>loudness_zwtv(field_type='free')</code>","text":"<p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing time-varying loudness values in sones.</p> <code>T_Processing</code> <p>Each channel is processed independently.</p> <code>T_Processing</code> <p>The output sampling rate is adjusted based on the loudness</p> <code>T_Processing</code> <p>calculation time resolution (typically ~500 Hz for 2ms steps).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>Examples:</p> <p>Calculate loudness for a signal:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre> Notes <ul> <li>The output contains time-varying loudness values in sones</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>The time resolution is approximately 2ms (determined by the algorithm)</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The output sampling rate is updated to reflect the time resolution</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 2ms analysis step. This differs slightly from the MoSQITo library, which uses the center time of each step. For example:</p> <ul> <li>wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)</li> <li>MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)</li> </ul> <p>The difference is very small (~1ms) and does not affect the loudness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        New ChannelFrame containing time-varying loudness values in sones.\n        Each channel is processed independently.\n        The output sampling rate is adjusted based on the loudness\n        calculation time resolution (typically ~500 Hz for 2ms steps).\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate loudness for a signal:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n    Notes:\n        - The output contains time-varying loudness values in sones\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - The time resolution is approximately 2ms (determined by the algorithm)\n        - For multi-channel signals, loudness is calculated per channel\n        - The output sampling rate is updated to reflect the time resolution\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 2ms analysis step. This differs slightly from the MoSQITo\n        library, which uses the center time of each step. For example:\n\n        - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n        - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n        The difference is very small (~1ms) and does not affect the loudness\n        values themselves. This design choice ensures consistency with\n        wandas's time axis convention across all frame types.\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.loudness_zwst","title":"<code>loudness_zwst(field_type='free')</code>","text":"<p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>This method is suitable for analyzing steady sounds such as fan noise, constant machinery sounds, or other stationary signals.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>Returns:</p> Type Description <code>NDArrayReal</code> <p>Loudness values in sones, one per channel. Shape: (n_channels,)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>Examples:</p> <p>Calculate steady-state loudness for a fan noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n&gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre> Notes <ul> <li>Returns a 1D array with one loudness value per channel</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>For multi-channel signals, loudness is calculated independently   per channel</li> <li>This method is designed for stationary signals (constant sounds)</li> <li>For time-varying signals, use loudness_zwtv() instead</li> <li>Similar to the rms property, returns NDArrayReal for consistency</li> </ul> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    This method is suitable for analyzing steady sounds such as fan noise,\n    constant machinery sounds, or other stationary signals.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        Loudness values in sones, one per channel. Shape: (n_channels,)\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate steady-state loudness for a fan noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n        &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n    Notes:\n        - Returns a 1D array with one loudness value per channel\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - For multi-channel signals, loudness is calculated independently\n          per channel\n        - This method is designed for stationary signals (constant sounds)\n        - For time-varying signals, use loudness_zwtv() instead\n        - Similar to the rms property, returns NDArrayReal for consistency\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    # Treat self as a ProcessingFrameProtocol so mypy understands\n    # where sampling_rate and data come from.\n    from wandas.processing.psychoacoustic import LoudnessZwst\n    from wandas.utils.types import NDArrayReal\n\n    # Create operation instance\n    operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n    # Get data (triggers computation if lazy)\n    data = self.data\n\n    # Ensure data is 2D (n_channels, n_samples)\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    # Process the array using the public API and materialize to NumPy\n    result = operation.process_array(data).compute()\n\n    # Squeeze to get 1D array (n_channels,)\n    loudness_values: NDArrayReal = result.squeeze()\n\n    # Ensure it's 1D even for single channel\n    if loudness_values.ndim == 0:\n        loudness_values = loudness_values.reshape(1)\n\n    return loudness_values\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.roughness_dw","title":"<code>roughness_dw(overlap=0.5)</code>","text":"<p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound, measured in asper. This method implements the Daniel &amp; Weber (1997) standard calculation.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>Parameters:</p> Name Type Description Default <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing time-varying roughness values in asper.</p> <code>T_Processing</code> <p>The output sampling rate depends on the overlap parameter.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>Examples:</p> <p>Calculate roughness for a motor noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n&gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n&gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n</code></pre> <p>Analyze roughness statistics:</p> <pre><code>&gt;&gt;&gt; mean_roughness = roughness.data.mean()\n&gt;&gt;&gt; max_roughness = roughness.data.max()\n&gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n&gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n</code></pre> <p>Compare before and after modification:</p> <pre><code>&gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n&gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n&gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n&gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n</code></pre> Notes <ul> <li>Returns a ChannelFrame with time-varying roughness values</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher values indicate rougher, harsher sounds</li> <li>For multi-channel signals, roughness is calculated independently   per channel</li> <li>This is the standard-compliant total roughness (R)</li> <li>For detailed Bark-band analysis, use roughness_dw_spec() instead</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 200ms analysis window. This differs from the MoSQITo library, which uses the center time of each window. For example:</p> <ul> <li>wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)</li> <li>MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)</li> </ul> <p>The difference is constant (half the window duration = 100ms) and does not affect the roughness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n    \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound, measured in asper. This method\n    implements the Daniel &amp; Weber (1997) standard calculation.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        New ChannelFrame containing time-varying roughness values in asper.\n        The output sampling rate depends on the overlap parameter.\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Calculate roughness for a motor noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n        &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n        &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n        Analyze roughness statistics:\n        &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n        &gt;&gt;&gt; max_roughness = roughness.data.max()\n        &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n        &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n        Compare before and after modification:\n        &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n        &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n        &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n        &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n    Notes:\n        - Returns a ChannelFrame with time-varying roughness values\n        - Typical roughness values: 0-2 asper for most sounds\n        - Higher values indicate rougher, harsher sounds\n        - For multi-channel signals, roughness is calculated independently\n          per channel\n        - This is the standard-compliant total roughness (R)\n        - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 200ms analysis window. This differs from the MoSQITo library,\n        which uses the center time of each window. For example:\n\n        - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n        - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n        The difference is constant (half the window duration = 100ms) and\n        does not affect the roughness values themselves. This design choice\n        ensures consistency with wandas's time axis convention across all\n        frame types.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n    logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n    result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.roughness_dw_spec","title":"<code>roughness_dw_spec(overlap=0.5)</code>","text":"<p>Calculate specific roughness with Bark-band frequency information.</p> <p>This method returns detailed roughness analysis data organized by Bark frequency bands over time, allowing for frequency-specific roughness analysis. It uses the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>Parameters:</p> Name Type Description Default <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>RoughnessFrame</code> <p>RoughnessFrame containing: - data: Specific roughness by Bark band, shape (47, n_time)         for mono or (n_channels, 47, n_time) for multi-channel - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5) - time: Time axis for each analysis frame - overlap: Overlap coefficient used - plot(): Method for Bark-Time heatmap visualization</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>Examples:</p> <p>Analyze frequency-specific roughness:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n&gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot Bark-Time heatmap\n&gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find dominant Bark band\n&gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n&gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n&gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Extract specific Bark band time series\n&gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n&gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify standard formula\n&gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n&gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n</code></pre> Notes <ul> <li>Returns a RoughnessFrame (not ChannelFrame)</li> <li>Contains 47 Bark bands from 0.5 to 23.5 Bark</li> <li>Each Bark band corresponds to a critical band of hearing</li> <li>Useful for identifying which frequencies contribute most to roughness</li> <li>The specific roughness can be integrated to obtain total roughness</li> <li>For simple time-series analysis, use roughness_dw() instead</li> </ul> <p>Time axis convention: The time axis represents the start time of each 200ms analysis window, consistent with roughness_dw() and other wandas methods.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n    \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n    This method returns detailed roughness analysis data organized by\n    Bark frequency bands over time, allowing for frequency-specific\n    roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n    The relationship between total roughness and specific roughness:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        RoughnessFrame containing:\n            - data: Specific roughness by Bark band, shape (47, n_time)\n                    for mono or (n_channels, 47, n_time) for multi-channel\n            - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n            - time: Time axis for each analysis frame\n            - overlap: Overlap coefficient used\n            - plot(): Method for Bark-Time heatmap visualization\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Analyze frequency-specific roughness:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot Bark-Time heatmap\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Find dominant Bark band\n        &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n        &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n        &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Extract specific Bark band time series\n        &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n        &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verify standard formula\n        &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n        &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n    Notes:\n        - Returns a RoughnessFrame (not ChannelFrame)\n        - Contains 47 Bark bands from 0.5 to 23.5 Bark\n        - Each Bark band corresponds to a critical band of hearing\n        - Useful for identifying which frequencies contribute most to roughness\n        - The specific roughness can be integrated to obtain total roughness\n        - For simple time-series analysis, use roughness_dw() instead\n\n        **Time axis convention:**\n        The time axis represents the start time of each 200ms analysis\n        window, consistent with roughness_dw() and other wandas methods.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n\n    params = {\"overlap\": overlap}\n    operation_name = \"roughness_dw_spec\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance via factory\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n\n    # Apply processing lazily to self._data (Dask)\n    r_spec_dask = operation.process(self._data)\n\n    # Get metadata updates (sampling rate, bark_axis)\n    metadata_updates = operation.get_metadata_updates()\n\n    # Build metadata and history\n    new_metadata = {**self.metadata, **params}\n    new_history = [\n        *self.operation_history,\n        {\"operation\": operation_name, \"params\": params},\n    ]\n\n    # Extract bark_axis with proper type handling\n    bark_axis_value = metadata_updates.get(\"bark_axis\")\n    if bark_axis_value is None:\n        raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n    # Create RoughnessFrame. operation.get_metadata_updates() should provide\n    # sampling_rate and bark_axis\n    roughness_frame = RoughnessFrame(\n        data=r_spec_dask,\n        sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n        bark_axis=bark_axis_value,\n        overlap=overlap,\n        label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=cast(\"BaseFrame[NDArrayReal]\", self),\n    )\n\n    logger.debug(\n        \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n        operation_name,\n        r_spec_dask.shape,\n        roughness_frame.sampling_rate,\n    )\n\n    return roughness_frame\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.fade","title":"<code>fade(fade_ms=50)</code>","text":"<p>Apply symmetric fade-in and fade-out to the signal using Tukey window.</p> <p>This method applies a symmetric fade-in and fade-out envelope to the signal using a Tukey (tapered cosine) window. The fade duration is the same for both the beginning and end of the signal.</p> <p>Parameters:</p> Name Type Description Default <code>fade_ms</code> <code>float</code> <p>Fade duration in milliseconds for each end of the signal. The total fade duration is 2 * fade_ms. Default is 50 ms. Must be positive and less than half the signal duration.</p> <code>50</code> <p>Returns:</p> Type Description <code>T_Processing</code> <p>New ChannelFrame containing the faded signal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If fade_ms is negative or too long for the signal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n&gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n&gt;&gt;&gt; # Apply very short fade (almost no effect)\n&gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n</code></pre> Notes <ul> <li>Uses SciPy's Tukey window for smooth fade transitions</li> <li>Fade is applied symmetrically to both ends of the signal</li> <li>The Tukey window alpha parameter is computed automatically   based on the fade duration and signal length</li> <li>For multi-channel signals, the same fade envelope is applied   to all channels</li> <li>Lazy evaluation is preserved - computation occurs only when needed</li> </ul> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n    \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n    This method applies a symmetric fade-in and fade-out envelope to the signal\n    using a Tukey (tapered cosine) window. The fade duration is the same for\n    both the beginning and end of the signal.\n\n    Args:\n        fade_ms: Fade duration in milliseconds for each end of the signal.\n            The total fade duration is 2 * fade_ms. Default is 50 ms.\n            Must be positive and less than half the signal duration.\n\n    Returns:\n        New ChannelFrame containing the faded signal\n\n    Raises:\n        ValueError: If fade_ms is negative or too long for the signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n        &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n        &gt;&gt;&gt; # Apply very short fade (almost no effect)\n        &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n    Notes:\n        - Uses SciPy's Tukey window for smooth fade transitions\n        - Fade is applied symmetrically to both ends of the signal\n        - The Tukey window alpha parameter is computed automatically\n          based on the fade duration and signal length\n        - For multi-channel signals, the same fade envelope is applied\n          to all channels\n        - Lazy evaluation is preserved - computation occurs only when needed\n    \"\"\"\n    logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n    result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"api/frames/#channeltransformmixin","title":"ChannelTransformMixin","text":""},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin","title":"<code>wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin</code>","text":"<p>Mixin providing methods related to frequency transformations.</p> <p>This mixin provides operations related to frequency analysis and transformations such as FFT, STFT, and Welch method.</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>class ChannelTransformMixin:\n    \"\"\"Mixin providing methods related to frequency transformations.\n\n    This mixin provides operations related to frequency analysis and\n    transformations such as FFT, STFT, and Welch method.\n    \"\"\"\n\n    def fft(\n        self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate Fast Fourier Transform (FFT).\n\n        Args:\n            n_fft: Number of FFT points. Default is the next power of 2 of the data\n                length.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectralFrame containing FFT results\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import FFT, create_operation\n\n        params = {\"n_fft\": n_fft, \"window\": window}\n        operation_name = \"fft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"FFT\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        if n_fft is None:\n            is_even = spectrum_data.shape[-1] % 2 == 0\n            _n_fft = (\n                spectrum_data.shape[-1] * 2 - 2\n                if is_even\n                else spectrum_data.shape[-1] * 2 - 1\n            )\n        else:\n            _n_fft = n_fft\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=_n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def welch(\n        self: T_Transform,\n        n_fft: int | None = None,\n        hop_length: int | None = None,\n        win_length: int = 2048,\n        window: str = \"hann\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate power spectral density using Welch's method.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing power spectral density\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import Welch, create_operation\n\n        params = dict(\n            n_fft=n_fft or win_length,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            average=average,\n        )\n        operation_name = \"welch\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Welch\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"welch\", \"params\": params},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def noct_spectrum(\n        self: T_Transform,\n        fmin: float = 25,\n        fmax: float = 20000,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; \"NOctFrame\":\n        \"\"\"Calculate N-octave band spectrum.\n\n        Args:\n            fmin: Minimum center frequency (Hz). Default is 25 Hz.\n            fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n            n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n            G: Reference gain (dB). Default is 10 dB.\n            fr: Reference frequency (Hz). Default is 1000 Hz.\n\n        Returns:\n            NOctFrame containing N-octave band spectrum\n        \"\"\"\n        from wandas.processing import NOctSpectrum, create_operation\n\n        from ..noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_spectrum\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSpectrum\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_spectrum\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def stft(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Calculate Short-Time Fourier Transform.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectrogramFrame containing STFT results\n        \"\"\"\n        from wandas.processing import STFT, create_operation\n\n        from ..spectrogram import SpectrogramFrame\n\n        # Set hop length and window length\n        _hop_length = hop_length if hop_length is not None else n_fft // 4\n        _win_length = win_length if win_length is not None else n_fft\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": _hop_length,\n            \"win_length\": _win_length,\n            \"window\": window,\n        }\n        operation_name = \"stft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"STFT\", operation)\n\n        # Apply processing to data\n        spectrogram_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new instance\n        return SpectrogramFrame(\n            data=spectrogram_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=n_fft,\n            hop_length=_hop_length,\n            win_length=_win_length,\n            window=window,\n            label=f\"stft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def coherence(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate magnitude squared coherence.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n        Returns:\n            SpectralFrame containing magnitude squared coherence\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.processing import Coherence, create_operation\n\n        from ..spectral import SpectralFrame\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n        }\n        operation_name = \"coherence\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Coherence\", operation)\n\n        # Apply processing to data\n        coherence_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=coherence_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Coherence of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def csd(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate cross-spectral density matrix.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing cross-spectral density matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import CSD, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"csd\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"CSD\", operation)\n\n        # Apply processing to data\n        csd_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=csd_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def transfer_function(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate transfer function matrix.\n\n        The transfer function represents the signal transfer characteristics between\n        channels in the frequency domain and represents the input-output relationship\n        of the system.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing transfer function matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import TransferFunction, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"transfer_function\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"TransferFunction\", operation)\n\n        # Apply processing to data\n        tf_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=tf_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Transfer function of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin-functions","title":"Functions","text":""},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.fft","title":"<code>fft(n_fft=None, window='hann')</code>","text":"<p>Calculate Fast Fourier Transform (FFT).</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is the next power of 2 of the data length.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing FFT results</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def fft(\n    self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate Fast Fourier Transform (FFT).\n\n    Args:\n        n_fft: Number of FFT points. Default is the next power of 2 of the data\n            length.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectralFrame containing FFT results\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import FFT, create_operation\n\n    params = {\"n_fft\": n_fft, \"window\": window}\n    operation_name = \"fft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"FFT\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    if n_fft is None:\n        is_even = spectrum_data.shape[-1] % 2 == 0\n        _n_fft = (\n            spectrum_data.shape[-1] * 2 - 2\n            if is_even\n            else spectrum_data.shape[-1] * 2 - 1\n        )\n    else:\n        _n_fft = n_fft\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=_n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.welch","title":"<code>welch(n_fft=None, hop_length=None, win_length=2048, window='hann', average='mean')</code>","text":"<p>Calculate power spectral density using Welch's method.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is 2048.</p> <code>None</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int</code> <p>Window length. Default is n_fft.</p> <code>2048</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing power spectral density</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def welch(\n    self: T_Transform,\n    n_fft: int | None = None,\n    hop_length: int | None = None,\n    win_length: int = 2048,\n    window: str = \"hann\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate power spectral density using Welch's method.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing power spectral density\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import Welch, create_operation\n\n    params = dict(\n        n_fft=n_fft or win_length,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        average=average,\n    )\n    operation_name = \"welch\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Welch\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"welch\", \"params\": params},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.noct_spectrum","title":"<code>noct_spectrum(fmin=25, fmax=20000, n=3, G=10, fr=1000)</code>","text":"<p>Calculate N-octave band spectrum.</p> <p>Parameters:</p> Name Type Description Default <code>fmin</code> <code>float</code> <p>Minimum center frequency (Hz). Default is 25 Hz.</p> <code>25</code> <code>fmax</code> <code>float</code> <p>Maximum center frequency (Hz). Default is 20000 Hz.</p> <code>20000</code> <code>n</code> <code>int</code> <p>Band division (1: octave, 3: 1/3 octave). Default is 3.</p> <code>3</code> <code>G</code> <code>int</code> <p>Reference gain (dB). Default is 10 dB.</p> <code>10</code> <code>fr</code> <code>int</code> <p>Reference frequency (Hz). Default is 1000 Hz.</p> <code>1000</code> <p>Returns:</p> Type Description <code>NOctFrame</code> <p>NOctFrame containing N-octave band spectrum</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def noct_spectrum(\n    self: T_Transform,\n    fmin: float = 25,\n    fmax: float = 20000,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; \"NOctFrame\":\n    \"\"\"Calculate N-octave band spectrum.\n\n    Args:\n        fmin: Minimum center frequency (Hz). Default is 25 Hz.\n        fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n        n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n        G: Reference gain (dB). Default is 10 dB.\n        fr: Reference frequency (Hz). Default is 1000 Hz.\n\n    Returns:\n        NOctFrame containing N-octave band spectrum\n    \"\"\"\n    from wandas.processing import NOctSpectrum, create_operation\n\n    from ..noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_spectrum\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSpectrum\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_spectrum\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.stft","title":"<code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code>","text":"<p>Calculate Short-Time Fourier Transform.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>Returns:</p> Type Description <code>SpectrogramFrame</code> <p>SpectrogramFrame containing STFT results</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def stft(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Calculate Short-Time Fourier Transform.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectrogramFrame containing STFT results\n    \"\"\"\n    from wandas.processing import STFT, create_operation\n\n    from ..spectrogram import SpectrogramFrame\n\n    # Set hop length and window length\n    _hop_length = hop_length if hop_length is not None else n_fft // 4\n    _win_length = win_length if win_length is not None else n_fft\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": _hop_length,\n        \"win_length\": _win_length,\n        \"window\": window,\n    }\n    operation_name = \"stft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"STFT\", operation)\n\n    # Apply processing to data\n    spectrogram_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new instance\n    return SpectrogramFrame(\n        data=spectrogram_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=n_fft,\n        hop_length=_hop_length,\n        win_length=_win_length,\n        window=window,\n        label=f\"stft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.coherence","title":"<code>coherence(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code>","text":"<p>Calculate magnitude squared coherence.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing magnitude squared coherence</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def coherence(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate magnitude squared coherence.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n    Returns:\n        SpectralFrame containing magnitude squared coherence\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.processing import Coherence, create_operation\n\n    from ..spectral import SpectralFrame\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n    }\n    operation_name = \"coherence\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Coherence\", operation)\n\n    # Apply processing to data\n    coherence_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=coherence_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Coherence of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.csd","title":"<code>csd(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Calculate cross-spectral density matrix.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing cross-spectral density matrix</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def csd(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate cross-spectral density matrix.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing cross-spectral density matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import CSD, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"csd\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"CSD\", operation)\n\n    # Apply processing to data\n    csd_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=csd_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.transfer_function","title":"<code>transfer_function(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Calculate transfer function matrix.</p> <p>The transfer function represents the signal transfer characteristics between channels in the frequency domain and represents the input-output relationship of the system.</p> <p>Parameters:</p> Name Type Description Default <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>SpectralFrame</code> <p>SpectralFrame containing transfer function matrix</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def transfer_function(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate transfer function matrix.\n\n    The transfer function represents the signal transfer characteristics between\n    channels in the frequency domain and represents the input-output relationship\n    of the system.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing transfer function matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import TransferFunction, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"transfer_function\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"TransferFunction\", operation)\n\n    # Apply processing to data\n    tf_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=tf_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Transfer function of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"api/io/","title":"\u5165\u51fa\u529b\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.io</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u69d8\u3005\u306a\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u306e\u8aad\u307f\u66f8\u304d\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/io/#_2","title":"\u30d5\u30a1\u30a4\u30eb\u30ea\u30fc\u30c0\u30fc","text":"<p>\u69d8\u3005\u306a\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u304b\u3089\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/io/#wandas.io.readers","title":"<code>wandas.io.readers</code>","text":""},{"location":"api/io/#wandas.io.readers-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.readers.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers-classes","title":"Classes","text":""},{"location":"api/io/#wandas.io.readers.CSVFileInfoParams","title":"<code>CSVFileInfoParams</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for CSV file reader parameters in get_file_info.</p>"},{"location":"api/io/#wandas.io.readers.CSVFileInfoParams--parameters","title":"Parameters","text":"<p>delimiter : str     Delimiter character. Default is \",\". header : Optional[int]     Row number to use as header. Default is 0 (first row).     Set to None if no header. time_column : Union[int, str]     Index or name of the time column. Default is 0.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class CSVFileInfoParams(TypedDict, total=False):\n    \"\"\"Type definition for CSV file reader parameters in get_file_info.\n\n    Parameters\n    ----------\n    delimiter : str\n        Delimiter character. Default is \",\".\n    header : Optional[int]\n        Row number to use as header. Default is 0 (first row).\n        Set to None if no header.\n    time_column : Union[int, str]\n        Index or name of the time column. Default is 0.\n    \"\"\"\n\n    delimiter: str\n    header: int | None\n    time_column: int | str\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVFileInfoParams-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.readers.CSVFileInfoParams.delimiter","title":"<code>delimiter</code>  <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.CSVFileInfoParams.header","title":"<code>header</code>  <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.CSVFileInfoParams.time_column","title":"<code>time_column</code>  <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.CSVGetDataParams","title":"<code>CSVGetDataParams</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for CSV file reader parameters in get_data.</p>"},{"location":"api/io/#wandas.io.readers.CSVGetDataParams--parameters","title":"Parameters","text":"<p>delimiter : str     Delimiter character. Default is \",\". header : Optional[int]     Row number to use as header. Default is 0. time_column : Union[int, str]     Index or name of the time column. Default is 0.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class CSVGetDataParams(TypedDict, total=False):\n    \"\"\"Type definition for CSV file reader parameters in get_data.\n\n    Parameters\n    ----------\n    delimiter : str\n        Delimiter character. Default is \",\".\n    header : Optional[int]\n        Row number to use as header. Default is 0.\n    time_column : Union[int, str]\n        Index or name of the time column. Default is 0.\n    \"\"\"\n\n    delimiter: str\n    header: int | None\n    time_column: int | str\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVGetDataParams-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.readers.CSVGetDataParams.delimiter","title":"<code>delimiter</code>  <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.CSVGetDataParams.header","title":"<code>header</code>  <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.CSVGetDataParams.time_column","title":"<code>time_column</code>  <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.FileReader","title":"<code>FileReader</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for audio file readers.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class FileReader(ABC):\n    \"\"\"Base class for audio file readers.\"\"\"\n\n    # Class attribute for supported file extensions\n    supported_extensions: list[str] = []\n\n    @classmethod\n    @abstractmethod\n    def get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the audio file.\n\n        Args:\n            path: Path to the file.\n            **kwargs: Additional parameters specific to the file reader.\n\n        Returns:\n            Dictionary containing file information including:\n            - samplerate: Sampling rate in Hz\n            - channels: Number of channels\n            - frames: Total number of frames\n            - format: File format\n            - duration: Duration in seconds\n        \"\"\"\n        pass\n\n    @classmethod\n    @abstractmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read audio data from the file.\n\n        Args:\n            path: Path to the file.\n            channels: List of channel indices to read.\n            start_idx: Starting frame index.\n            frames: Number of frames to read.\n            **kwargs: Additional parameters specific to the file reader.\n\n        Returns:\n            Array of shape (channels, frames) containing the audio data.\n        \"\"\"\n        pass\n\n    @classmethod\n    def can_read(cls, path: str | Path) -&gt; bool:\n        \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n        ext = Path(path).suffix.lower()\n        return ext in cls.supported_extensions\n</code></pre>"},{"location":"api/io/#wandas.io.readers.FileReader-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.readers.FileReader.supported_extensions","title":"<code>supported_extensions = []</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.FileReader-functions","title":"Functions","text":""},{"location":"api/io/#wandas.io.readers.FileReader.get_file_info","title":"<code>get_file_info(path, **kwargs)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Get basic information about the audio file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the file.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing file information including:</p> <code>dict[str, Any]</code> <ul> <li>samplerate: Sampling rate in Hz</li> </ul> <code>dict[str, Any]</code> <ul> <li>channels: Number of channels</li> </ul> <code>dict[str, Any]</code> <ul> <li>frames: Total number of frames</li> </ul> <code>dict[str, Any]</code> <ul> <li>format: File format</li> </ul> <code>dict[str, Any]</code> <ul> <li>duration: Duration in seconds</li> </ul> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\n\n    Args:\n        path: Path to the file.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Dictionary containing file information including:\n        - samplerate: Sampling rate in Hz\n        - channels: Number of channels\n        - frames: Total number of frames\n        - format: File format\n        - duration: Duration in seconds\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/io/#wandas.io.readers.FileReader.get_data","title":"<code>get_data(path, channels, start_idx, frames, **kwargs)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Read audio data from the file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the file.</p> required <code>channels</code> <code>list[int]</code> <p>List of channel indices to read.</p> required <code>start_idx</code> <code>int</code> <p>Starting frame index.</p> required <code>frames</code> <code>int</code> <p>Number of frames to read.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ArrayLike</code> <p>Array of shape (channels, frames) containing the audio data.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\n\n    Args:\n        path: Path to the file.\n        channels: List of channel indices to read.\n        start_idx: Starting frame index.\n        frames: Number of frames to read.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Array of shape (channels, frames) containing the audio data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/io/#wandas.io.readers.FileReader.can_read","title":"<code>can_read(path)</code>  <code>classmethod</code>","text":"<p>Check if this reader can handle the file based on extension.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef can_read(cls, path: str | Path) -&gt; bool:\n    \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n    ext = Path(path).suffix.lower()\n    return ext in cls.supported_extensions\n</code></pre>"},{"location":"api/io/#wandas.io.readers.SoundFileReader","title":"<code>SoundFileReader</code>","text":"<p>               Bases: <code>FileReader</code></p> <p>Audio file reader using SoundFile library.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class SoundFileReader(FileReader):\n    \"\"\"Audio file reader using SoundFile library.\"\"\"\n\n    # SoundFile supported formats\n    supported_extensions = [\".wav\", \".flac\", \".ogg\", \".aiff\", \".aif\", \".snd\"]\n\n    @classmethod\n    def get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the audio file.\"\"\"\n        info = sf.info(str(path))\n        return {\n            \"samplerate\": info.samplerate,\n            \"channels\": info.channels,\n            \"frames\": info.frames,\n            \"format\": info.format,\n            \"subtype\": info.subtype,\n            \"duration\": info.frames / info.samplerate,\n        }\n\n    @classmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read audio data from the file.\"\"\"\n        logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n        with sf.SoundFile(str(path)) as f:\n            if start_idx &gt; 0:\n                f.seek(start_idx)\n            data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n            # Select requested channels\n            if len(channels) &lt; f.channels:\n                data = data[:, channels]\n\n            # Transpose to get (channels, samples) format\n            result: ArrayLike = data.T\n            if not isinstance(result, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n\n        _shape = result.shape\n        logger.debug(f\"File read complete, returning data with shape {_shape}\")\n        return result\n</code></pre>"},{"location":"api/io/#wandas.io.readers.SoundFileReader-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.readers.SoundFileReader.supported_extensions","title":"<code>supported_extensions = ['.wav', '.flac', '.ogg', '.aiff', '.aif', '.snd']</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.SoundFileReader-functions","title":"Functions","text":""},{"location":"api/io/#wandas.io.readers.SoundFileReader.get_file_info","title":"<code>get_file_info(path, **kwargs)</code>  <code>classmethod</code>","text":"<p>Get basic information about the audio file.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\"\"\"\n    info = sf.info(str(path))\n    return {\n        \"samplerate\": info.samplerate,\n        \"channels\": info.channels,\n        \"frames\": info.frames,\n        \"format\": info.format,\n        \"subtype\": info.subtype,\n        \"duration\": info.frames / info.samplerate,\n    }\n</code></pre>"},{"location":"api/io/#wandas.io.readers.SoundFileReader.get_data","title":"<code>get_data(path, channels, start_idx, frames, **kwargs)</code>  <code>classmethod</code>","text":"<p>Read audio data from the file.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\"\"\"\n    logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n    with sf.SoundFile(str(path)) as f:\n        if start_idx &gt; 0:\n            f.seek(start_idx)\n        data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n        # Select requested channels\n        if len(channels) &lt; f.channels:\n            data = data[:, channels]\n\n        # Transpose to get (channels, samples) format\n        result: ArrayLike = data.T\n        if not isinstance(result, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"File read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVFileReader","title":"<code>CSVFileReader</code>","text":"<p>               Bases: <code>FileReader</code></p> <p>CSV file reader for time series data.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class CSVFileReader(FileReader):\n    \"\"\"CSV file reader for time series data.\"\"\"\n\n    # CSV supported formats\n    supported_extensions = [\".csv\"]\n\n    @classmethod\n    def get_file_info(\n        cls,\n        path: str | Path,\n        **kwargs: Any,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the CSV file.\n\n        Parameters\n        ----------\n        path : Union[str, Path]\n            Path to the CSV file.\n        **kwargs : Any\n            Additional parameters for CSV reading. Supported parameters:\n\n            - delimiter : str, default=\",\"\n                Delimiter character.\n            - header : Optional[int], default=0\n                Row number to use as header. Set to None if no header.\n            - time_column : Union[int, str], default=0\n                Index or name of the time column.\n\n        Returns\n        -------\n        dict[str, Any]\n            Dictionary containing file information including:\n            - samplerate: Estimated sampling rate in Hz\n            - channels: Number of data channels (excluding time column)\n            - frames: Total number of frames\n            - format: \"CSV\"\n            - duration: Duration in seconds (or None if cannot be calculated)\n            - ch_labels: List of channel labels\n\n        Notes\n        -----\n        This method accepts CSV-specific parameters through kwargs.\n        See CSVFileInfoParams for supported parameter types.\n        \"\"\"\n        # Extract parameters with defaults\n        delimiter: str = kwargs.get(\"delimiter\", \",\")\n        header: int | None = kwargs.get(\"header\", 0)\n        time_column: int | str = kwargs.get(\"time_column\", 0)\n\n        # Read first few lines to determine structure\n        df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n        # Estimate sampling rate from first column (assuming it's time)\n        try:\n            # Get time column as Series\n            if isinstance(time_column, str):\n                time_series = df[time_column]\n            else:\n                time_series = df.iloc[:, time_column]\n            time_values = np.array(time_series.values)\n            if len(time_values) &gt; 1:\n                # Use round() instead of int() to handle floating-point precision issues\n                estimated_sr = round(1 / np.mean(np.diff(time_values)))\n            else:\n                estimated_sr = 0  # Cannot determine from single row\n        except Exception:\n            estimated_sr = 0  # Default if can't calculate\n\n        frames = df.shape[0]\n        duration = frames / estimated_sr if estimated_sr &gt; 0 else None\n\n        # Return file info\n        return {\n            \"samplerate\": estimated_sr,\n            \"channels\": df.shape[1] - 1,  # Assuming first column is time\n            \"frames\": frames,\n            \"format\": \"CSV\",\n            \"duration\": duration,\n            \"ch_labels\": df.columns[1:].tolist(),  # Assuming first column is time\n        }\n\n    @classmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read data from the CSV file.\n\n        Parameters\n        ----------\n        path : Union[str, Path]\n            Path to the CSV file.\n        channels : list[int]\n            List of channel indices to read.\n        start_idx : int\n            Starting frame index.\n        frames : int\n            Number of frames to read.\n        **kwargs : Any\n            Additional parameters for CSV reading. Supported parameters:\n\n            - delimiter : str, default=\",\"\n                Delimiter character.\n            - header : Optional[int], default=0\n                Row number to use as header.\n            - time_column : Union[int, str], default=0\n                Index or name of the time column.\n\n        Returns\n        -------\n        ArrayLike\n            Array of shape (channels, frames) containing the data.\n\n        Notes\n        -----\n        This method accepts CSV-specific parameters through kwargs.\n        See CSVGetDataParams for supported parameter types.\n        \"\"\"\n        # Extract parameters with defaults\n        time_column: int | str = kwargs.get(\"time_column\", 0)\n        delimiter: str = kwargs.get(\"delimiter\", \",\")\n        header: int | None = kwargs.get(\"header\", 0)\n\n        logger.debug(f\"Reading CSV data from {path} starting at {start_idx}\")\n\n        # Read the CSV file\n        df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n        # Remove time column\n        df = df.drop(\n            columns=[time_column]\n            if isinstance(time_column, str)\n            else df.columns[time_column]\n        )\n\n        # Select requested channels - adjust indices to account for time column removal\n        if channels:\n            try:\n                data_df = df.iloc[:, channels]\n            except IndexError:\n                raise ValueError(f\"Requested channels {channels} out of range\")\n        else:\n            data_df = df\n\n        # Handle start_idx and frames for partial reading\n        end_idx = start_idx + frames if frames &gt; 0 else None\n        data_df = data_df.iloc[start_idx:end_idx]\n\n        # Convert to numpy array and transpose to (channels, samples) format\n        result = data_df.values.T\n\n        if not isinstance(result, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n\n        _shape = result.shape\n        logger.debug(f\"CSV read complete, returning data with shape {_shape}\")\n        return result\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVFileReader-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.readers.CSVFileReader.supported_extensions","title":"<code>supported_extensions = ['.csv']</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/io/#wandas.io.readers.CSVFileReader-functions","title":"Functions","text":""},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_file_info","title":"<code>get_file_info(path, **kwargs)</code>  <code>classmethod</code>","text":"<p>Get basic information about the CSV file.</p>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_file_info--parameters","title":"Parameters","text":"<p>path : Union[str, Path]     Path to the CSV file. **kwargs : Any     Additional parameters for CSV reading. Supported parameters:</p> <pre><code>- delimiter : str, default=\",\"\n    Delimiter character.\n- header : Optional[int], default=0\n    Row number to use as header. Set to None if no header.\n- time_column : Union[int, str], default=0\n    Index or name of the time column.\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_file_info--returns","title":"Returns","text":"<p>dict[str, Any]     Dictionary containing file information including:     - samplerate: Estimated sampling rate in Hz     - channels: Number of data channels (excluding time column)     - frames: Total number of frames     - format: \"CSV\"     - duration: Duration in seconds (or None if cannot be calculated)     - ch_labels: List of channel labels</p>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_file_info--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVFileInfoParams for supported parameter types.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(\n    cls,\n    path: str | Path,\n    **kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header. Set to None if no header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing file information including:\n        - samplerate: Estimated sampling rate in Hz\n        - channels: Number of data channels (excluding time column)\n        - frames: Total number of frames\n        - format: \"CSV\"\n        - duration: Duration in seconds (or None if cannot be calculated)\n        - ch_labels: List of channel labels\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVFileInfoParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n\n    # Read first few lines to determine structure\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Estimate sampling rate from first column (assuming it's time)\n    try:\n        # Get time column as Series\n        if isinstance(time_column, str):\n            time_series = df[time_column]\n        else:\n            time_series = df.iloc[:, time_column]\n        time_values = np.array(time_series.values)\n        if len(time_values) &gt; 1:\n            # Use round() instead of int() to handle floating-point precision issues\n            estimated_sr = round(1 / np.mean(np.diff(time_values)))\n        else:\n            estimated_sr = 0  # Cannot determine from single row\n    except Exception:\n        estimated_sr = 0  # Default if can't calculate\n\n    frames = df.shape[0]\n    duration = frames / estimated_sr if estimated_sr &gt; 0 else None\n\n    # Return file info\n    return {\n        \"samplerate\": estimated_sr,\n        \"channels\": df.shape[1] - 1,  # Assuming first column is time\n        \"frames\": frames,\n        \"format\": \"CSV\",\n        \"duration\": duration,\n        \"ch_labels\": df.columns[1:].tolist(),  # Assuming first column is time\n    }\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_data","title":"<code>get_data(path, channels, start_idx, frames, **kwargs)</code>  <code>classmethod</code>","text":"<p>Read data from the CSV file.</p>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_data--parameters","title":"Parameters","text":"<p>path : Union[str, Path]     Path to the CSV file. channels : list[int]     List of channel indices to read. start_idx : int     Starting frame index. frames : int     Number of frames to read. **kwargs : Any     Additional parameters for CSV reading. Supported parameters:</p> <pre><code>- delimiter : str, default=\",\"\n    Delimiter character.\n- header : Optional[int], default=0\n    Row number to use as header.\n- time_column : Union[int, str], default=0\n    Index or name of the time column.\n</code></pre>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_data--returns","title":"Returns","text":"<p>ArrayLike     Array of shape (channels, frames) containing the data.</p>"},{"location":"api/io/#wandas.io.readers.CSVFileReader.get_data--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVGetDataParams for supported parameter types.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read data from the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    channels : list[int]\n        List of channel indices to read.\n    start_idx : int\n        Starting frame index.\n    frames : int\n        Number of frames to read.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    ArrayLike\n        Array of shape (channels, frames) containing the data.\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVGetDataParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n\n    logger.debug(f\"Reading CSV data from {path} starting at {start_idx}\")\n\n    # Read the CSV file\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Remove time column\n    df = df.drop(\n        columns=[time_column]\n        if isinstance(time_column, str)\n        else df.columns[time_column]\n    )\n\n    # Select requested channels - adjust indices to account for time column removal\n    if channels:\n        try:\n            data_df = df.iloc[:, channels]\n        except IndexError:\n            raise ValueError(f\"Requested channels {channels} out of range\")\n    else:\n        data_df = df\n\n    # Handle start_idx and frames for partial reading\n    end_idx = start_idx + frames if frames &gt; 0 else None\n    data_df = data_df.iloc[start_idx:end_idx]\n\n    # Convert to numpy array and transpose to (channels, samples) format\n    result = data_df.values.T\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"CSV read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"api/io/#wandas.io.readers-functions","title":"Functions","text":""},{"location":"api/io/#wandas.io.readers.get_file_reader","title":"<code>get_file_reader(path)</code>","text":"<p>Get an appropriate file reader for the given path.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>def get_file_reader(path: str | Path) -&gt; FileReader:\n    \"\"\"Get an appropriate file reader for the given path.\"\"\"\n    path_str = str(path)\n    ext = Path(path).suffix.lower()\n\n    # Try each reader in order\n    for reader in _file_readers:\n        if ext in reader.__class__.supported_extensions:\n            logger.debug(f\"Using {reader.__class__.__name__} for {path_str}\")\n            return reader\n\n    # If no reader found, raise error\n    raise ValueError(f\"No suitable file reader found for {path_str}\")\n</code></pre>"},{"location":"api/io/#wandas.io.readers.register_file_reader","title":"<code>register_file_reader(reader_class)</code>","text":"<p>Register a new file reader.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>def register_file_reader(reader_class: type) -&gt; None:\n    \"\"\"Register a new file reader.\"\"\"\n    reader = reader_class()\n    _file_readers.append(reader)\n    logger.debug(f\"Registered new file reader: {reader_class.__name__}\")\n</code></pre>"},{"location":"api/io/#wav","title":"WAV\u30d5\u30a1\u30a4\u30eb\u5165\u51fa\u529b","text":"<p>WAV\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u66f8\u304d\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/io/#wandas.io.wav_io","title":"<code>wandas.io.wav_io</code>","text":""},{"location":"api/io/#wandas.io.wav_io-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.wav_io.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/io/#wandas.io.wav_io-classes","title":"Classes","text":""},{"location":"api/io/#wandas.io.wav_io-functions","title":"Functions","text":""},{"location":"api/io/#wandas.io.wav_io.read_wav","title":"<code>read_wav(filename, labels=None)</code>","text":"<p>Read a WAV file and create a ChannelFrame object.</p>"},{"location":"api/io/#wandas.io.wav_io.read_wav--parameters","title":"Parameters","text":"<p>filename : str     Path to the WAV file or URL to the WAV file. labels : list of str, optional     Labels for each channel.</p>"},{"location":"api/io/#wandas.io.wav_io.read_wav--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the audio data.</p> Source code in <code>wandas/io/wav_io.py</code> <pre><code>def read_wav(filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Read a WAV file and create a ChannelFrame object.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file or URL to the WAV file.\n    labels : list of str, optional\n        Labels for each channel.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the audio data.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304cURL\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\n    if filename.startswith(\"http://\") or filename.startswith(\"https://\"):\n        # URL\u306e\u5834\u5408\u3001requests\u3092\u4f7f\u7528\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n        response = requests.get(filename)\n        file_obj = io.BytesIO(response.content)\n        file_label = os.path.basename(filename)\n        # \u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u306f\u4f7f\u7528\u305b\u305a\u306b\u8aad\u307f\u8fbc\u3080\n        sampling_rate, data = wavfile.read(file_obj)\n    else:\n        # \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u5834\u5408\n        file_label = os.path.basename(filename)\n        # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\uff08\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4f7f\u7528\uff09\n        sampling_rate, data = wavfile.read(filename, mmap=True)\n\n    # \u30c7\u30fc\u30bf\u3092(num_channels, num_samples)\u5f62\u72b6\u306eNumPy\u914d\u5217\u306b\u5909\u63db\n    if data.ndim == 1:\n        # \u30e2\u30ce\u30e9\u30eb\uff1a(samples,) -&gt; (1, samples)\n        data = np.expand_dims(data, axis=0)\n    else:\n        # \u30b9\u30c6\u30ec\u30aa\uff1a(samples, channels) -&gt; (channels, samples)\n        data = data.T\n\n    # NumPy\u914d\u5217\u304b\u3089ChannelFrame\u3092\u4f5c\u6210\n    channel_frame = ChannelFrame.from_numpy(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=file_label,\n        ch_labels=labels,\n    )\n\n    return channel_frame\n</code></pre>"},{"location":"api/io/#wandas.io.wav_io.write_wav","title":"<code>write_wav(filename, target, format=None)</code>","text":"<p>Write a ChannelFrame object to a WAV file.</p>"},{"location":"api/io/#wandas.io.wav_io.write_wav--parameters","title":"Parameters","text":"<p>filename : str     Path to the WAV file. target : ChannelFrame     ChannelFrame object containing the data to write. format : str, optional     File format. If None, determined from file extension.</p>"},{"location":"api/io/#wandas.io.wav_io.write_wav--raises","title":"Raises","text":"<p>ValueError     If target is not a ChannelFrame object.</p> Source code in <code>wandas/io/wav_io.py</code> <pre><code>def write_wav(filename: str, target: \"ChannelFrame\", format: str | None = None) -&gt; None:\n    \"\"\"\n    Write a ChannelFrame object to a WAV file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file.\n    target : ChannelFrame\n        ChannelFrame object containing the data to write.\n    format : str, optional\n        File format. If None, determined from file extension.\n\n    Raises\n    ------\n    ValueError\n        If target is not a ChannelFrame object.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    if not isinstance(target, ChannelFrame):\n        raise ValueError(\"target must be a ChannelFrame object.\")\n\n    logger.debug(f\"Saving audio data to file: {filename} (will compute now)\")\n    data = target.compute()\n    data = data.T\n    if data.shape[1] == 1:\n        data = data.squeeze(axis=1)\n    if data.dtype == float and max([np.abs(data.max()), np.abs(data.min())]) &lt; 1:\n        sf.write(\n            str(filename),\n            data,\n            int(target.sampling_rate),\n            subtype=\"FLOAT\",\n            format=format,\n        )\n    else:\n        sf.write(str(filename), data, int(target.sampling_rate), format=format)\n    logger.debug(f\"Save complete: {filename}\")\n</code></pre>"},{"location":"api/io/#wdf","title":"WDF\u30d5\u30a1\u30a4\u30eb\u5165\u51fa\u529b","text":"<p>WDF\uff08Wandas Data File\uff09\u5f62\u5f0f\u306e\u8aad\u307f\u66f8\u304d\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u3053\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u542b\u3080\u5b8c\u5168\u306a\u4fdd\u5b58\u304c\u53ef\u80fd\u3067\u3059\u3002</p>"},{"location":"api/io/#wandas.io.wdf_io","title":"<code>wandas.io.wdf_io</code>","text":"<p>WDF (Wandas Data File) I/O module for saving and loading ChannelFrame objects.</p> <p>This module provides functionality to save and load ChannelFrame objects in the WDF (Wandas Data File) format, which is based on HDF5. The format preserves all metadata including sampling rate, channel labels, units, and frame metadata.</p>"},{"location":"api/io/#wandas.io.wdf_io-attributes","title":"Attributes","text":""},{"location":"api/io/#wandas.io.wdf_io.da_from_array","title":"<code>da_from_array = da.from_array</code>  <code>module-attribute</code>","text":""},{"location":"api/io/#wandas.io.wdf_io.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/io/#wandas.io.wdf_io.WDF_FORMAT_VERSION","title":"<code>WDF_FORMAT_VERSION = '0.1'</code>  <code>module-attribute</code>","text":""},{"location":"api/io/#wandas.io.wdf_io-classes","title":"Classes","text":""},{"location":"api/io/#wandas.io.wdf_io-functions","title":"Functions","text":""},{"location":"api/io/#wandas.io.wdf_io.save","title":"<code>save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> required <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"api/io/#wandas.io.wdf_io.load","title":"<code>load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> required <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"api/processing/","title":"\u51e6\u7406\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.processing</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u69d8\u3005\u306a\u51e6\u7406\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#_2","title":"\u57fa\u672c\u51e6\u7406","text":"<p>\u57fa\u672c\u7684\u306a\u51e6\u7406\u64cd\u4f5c\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#wandas.processing.base","title":"<code>wandas.processing.base</code>","text":""},{"location":"api/processing/#wandas.processing.base-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.base.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base.InputArrayType","title":"<code>InputArrayType = TypeVar('InputArrayType', NDArrayReal, NDArrayComplex)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base.OutputArrayType","title":"<code>OutputArrayType = TypeVar('OutputArrayType', NDArrayReal, NDArrayComplex)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base-classes","title":"Classes","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation","title":"<code>AudioOperation</code>","text":"<p>               Bases: <code>Generic[InputArrayType, OutputArrayType]</code></p> <p>Abstract base class for audio processing operations.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>class AudioOperation(Generic[InputArrayType, OutputArrayType]):\n    \"\"\"Abstract base class for audio processing operations.\"\"\"\n\n    # Class variable: operation name\n    name: ClassVar[str]\n\n    def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n        \"\"\"\n        Initialize AudioOperation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        pure : bool, default=True\n            Whether the operation is pure (deterministic with no side effects).\n            When True, Dask can cache results for identical inputs.\n            Set to False only if the operation has side effects or is non-deterministic.\n        **params : Any\n            Operation-specific parameters\n        \"\"\"\n        self.sampling_rate = sampling_rate\n        self.pure = pure\n        self.params = params\n\n        # Validate parameters during initialization\n        self.validate_params()\n\n        # Create processor function (lazy initialization possible)\n        self._setup_processor()\n\n        logger.debug(\n            f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n        pass\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up processor function (implemented by subclasses)\"\"\"\n        pass\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get metadata updates to apply after processing.\n\n        This method allows operations to specify how metadata should be\n        updated after processing. By default, no metadata is updated.\n\n        Returns\n        -------\n        dict\n            Dictionary of metadata updates. Can include:\n            - 'sampling_rate': New sampling rate (float)\n            - Other metadata keys as needed\n\n        Examples\n        --------\n        Return empty dict for operations that don't change metadata:\n\n        &gt;&gt;&gt; return {}\n\n        Return new sampling rate for operations that resample:\n\n        &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n        Notes\n        -----\n        This method is called by the framework after processing to update\n        the frame metadata. Subclasses should override this method if they\n        need to update metadata (e.g., changing sampling rate).\n\n        Design principle: Operations should use parameters provided at\n        initialization (via __init__). All necessary information should be\n        available as instance variables.\n        \"\"\"\n        return {}\n\n    def get_display_name(self) -&gt; str | None:\n        \"\"\"\n        Get display name for the operation for use in channel labels.\n\n        This method allows operations to customize how they appear in\n        channel labels. By default, returns None, which means the\n        operation name will be used.\n\n        Returns\n        -------\n        str or None\n            Display name for the operation. If None, the operation name\n            (from the `name` class variable) is used.\n\n        Examples\n        --------\n        Default behavior (returns None, uses operation name):\n\n        &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n        ...     name = \"normalize\"\n        &gt;&gt;&gt; op = NormalizeOp(44100)\n        &gt;&gt;&gt; op.get_display_name()  # Returns None\n        &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n        Custom display name:\n\n        &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n        ...     name = \"lowpass_filter\"\n        ...\n        ...     def __init__(self, sr, cutoff):\n        ...         self.cutoff = cutoff\n        ...         super().__init__(sr, cutoff=cutoff)\n        ...\n        ...     def get_display_name(self):\n        ...         return f\"lpf_{self.cutoff}Hz\"\n        &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n        &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n        &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n        Notes\n        -----\n        Subclasses can override this method to provide operation-specific\n        display names that include parameter information, making labels\n        more informative.\n        \"\"\"\n        return None\n\n    def _process_array(self, x: InputArrayType) -&gt; OutputArrayType:\n        \"\"\"Processing function (implemented by subclasses)\"\"\"\n        # Default is no-op function\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n\n    def _create_named_wrapper(self) -&gt; Any:\n        \"\"\"\n        Create a named wrapper function for better Dask graph visualization.\n\n        Returns\n        -------\n        callable\n            A wrapper function with the operation name set as __name__.\n        \"\"\"\n\n        def operation_wrapper(x: InputArrayType) -&gt; OutputArrayType:\n            return self._process_array(x)\n\n        # Set the function name to the operation name for better visualization\n        operation_wrapper.__name__ = self.name\n        return operation_wrapper\n\n    def process_array(self, x: InputArrayType) -&gt; Any:\n        \"\"\"\n        Processing function wrapped with @dask.delayed.\n\n        This method returns a Delayed object that can be computed later.\n        The operation name is used in the Dask task graph for better visualization.\n\n        Parameters\n        ----------\n        x : InputArrayType\n            Input array to process.\n\n        Returns\n        -------\n        dask.delayed.Delayed\n            A Delayed object representing the computation.\n        \"\"\"\n        logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n        # Create wrapper with operation name and wrap it with dask.delayed\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        return delayed_func(x)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        This method can be overridden by subclasses for efficiency.\n        If not overridden, it will execute _process_array on a small test array\n        to determine the output shape.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n\n        Notes\n        -----\n        The default implementation creates a minimal test array and processes it\n        to determine output shape. For performance-critical code, subclasses should\n        override this method with a direct calculation.\n        \"\"\"\n        # Try to infer shape by executing _process_array on test data\n        import numpy as np\n\n        try:\n            # Create minimal test array with input shape\n            if len(input_shape) == 0:\n                return input_shape\n\n            # Create test input with correct dtype\n            # Try complex first, fall back to float if needed\n            test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n            # Process test input\n            test_output: Any = self._process_array(test_input)\n\n            # Return the shape of the output\n            if isinstance(test_output, np.ndarray):\n                return tuple(int(s) for s in test_output.shape)\n            return input_shape\n        except Exception as e:\n            logger.warning(\n                f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n                \"Please implement calculate_output_shape method.\"\n            )\n            raise NotImplementedError(\n                f\"Subclass {self.__class__.__name__} must implement \"\n                f\"calculate_output_shape or ensure _process_array can be \"\n                f\"called with test data.\"\n            ) from e\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        \"\"\"\n        Execute operation and return result\n        data shape is (channels, samples)\n        \"\"\"\n        # Add task as delayed processing with custom name for visualization\n        logger.debug(\"Adding delayed operation to computation graph\")\n\n        # Create a wrapper function with the operation name\n        # This allows Dask to use the operation name in the task graph\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        delayed_result = delayed_func(data)\n\n        # Convert delayed result to dask array and return\n        output_shape = self.calculate_output_shape(data.shape)\n        return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.name","title":"<code>name</code>  <code>class-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.sampling_rate","title":"<code>sampling_rate = sampling_rate</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.pure","title":"<code>pure = pure</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.params","title":"<code>params = params</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.__init__","title":"<code>__init__(sampling_rate, *, pure=True, **params)</code>","text":"<p>Initialize AudioOperation.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) pure : bool, default=True     Whether the operation is pure (deterministic with no side effects).     When True, Dask can cache results for identical inputs.     Set to False only if the operation has side effects or is non-deterministic. **params : Any     Operation-specific parameters</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n    \"\"\"\n    Initialize AudioOperation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    pure : bool, default=True\n        Whether the operation is pure (deterministic with no side effects).\n        When True, Dask can cache results for identical inputs.\n        Set to False only if the operation has side effects or is non-deterministic.\n    **params : Any\n        Operation-specific parameters\n    \"\"\"\n    self.sampling_rate = sampling_rate\n    self.pure = pure\n    self.params = params\n\n    # Validate parameters during initialization\n    self.validate_params()\n\n    # Create processor function (lazy initialization possible)\n    self._setup_processor()\n\n    logger.debug(\n        f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters (raises exception if invalid)</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n    pass\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Get metadata updates to apply after processing.</p> <p>This method allows operations to specify how metadata should be updated after processing. By default, no metadata is updated.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Dictionary of metadata updates. Can include:     - 'sampling_rate': New sampling rate (float)     - Other metadata keys as needed</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_metadata_updates--examples","title":"Examples","text":"<p>Return empty dict for operations that don't change metadata:</p> <p>return {}</p> <p>Return new sampling rate for operations that resample:</p> <p>return {\"sampling_rate\": self.target_sr}</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_metadata_updates--notes","title":"Notes","text":"<p>This method is called by the framework after processing to update the frame metadata. Subclasses should override this method if they need to update metadata (e.g., changing sampling rate).</p> <p>Design principle: Operations should use parameters provided at initialization (via init). All necessary information should be available as instance variables.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    This method allows operations to specify how metadata should be\n    updated after processing. By default, no metadata is updated.\n\n    Returns\n    -------\n    dict\n        Dictionary of metadata updates. Can include:\n        - 'sampling_rate': New sampling rate (float)\n        - Other metadata keys as needed\n\n    Examples\n    --------\n    Return empty dict for operations that don't change metadata:\n\n    &gt;&gt;&gt; return {}\n\n    Return new sampling rate for operations that resample:\n\n    &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n    Notes\n    -----\n    This method is called by the framework after processing to update\n    the frame metadata. Subclasses should override this method if they\n    need to update metadata (e.g., changing sampling rate).\n\n    Design principle: Operations should use parameters provided at\n    initialization (via __init__). All necessary information should be\n    available as instance variables.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> <p>This method allows operations to customize how they appear in channel labels. By default, returns None, which means the operation name will be used.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_display_name--returns","title":"Returns","text":"<p>str or None     Display name for the operation. If None, the operation name     (from the <code>name</code> class variable) is used.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_display_name--examples","title":"Examples","text":"<p>Default behavior (returns None, uses operation name):</p> <p>class NormalizeOp(AudioOperation): ...     name = \"normalize\" op = NormalizeOp(44100) op.get_display_name()  # Returns None</p> <p>Custom display name:</p> <p>class LowPassFilter(AudioOperation): ...     name = \"lowpass_filter\" ... ...     def init(self, sr, cutoff): ...         self.cutoff = cutoff ...         super().init(sr, cutoff=cutoff) ... ...     def get_display_name(self): ...         return f\"lpf_{self.cutoff}Hz\" op = LowPassFilter(44100, cutoff=1000) op.get_display_name()  # Returns \"lpf_1000Hz\"</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_display_name--channel-label-normalizech0","title":"Channel label: \"normalize(ch0)\"","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_display_name--channel-label-lpf_1000hzch0","title":"Channel label: \"lpf_1000Hz(ch0)\"","text":""},{"location":"api/processing/#wandas.processing.base.AudioOperation.get_display_name--notes","title":"Notes","text":"<p>Subclasses can override this method to provide operation-specific display names that include parameter information, making labels more informative.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_display_name(self) -&gt; str | None:\n    \"\"\"\n    Get display name for the operation for use in channel labels.\n\n    This method allows operations to customize how they appear in\n    channel labels. By default, returns None, which means the\n    operation name will be used.\n\n    Returns\n    -------\n    str or None\n        Display name for the operation. If None, the operation name\n        (from the `name` class variable) is used.\n\n    Examples\n    --------\n    Default behavior (returns None, uses operation name):\n\n    &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n    ...     name = \"normalize\"\n    &gt;&gt;&gt; op = NormalizeOp(44100)\n    &gt;&gt;&gt; op.get_display_name()  # Returns None\n    &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n    Custom display name:\n\n    &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n    ...     name = \"lowpass_filter\"\n    ...\n    ...     def __init__(self, sr, cutoff):\n    ...         self.cutoff = cutoff\n    ...         super().__init__(sr, cutoff=cutoff)\n    ...\n    ...     def get_display_name(self):\n    ...         return f\"lpf_{self.cutoff}Hz\"\n    &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n    &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n    &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n    Notes\n    -----\n    Subclasses can override this method to provide operation-specific\n    display names that include parameter information, making labels\n    more informative.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.process_array","title":"<code>process_array(x)</code>","text":"<p>Processing function wrapped with @dask.delayed.</p> <p>This method returns a Delayed object that can be computed later. The operation name is used in the Dask task graph for better visualization.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.process_array--parameters","title":"Parameters","text":"<p>x : InputArrayType     Input array to process.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.process_array--returns","title":"Returns","text":"<p>dask.delayed.Delayed     A Delayed object representing the computation.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def process_array(self, x: InputArrayType) -&gt; Any:\n    \"\"\"\n    Processing function wrapped with @dask.delayed.\n\n    This method returns a Delayed object that can be computed later.\n    The operation name is used in the Dask task graph for better visualization.\n\n    Parameters\n    ----------\n    x : InputArrayType\n        Input array to process.\n\n    Returns\n    -------\n    dask.delayed.Delayed\n        A Delayed object representing the computation.\n    \"\"\"\n    logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n    # Create wrapper with operation name and wrap it with dask.delayed\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    return delayed_func(x)\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation.</p> <p>This method can be overridden by subclasses for efficiency. If not overridden, it will execute _process_array on a small test array to determine the output shape.</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.calculate_output_shape--notes","title":"Notes","text":"<p>The default implementation creates a minimal test array and processes it to determine output shape. For performance-critical code, subclasses should override this method with a direct calculation.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    This method can be overridden by subclasses for efficiency.\n    If not overridden, it will execute _process_array on a small test array\n    to determine the output shape.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n\n    Notes\n    -----\n    The default implementation creates a minimal test array and processes it\n    to determine output shape. For performance-critical code, subclasses should\n    override this method with a direct calculation.\n    \"\"\"\n    # Try to infer shape by executing _process_array on test data\n    import numpy as np\n\n    try:\n        # Create minimal test array with input shape\n        if len(input_shape) == 0:\n            return input_shape\n\n        # Create test input with correct dtype\n        # Try complex first, fall back to float if needed\n        test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n        # Process test input\n        test_output: Any = self._process_array(test_input)\n\n        # Return the shape of the output\n        if isinstance(test_output, np.ndarray):\n            return tuple(int(s) for s in test_output.shape)\n        return input_shape\n    except Exception as e:\n        logger.warning(\n            f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n            \"Please implement calculate_output_shape method.\"\n        )\n        raise NotImplementedError(\n            f\"Subclass {self.__class__.__name__} must implement \"\n            f\"calculate_output_shape or ensure _process_array can be \"\n            f\"called with test data.\"\n        ) from e\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.AudioOperation.process","title":"<code>process(data)</code>","text":"<p>Execute operation and return result data shape is (channels, samples)</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    \"\"\"\n    Execute operation and return result\n    data shape is (channels, samples)\n    \"\"\"\n    # Add task as delayed processing with custom name for visualization\n    logger.debug(\"Adding delayed operation to computation graph\")\n\n    # Create a wrapper function with the operation name\n    # This allows Dask to use the operation name in the task graph\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    delayed_result = delayed_func(data)\n\n    # Convert delayed result to dask array and return\n    output_shape = self.calculate_output_shape(data.shape)\n    return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"api/processing/#wandas.processing.base-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.base.register_operation","title":"<code>register_operation(operation_class)</code>","text":"<p>Register a new operation type</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def register_operation(operation_class: type) -&gt; None:\n    \"\"\"Register a new operation type\"\"\"\n\n    if not issubclass(operation_class, AudioOperation):\n        raise TypeError(\"Strategy class must inherit from AudioOperation.\")\n    if inspect.isabstract(operation_class):\n        raise TypeError(\"Cannot register abstract AudioOperation class.\")\n\n    _OPERATION_REGISTRY[operation_class.name] = operation_class\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.get_operation","title":"<code>get_operation(name)</code>","text":"<p>Get operation class by name</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def get_operation(name: str) -&gt; type[AudioOperation[Any, Any]]:\n    \"\"\"Get operation class by name\"\"\"\n    if name not in _OPERATION_REGISTRY:\n        raise ValueError(f\"Unknown operation type: {name}\")\n    return _OPERATION_REGISTRY[name]\n</code></pre>"},{"location":"api/processing/#wandas.processing.base.create_operation","title":"<code>create_operation(name, sampling_rate, **params)</code>","text":"<p>Create operation instance from name and parameters</p> Source code in <code>wandas/processing/base.py</code> <pre><code>def create_operation(\n    name: str, sampling_rate: float, **params: Any\n) -&gt; AudioOperation[Any, Any]:\n    \"\"\"Create operation instance from name and parameters\"\"\"\n    operation_class = get_operation(name)\n    return operation_class(sampling_rate, **params)\n</code></pre>"},{"location":"api/processing/#_3","title":"\u30a8\u30d5\u30a7\u30af\u30c8","text":"<p>\u30aa\u30fc\u30c7\u30a3\u30aa\u30a8\u30d5\u30a7\u30af\u30c8\u51e6\u7406\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#wandas.processing.effects","title":"<code>wandas.processing.effects</code>","text":""},{"location":"api/processing/#wandas.processing.effects-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects-classes","title":"Classes","text":""},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic","title":"<code>HpssHarmonic</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Harmonic operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssHarmonic(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Harmonic operation\"\"\"\n\n    name = \"hpss_harmonic\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Harmonic\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Hrm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Harmonic\"\"\"\n        logger.debug(f\"Applying HPSS Harmonic to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.harmonic(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Harmonic applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic.name","title":"<code>name = 'hpss_harmonic'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic.kwargs","title":"<code>kwargs = kwargs</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic.__init__","title":"<code>__init__(sampling_rate, **kwargs)</code>","text":"<p>Initialize HPSS Harmonic</p>"},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Harmonic\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssHarmonic.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Hrm\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssPercussive","title":"<code>HpssPercussive</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Percussive operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssPercussive(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Percussive operation\"\"\"\n\n    name = \"hpss_percussive\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Percussive\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Prc\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Percussive\"\"\"\n        logger.debug(f\"Applying HPSS Percussive to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.percussive(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Percussive applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssPercussive-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.HpssPercussive.name","title":"<code>name = 'hpss_percussive'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.HpssPercussive.kwargs","title":"<code>kwargs = kwargs</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.HpssPercussive-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects.HpssPercussive.__init__","title":"<code>__init__(sampling_rate, **kwargs)</code>","text":"<p>Initialize HPSS Percussive</p>"},{"location":"api/processing/#wandas.processing.effects.HpssPercussive.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Percussive\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssPercussive.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.HpssPercussive.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Prc\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Normalize","title":"<code>Normalize</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Signal normalization operation using librosa.util.normalize</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class Normalize(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Signal normalization operation using librosa.util.normalize\"\"\"\n\n    name = \"normalize\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        norm: float | None = np.inf,\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ):\n        \"\"\"\n        Initialize normalization operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        norm : float or np.inf, default=np.inf\n            Norm type. Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n            - float: Lp norm\n            - None: No normalization\n        axis : int or None, default=-1\n            Axis along which to normalize.\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold : float or None, optional\n            Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill : bool or None, optional\n            Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n        Raises\n        ------\n        ValueError\n            If norm parameter is invalid or threshold is negative\n        \"\"\"\n        # Validate norm parameter\n        if norm is not None and not isinstance(norm, int | float):\n            raise ValueError(\n                f\"Invalid normalization method\\n\"\n                f\"  Got: {type(norm).__name__} ({norm})\\n\"\n                f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n                f\"Norm parameter must be a numeric value or None.\\n\"\n                f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n                f\"1 (L1 norm), 0 (pseudo L0)\"\n            )\n\n        # Validate that norm is non-negative (except for -np.inf which is valid)\n        if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n            raise ValueError(\n                f\"Invalid normalization method\\n\"\n                f\"  Got: {norm}\\n\"\n                f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n                f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n                f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n                f\"1 (L1 norm), 0 (pseudo L0)\"\n            )\n\n        # Validate threshold\n        if threshold is not None and threshold &lt; 0:\n            raise ValueError(\n                f\"Invalid threshold for normalization\\n\"\n                f\"  Got: {threshold}\\n\"\n                f\"  Expected: Non-negative value or None\\n\"\n                f\"Threshold must be non-negative.\\n\"\n                f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n            )\n\n        super().__init__(\n            sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        self.norm = norm\n        self.axis = axis\n        self.threshold = threshold\n        self.fill = fill\n        logger.debug(\n            f\"Initialized Normalize operation with norm={norm}, \"\n            f\"axis={axis}, threshold={threshold}, fill={fill}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"norm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform normalization processing\"\"\"\n        logger.debug(\n            f\"Applying normalization to array with shape: {x.shape}, \"\n            f\"norm={self.norm}, axis={self.axis}\"\n        )\n\n        # Apply librosa.util.normalize\n        result: NDArrayReal = librosa_util.normalize(\n            x, norm=self.norm, axis=self.axis, threshold=self.threshold, fill=self.fill\n        )\n\n        logger.debug(\n            f\"Normalization applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Normalize-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize.name","title":"<code>name = 'normalize'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize.norm","title":"<code>norm = norm</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize.axis","title":"<code>axis = axis</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize.threshold","title":"<code>threshold = threshold</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize.fill","title":"<code>fill = fill</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects.Normalize.__init__","title":"<code>__init__(sampling_rate, norm=np.inf, axis=-1, threshold=None, fill=None)</code>","text":"<p>Initialize normalization operation</p>"},{"location":"api/processing/#wandas.processing.effects.Normalize.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) norm : float or np.inf, default=np.inf     Norm type. Supported values:     - np.inf: Maximum absolute value normalization     - -np.inf: Minimum absolute value normalization     - 0: Pseudo L0 normalization (divide by number of non-zero elements)     - float: Lp norm     - None: No normalization axis : int or None, default=-1     Axis along which to normalize.     - -1: Normalize along time axis (each channel independently)     - None: Global normalization across all axes     - int: Normalize along specified axis threshold : float or None, optional     Threshold below which values are considered zero.     If None, no threshold is applied. fill : bool or None, optional     Value to fill when the norm is zero.     If None, the zero vector remains zero.</p>"},{"location":"api/processing/#wandas.processing.effects.Normalize.__init__--raises","title":"Raises","text":"<p>ValueError     If norm parameter is invalid or threshold is negative</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    norm: float | None = np.inf,\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n):\n    \"\"\"\n    Initialize normalization operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    norm : float or np.inf, default=np.inf\n        Norm type. Supported values:\n        - np.inf: Maximum absolute value normalization\n        - -np.inf: Minimum absolute value normalization\n        - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n        - float: Lp norm\n        - None: No normalization\n    axis : int or None, default=-1\n        Axis along which to normalize.\n        - -1: Normalize along time axis (each channel independently)\n        - None: Global normalization across all axes\n        - int: Normalize along specified axis\n    threshold : float or None, optional\n        Threshold below which values are considered zero.\n        If None, no threshold is applied.\n    fill : bool or None, optional\n        Value to fill when the norm is zero.\n        If None, the zero vector remains zero.\n\n    Raises\n    ------\n    ValueError\n        If norm parameter is invalid or threshold is negative\n    \"\"\"\n    # Validate norm parameter\n    if norm is not None and not isinstance(norm, int | float):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {type(norm).__name__} ({norm})\\n\"\n            f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be a numeric value or None.\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate that norm is non-negative (except for -np.inf which is valid)\n    if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {norm}\\n\"\n            f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate threshold\n    if threshold is not None and threshold &lt; 0:\n        raise ValueError(\n            f\"Invalid threshold for normalization\\n\"\n            f\"  Got: {threshold}\\n\"\n            f\"  Expected: Non-negative value or None\\n\"\n            f\"Threshold must be non-negative.\\n\"\n            f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n        )\n\n    super().__init__(\n        sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    self.norm = norm\n    self.axis = axis\n    self.threshold = threshold\n    self.fill = fill\n    logger.debug(\n        f\"Initialized Normalize operation with norm={norm}, \"\n        f\"axis={axis}, threshold={threshold}, fill={fill}\"\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Normalize.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.effects.Normalize.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.effects.Normalize.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Normalize.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"norm\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC","title":"<code>RemoveDC</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Remove DC component (DC offset) from the signal.</p> <p>This operation removes the DC component by subtracting the mean value from each channel, centering the signal around zero.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class RemoveDC(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This operation removes the DC component by subtracting the mean value\n    from each channel, centering the signal around zero.\n    \"\"\"\n\n    name = \"remove_dc\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"Initialize DC removal operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n        logger.debug(\"Initialized RemoveDC operation\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"Calculate output data shape after operation.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"dcRM\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform DC removal processing.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array (channels, samples)\n\n        Returns\n        -------\n        NDArrayReal\n            Signal with DC component removed\n        \"\"\"\n        logger.debug(f\"Removing DC component from array with shape: {x.shape}\")\n\n        # Subtract mean along time axis (axis=1 for channel data)\n        mean_values = x.mean(axis=-1, keepdims=True)\n        result: NDArrayReal = x - mean_values\n\n        logger.debug(f\"DC removal applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.RemoveDC.name","title":"<code>name = 'remove_dc'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.RemoveDC-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects.RemoveDC.__init__","title":"<code>__init__(sampling_rate)</code>","text":"<p>Initialize DC removal operation.</p>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"Initialize DC removal operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n    logger.debug(\"Initialized RemoveDC operation\")\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation.</p>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"Calculate output data shape after operation.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.RemoveDC.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"dcRM\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR","title":"<code>AddWithSNR</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Addition operation considering SNR</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class AddWithSNR(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Addition operation considering SNR\"\"\"\n\n    name = \"add_with_snr\"\n\n    def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n        \"\"\"\n        Initialize addition operation considering SNR\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other : DaArray\n            Noise signal to add (channel-frame format)\n        snr : float\n            Signal-to-noise ratio (dB)\n        \"\"\"\n        super().__init__(sampling_rate, other=other, snr=snr)\n\n        self.other = other\n        self.snr = snr\n        logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"+SNR\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform addition processing considering SNR\"\"\"\n        logger.debug(f\"Applying SNR-based addition with shape: {x.shape}\")\n        other: NDArrayReal = self.other.compute()\n\n        # Use multi-channel versions of calculate_rms and calculate_desired_noise_rms\n        clean_rms = util.calculate_rms(x)\n        other_rms = util.calculate_rms(other)\n\n        # Adjust noise gain based on specified SNR (apply per channel)\n        desired_noise_rms = util.calculate_desired_noise_rms(clean_rms, self.snr)\n\n        # Apply gain per channel using broadcasting\n        gain = desired_noise_rms / other_rms\n        # Add adjusted noise to signal\n        result: NDArrayReal = x + other * gain\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.name","title":"<code>name = 'add_with_snr'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.other","title":"<code>other = other</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.snr","title":"<code>snr = snr</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.AddWithSNR-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.__init__","title":"<code>__init__(sampling_rate, other, snr=1.0)</code>","text":"<p>Initialize addition operation considering SNR</p>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other : DaArray     Noise signal to add (channel-frame format) snr : float     Signal-to-noise ratio (dB)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n    \"\"\"\n    Initialize addition operation considering SNR\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other : DaArray\n        Noise signal to add (channel-frame format)\n    snr : float\n        Signal-to-noise ratio (dB)\n    \"\"\"\n    super().__init__(sampling_rate, other=other, snr=snr)\n\n    self.other = other\n    self.snr = snr\n    logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.AddWithSNR.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"+SNR\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Fade","title":"<code>Fade</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Fade operation using a Tukey (tapered cosine) window.</p> <p>This operation applies symmetric fade-in and fade-out with the same duration. The Tukey window alpha parameter is computed from the fade duration so that the tapered portion equals the requested fade length at each end.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class Fade(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Fade operation using a Tukey (tapered cosine) window.\n\n    This operation applies symmetric fade-in and fade-out with the same\n    duration. The Tukey window alpha parameter is computed from the fade\n    duration so that the tapered portion equals the requested fade length\n    at each end.\n    \"\"\"\n\n    name = \"fade\"\n\n    def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n        self.fade_ms = float(fade_ms)\n        # Precompute fade length in samples at construction time\n        self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n        super().__init__(sampling_rate, fade_ms=fade_ms)\n\n    def validate_params(self) -&gt; None:\n        if self.fade_ms &lt; 0:\n            raise ValueError(\"fade_ms must be non-negative\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"fade\"\n\n    @staticmethod\n    def calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n        \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n        The alpha parameter determines what fraction of the window is tapered.\n        For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n        that each side's taper has exactly fade_len samples.\n\n        Parameters\n        ----------\n        fade_len : int\n            Desired fade length in samples for each end (in and out).\n        n_samples : int\n            Total number of samples in the signal.\n\n        Returns\n        -------\n        float\n            Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n        Examples\n        --------\n        &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n        0.2\n        &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n        1.0\n        \"\"\"\n        alpha = float(2 * fade_len) / float(n_samples)\n        return min(1.0, alpha)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        logger.debug(f\"Applying Tukey Fade to array with shape: {x.shape}\")\n\n        arr = x\n        if arr.ndim == 1:\n            arr = arr.reshape(1, -1)\n\n        n_samples = int(arr.shape[-1])\n\n        # If no fade requested, return input\n        if self.fade_len &lt;= 0:\n            return arr\n\n        if 2 * self.fade_len &gt;= n_samples:\n            raise ValueError(\n                \"Fade length too long: 2*fade_ms must be less than signal length\"\n            )\n\n        # Calculate Tukey window alpha parameter\n        alpha = self.calculate_tukey_alpha(self.fade_len, n_samples)\n\n        # Create tukey window (numpy) and apply\n        env = sp_windows.tukey(n_samples, alpha=alpha)\n\n        result: NDArrayReal = arr * env[None, :]\n        logger.debug(\"Tukey fade applied\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Fade-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.effects.Fade.name","title":"<code>name = 'fade'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Fade.fade_ms","title":"<code>fade_ms = float(fade_ms)</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Fade.fade_len","title":"<code>fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.effects.Fade-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects.Fade.__init__","title":"<code>__init__(sampling_rate, fade_ms=50)</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n    self.fade_ms = float(fade_ms)\n    # Precompute fade length in samples at construction time\n    self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n    super().__init__(sampling_rate, fade_ms=fade_ms)\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Fade.validate_params","title":"<code>validate_params()</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def validate_params(self) -&gt; None:\n    if self.fade_ms &lt; 0:\n        raise ValueError(\"fade_ms must be non-negative\")\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Fade.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Fade.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fade\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects.Fade.calculate_tukey_alpha","title":"<code>calculate_tukey_alpha(fade_len, n_samples)</code>  <code>staticmethod</code>","text":"<p>Calculate Tukey window alpha parameter from fade length.</p> <p>The alpha parameter determines what fraction of the window is tapered. For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures that each side's taper has exactly fade_len samples.</p>"},{"location":"api/processing/#wandas.processing.effects.Fade.calculate_tukey_alpha--parameters","title":"Parameters","text":"<p>fade_len : int     Desired fade length in samples for each end (in and out). n_samples : int     Total number of samples in the signal.</p>"},{"location":"api/processing/#wandas.processing.effects.Fade.calculate_tukey_alpha--returns","title":"Returns","text":"<p>float     Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].</p>"},{"location":"api/processing/#wandas.processing.effects.Fade.calculate_tukey_alpha--examples","title":"Examples","text":"<p>Fade.calculate_tukey_alpha(fade_len=20, n_samples=200) 0.2 Fade.calculate_tukey_alpha(fade_len=100, n_samples=100) 1.0</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>@staticmethod\ndef calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n    \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n    The alpha parameter determines what fraction of the window is tapered.\n    For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n    that each side's taper has exactly fade_len samples.\n\n    Parameters\n    ----------\n    fade_len : int\n        Desired fade length in samples for each end (in and out).\n    n_samples : int\n        Total number of samples in the signal.\n\n    Returns\n    -------\n    float\n        Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n    Examples\n    --------\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n    0.2\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n    1.0\n    \"\"\"\n    alpha = float(2 * fade_len) / float(n_samples)\n    return min(1.0, alpha)\n</code></pre>"},{"location":"api/processing/#wandas.processing.effects-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.effects-modules","title":"Modules","text":""},{"location":"api/processing/#_4","title":"\u30d5\u30a3\u30eb\u30bf\u30fc","text":"<p>\u69d8\u3005\u306a\u30aa\u30fc\u30c7\u30a3\u30aa\u30d5\u30a3\u30eb\u30bf\u30fc\u51e6\u7406\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#wandas.processing.filters","title":"<code>wandas.processing.filters</code>","text":""},{"location":"api/processing/#wandas.processing.filters-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.filters.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters-classes","title":"Classes","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter","title":"<code>HighPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>High-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class HighPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"High-pass filter operation\"\"\"\n\n    name = \"highpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize high-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up high-pass filter processor\"\"\"\n        # Calculate filter coefficients (once) - safely retrieve from instance variables\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"high\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Highpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"hpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying highpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.HighPassFilter-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.name","title":"<code>name = 'highpass_filter'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.a","title":"<code>a</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.b","title":"<code>b</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.cutoff","title":"<code>cutoff = cutoff</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.order","title":"<code>order = order</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.__init__","title":"<code>__init__(sampling_rate, cutoff, order=4)</code>","text":"<p>Initialize high-pass filter</p>"},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) cutoff : float     Cutoff frequency (Hz). Must be between 0 and Nyquist frequency     (sampling_rate / 2). order : int, optional     Filter order, default is 4</p>"},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize high-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.HighPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"hpf\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter","title":"<code>LowPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Low-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class LowPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Low-pass filter operation\"\"\"\n\n    name = \"lowpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize low-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up low-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"low\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Lowpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"lpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying lowpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.name","title":"<code>name = 'lowpass_filter'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.a","title":"<code>a</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.b","title":"<code>b</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.cutoff","title":"<code>cutoff = cutoff</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.order","title":"<code>order = order</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.__init__","title":"<code>__init__(sampling_rate, cutoff, order=4)</code>","text":"<p>Initialize low-pass filter</p>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) cutoff : float     Cutoff frequency (Hz). Must be between 0 and Nyquist frequency     (sampling_rate / 2). order : int, optional     Filter order, default is 4</p>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize low-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.LowPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"lpf\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter","title":"<code>BandPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Band-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class BandPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Band-pass filter operation\"\"\"\n\n    name = \"bandpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        low_cutoff: float,\n        high_cutoff: float,\n        order: int = 4,\n    ):\n        \"\"\"\n        Initialize band-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        low_cutoff : float\n            Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n        high_cutoff : float\n            Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            and greater than low_cutoff.\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n            or if low_cutoff &gt;= high_cutoff\n        \"\"\"\n        self.low_cutoff = low_cutoff\n        self.high_cutoff = high_cutoff\n        self.order = order\n        super().__init__(\n            sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Lower cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.low_cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Use a lower cutoff frequency below {nyquist} Hz\"\n            )\n        if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Higher cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.high_cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Use a cutoff frequency below {nyquist} Hz\"\n            )\n        if self.low_cutoff &gt;= self.high_cutoff:\n            raise ValueError(\n                f\"Invalid bandpass filter cutoff frequencies\\n\"\n                f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n                f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n                f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n                f\"A bandpass filter passes frequencies between low and high\\n\"\n                f\"  cutoffs.\\n\"\n                f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n                f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up band-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        low_normal_cutoff = self.low_cutoff / nyquist\n        high_normal_cutoff = self.high_cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(\n            self.order, [low_normal_cutoff, high_normal_cutoff], btype=\"band\"\n        )  # type: ignore [unused-ignore]\n        logger.debug(f\"Bandpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"bpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying bandpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.name","title":"<code>name = 'bandpass_filter'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.a","title":"<code>a</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.b","title":"<code>b</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.low_cutoff","title":"<code>low_cutoff = low_cutoff</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.high_cutoff","title":"<code>high_cutoff = high_cutoff</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.order","title":"<code>order = order</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.__init__","title":"<code>__init__(sampling_rate, low_cutoff, high_cutoff, order=4)</code>","text":"<p>Initialize band-pass filter</p>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) low_cutoff : float     Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency. high_cutoff : float     Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency     and greater than low_cutoff. order : int, optional     Filter order, default is 4</p>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),     or if low_cutoff &gt;= high_cutoff</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    low_cutoff: float,\n    high_cutoff: float,\n    order: int = 4,\n):\n    \"\"\"\n    Initialize band-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    low_cutoff : float\n        Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n    high_cutoff : float\n        Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        and greater than low_cutoff.\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n        or if low_cutoff &gt;= high_cutoff\n    \"\"\"\n    self.low_cutoff = low_cutoff\n    self.high_cutoff = high_cutoff\n    self.order = order\n    super().__init__(\n        sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Lower cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.low_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a lower cutoff frequency below {nyquist} Hz\"\n        )\n    if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Higher cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.high_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a cutoff frequency below {nyquist} Hz\"\n        )\n    if self.low_cutoff &gt;= self.high_cutoff:\n        raise ValueError(\n            f\"Invalid bandpass filter cutoff frequencies\\n\"\n            f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n            f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n            f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n            f\"A bandpass filter passes frequencies between low and high\\n\"\n            f\"  cutoffs.\\n\"\n            f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n            f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n        )\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.BandPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"bpf\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.AWeighting","title":"<code>AWeighting</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>A-weighting filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class AWeighting(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"A-weighting filter operation\"\"\"\n\n    name = \"a_weighting\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize A-weighting filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Aw\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for A-weighting filter\"\"\"\n        logger.debug(f\"Applying A-weighting to array with shape: {x.shape}\")\n        result = A_weight(x, self.sampling_rate)\n\n        # Handle case where A_weight returns a tuple\n        if isinstance(result, tuple):\n            # Use the first element of the tuple\n            result = result[0]\n\n        logger.debug(\n            f\"A-weighting applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.AWeighting-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.filters.AWeighting.name","title":"<code>name = 'a_weighting'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.filters.AWeighting-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.filters.AWeighting.__init__","title":"<code>__init__(sampling_rate)</code>","text":"<p>Initialize A-weighting filter</p>"},{"location":"api/processing/#wandas.processing.filters.AWeighting.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize A-weighting filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.AWeighting.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"Source code in <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters.AWeighting.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Aw\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.filters-functions","title":"Functions","text":""},{"location":"api/processing/#_5","title":"\u30b9\u30da\u30af\u30c8\u30eb\u51e6\u7406","text":"<p>\u30b9\u30da\u30af\u30c8\u30eb\u89e3\u6790\u3068\u51e6\u7406\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#wandas.processing.spectral","title":"<code>wandas.processing.spectral</code>","text":""},{"location":"api/processing/#wandas.processing.spectral-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral-classes","title":"Classes","text":""},{"location":"api/processing/#wandas.processing.spectral.FFT","title":"<code>FFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>FFT (Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class FFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"FFT (Fast Fourier Transform) operation\"\"\"\n\n    name = \"fft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize FFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is None (determined by input size)\n        window : str, optional\n            Window function type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not a positive integer\n        \"\"\"\n        # Validate n_fft parameter\n        if n_fft is not None and n_fft &lt;= 0:\n            raise ValueError(\n                f\"Invalid FFT size\\n\"\n                f\"  Got: {n_fft}\\n\"\n                f\"  Expected: Positive integer &gt; 0\\n\"\n                f\"FFT size must be a positive integer.\\n\"\n                f\"Common values: 512, 1024, 2048, 4096,\\n\"\n                f\"8192 (powers of 2 are most efficient)\"\n            )\n\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n        Parameters\n        ----------\n        input_shape : tuple\n            \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n        Returns\n        -------\n        tuple\n            \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"FFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"FFT\u64cd\u4f5c\u306e\u30d7\u30ed\u30bb\u30c3\u30b5\u95a2\u6570\u3092\u4f5c\u6210\"\"\"\n        from scipy.signal import get_window\n\n        if self.n_fft is not None and x.shape[-1] &gt; self.n_fft:\n            # If n_fft is specified and input length exceeds it, truncate\n            x = x[..., : self.n_fft]\n\n        win = get_window(self.window, x.shape[-1])\n        x = x * win\n        result: NDArrayComplex = np.fft.rfft(x, n=self.n_fft, axis=-1)\n        result[..., 1:-1] *= 2.0\n        # \u7a93\u95a2\u6570\u88dc\u6b63\n        scaling_factor = np.sum(win)\n        result = result / scaling_factor\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.FFT-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.FFT.name","title":"<code>name = 'fft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.FFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.FFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.FFT-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.FFT.__init__","title":"<code>__init__(sampling_rate, n_fft=None, window='hann')</code>","text":"<p>Initialize FFT operation</p>"},{"location":"api/processing/#wandas.processing.spectral.FFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int, optional     FFT size, default is None (determined by input size) window : str, optional     Window function type, default is 'hann'</p>"},{"location":"api/processing/#wandas.processing.spectral.FFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not a positive integer</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize FFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is None (determined by input size)\n    window : str, optional\n        Window function type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not a positive integer\n    \"\"\"\n    # Validate n_fft parameter\n    if n_fft is not None and n_fft &lt;= 0:\n        raise ValueError(\n            f\"Invalid FFT size\\n\"\n            f\"  Got: {n_fft}\\n\"\n            f\"  Expected: Positive integer &gt; 0\\n\"\n            f\"FFT size must be a positive integer.\\n\"\n            f\"Common values: 512, 1024, 2048, 4096,\\n\"\n            f\"8192 (powers of 2 are most efficient)\"\n        )\n\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.FFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>\u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059</p>"},{"location":"api/processing/#wandas.processing.spectral.FFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)</p>"},{"location":"api/processing/#wandas.processing.spectral.FFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n    Parameters\n    ----------\n    input_shape : tuple\n        \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n    Returns\n    -------\n    tuple\n        \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.FFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"FFT\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.IFFT","title":"<code>IFFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>IFFT (Inverse Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class IFFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"IFFT (Inverse Fast Fourier Transform) operation\"\"\"\n\n    name = \"ifft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize IFFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : Optional[int], optional\n            IFFT size, default is None (determined based on input size)\n        window : str, optional\n            Window function type, default is 'hann'\n        \"\"\"\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, freqs)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, samples)\n        \"\"\"\n        n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iFFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"Create processor function for IFFT operation\"\"\"\n        logger.debug(f\"Applying IFFT to array with shape: {x.shape}\")\n\n        # Restore frequency component scaling (remove the 2.0 multiplier applied in FFT)\n        _x = x.copy()\n        _x[..., 1:-1] /= 2.0\n\n        # Execute IFFT\n        result: NDArrayReal = np.fft.irfft(_x, n=self.n_fft, axis=-1)\n\n        # Window function correction (inverse of FFT operation)\n        from scipy.signal import get_window\n\n        win = get_window(self.window, result.shape[-1])\n\n        # Correct the FFT window function scaling\n        scaling_factor = np.sum(win) / result.shape[-1]\n        result = result / scaling_factor\n\n        logger.debug(f\"IFFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.IFFT-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.IFFT.name","title":"<code>name = 'ifft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.IFFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.IFFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.IFFT-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.IFFT.__init__","title":"<code>__init__(sampling_rate, n_fft=None, window='hann')</code>","text":"<p>Initialize IFFT operation</p>"},{"location":"api/processing/#wandas.processing.spectral.IFFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : Optional[int], optional     IFFT size, default is None (determined based on input size) window : str, optional     Window function type, default is 'hann'</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize IFFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : Optional[int], optional\n        IFFT size, default is None (determined based on input size)\n    window : str, optional\n        Window function type, default is 'hann'\n    \"\"\"\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.IFFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.IFFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, freqs)</p>"},{"location":"api/processing/#wandas.processing.spectral.IFFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, samples)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, freqs)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, samples)\n    \"\"\"\n    n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.IFFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iFFT\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.STFT","title":"<code>STFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class STFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Short-Time Fourier Transform operation\"\"\"\n\n    name = \"stft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ):\n        \"\"\"\n        Initialize STFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"STFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",\n        )\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        n_samples = input_shape[-1]\n        n_f = len(self.SFT.f)\n        n_t = len(self.SFT.t(n_samples))\n        return (input_shape[0], n_f, n_t)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"STFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Apply SciPy STFT processing to multiple channels at once\"\"\"\n        logger.debug(f\"Applying SciPy STFT to array with shape: {x.shape}\")\n\n        # Convert 1D input to 2D\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        # Apply STFT to all channels at once\n        result: NDArrayComplex = self.SFT.stft(x)\n        result[..., 1:-1, :] *= 2.0\n        logger.debug(f\"SciPy STFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.STFT-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.name","title":"<code>name = 'stft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.noverlap","title":"<code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.SFT","title":"<code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.STFT.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann')</code>","text":"<p>Initialize STFT operation</p>"},{"location":"api/processing/#wandas.processing.spectral.STFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window type, default is 'hann'</p>"},{"location":"api/processing/#wandas.processing.spectral.STFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n):\n    \"\"\"\n    Initialize STFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"STFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",\n    )\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.STFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.STFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.spectral.STFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    n_samples = input_shape[-1]\n    n_f = len(self.SFT.f)\n    n_t = len(self.SFT.t(n_samples))\n    return (input_shape[0], n_f, n_t)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.STFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"STFT\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT","title":"<code>ISTFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>Inverse Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class ISTFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"Inverse Short-Time Fourier Transform operation\"\"\"\n\n    name = \"istft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        length: int | None = None,\n    ):\n        \"\"\"\n        Initialize ISTFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n        length : int, optional\n            Length of output signal. Default is None (determined from input)\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"ISTFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.length = length\n\n        # Instantiate ShortTimeFFT for ISTFT calculation\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",  # Consistent scaling with STFT\n        )\n\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            length=length,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after ISTFT operation.\n\n        Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n        output length based on the input spectrogram dimensions and output range\n        parameters (k0, k1).\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input spectrogram shape (channels, n_freqs, n_frames)\n            where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n        Returns\n        -------\n        tuple\n            Output shape (channels, output_samples) where output_samples is the\n            reconstructed signal length determined by the output range [k0, k1).\n\n        Notes\n        -----\n        The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n        When k1 is None (default), the maximum reconstructible signal length is\n        computed as:\n\n        .. math::\n\n            q_{max} = n_{frames} + p_{min}\n\n            k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n        The output length is then:\n\n        .. math::\n\n            output\\\\_samples = k_1 - k_0\n\n        where k0 defaults to 0 and k1 defaults to k_max.\n\n        Parameters that affect the calculation:\n        - n_frames: number of time frames in the STFT\n        - p_min: minimum frame index (ShortTimeFFT property)\n        - hop: hop length (samples between frames)\n        - m_num: window length\n        - m_num_mid: window midpoint position\n        - self.length: optional length override (if set, limits output)\n\n        References\n        ----------\n        - SciPy ShortTimeFFT.istft:\n          https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n        - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        \"\"\"\n        n_channels = input_shape[0]\n        n_frames = input_shape[-1]  # time_frames\n\n        # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n        # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        q_max = n_frames + self.SFT.p_min\n        k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n        # Default parameters: k0=0, k1=None (which becomes k_max)\n        # The output length is k1 - k0 = k_max - 0 = k_max\n        k0 = 0\n        k1 = k_max\n\n        # If self.length is specified, it acts as an override to limit the output\n        if self.length is not None:\n            k1 = min(self.length, k1)\n\n        output_samples = k1 - k0\n\n        return (n_channels, output_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iSTFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"\n        Apply SciPy ISTFT processing to multiple channels at once using ShortTimeFFT\"\"\"\n        logger.debug(\n            f\"Applying SciPy ISTFT (ShortTimeFFT) to array with shape: {x.shape}\"\n        )\n\n        # Convert 2D input to 3D (assume single channel)\n        if x.ndim == 2:\n            x = x.reshape(1, *x.shape)\n\n        # Adjust scaling back if STFT applied factor of 2\n        _x = np.copy(x)\n        _x[..., 1:-1, :] /= 2.0\n\n        # Apply ISTFT using the ShortTimeFFT instance\n        result: NDArrayReal = self.SFT.istft(_x)\n\n        # Trim to desired length if specified\n        if self.length is not None:\n            result = result[..., : self.length]\n\n        logger.debug(\n            f\"ShortTimeFFT applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.name","title":"<code>name = 'istft'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.length","title":"<code>length = length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.SFT","title":"<code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.ISTFT.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', length=None)</code>","text":"<p>Initialize ISTFT operation</p>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window type, default is 'hann' length : int, optional     Length of output signal. Default is None (determined from input)</p>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    length: int | None = None,\n):\n    \"\"\"\n    Initialize ISTFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n    length : int, optional\n        Length of output signal. Default is None (determined from input)\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"ISTFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.length = length\n\n    # Instantiate ShortTimeFFT for ISTFT calculation\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",  # Consistent scaling with STFT\n    )\n\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        length=length,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after ISTFT operation.</p> <p>Uses the SciPy ShortTimeFFT calculation formula to compute the expected output length based on the input spectrogram dimensions and output range parameters (k0, k1).</p>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input spectrogram shape (channels, n_freqs, n_frames)     where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.</p>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output shape (channels, output_samples) where output_samples is the     reconstructed signal length determined by the output range [k0, k1).</p>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.calculate_output_shape--notes","title":"Notes","text":"<p>The calculation follows SciPy's ShortTimeFFT.istft() implementation. When k1 is None (default), the maximum reconstructible signal length is computed as:</p> <p>.. math::</p> <pre><code>q_{max} = n_{frames} + p_{min}\n\nk_{max} = (q_{max} - 1) \\cdot hop + m_{num} - m_{num\\_mid}\n</code></pre> <p>The output length is then:</p> <p>.. math::</p> <pre><code>output\\_samples = k_1 - k_0\n</code></pre> <p>where k0 defaults to 0 and k1 defaults to k_max.</p> <p>Parameters that affect the calculation: - n_frames: number of time frames in the STFT - p_min: minimum frame index (ShortTimeFFT property) - hop: hop length (samples between frames) - m_num: window length - m_num_mid: window midpoint position - self.length: optional length override (if set, limits output)</p>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.calculate_output_shape--references","title":"References","text":"<ul> <li>SciPy ShortTimeFFT.istft:   https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html</li> <li>SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py</li> </ul> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after ISTFT operation.\n\n    Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n    output length based on the input spectrogram dimensions and output range\n    parameters (k0, k1).\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input spectrogram shape (channels, n_freqs, n_frames)\n        where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n    Returns\n    -------\n    tuple\n        Output shape (channels, output_samples) where output_samples is the\n        reconstructed signal length determined by the output range [k0, k1).\n\n    Notes\n    -----\n    The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n    When k1 is None (default), the maximum reconstructible signal length is\n    computed as:\n\n    .. math::\n\n        q_{max} = n_{frames} + p_{min}\n\n        k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n    The output length is then:\n\n    .. math::\n\n        output\\\\_samples = k_1 - k_0\n\n    where k0 defaults to 0 and k1 defaults to k_max.\n\n    Parameters that affect the calculation:\n    - n_frames: number of time frames in the STFT\n    - p_min: minimum frame index (ShortTimeFFT property)\n    - hop: hop length (samples between frames)\n    - m_num: window length\n    - m_num_mid: window midpoint position\n    - self.length: optional length override (if set, limits output)\n\n    References\n    ----------\n    - SciPy ShortTimeFFT.istft:\n      https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n    - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    \"\"\"\n    n_channels = input_shape[0]\n    n_frames = input_shape[-1]  # time_frames\n\n    # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n    # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    q_max = n_frames + self.SFT.p_min\n    k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n    # Default parameters: k0=0, k1=None (which becomes k_max)\n    # The output length is k1 - k0 = k_max - 0 = k_max\n    k0 = 0\n    k1 = k_max\n\n    # If self.length is specified, it acts as an override to limit the output\n    if self.length is not None:\n        k1 = min(self.length, k1)\n\n    output_samples = k1 - k0\n\n    return (n_channels, output_samples)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.ISTFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iSTFT\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Welch","title":"<code>Welch</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Welch</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Welch(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Welch\"\"\"\n\n    name = \"welch\"\n    n_fft: int\n    window: str\n    hop_length: int | None\n    win_length: int | None\n    average: str\n    detrend: str\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        average: str = \"mean\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize Welch operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str, optional\n            Window function type, default is 'hann'\n        average : str, optional\n            Averaging method, default is 'mean'\n        detrend : str, optional\n            Detrend method, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft, win_length, or hop_length are invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Welch method\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n        self.average = average\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            average=average,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"PS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for Welch operation\"\"\"\n        from scipy import signal as ss\n\n        _, result = ss.welch(\n            x,\n            nperseg=self.win_length,\n            noverlap=self.noverlap,\n            nfft=self.n_fft,\n            window=self.window,\n            average=self.average,\n            detrend=self.detrend,\n            scaling=\"spectrum\",\n        )\n\n        if not isinstance(x, np.ndarray):\n            # Trigger computation for Dask array\n            raise ValueError(\n                \"Welch operation requires a Dask array, but received a non-ndarray.\"\n            )\n        return np.array(result)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Welch-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.name","title":"<code>name = 'welch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.noverlap","title":"<code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.average","title":"<code>average = average</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.Welch.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', average='mean', detrend='constant')</code>","text":"<p>Initialize Welch operation</p>"},{"location":"api/processing/#wandas.processing.spectral.Welch.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int, optional     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str, optional     Window function type, default is 'hann' average : str, optional     Averaging method, default is 'mean' detrend : str, optional     Detrend method, default is 'constant'</p>"},{"location":"api/processing/#wandas.processing.spectral.Welch.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft, win_length, or hop_length are invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    average: str = \"mean\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize Welch operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str, optional\n        Window function type, default is 'hann'\n    average : str, optional\n        Averaging method, default is 'mean'\n    detrend : str, optional\n        Detrend method, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft, win_length, or hop_length are invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Welch method\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n    self.average = average\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        average=average,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Welch.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.Welch.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/processing/#wandas.processing.spectral.Welch.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Welch.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"PS\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum","title":"<code>NOctSpectrum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>N-octave spectrum operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSpectrum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"N-octave spectrum operation\"\"\"\n\n    name = \"noct_spectrum\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize N-octave spectrum\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Oct\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave spectrum\"\"\"\n        logger.debug(f\"Applying NoctSpectrum to array with shape: {x.shape}\")\n        spec, _ = noct_spectrum(\n            sig=x.T,\n            fs=self.sampling_rate,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if spec.ndim == 1:\n            # Add channel dimension for 1D\n            spec = np.expand_dims(spec, axis=0)\n        else:\n            spec = spec.T\n        logger.debug(f\"NoctSpectrum applied, returning result with shape: {spec.shape}\")\n        return np.array(spec)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.name","title":"<code>name = 'noct_spectrum'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.fmin","title":"<code>fmin = fmin</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.fmax","title":"<code>fmax = fmax</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.n","title":"<code>n = n</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.G","title":"<code>G = G</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.fr","title":"<code>fr = fr</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.__init__","title":"<code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code>","text":"<p>Initialize N-octave spectrum</p>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize N-octave spectrum\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSpectrum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Oct\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis","title":"<code>NOctSynthesis</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Octave synthesis operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSynthesis(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Octave synthesis operation\"\"\"\n\n    name = \"noct_synthesis\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize octave synthesis\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Octs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave synthesis\"\"\"\n        logger.debug(f\"Applying NoctSynthesis to array with shape: {x.shape}\")\n        # Calculate n from shape[-1]\n        n = x.shape[-1]  # Calculate n from shape[-1]\n        if n % 2 == 0:\n            n = n * 2 - 1\n        else:\n            n = (n - 1) * 2\n        freqs = np.fft.rfftfreq(n, d=1 / self.sampling_rate)\n        result, _ = noct_synthesis(\n            spectrum=np.abs(x).T,\n            freqs=freqs,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        result = result.T\n        logger.debug(\n            f\"NoctSynthesis applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.name","title":"<code>name = 'noct_synthesis'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.fmin","title":"<code>fmin = fmin</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.fmax","title":"<code>fmax = fmax</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.n","title":"<code>n = n</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.G","title":"<code>G = G</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.fr","title":"<code>fr = fr</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.__init__","title":"<code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code>","text":"<p>Initialize octave synthesis</p>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize octave synthesis\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.NOctSynthesis.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Octs\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Coherence","title":"<code>Coherence</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Coherence estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Coherence(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Coherence estimation operation\"\"\"\n\n    name = \"coherence\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize coherence estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Coherence\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Coh\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Processor function for coherence estimation operation\"\"\"\n        logger.debug(f\"Applying coherence estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        _, coh = ss.coherence(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayReal = coh.transpose(1, 0, 2).reshape(-1, coh.shape[-1])\n\n        logger.debug(f\"Coherence estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Coherence-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.name","title":"<code>name = 'coherence'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.Coherence.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code>","text":"<p>Initialize coherence estimation operation</p>"},{"location":"api/processing/#wandas.processing.spectral.Coherence.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant'</p>"},{"location":"api/processing/#wandas.processing.spectral.Coherence.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize coherence estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Coherence\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Coherence.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.Coherence.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/processing/#wandas.processing.spectral.Coherence.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.Coherence.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Coh\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.CSD","title":"<code>CSD</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Cross-spectral density estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class CSD(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Cross-spectral density estimation operation\"\"\"\n\n    name = \"csd\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize cross-spectral density estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"CSD\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"CSD\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for cross-spectral density estimation operation\"\"\"\n        logger.debug(f\"Applying CSD estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        # Calculate all combinations using scipy's csd function\n        _, csd_result = ss.csd(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayComplex = csd_result.transpose(1, 0, 2).reshape(\n            -1, csd_result.shape[-1]\n        )\n\n        logger.debug(f\"CSD estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.CSD-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.name","title":"<code>name = 'csd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.scaling","title":"<code>scaling = scaling</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.average","title":"<code>average = average</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.CSD.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Initialize cross-spectral density estimation operation</p>"},{"location":"api/processing/#wandas.processing.spectral.CSD.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant' scaling : str     Type of scaling, default is 'spectrum' average : str     Method of averaging, default is 'mean'</p>"},{"location":"api/processing/#wandas.processing.spectral.CSD.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize cross-spectral density estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"CSD\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.CSD.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.CSD.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/processing/#wandas.processing.spectral.CSD.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.CSD.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"CSD\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction","title":"<code>TransferFunction</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Transfer function estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class TransferFunction(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Transfer function estimation operation\"\"\"\n\n    name = \"transfer_function\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize transfer function estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Transfer function\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"H\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for transfer function estimation operation\"\"\"\n        logger.debug(\n            f\"Applying transfer function estimation to array with shape: {x.shape}\"\n        )\n        from scipy import signal as ss\n\n        # Calculate cross-spectral density between all channels\n        f, p_yx = ss.csd(\n            x=x[:, np.newaxis, :],\n            y=x[np.newaxis, :, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_yx shape: (num_channels, num_channels, num_frequencies)\n\n        # Calculate power spectral density for each channel\n        f, p_xx = ss.welch(\n            x=x,\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_xx shape: (num_channels, num_frequencies)\n\n        # Calculate transfer function H(f) = P_yx / P_xx\n        h_f = p_yx / p_xx[np.newaxis, :, :]\n        result: NDArrayComplex = h_f.transpose(1, 0, 2).reshape(-1, h_f.shape[-1])\n\n        logger.debug(\n            f\"Transfer function estimation applied, result shape: {result.shape}\"\n        )\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.name","title":"<code>name = 'transfer_function'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.n_fft","title":"<code>n_fft = n_fft</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.win_length","title":"<code>win_length = actual_win_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.hop_length","title":"<code>hop_length = actual_hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.window","title":"<code>window = window</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.detrend","title":"<code>detrend = detrend</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.scaling","title":"<code>scaling = scaling</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.average","title":"<code>average = average</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.__init__","title":"<code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Initialize transfer function estimation operation</p>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : int     FFT size, default is 2048 hop_length : int, optional     Number of samples between frames. Default is win_length // 4 win_length : int, optional     Window length. Default is n_fft window : str     Window function, default is 'hann' detrend : str     Type of detrend, default is 'constant' scaling : str     Type of scaling, default is 'spectrum' average : str     Method of averaging, default is 'mean'</p>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize transfer function estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Transfer function\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral.TransferFunction.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"H\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.spectral-functions","title":"Functions","text":""},{"location":"api/processing/#_6","title":"\u7d71\u8a08\u51e6\u7406","text":"<p>\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u306e\u7d71\u8a08\u5206\u6790\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#wandas.processing.stats","title":"<code>wandas.processing.stats</code>","text":""},{"location":"api/processing/#wandas.processing.stats-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.stats.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats-classes","title":"Classes","text":""},{"location":"api/processing/#wandas.processing.stats.ABS","title":"<code>ABS</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Absolute value operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ABS(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Absolute value operation\"\"\"\n\n    name = \"abs\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize absolute value operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"abs\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ABS-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.stats.ABS.name","title":"<code>name = 'abs'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.ABS-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.stats.ABS.__init__","title":"<code>__init__(sampling_rate)</code>","text":"<p>Initialize absolute value operation</p>"},{"location":"api/processing/#wandas.processing.stats.ABS.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize absolute value operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ABS.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"abs\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ABS.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Power","title":"<code>Power</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Power operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Power(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Power operation\"\"\"\n\n    name = \"power\"\n\n    def __init__(self, sampling_rate: float, exponent: float):\n        \"\"\"\n        Initialize power operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        exponent : float\n            Power exponent\n        \"\"\"\n        super().__init__(sampling_rate)\n        self.exp = exponent\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"pow\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Power-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.stats.Power.name","title":"<code>name = 'power'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.Power.exp","title":"<code>exp = exponent</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.Power-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.stats.Power.__init__","title":"<code>__init__(sampling_rate, exponent)</code>","text":"<p>Initialize power operation</p>"},{"location":"api/processing/#wandas.processing.stats.Power.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) exponent : float     Power exponent</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, exponent: float):\n    \"\"\"\n    Initialize power operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    exponent : float\n        Power exponent\n    \"\"\"\n    super().__init__(sampling_rate)\n    self.exp = exponent\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Power.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"pow\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Power.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Sum","title":"<code>Sum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Sum calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Sum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Sum calculation\"\"\"\n\n    name = \"sum\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"sum\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Sum-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.stats.Sum.name","title":"<code>name = 'sum'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.Sum-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.stats.Sum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"sum\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Sum.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Mean","title":"<code>Mean</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Mean calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Mean(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Mean calculation\"\"\"\n\n    name = \"mean\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"mean\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Mean-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.stats.Mean.name","title":"<code>name = 'mean'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.Mean-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.stats.Mean.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"mean\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.Mean.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ChannelDifference","title":"<code>ChannelDifference</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Channel difference calculation operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ChannelDifference(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Channel difference calculation operation\"\"\"\n\n    name = \"channel_difference\"\n    other_channel: int\n\n    def __init__(self, sampling_rate: float, other_channel: int = 0):\n        \"\"\"\n        Initialize channel difference calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other_channel : int\n            Channel to calculate difference with, default is 0\n        \"\"\"\n        self.other_channel = other_channel\n        super().__init__(sampling_rate, other_channel=other_channel)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"diff\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        result = data - data[self.other_channel]\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ChannelDifference-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.stats.ChannelDifference.name","title":"<code>name = 'channel_difference'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.ChannelDifference.other_channel","title":"<code>other_channel = other_channel</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.stats.ChannelDifference-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.stats.ChannelDifference.__init__","title":"<code>__init__(sampling_rate, other_channel=0)</code>","text":"<p>Initialize channel difference calculation</p>"},{"location":"api/processing/#wandas.processing.stats.ChannelDifference.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other_channel : int     Channel to calculate difference with, default is 0</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, other_channel: int = 0):\n    \"\"\"\n    Initialize channel difference calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other_channel : int\n        Channel to calculate difference with, default is 0\n    \"\"\"\n    self.other_channel = other_channel\n    super().__init__(sampling_rate, other_channel=other_channel)\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ChannelDifference.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"diff\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats.ChannelDifference.process","title":"<code>process(data)</code>","text":"Source code in <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    result = data - data[self.other_channel]\n    return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.stats-functions","title":"Functions","text":""},{"location":"api/processing/#_7","title":"\u6642\u9593\u9818\u57df\u51e6\u7406","text":"<p>\u6642\u9593\u9818\u57df\u306e\u51e6\u7406\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/processing/#wandas.processing.temporal","title":"<code>wandas.processing.temporal</code>","text":""},{"location":"api/processing/#wandas.processing.temporal-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.temporal.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal-classes","title":"Classes","text":""},{"location":"api/processing/#wandas.processing.temporal.ReSampling","title":"<code>ReSampling</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Resampling operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class ReSampling(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Resampling operation\"\"\"\n\n    name = \"resampling\"\n\n    def __init__(self, sampling_rate: float, target_sr: float):\n        \"\"\"\n        Initialize resampling operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        target_sampling_rate : float\n            Target sampling rate (Hz)\n\n        Raises\n        ------\n        ValueError\n            If sampling_rate or target_sr is not positive\n        \"\"\"\n        validate_sampling_rate(sampling_rate, \"source sampling rate\")\n        validate_sampling_rate(target_sr, \"target sampling rate\")\n        super().__init__(sampling_rate, target_sr=target_sr)\n        self.target_sr = target_sr\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate to target sampling rate.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        Resampling always produces output at target_sr, regardless of input\n        sampling rate. All necessary parameters are provided at initialization.\n        \"\"\"\n        return {\"sampling_rate\": self.target_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after resampling\n        ratio = float(self.target_sr) / float(self.sampling_rate)\n        n_samples = int(np.ceil(input_shape[-1] * ratio))\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"rs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for resampling operation\"\"\"\n        logger.debug(f\"Applying resampling to array with shape: {x.shape}\")\n        result: NDArrayReal = librosa.resample(\n            x, orig_sr=self.sampling_rate, target_sr=self.target_sr\n        )\n        logger.debug(f\"Resampling applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.temporal.ReSampling.name","title":"<code>name = 'resampling'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.ReSampling.target_sr","title":"<code>target_sr = target_sr</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.ReSampling-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.temporal.ReSampling.__init__","title":"<code>__init__(sampling_rate, target_sr)</code>","text":"<p>Initialize resampling operation</p>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) target_sampling_rate : float     Target sampling rate (Hz)</p>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.__init__--raises","title":"Raises","text":"<p>ValueError     If sampling_rate or target_sr is not positive</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(self, sampling_rate: float, target_sr: float):\n    \"\"\"\n    Initialize resampling operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    target_sampling_rate : float\n        Target sampling rate (Hz)\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate or target_sr is not positive\n    \"\"\"\n    validate_sampling_rate(sampling_rate, \"source sampling rate\")\n    validate_sampling_rate(target_sr, \"target sampling rate\")\n    super().__init__(sampling_rate, target_sr=target_sr)\n    self.target_sr = target_sr\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Update sampling rate to target sampling rate.</p>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate</p>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.get_metadata_updates--notes","title":"Notes","text":"<p>Resampling always produces output at target_sr, regardless of input sampling rate. All necessary parameters are provided at initialization.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate to target sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    Resampling always produces output at target_sr, regardless of input\n    sampling rate. All necessary parameters are provided at initialization.\n    \"\"\"\n    return {\"sampling_rate\": self.target_sr}\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after resampling\n    ratio = float(self.target_sr) / float(self.sampling_rate)\n    n_samples = int(np.ceil(input_shape[-1] * ratio))\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.ReSampling.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"rs\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.Trim","title":"<code>Trim</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Trimming operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class Trim(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Trimming operation\"\"\"\n\n    name = \"trim\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        start: float,\n        end: float,\n    ):\n        \"\"\"\n        Initialize trimming operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        start : float\n            Start time for trimming (seconds)\n        end : float\n            End time for trimming (seconds)\n        \"\"\"\n        super().__init__(sampling_rate, start=start, end=end)\n        self.start = start\n        self.end = end\n        self.start_sample = int(start * sampling_rate)\n        self.end_sample = int(end * sampling_rate)\n        logger.debug(\n            f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after trimming\n        # Exclude parts where there is no signal\n        end_sample = min(self.end_sample, input_shape[-1])\n        n_samples = end_sample - self.start_sample\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"trim\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for trimming operation\"\"\"\n        logger.debug(f\"Applying trim to array with shape: {x.shape}\")\n        # Apply trimming\n        result = x[..., self.start_sample : self.end_sample]\n        logger.debug(f\"Trim applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.Trim-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim.name","title":"<code>name = 'trim'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim.start","title":"<code>start = start</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim.end","title":"<code>end = end</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim.start_sample","title":"<code>start_sample = int(start * sampling_rate)</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim.end_sample","title":"<code>end_sample = int(end * sampling_rate)</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.temporal.Trim.__init__","title":"<code>__init__(sampling_rate, start, end)</code>","text":"<p>Initialize trimming operation</p>"},{"location":"api/processing/#wandas.processing.temporal.Trim.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) start : float     Start time for trimming (seconds) end : float     End time for trimming (seconds)</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    start: float,\n    end: float,\n):\n    \"\"\"\n    Initialize trimming operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    start : float\n        Start time for trimming (seconds)\n    end : float\n        End time for trimming (seconds)\n    \"\"\"\n    super().__init__(sampling_rate, start=start, end=end)\n    self.start = start\n    self.end = end\n    self.start_sample = int(start * sampling_rate)\n    self.end_sample = int(end * sampling_rate)\n    logger.debug(\n        f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.Trim.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.temporal.Trim.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.temporal.Trim.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after trimming\n    # Exclude parts where there is no signal\n    end_sample = min(self.end_sample, input_shape[-1])\n    n_samples = end_sample - self.start_sample\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.Trim.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"trim\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.FixLength","title":"<code>FixLength</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>\u4fe1\u53f7\u306e\u9577\u3055\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u8abf\u6574\u3059\u308b\u64cd\u4f5c</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class FixLength(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\u4fe1\u53f7\u306e\u9577\u3055\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u8abf\u6574\u3059\u308b\u64cd\u4f5c\"\"\"\n\n    name = \"fix_length\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        length: int | None = None,\n        duration: float | None = None,\n    ):\n        \"\"\"\n        Initialize fix length operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        length : Optional[int]\n            Target length for fixing\n        duration : Optional[float]\n            Target length for fixing\n        \"\"\"\n        if length is None:\n            if duration is None:\n                raise ValueError(\"Either length or duration must be provided.\")\n            else:\n                length = int(duration * sampling_rate)\n        self.target_length = length\n\n        super().__init__(sampling_rate, target_length=self.target_length)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        return (*input_shape[:-1], self.target_length)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"fix\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for padding operation\"\"\"\n        logger.debug(f\"Applying padding to array with shape: {x.shape}\")\n        # Apply padding\n        pad_width = self.target_length - x.shape[-1]\n        if pad_width &gt; 0:\n            result = np.pad(x, ((0, 0), (0, pad_width)), mode=\"constant\")\n        else:\n            result = x[..., : self.target_length]\n        logger.debug(f\"Padding applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.FixLength-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.temporal.FixLength.name","title":"<code>name = 'fix_length'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.FixLength.target_length","title":"<code>target_length = length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.FixLength-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.temporal.FixLength.__init__","title":"<code>__init__(sampling_rate, length=None, duration=None)</code>","text":"<p>Initialize fix length operation</p>"},{"location":"api/processing/#wandas.processing.temporal.FixLength.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) length : Optional[int]     Target length for fixing duration : Optional[float]     Target length for fixing</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    length: int | None = None,\n    duration: float | None = None,\n):\n    \"\"\"\n    Initialize fix length operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    length : Optional[int]\n        Target length for fixing\n    duration : Optional[float]\n        Target length for fixing\n    \"\"\"\n    if length is None:\n        if duration is None:\n            raise ValueError(\"Either length or duration must be provided.\")\n        else:\n            length = int(duration * sampling_rate)\n    self.target_length = length\n\n    super().__init__(sampling_rate, target_length=self.target_length)\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.FixLength.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.temporal.FixLength.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape</p>"},{"location":"api/processing/#wandas.processing.temporal.FixLength.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    return (*input_shape[:-1], self.target_length)\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.FixLength.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fix\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend","title":"<code>RmsTrend</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class RmsTrend(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"RMS calculation\"\"\"\n\n    name = \"rms_trend\"\n    frame_length: int\n    hop_length: int\n    Aw: bool\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        ref: list[float] | float = 1.0,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; None:\n        \"\"\"\n        Initialize RMS calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        frame_length : int\n            Frame length, default is 2048\n        hop_length : int\n            Hop length, default is 512\n        ref : Union[list[float], float]\n            Reference value(s) for dB calculation\n        dB : bool\n            Whether to convert to decibels\n        Aw : bool\n            Whether to apply A-weighting before RMS calculation\n        \"\"\"\n        self.frame_length = frame_length\n        self.hop_length = hop_length\n        self.dB = dB\n        self.Aw = Aw\n        self.ref = np.array(ref if isinstance(ref, list) else [ref])\n        super().__init__(\n            sampling_rate,\n            frame_length=frame_length,\n            hop_length=hop_length,\n            dB=dB,\n            Aw=Aw,\n            ref=self.ref,\n        )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on hop length.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate based on hop length\n\n        Notes\n        -----\n        The output sampling rate is determined by downsampling the input\n        by hop_length. All necessary parameters are provided at initialization.\n        \"\"\"\n        new_sr = self.sampling_rate / self.hop_length\n        return {\"sampling_rate\": new_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, frames)\n        \"\"\"\n        n_frames = librosa.feature.rms(\n            y=np.ones((1, input_shape[-1])),\n            frame_length=self.frame_length,\n            hop_length=self.hop_length,\n        ).shape[-1]\n        return (*input_shape[:-1], n_frames)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"RMS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for RMS calculation\"\"\"\n        logger.debug(f\"Applying RMS to array with shape: {x.shape}\")\n\n        if self.Aw:\n            # Apply A-weighting\n            _x = A_weight(x, self.sampling_rate)\n            if isinstance(_x, np.ndarray):\n                # A_weight\u304c\u30bf\u30d7\u30eb\u3092\u8fd4\u3059\u5834\u5408\u3001\u6700\u521d\u306e\u8981\u7d20\u3092\u4f7f\u7528\n                x = _x\n            elif isinstance(_x, tuple):\n                # Use the first element if A_weight returns a tuple\n                x = _x[0]\n            else:\n                raise ValueError(\"A_weighting returned an unexpected type.\")\n\n        # Calculate RMS\n        result: NDArrayReal = librosa.feature.rms(\n            y=x, frame_length=self.frame_length, hop_length=self.hop_length\n        )[..., 0, :]\n\n        if self.dB:\n            # Convert to dB\n            result = 20 * np.log10(\n                np.maximum(result / self.ref[..., np.newaxis], 1e-12)\n            )\n        #\n        logger.debug(f\"RMS applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend-attributes","title":"Attributes","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.name","title":"<code>name = 'rms_trend'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.frame_length","title":"<code>frame_length = frame_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.hop_length","title":"<code>hop_length = hop_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.dB","title":"<code>dB = dB</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.Aw","title":"<code>Aw = Aw</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.ref","title":"<code>ref = np.array(ref if isinstance(ref, list) else [ref])</code>  <code>instance-attribute</code>","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend-functions","title":"Functions","text":""},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.__init__","title":"<code>__init__(sampling_rate, frame_length=2048, hop_length=512, ref=1.0, dB=False, Aw=False)</code>","text":"<p>Initialize RMS calculation</p>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) frame_length : int     Frame length, default is 2048 hop_length : int     Hop length, default is 512 ref : Union[list[float], float]     Reference value(s) for dB calculation dB : bool     Whether to convert to decibels Aw : bool     Whether to apply A-weighting before RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    ref: list[float] | float = 1.0,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; None:\n    \"\"\"\n    Initialize RMS calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    frame_length : int\n        Frame length, default is 2048\n    hop_length : int\n        Hop length, default is 512\n    ref : Union[list[float], float]\n        Reference value(s) for dB calculation\n    dB : bool\n        Whether to convert to decibels\n    Aw : bool\n        Whether to apply A-weighting before RMS calculation\n    \"\"\"\n    self.frame_length = frame_length\n    self.hop_length = hop_length\n    self.dB = dB\n    self.Aw = Aw\n    self.ref = np.array(ref if isinstance(ref, list) else [ref])\n    super().__init__(\n        sampling_rate,\n        frame_length=frame_length,\n        hop_length=hop_length,\n        dB=dB,\n        Aw=Aw,\n        ref=self.ref,\n    )\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.get_metadata_updates","title":"<code>get_metadata_updates()</code>","text":"<p>Update sampling rate based on hop length.</p>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.get_metadata_updates--returns","title":"Returns","text":"<p>dict     Metadata updates with new sampling rate based on hop length</p>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is determined by downsampling the input by hop_length. All necessary parameters are provided at initialization.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on hop length.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate based on hop length\n\n    Notes\n    -----\n    The output sampling rate is determined by downsampling the input\n    by hop_length. All necessary parameters are provided at initialization.\n    \"\"\"\n    new_sr = self.sampling_rate / self.hop_length\n    return {\"sampling_rate\": new_sr}\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"<p>Calculate output data shape after operation</p>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.calculate_output_shape--parameters","title":"Parameters","text":"<p>input_shape : tuple     Input data shape (channels, samples)</p>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, frames)</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, frames)\n    \"\"\"\n    n_frames = librosa.feature.rms(\n        y=np.ones((1, input_shape[-1])),\n        frame_length=self.frame_length,\n        hop_length=self.hop_length,\n    ).shape[-1]\n    return (*input_shape[:-1], n_frames)\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal.RmsTrend.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"RMS\"\n</code></pre>"},{"location":"api/processing/#wandas.processing.temporal-functions","title":"Functions","text":""},{"location":"api/utils/","title":"\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.utils</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u4f7f\u7528\u3055\u308c\u308b\u69d8\u3005\u306a\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/utils/#_2","title":"\u30d5\u30ec\u30fc\u30e0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8","text":"<p>\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u7ba1\u7406\u3059\u308b\u305f\u3081\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/utils/#_3","title":"\u6982\u8981","text":"<p><code>FrameDataset</code> \u30af\u30e9\u30b9\u306f\u3001\u30d5\u30a9\u30eb\u30c0\u5185\u306e\u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u306e\u52b9\u7387\u7684\u306a\u30d0\u30c3\u30c1\u51e6\u7406\u3092\u53ef\u80fd\u306b\u3057\u307e\u3059\u3002\u4e3b\u306a\u6a5f\u80fd\uff1a</p> <ul> <li>\u9045\u5ef6\u8aad\u307f\u8fbc\u307f: \u30a2\u30af\u30bb\u30b9\u6642\u306e\u307f\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u3001\u30e1\u30e2\u30ea\u4f7f\u7528\u91cf\u3092\u524a\u6e1b</li> <li>\u5909\u63db\u306e\u30c1\u30a7\u30fc\u30f3: \u8907\u6570\u306e\u51e6\u7406\u64cd\u4f5c\u3092\u52b9\u7387\u7684\u306b\u9069\u7528</li> <li>\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0: \u30c6\u30b9\u30c8\u3084\u5206\u6790\u306e\u305f\u3081\u306b\u30e9\u30f3\u30c0\u30e0\u306a\u30b5\u30d6\u30bb\u30c3\u30c8\u3092\u62bd\u51fa</li> <li>\u30e1\u30bf\u30c7\u30fc\u30bf\u8ffd\u8de1: \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d7\u30ed\u30d1\u30c6\u30a3\u3068\u51e6\u7406\u5c65\u6b74\u3092\u8a18\u9332</li> </ul>"},{"location":"api/utils/#_4","title":"\u4e3b\u306a\u30af\u30e9\u30b9","text":"<ul> <li><code>ChannelFrameDataset</code>: \u6642\u9593\u9818\u57df\u306e\u97f3\u58f0\u30c7\u30fc\u30bf\u7528\uff08WAV\u3001MP3\u3001FLAC\u3001CSV\u30d5\u30a1\u30a4\u30eb\uff09</li> <li><code>SpectrogramFrameDataset</code>: \u6642\u9593\u5468\u6ce2\u6570\u9818\u57df\u30c7\u30fc\u30bf\u7528\uff08\u901a\u5e38\u306fSTFT\u304b\u3089\u4f5c\u6210\uff09</li> </ul>"},{"location":"api/utils/#_5","title":"\u57fa\u672c\u7684\u306a\u4f7f\u7528\u65b9\u6cd5","text":"<pre><code>from wandas.utils.frame_dataset import ChannelFrameDataset\n\n# \u30d5\u30a9\u30eb\u30c0\u304b\u3089\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\ndataset = ChannelFrameDataset.from_folder(\n    folder_path=\"path/to/audio/files\",\n    sampling_rate=16000,  # \u30aa\u30d7\u30b7\u30e7\u30f3: \u3059\u3079\u3066\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u3053\u306e\u30ec\u30fc\u30c8\u306b\u30ea\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\n    file_extensions=[\".wav\", \".mp3\"],  # \u542b\u3081\u308b\u30d5\u30a1\u30a4\u30eb\u30bf\u30a4\u30d7\n    recursive=True,  # \u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u691c\u7d22\n    lazy_loading=True  # \u30aa\u30f3\u30c7\u30de\u30f3\u30c9\u3067\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\uff08\u63a8\u5968\uff09\n)\n\n# \u500b\u5225\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u30a2\u30af\u30bb\u30b9\nfirst_file = dataset[0]\nprint(f\"\u30d5\u30a1\u30a4\u30eb: {first_file.label}\")\nprint(f\"\u9577\u3055: {first_file.duration}\u79d2\")\n\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u60c5\u5831\u3092\u53d6\u5f97\nmetadata = dataset.get_metadata()\nprint(f\"\u7dcf\u30d5\u30a1\u30a4\u30eb\u6570: {metadata['file_count']}\")\nprint(f\"\u8aad\u307f\u8fbc\u307f\u6e08\u307f\u30d5\u30a1\u30a4\u30eb\u6570: {metadata['loaded_count']}\")\n</code></pre>"},{"location":"api/utils/#_6","title":"\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0","text":"<p>\u30c6\u30b9\u30c8\u3084\u5206\u6790\u306e\u305f\u3081\u306b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u30b5\u30d6\u30bb\u30c3\u30c8\u3092\u62bd\u51fa\uff1a</p> <pre><code># \u30d5\u30a1\u30a4\u30eb\u6570\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\nsampled = dataset.sample(n=10, seed=42)\n\n# \u6bd4\u7387\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\nsampled = dataset.sample(ratio=0.1, seed=42)\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8: 10%\u307e\u305f\u306f\u6700\u5c0f1\u30d5\u30a1\u30a4\u30eb\nsampled = dataset.sample(seed=42)\n</code></pre>"},{"location":"api/utils/#_7","title":"\u5909\u63db","text":"<p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u5185\u306e\u3059\u3079\u3066\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u51e6\u7406\u64cd\u4f5c\u3092\u9069\u7528\uff1a</p> <pre><code># \u7d44\u307f\u8fbc\u307f\u5909\u63db\nresampled = dataset.resample(target_sr=8000)\ntrimmed = dataset.trim(start=0.5, end=2.0)\n\n# \u8907\u6570\u306e\u5909\u63db\u3092\u30c1\u30a7\u30fc\u30f3\nprocessed = (\n    dataset\n    .resample(target_sr=8000)\n    .trim(start=0.5, end=2.0)\n)\n\n# \u30ab\u30b9\u30bf\u30e0\u5909\u63db\ndef custom_filter(frame):\n    return frame.low_pass_filter(cutoff=1000)\n\nfiltered = dataset.apply(custom_filter)\n</code></pre>"},{"location":"api/utils/#stft-","title":"STFT - \u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u751f\u6210","text":"<p>\u6642\u9593\u9818\u57df\u30c7\u30fc\u30bf\u3092\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u5909\u63db\uff1a</p> <pre><code># \u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\nspec_dataset = dataset.stft(\n    n_fft=2048,\n    hop_length=512,\n    window=\"hann\"\n)\n\n# \u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u30a2\u30af\u30bb\u30b9\nspec_frame = spec_dataset[0]\nspec_frame.plot()\n</code></pre>"},{"location":"api/utils/#_8","title":"\u53cd\u5fa9\u51e6\u7406","text":"<p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u5185\u306e\u3059\u3079\u3066\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u51e6\u7406\uff1a</p> <pre><code>for i in range(len(dataset)):\n    frame = dataset[i]\n    if frame is not None:\n        # \u30d5\u30ec\u30fc\u30e0\u3092\u51e6\u7406\n        print(f\"{frame.label} \u3092\u51e6\u7406\u4e2d...\")\n</code></pre>"},{"location":"api/utils/#_9","title":"\u4e3b\u8981\u306a\u30d1\u30e9\u30e1\u30fc\u30bf","text":"<p>folder_path (str): \u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u3092\u542b\u3080\u30d5\u30a9\u30eb\u30c0\u3078\u306e\u30d1\u30b9</p> <p>sampling_rate (Optional[int]): \u76ee\u6a19\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u3002\u3053\u306e\u30ec\u30fc\u30c8\u3068\u7570\u306a\u308b\u5834\u5408\u3001\u30d5\u30a1\u30a4\u30eb\u306f\u30ea\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u307e\u3059</p> <p>file_extensions (Optional[list[str]]): \u542b\u3081\u308b\u30d5\u30a1\u30a4\u30eb\u62e1\u5f35\u5b50\u306e\u30ea\u30b9\u30c8\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: <code>[\".wav\", \".mp3\", \".flac\", \".csv\"]</code></p> <p>lazy_loading (bool): True \u306e\u5834\u5408\u3001\u30a2\u30af\u30bb\u30b9\u6642\u306e\u307f\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: True</p> <p>recursive (bool): True \u306e\u5834\u5408\u3001\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u518d\u5e30\u7684\u306b\u691c\u7d22\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: False</p>"},{"location":"api/utils/#_10","title":"\u4f7f\u7528\u4f8b","text":"<p>\u8a73\u7d30\u306a\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001FrameDataset \u4f7f\u7528\u30ac\u30a4\u30c9 \u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"api/utils/#api","title":"API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9","text":""},{"location":"api/utils/#wandas.utils.frame_dataset","title":"<code>wandas.utils.frame_dataset</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset-attributes","title":"Attributes","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameType","title":"<code>FrameType = ChannelFrame | SpectrogramFrame</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.F","title":"<code>F = TypeVar('F', bound=FrameType)</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.F_out","title":"<code>F_out = TypeVar('F_out', bound=FrameType)</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset-classes","title":"Classes","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame","title":"<code>LazyFrame</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[F]</code></p> <p>A class that encapsulates a frame and its loading state.</p> <p>Attributes:</p> Name Type Description <code>file_path</code> <code>Path</code> <p>File path associated with the frame</p> <code>frame</code> <code>F | None</code> <p>Loaded frame object (None if not loaded)</p> <code>is_loaded</code> <code>bool</code> <p>Flag indicating if the frame is loaded</p> <code>load_attempted</code> <code>bool</code> <p>Flag indicating if loading was attempted (for error detection)</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>@dataclass\nclass LazyFrame(Generic[F]):\n    \"\"\"\n    A class that encapsulates a frame and its loading state.\n\n    Attributes:\n        file_path: File path associated with the frame\n        frame: Loaded frame object (None if not loaded)\n        is_loaded: Flag indicating if the frame is loaded\n        load_attempted: Flag indicating if loading was attempted (for error detection)\n    \"\"\"\n\n    file_path: Path\n    frame: F | None = None\n    is_loaded: bool = False\n    load_attempted: bool = False\n\n    def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n        \"\"\"\n        Ensures the frame is loaded, loading it if necessary.\n\n        Args:\n            loader: Function to load a frame from a file path\n\n        Returns:\n            The loaded frame, or None if loading failed\n        \"\"\"\n        # Return the current frame if already loaded\n        if self.is_loaded:\n            return self.frame\n\n        # Attempt to load if not loaded yet\n        try:\n            self.load_attempted = True\n            self.frame = loader(self.file_path)\n            self.is_loaded = True\n            return self.frame\n        except Exception as e:\n            logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n            self.is_loaded = True  # Loading was attempted\n            self.frame = None\n            return None\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the frame state.\n        \"\"\"\n        self.frame = None\n        self.is_loaded = False\n        self.load_attempted = False\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame-attributes","title":"Attributes","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.file_path","title":"<code>file_path</code>  <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.frame","title":"<code>frame = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.is_loaded","title":"<code>is_loaded = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.load_attempted","title":"<code>load_attempted = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame-functions","title":"Functions","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.__init__","title":"<code>__init__(file_path, frame=None, is_loaded=False, load_attempted=False)</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.ensure_loaded","title":"<code>ensure_loaded(loader)</code>","text":"<p>Ensures the frame is loaded, loading it if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>loader</code> <code>Callable[[Path], F | None]</code> <p>Function to load a frame from a file path</p> required <p>Returns:</p> Type Description <code>F | None</code> <p>The loaded frame, or None if loading failed</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n    \"\"\"\n    Ensures the frame is loaded, loading it if necessary.\n\n    Args:\n        loader: Function to load a frame from a file path\n\n    Returns:\n        The loaded frame, or None if loading failed\n    \"\"\"\n    # Return the current frame if already loaded\n    if self.is_loaded:\n        return self.frame\n\n    # Attempt to load if not loaded yet\n    try:\n        self.load_attempted = True\n        self.frame = loader(self.file_path)\n        self.is_loaded = True\n        return self.frame\n    except Exception as e:\n        logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n        self.is_loaded = True  # Loading was attempted\n        self.frame = None\n        return None\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.LazyFrame.reset","title":"<code>reset()</code>","text":"<p>Reset the frame state.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the frame state.\n    \"\"\"\n    self.frame = None\n    self.is_loaded = False\n    self.load_attempted = False\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset","title":"<code>FrameDataset</code>","text":"<p>               Bases: <code>Generic[F]</code>, <code>ABC</code></p> <p>Abstract base dataset class for processing files in a folder. Includes lazy loading capability to efficiently handle large datasets. Subclasses handle specific frame types (ChannelFrame, SpectrogramFrame, etc.).</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class FrameDataset(Generic[F], ABC):\n    \"\"\"\n    Abstract base dataset class for processing files in a folder.\n    Includes lazy loading capability to efficiently handle large datasets.\n    Subclasses handle specific frame types (ChannelFrame, SpectrogramFrame, etc.).\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], F | None] | None = None,\n    ):\n        self.folder_path = Path(folder_path)\n        if source_dataset is None and not self.folder_path.exists():\n            raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n        self.sampling_rate = sampling_rate\n        self.signal_length = signal_length\n        self.file_extensions = file_extensions or [\".wav\"]\n        self._recursive = recursive\n        self._lazy_loading = lazy_loading\n\n        # Changed to a list of LazyFrame\n        self._lazy_frames: list[LazyFrame[F]] = []\n\n        self._source_dataset = source_dataset\n        self._transform = transform\n\n        if self._source_dataset:\n            self._initialize_from_source()\n        else:\n            self._initialize_from_folder()\n\n    def _initialize_from_source(self) -&gt; None:\n        \"\"\"Initialize from a source dataset.\"\"\"\n        if self._source_dataset is None:\n            return\n\n        # Copy file paths from source\n        file_paths = self._source_dataset._get_file_paths()\n        self._lazy_frames = [LazyFrame(file_path) for file_path in file_paths]\n\n        # Inherit other properties\n        self.sampling_rate = self.sampling_rate or self._source_dataset.sampling_rate\n        self.signal_length = self.signal_length or self._source_dataset.signal_length\n        self.file_extensions = (\n            self.file_extensions or self._source_dataset.file_extensions\n        )\n        self._recursive = self._source_dataset._recursive\n        self.folder_path = self._source_dataset.folder_path\n\n    def _initialize_from_folder(self) -&gt; None:\n        \"\"\"Initialize from a folder.\"\"\"\n        self._discover_files()\n        if not self._lazy_loading:\n            self._load_all_files()\n\n    def _discover_files(self) -&gt; None:\n        \"\"\"Discover files in the folder and store them in a list of LazyFrame.\"\"\"\n        file_paths = []\n        for ext in self.file_extensions:\n            pattern = f\"**/*{ext}\" if self._recursive else f\"*{ext}\"\n            file_paths.extend(\n                sorted(p for p in self.folder_path.glob(pattern) if p.is_file())\n            )\n\n        # Remove duplicates and sort\n        file_paths = sorted(list(set(file_paths)))\n\n        # Create a list of LazyFrame\n        self._lazy_frames = [LazyFrame(file_path) for file_path in file_paths]\n\n    def _load_all_files(self) -&gt; None:\n        \"\"\"Load all files.\"\"\"\n        for i in tqdm(range(len(self._lazy_frames)), desc=\"Loading/transforming\"):\n            try:\n                self._ensure_loaded(i)\n            except Exception as e:\n                filepath = self._lazy_frames[i].file_path\n                logger.warning(\n                    f\"Failed to load/transform index {i} ({filepath}): {str(e)}\"\n                )\n        self._lazy_loading = False\n\n    @abstractmethod\n    def _load_file(self, file_path: Path) -&gt; F | None:\n        \"\"\"Abstract method to load a frame from a file.\"\"\"\n        pass\n\n    def _load_from_source(self, index: int) -&gt; F | None:\n        \"\"\"Load a frame from the source dataset and transform it if necessary.\"\"\"\n        if self._source_dataset is None or self._transform is None:\n            return None\n\n        source_frame = self._source_dataset._ensure_loaded(index)\n        if source_frame is None:\n            return None\n\n        try:\n            return self._transform(source_frame)\n        except Exception as e:\n            logger.warning(f\"Failed to transform index {index}: {str(e)}\")\n            return None\n\n    def _ensure_loaded(self, index: int) -&gt; F | None:\n        \"\"\"Ensure the frame at the given index is loaded.\"\"\"\n        if not (0 &lt;= index &lt; len(self._lazy_frames)):\n            raise IndexError(\n                f\"Index {index} is out of range (0-{len(self._lazy_frames) - 1})\"\n            )\n\n        lazy_frame = self._lazy_frames[index]\n\n        # Return if already loaded\n        if lazy_frame.is_loaded:\n            return lazy_frame.frame\n\n        try:\n            # Convert from source dataset\n            if self._transform and self._source_dataset:\n                lazy_frame.load_attempted = True\n                frame = self._load_from_source(index)\n                lazy_frame.frame = frame\n                lazy_frame.is_loaded = True\n                return frame\n            # Load directly from file\n            else:\n                return lazy_frame.ensure_loaded(self._load_file)\n        except Exception as e:\n            f_path = lazy_frame.file_path\n            logger.error(\n                f\"Failed to load or initialize index {index} ({f_path}): {str(e)}\"\n            )\n            lazy_frame.frame = None\n            lazy_frame.is_loaded = True\n            lazy_frame.load_attempted = True\n            return None\n\n    def _get_file_paths(self) -&gt; list[Path]:\n        \"\"\"Get a list of file paths.\"\"\"\n        return [lazy_frame.file_path for lazy_frame in self._lazy_frames]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of files in the dataset.\"\"\"\n        return len(self._lazy_frames)\n\n    def get_by_label(self, label: str) -&gt; F | None:\n        \"\"\"\n        Get a frame by its label (filename).\n\n        Parameters\n        ----------\n        label : str\n            The filename (label) to search for (e.g., 'sample_1.wav').\n\n        Returns\n        -------\n        Optional[F]\n            The frame if found, otherwise None.\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n        &gt;&gt;&gt; if frame:\n        ...     print(frame.label)\n        \"\"\"\n        # Keep for backward compatibility: return the first match but emit\n        # a DeprecationWarning recommending `get_all_by_label`.\n        all_matches = self.get_all_by_label(label)\n        if len(all_matches) &gt; 0:\n            warnings.warn(\n                \"get_by_label() returns the first matching frame and is deprecated; \"\n                \"use get_all_by_label() to obtain all matches.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return all_matches[0]\n        return None\n\n    def get_all_by_label(self, label: str) -&gt; list[F]:\n        \"\"\"\n        Get all frames matching the given label (filename).\n\n        Parameters\n        ----------\n        label : str\n            The filename (label) to search for (e.g., 'sample_1.wav').\n\n        Returns\n        -------\n        list[F]\n            A list of frames matching the label.\n            If none are found, returns an empty list.\n\n        Notes\n        -----\n        - Search is performed against the filename portion only (i.e. Path.name).\n        - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n        \"\"\"\n        matches: list[F] = []\n        for i, lazy_frame in enumerate(self._lazy_frames):\n            if lazy_frame.file_path.name == label:\n                loaded = self._ensure_loaded(i)\n                if loaded is not None:\n                    matches.append(loaded)\n        return matches\n\n    @overload\n    def __getitem__(self, key: int) -&gt; F | None: ...\n\n    @overload\n    def __getitem__(self, key: str) -&gt; list[F]: ...\n\n    def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n        \"\"\"\n        Get the frame by index (int) or label (str).\n\n        Parameters\n        ----------\n        key : int or str\n            Index (int) or filename/label (str).\n\n        Returns\n        -------\n        Optional[F] or list[F]\n            If `key` is an int, returns the frame or None. If `key` is a str,\n            returns a list of matching frames (may be empty).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame = dataset[0]  # by index\n        &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n        \"\"\"\n        if isinstance(key, int):\n            return self._ensure_loaded(key)\n        if isinstance(key, str):\n            # pandas-like behaviour: return all matches for the label as a list\n            return self.get_all_by_label(key)\n        raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n\n    @overload\n    def apply(self, func: Callable[[F], F_out | None]) -&gt; \"FrameDataset[F_out]\": ...\n\n    @overload\n    def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\": ...\n\n    def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n        \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n        new_dataset = type(self)(\n            folder_path=str(self.folder_path),\n            lazy_loading=True,\n            source_dataset=self,\n            transform=func,\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            recursive=self._recursive,\n        )\n        return cast(\"FrameDataset[Any]\", new_dataset)\n\n    def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n        \"\"\"Save processed frames to files.\"\"\"\n        raise NotImplementedError(\"The save method is not currently implemented.\")\n\n    def sample(\n        self,\n        n: int | None = None,\n        ratio: float | None = None,\n        seed: int | None = None,\n    ) -&gt; \"FrameDataset[F]\":\n        \"\"\"Get a sample from the dataset.\"\"\"\n        if seed is not None:\n            random.seed(seed)\n\n        total = len(self._lazy_frames)\n        if total == 0:\n            return type(self)(\n                str(self.folder_path),\n                sampling_rate=self.sampling_rate,\n                signal_length=self.signal_length,\n                file_extensions=self.file_extensions,\n                lazy_loading=self._lazy_loading,\n                recursive=self._recursive,\n            )\n\n        # Determine sample size\n        if n is None and ratio is None:\n            n = max(1, min(10, int(total * 0.1)))\n        elif n is None and ratio is not None:\n            n = max(1, int(total * ratio))\n        elif n is not None:\n            n = max(1, n)\n        else:\n            n = 1\n\n        n = min(n, total)\n\n        # Randomly select indices\n        sampled_indices = sorted(random.sample(range(total), n))\n\n        return _SampledFrameDataset(self, sampled_indices)\n\n    def get_metadata(self) -&gt; dict[str, Any]:\n        \"\"\"Get metadata for the dataset.\"\"\"\n        actual_sr: int | float | None = self.sampling_rate\n        frame_type_name = \"Unknown\"\n\n        # Count loaded frames\n        loaded_count = sum(\n            1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n        )\n\n        # Get metadata from the first frame (if possible)\n        first_frame: F | None = None\n        if len(self._lazy_frames) &gt; 0:\n            try:\n                if self._lazy_frames[0].is_loaded:\n                    first_frame = self._lazy_frames[0].frame\n\n                if first_frame:\n                    actual_sr = getattr(\n                        first_frame, \"sampling_rate\", self.sampling_rate\n                    )\n                    frame_type_name = type(first_frame).__name__\n            except Exception as e:\n                logger.warning(\n                    f\"Error accessing the first frame during metadata retrieval: {e}\"\n                )\n\n        return {\n            \"folder_path\": str(self.folder_path),\n            \"file_count\": len(self._lazy_frames),\n            \"loaded_count\": loaded_count,\n            \"target_sampling_rate\": self.sampling_rate,\n            \"actual_sampling_rate\": actual_sr,\n            \"signal_length\": self.signal_length,\n            \"file_extensions\": self.file_extensions,\n            \"lazy_loading\": self._lazy_loading,\n            \"recursive\": self._recursive,\n            \"frame_type\": frame_type_name,\n            \"has_transform\": self._transform is not None,\n            \"is_sampled\": isinstance(self, _SampledFrameDataset),\n        }\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset-attributes","title":"Attributes","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.folder_path","title":"<code>folder_path = Path(folder_path)</code>  <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.sampling_rate","title":"<code>sampling_rate = sampling_rate</code>  <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.signal_length","title":"<code>signal_length = signal_length</code>  <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.file_extensions","title":"<code>file_extensions = file_extensions or ['.wav']</code>  <code>instance-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset-functions","title":"Functions","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.__init__","title":"<code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code>","text":"Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], F | None] | None = None,\n):\n    self.folder_path = Path(folder_path)\n    if source_dataset is None and not self.folder_path.exists():\n        raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n    self.sampling_rate = sampling_rate\n    self.signal_length = signal_length\n    self.file_extensions = file_extensions or [\".wav\"]\n    self._recursive = recursive\n    self._lazy_loading = lazy_loading\n\n    # Changed to a list of LazyFrame\n    self._lazy_frames: list[LazyFrame[F]] = []\n\n    self._source_dataset = source_dataset\n    self._transform = transform\n\n    if self._source_dataset:\n        self._initialize_from_source()\n    else:\n        self._initialize_from_folder()\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of files in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of files in the dataset.\"\"\"\n    return len(self._lazy_frames)\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_by_label","title":"<code>get_by_label(label)</code>","text":"<p>Get a frame by its label (filename).</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_by_label--parameters","title":"Parameters","text":"<p>label : str     The filename (label) to search for (e.g., 'sample_1.wav').</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_by_label--returns","title":"Returns","text":"<p>Optional[F]     The frame if found, otherwise None.</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_by_label--examples","title":"Examples","text":"<p>frame = dataset.get_by_label(\"sample_1.wav\") if frame: ...     print(frame.label)</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_by_label(self, label: str) -&gt; F | None:\n    \"\"\"\n    Get a frame by its label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    Optional[F]\n        The frame if found, otherwise None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n    &gt;&gt;&gt; if frame:\n    ...     print(frame.label)\n    \"\"\"\n    # Keep for backward compatibility: return the first match but emit\n    # a DeprecationWarning recommending `get_all_by_label`.\n    all_matches = self.get_all_by_label(label)\n    if len(all_matches) &gt; 0:\n        warnings.warn(\n            \"get_by_label() returns the first matching frame and is deprecated; \"\n            \"use get_all_by_label() to obtain all matches.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return all_matches[0]\n    return None\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label","title":"<code>get_all_by_label(label)</code>","text":"<p>Get all frames matching the given label (filename).</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--parameters","title":"Parameters","text":"<p>label : str     The filename (label) to search for (e.g., 'sample_1.wav').</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--returns","title":"Returns","text":"<p>list[F]     A list of frames matching the label.     If none are found, returns an empty list.</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--notes","title":"Notes","text":"<ul> <li>Search is performed against the filename portion only (i.e. Path.name).</li> <li>Each matched frame will be loaded (triggering lazy load) via <code>_ensure_loaded</code>.</li> </ul> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_all_by_label(self, label: str) -&gt; list[F]:\n    \"\"\"\n    Get all frames matching the given label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    list[F]\n        A list of frames matching the label.\n        If none are found, returns an empty list.\n\n    Notes\n    -----\n    - Search is performed against the filename portion only (i.e. Path.name).\n    - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n    \"\"\"\n    matches: list[F] = []\n    for i, lazy_frame in enumerate(self._lazy_frames):\n        if lazy_frame.file_path.name == label:\n            loaded = self._ensure_loaded(i)\n            if loaded is not None:\n                matches.append(loaded)\n    return matches\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.__getitem__","title":"<code>__getitem__(key)</code>","text":"<pre><code>__getitem__(key: int) -&gt; F | None\n</code></pre><pre><code>__getitem__(key: str) -&gt; list[F]\n</code></pre> <p>Get the frame by index (int) or label (str).</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.__getitem__--parameters","title":"Parameters","text":"<p>key : int or str     Index (int) or filename/label (str).</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.__getitem__--returns","title":"Returns","text":"<p>Optional[F] or list[F]     If <code>key</code> is an int, returns the frame or None. If <code>key</code> is a str,     returns a list of matching frames (may be empty).</p>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.__getitem__--examples","title":"Examples","text":"<p>frame = dataset[0]  # by index frames = dataset[\"sample_1.wav\"]  # list of matches by filename</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n    \"\"\"\n    Get the frame by index (int) or label (str).\n\n    Parameters\n    ----------\n    key : int or str\n        Index (int) or filename/label (str).\n\n    Returns\n    -------\n    Optional[F] or list[F]\n        If `key` is an int, returns the frame or None. If `key` is a str,\n        returns a list of matching frames (may be empty).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset[0]  # by index\n    &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n    \"\"\"\n    if isinstance(key, int):\n        return self._ensure_loaded(key)\n    if isinstance(key, str):\n        # pandas-like behaviour: return all matches for the label as a list\n        return self.get_all_by_label(key)\n    raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.apply","title":"<code>apply(func)</code>","text":"<pre><code>apply(func: Callable[[F], F_out | None]) -&gt; FrameDataset[F_out]\n</code></pre><pre><code>apply(func: Callable[[F], Any | None]) -&gt; FrameDataset[Any]\n</code></pre> <p>Apply a function to the entire dataset to create a new dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n    \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n    new_dataset = type(self)(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=func,\n        sampling_rate=self.sampling_rate,\n        signal_length=self.signal_length,\n        file_extensions=self.file_extensions,\n        recursive=self._recursive,\n    )\n    return cast(\"FrameDataset[Any]\", new_dataset)\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.save","title":"<code>save(output_folder, filename_prefix='')</code>","text":"<p>Save processed frames to files.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n    \"\"\"Save processed frames to files.\"\"\"\n    raise NotImplementedError(\"The save method is not currently implemented.\")\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.sample","title":"<code>sample(n=None, ratio=None, seed=None)</code>","text":"<p>Get a sample from the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def sample(\n    self,\n    n: int | None = None,\n    ratio: float | None = None,\n    seed: int | None = None,\n) -&gt; \"FrameDataset[F]\":\n    \"\"\"Get a sample from the dataset.\"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    total = len(self._lazy_frames)\n    if total == 0:\n        return type(self)(\n            str(self.folder_path),\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            lazy_loading=self._lazy_loading,\n            recursive=self._recursive,\n        )\n\n    # Determine sample size\n    if n is None and ratio is None:\n        n = max(1, min(10, int(total * 0.1)))\n    elif n is None and ratio is not None:\n        n = max(1, int(total * ratio))\n    elif n is not None:\n        n = max(1, n)\n    else:\n        n = 1\n\n    n = min(n, total)\n\n    # Randomly select indices\n    sampled_indices = sorted(random.sample(range(total), n))\n\n    return _SampledFrameDataset(self, sampled_indices)\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.FrameDataset.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Get metadata for the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_metadata(self) -&gt; dict[str, Any]:\n    \"\"\"Get metadata for the dataset.\"\"\"\n    actual_sr: int | float | None = self.sampling_rate\n    frame_type_name = \"Unknown\"\n\n    # Count loaded frames\n    loaded_count = sum(\n        1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n    )\n\n    # Get metadata from the first frame (if possible)\n    first_frame: F | None = None\n    if len(self._lazy_frames) &gt; 0:\n        try:\n            if self._lazy_frames[0].is_loaded:\n                first_frame = self._lazy_frames[0].frame\n\n            if first_frame:\n                actual_sr = getattr(\n                    first_frame, \"sampling_rate\", self.sampling_rate\n                )\n                frame_type_name = type(first_frame).__name__\n        except Exception as e:\n            logger.warning(\n                f\"Error accessing the first frame during metadata retrieval: {e}\"\n            )\n\n    return {\n        \"folder_path\": str(self.folder_path),\n        \"file_count\": len(self._lazy_frames),\n        \"loaded_count\": loaded_count,\n        \"target_sampling_rate\": self.sampling_rate,\n        \"actual_sampling_rate\": actual_sr,\n        \"signal_length\": self.signal_length,\n        \"file_extensions\": self.file_extensions,\n        \"lazy_loading\": self._lazy_loading,\n        \"recursive\": self._recursive,\n        \"frame_type\": frame_type_name,\n        \"has_transform\": self._transform is not None,\n        \"is_sampled\": isinstance(self, _SampledFrameDataset),\n    }\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset","title":"<code>ChannelFrameDataset</code>","text":"<p>               Bases: <code>FrameDataset[ChannelFrame]</code></p> <p>Dataset class for handling audio files as ChannelFrames in a folder.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class ChannelFrameDataset(FrameDataset[ChannelFrame]):\n    \"\"\"\n    Dataset class for handling audio files as ChannelFrames in a folder.\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], ChannelFrame | None] | None = None,\n    ):\n        _file_extensions = file_extensions or [\n            \".wav\",\n            \".mp3\",\n            \".flac\",\n            \".csv\",\n        ]\n\n        super().__init__(\n            folder_path=folder_path,\n            sampling_rate=sampling_rate,\n            signal_length=signal_length,\n            file_extensions=_file_extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n            source_dataset=source_dataset,\n            transform=transform,\n        )\n\n    def _load_file(self, file_path: Path) -&gt; ChannelFrame | None:\n        \"\"\"Load an audio file and return a ChannelFrame.\"\"\"\n        try:\n            frame = ChannelFrame.from_file(file_path)\n            if self.sampling_rate and frame.sampling_rate != self.sampling_rate:\n                logger.info(\n                    f\"Resampling file {file_path.name} ({frame.sampling_rate} Hz) to \"\n                    f\"dataset rate ({self.sampling_rate} Hz).\"\n                )\n                frame = frame.resampling(target_sr=self.sampling_rate)\n            return frame\n        except Exception as e:\n            logger.error(f\"Failed to load or initialize file {file_path}: {str(e)}\")\n            return None\n\n    def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Resample all frames in the dataset.\"\"\"\n\n        def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.resampling(target_sr=target_sr)\n            except Exception as e:\n                logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n                return None\n\n        new_dataset = self.apply(_resample_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Trim all frames in the dataset.\"\"\"\n\n        def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.trim(start=start, end=end)\n            except Exception as e:\n                logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n                return None\n\n        new_dataset = self.apply(_trim_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Normalize all frames in the dataset.\"\"\"\n\n        def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.normalize(**kwargs)\n            except Exception as e:\n                logger.warning(f\"Normalization error ({kwargs}): {e}\")\n                return None\n\n        new_dataset = self.apply(_normalize_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def stft(\n        self,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrameDataset\":\n        \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n        _hop = hop_length or n_fft // 4\n\n        def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.stft(\n                    n_fft=n_fft,\n                    hop_length=_hop,\n                    win_length=win_length,\n                    window=window,\n                )\n            except Exception as e:\n                logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n                return None\n\n        new_dataset = SpectrogramFrameDataset(\n            folder_path=str(self.folder_path),\n            lazy_loading=True,\n            source_dataset=self,\n            transform=_stft_func,\n            sampling_rate=self.sampling_rate,\n        )\n        return new_dataset\n\n    @classmethod\n    def from_folder(\n        cls,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        file_extensions: list[str] | None = None,\n        recursive: bool = False,\n        lazy_loading: bool = True,\n    ) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n        extensions = (\n            file_extensions\n            if file_extensions is not None\n            else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n        )\n\n        return cls(\n            folder_path,\n            sampling_rate=sampling_rate,\n            file_extensions=extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n        )\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset-functions","title":"Functions","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.__init__","title":"<code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code>","text":"Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], ChannelFrame | None] | None = None,\n):\n    _file_extensions = file_extensions or [\n        \".wav\",\n        \".mp3\",\n        \".flac\",\n        \".csv\",\n    ]\n\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=_file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.resample","title":"<code>resample(target_sr)</code>","text":"<p>Resample all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Resample all frames in the dataset.\"\"\"\n\n    def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.resampling(target_sr=target_sr)\n        except Exception as e:\n            logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n            return None\n\n    new_dataset = self.apply(_resample_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.trim","title":"<code>trim(start, end)</code>","text":"<p>Trim all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Trim all frames in the dataset.\"\"\"\n\n    def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.trim(start=start, end=end)\n        except Exception as e:\n            logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n            return None\n\n    new_dataset = self.apply(_trim_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.normalize","title":"<code>normalize(**kwargs)</code>","text":"<p>Normalize all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Normalize all frames in the dataset.\"\"\"\n\n    def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.normalize(**kwargs)\n        except Exception as e:\n            logger.warning(f\"Normalization error ({kwargs}): {e}\")\n            return None\n\n    new_dataset = self.apply(_normalize_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.stft","title":"<code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code>","text":"<p>Apply STFT to all frames in the dataset.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def stft(\n    self,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrameDataset\":\n    \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n    _hop = hop_length or n_fft // 4\n\n    def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.stft(\n                n_fft=n_fft,\n                hop_length=_hop,\n                win_length=win_length,\n                window=window,\n            )\n        except Exception as e:\n            logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n            return None\n\n    new_dataset = SpectrogramFrameDataset(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=_stft_func,\n        sampling_rate=self.sampling_rate,\n    )\n    return new_dataset\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.from_folder","title":"<code>from_folder(folder_path, sampling_rate=None, file_extensions=None, recursive=False, lazy_loading=True)</code>  <code>classmethod</code>","text":"<p>Class method to create a ChannelFrameDataset from a folder.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>@classmethod\ndef from_folder(\n    cls,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    file_extensions: list[str] | None = None,\n    recursive: bool = False,\n    lazy_loading: bool = True,\n) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n    extensions = (\n        file_extensions\n        if file_extensions is not None\n        else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n    )\n\n    return cls(\n        folder_path,\n        sampling_rate=sampling_rate,\n        file_extensions=extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n    )\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.SpectrogramFrameDataset","title":"<code>SpectrogramFrameDataset</code>","text":"<p>               Bases: <code>FrameDataset[SpectrogramFrame]</code></p> <p>Dataset class for handling spectrogram data as SpectrogramFrames. Expected to be generated mainly as a result of ChannelFrameDataset.stft().</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class SpectrogramFrameDataset(FrameDataset[SpectrogramFrame]):\n    \"\"\"\n    Dataset class for handling spectrogram data as SpectrogramFrames.\n    Expected to be generated mainly as a result of ChannelFrameDataset.stft().\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n    ):\n        super().__init__(\n            folder_path=folder_path,\n            sampling_rate=sampling_rate,\n            signal_length=signal_length,\n            file_extensions=file_extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n            source_dataset=source_dataset,\n            transform=transform,\n        )\n\n    def _load_file(self, file_path: Path) -&gt; SpectrogramFrame | None:\n        \"\"\"Direct loading from files is not currently supported.\"\"\"\n        logger.warning(\n            \"No method defined for directly loading SpectrogramFrames. Normally \"\n            \"created from ChannelFrameDataset.stft().\"\n        )\n        raise NotImplementedError(\n            \"No method defined for directly loading SpectrogramFrames\"\n        )\n\n    def plot(self, index: int, **kwargs: Any) -&gt; None:\n        \"\"\"Plot the spectrogram at the specified index.\"\"\"\n        try:\n            frame = self._ensure_loaded(index)\n\n            if frame is None:\n                logger.warning(\n                    f\"Cannot plot index {index} as it failed to load/transform.\"\n                )\n                return\n\n            plot_method = getattr(frame, \"plot\", None)\n            if callable(plot_method):\n                plot_method(**kwargs)\n            else:\n                logger.warning(\n                    f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                    f\"have a plot method implemented.\"\n                )\n        except Exception as e:\n            logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.SpectrogramFrameDataset-functions","title":"Functions","text":""},{"location":"api/utils/#wandas.utils.frame_dataset.SpectrogramFrameDataset.__init__","title":"<code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code>","text":"Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n):\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre>"},{"location":"api/utils/#wandas.utils.frame_dataset.SpectrogramFrameDataset.plot","title":"<code>plot(index, **kwargs)</code>","text":"<p>Plot the spectrogram at the specified index.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>def plot(self, index: int, **kwargs: Any) -&gt; None:\n    \"\"\"Plot the spectrogram at the specified index.\"\"\"\n    try:\n        frame = self._ensure_loaded(index)\n\n        if frame is None:\n            logger.warning(\n                f\"Cannot plot index {index} as it failed to load/transform.\"\n            )\n            return\n\n        plot_method = getattr(frame, \"plot\", None)\n        if callable(plot_method):\n            plot_method(**kwargs)\n        else:\n            logger.warning(\n                f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                f\"have a plot method implemented.\"\n            )\n    except Exception as e:\n        logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre>"},{"location":"api/utils/#_11","title":"\u30b5\u30f3\u30d7\u30eb\u751f\u6210","text":"<p>\u30c6\u30b9\u30c8\u7528\u306e\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3059\u308b\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/utils/#wandas.utils.generate_sample","title":"<code>wandas.utils.generate_sample</code>","text":""},{"location":"api/utils/#wandas.utils.generate_sample-classes","title":"Classes","text":""},{"location":"api/utils/#wandas.utils.generate_sample-functions","title":"Functions","text":""},{"location":"api/utils/#wandas.utils.generate_sample.generate_sin","title":"<code>generate_sin(freqs=1000, sampling_rate=16000, duration=1.0, label=None)</code>","text":"<p>Generate sample sine wave signals.</p>"},{"location":"api/utils/#wandas.utils.generate_sample.generate_sin--parameters","title":"Parameters","text":"<p>freqs : float or list of float, default=1000     Frequency of the sine wave(s) in Hz.     If multiple frequencies are specified, multiple channels will be created. sampling_rate : int, default=16000     Sampling rate in Hz. duration : float, default=1.0     Duration of the signal in seconds. label : str, optional     Label for the entire signal.</p>"},{"location":"api/utils/#wandas.utils.generate_sample.generate_sin--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the sine wave(s).</p> Source code in <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    # \u76f4\u63a5\u3001generate_sin_lazy\u95a2\u6570\u3092\u547c\u3073\u51fa\u3059\n    return generate_sin_lazy(\n        freqs=freqs, sampling_rate=sampling_rate, duration=duration, label=label\n    )\n</code></pre>"},{"location":"api/utils/#wandas.utils.generate_sample.generate_sin_lazy","title":"<code>generate_sin_lazy(freqs=1000, sampling_rate=16000, duration=1.0, label=None)</code>","text":"<p>Generate sample sine wave signals using lazy computation.</p>"},{"location":"api/utils/#wandas.utils.generate_sample.generate_sin_lazy--parameters","title":"Parameters","text":"<p>freqs : float or list of float, default=1000     Frequency of the sine wave(s) in Hz.     If multiple frequencies are specified, multiple channels will be created. sampling_rate : int, default=16000     Sampling rate in Hz. duration : float, default=1.0     Duration of the signal in seconds. label : str, optional     Label for the entire signal.</p>"},{"location":"api/utils/#wandas.utils.generate_sample.generate_sin_lazy--returns","title":"Returns","text":"<p>ChannelFrame     Lazy ChannelFrame object containing the sine wave(s).</p> Source code in <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin_lazy(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals using lazy computation.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        Lazy ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    label = label or \"Generated Sin\"\n    t = np.linspace(0, duration, int(sampling_rate * duration), endpoint=False)\n\n    _freqs: list[float]\n    if isinstance(freqs, float):\n        _freqs = [freqs]\n    elif isinstance(freqs, list):\n        _freqs = freqs\n    else:\n        raise ValueError(\"freqs must be a float or a list of floats.\")\n\n    channels = []\n    labels = []\n    for idx, freq in enumerate(_freqs):\n        data = np.sin(2 * np.pi * freq * t)\n        labels.append(f\"Channel {idx + 1}\")\n        channels.append(data)\n    return ChannelFrame.from_numpy(\n        data=np.array(channels),\n        label=label,\n        sampling_rate=sampling_rate,\n        ch_labels=labels,\n    )\n</code></pre>"},{"location":"api/utils/#_12","title":"\u578b\u5b9a\u7fa9","text":"<p>Wandas\u3067\u4f7f\u7528\u3055\u308c\u308b\u578b\u5b9a\u7fa9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/utils/#wandas.utils.types","title":"<code>wandas.utils.types</code>","text":""},{"location":"api/utils/#wandas.utils.types-attributes","title":"Attributes","text":""},{"location":"api/utils/#wandas.utils.types.Real","title":"<code>Real = np.number[Any]</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.types.Complex","title":"<code>Complex = np.complexfloating[Any, Any]</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.types.NDArrayReal","title":"<code>NDArrayReal = npt.NDArray[Real]</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#wandas.utils.types.NDArrayComplex","title":"<code>NDArrayComplex = npt.NDArray[Complex]</code>  <code>module-attribute</code>","text":""},{"location":"api/utils/#_13","title":"\u4e00\u822c\u7684\u306a\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3","text":"<p>\u305d\u306e\u4ed6\u306e\u4e00\u822c\u7684\u306a\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/utils/#wandas.utils.util","title":"<code>wandas.utils.util</code>","text":""},{"location":"api/utils/#wandas.utils.util-attributes","title":"Attributes","text":""},{"location":"api/utils/#wandas.utils.util-functions","title":"Functions","text":""},{"location":"api/utils/#wandas.utils.util.validate_sampling_rate","title":"<code>validate_sampling_rate(sampling_rate, param_name='sampling_rate')</code>","text":"<p>Validate that sampling rate is positive.</p>"},{"location":"api/utils/#wandas.utils.util.validate_sampling_rate--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate in Hz to validate. param_name : str, default=\"sampling_rate\"     Name of the parameter being validated (for error messages).</p>"},{"location":"api/utils/#wandas.utils.util.validate_sampling_rate--raises","title":"Raises","text":"<p>ValueError     If sampling_rate is not positive (i.e., &lt;= 0).</p>"},{"location":"api/utils/#wandas.utils.util.validate_sampling_rate--examples","title":"Examples","text":"<p>validate_sampling_rate(44100)  # No error validate_sampling_rate(0)  # Raises ValueError validate_sampling_rate(-100)  # Raises ValueError</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def validate_sampling_rate(\n    sampling_rate: float, param_name: str = \"sampling_rate\"\n) -&gt; None:\n    \"\"\"\n    Validate that sampling rate is positive.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz to validate.\n    param_name : str, default=\"sampling_rate\"\n        Name of the parameter being validated (for error messages).\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate is not positive (i.e., &lt;= 0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; validate_sampling_rate(44100)  # No error\n    &gt;&gt;&gt; validate_sampling_rate(0)  # Raises ValueError\n    &gt;&gt;&gt; validate_sampling_rate(-100)  # Raises ValueError\n    \"\"\"\n    if sampling_rate &lt;= 0:\n        raise ValueError(\n            f\"Invalid {param_name}\\n\"\n            f\"  Got: {sampling_rate} Hz\\n\"\n            f\"  Expected: Positive value &gt; 0\\n\"\n            f\"Sampling rate represents samples per second and must be positive.\\n\"\n            f\"Common values: 8000, 16000, 22050, 44100, 48000 Hz\"\n        )\n</code></pre>"},{"location":"api/utils/#wandas.utils.util.unit_to_ref","title":"<code>unit_to_ref(unit)</code>","text":"<p>Convert unit to reference value.</p>"},{"location":"api/utils/#wandas.utils.util.unit_to_ref--parameters","title":"Parameters","text":"<p>unit : str     Unit string.</p>"},{"location":"api/utils/#wandas.utils.util.unit_to_ref--returns","title":"Returns","text":"<p>float     Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).     For other units, returns 1.0.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def unit_to_ref(unit: str) -&gt; float:\n    \"\"\"\n    Convert unit to reference value.\n\n    Parameters\n    ----------\n    unit : str\n        Unit string.\n\n    Returns\n    -------\n    float\n        Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).\n        For other units, returns 1.0.\n    \"\"\"\n    if unit == \"Pa\":\n        return 2e-5\n\n    else:\n        return 1.0\n</code></pre>"},{"location":"api/utils/#wandas.utils.util.calculate_rms","title":"<code>calculate_rms(wave)</code>","text":"<p>Calculate the root mean square of the wave.</p>"},{"location":"api/utils/#wandas.utils.util.calculate_rms--parameters","title":"Parameters","text":"<p>wave : NDArrayReal     Input waveform data. Can be multi-channel (shape: [channels, samples])     or single channel (shape: [samples]).</p>"},{"location":"api/utils/#wandas.utils.util.calculate_rms--returns","title":"Returns","text":"<p>Union[float, NDArray[np.float64]]     RMS value(s). For multi-channel input, returns an array of RMS values,     one per channel. For single-channel input, returns a single RMS value.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def calculate_rms(wave: \"NDArrayReal\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the root mean square of the wave.\n\n    Parameters\n    ----------\n    wave : NDArrayReal\n        Input waveform data. Can be multi-channel (shape: [channels, samples])\n        or single channel (shape: [samples]).\n\n    Returns\n    -------\n    Union[float, NDArray[np.float64]]\n        RMS value(s). For multi-channel input, returns an array of RMS values,\n        one per channel. For single-channel input, returns a single RMS value.\n    \"\"\"\n    # Calculate RMS considering axis (over the last dimension)\n    axis_to_use = -1 if wave.ndim &gt; 1 else None\n    rms_values: NDArrayReal = np.sqrt(\n        np.mean(np.square(wave), axis=axis_to_use, keepdims=True)\n    )\n    return rms_values\n</code></pre>"},{"location":"api/utils/#wandas.utils.util.calculate_desired_noise_rms","title":"<code>calculate_desired_noise_rms(clean_rms, snr)</code>","text":"<p>Calculate the desired noise RMS based on clean signal RMS and target SNR.</p>"},{"location":"api/utils/#wandas.utils.util.calculate_desired_noise_rms--parameters","title":"Parameters","text":"<p>clean_rms : \"NDArrayReal\"     RMS value(s) of the clean signal.     Can be a single value or an array for multi-channel. snr : float     Target Signal-to-Noise Ratio in dB.</p>"},{"location":"api/utils/#wandas.utils.util.calculate_desired_noise_rms--returns","title":"Returns","text":"<p>\"NDArrayReal\"     Desired noise RMS value(s) to achieve the target SNR.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def calculate_desired_noise_rms(clean_rms: \"NDArrayReal\", snr: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the desired noise RMS based on clean signal RMS and target SNR.\n\n    Parameters\n    ----------\n    clean_rms : \"NDArrayReal\"\n        RMS value(s) of the clean signal.\n        Can be a single value or an array for multi-channel.\n    snr : float\n        Target Signal-to-Noise Ratio in dB.\n\n    Returns\n    -------\n    \"NDArrayReal\"\n        Desired noise RMS value(s) to achieve the target SNR.\n    \"\"\"\n    a = snr / 20\n    noise_rms = clean_rms / (10**a)\n    return noise_rms\n</code></pre>"},{"location":"api/utils/#wandas.utils.util.amplitude_to_db","title":"<code>amplitude_to_db(amplitude, ref)</code>","text":"<p>Convert amplitude to decibel.</p>"},{"location":"api/utils/#wandas.utils.util.amplitude_to_db--parameters","title":"Parameters","text":"<p>amplitude : NDArrayReal     Input amplitude data. ref : float     Reference value for conversion.</p>"},{"location":"api/utils/#wandas.utils.util.amplitude_to_db--returns","title":"Returns","text":"<p>NDArrayReal     Amplitude data converted to decibels.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def amplitude_to_db(amplitude: \"NDArrayReal\", ref: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Convert amplitude to decibel.\n\n    Parameters\n    ----------\n    amplitude : NDArrayReal\n        Input amplitude data.\n    ref : float\n        Reference value for conversion.\n\n    Returns\n    -------\n    NDArrayReal\n        Amplitude data converted to decibels.\n    \"\"\"\n    db: NDArrayReal = librosa.amplitude_to_db(\n        np.abs(amplitude), ref=ref, amin=1e-15, top_db=None\n    )\n    return db\n</code></pre>"},{"location":"api/utils/#wandas.utils.util.level_trigger","title":"<code>level_trigger(data, level, offset=0, hold=1)</code>","text":"<p>Find points where the signal crosses the specified level from below.</p>"},{"location":"api/utils/#wandas.utils.util.level_trigger--parameters","title":"Parameters","text":"<p>data : NDArrayReal     Input signal data. level : float     Threshold level for triggering. offset : int, default=0     Offset to add to trigger points. hold : int, default=1     Minimum number of samples between successive trigger points.</p>"},{"location":"api/utils/#wandas.utils.util.level_trigger--returns","title":"Returns","text":"<p>list of int     List of sample indices where the signal crosses the level.</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def level_trigger(\n    data: \"NDArrayReal\", level: float, offset: int = 0, hold: int = 1\n) -&gt; list[int]:\n    \"\"\"\n    Find points where the signal crosses the specified level from below.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    level : float\n        Threshold level for triggering.\n    offset : int, default=0\n        Offset to add to trigger points.\n    hold : int, default=1\n        Minimum number of samples between successive trigger points.\n\n    Returns\n    -------\n    list of int\n        List of sample indices where the signal crosses the level.\n    \"\"\"\n    trig_point: list[int] = []\n\n    sig_len = len(data)\n    diff = np.diff(np.sign(data - level))\n    level_point = np.where(diff &gt; 0)[0]\n    level_point = level_point[(level_point + hold) &lt; sig_len]\n\n    if len(level_point) == 0:\n        return list()\n\n    last_point = level_point[0]\n    trig_point.append(last_point + offset)\n    for i in level_point:\n        if (last_point + hold) &lt; i:\n            trig_point.append(i + offset)\n            last_point = i\n\n    return trig_point\n</code></pre>"},{"location":"api/utils/#wandas.utils.util.cut_sig","title":"<code>cut_sig(data, point_list, cut_len, taper_rate=0, dc_cut=False)</code>","text":"<p>Cut segments from signal at specified points.</p>"},{"location":"api/utils/#wandas.utils.util.cut_sig--parameters","title":"Parameters","text":"<p>data : NDArrayReal     Input signal data. point_list : list of int     List of starting points for cutting. cut_len : int     Length of each segment to cut. taper_rate : float, default=0     Taper rate for Tukey window applied to segments.     A value of 0 means no tapering, 1 means full tapering. dc_cut : bool, default=False     Whether to remove DC component (mean) from segments.</p>"},{"location":"api/utils/#wandas.utils.util.cut_sig--returns","title":"Returns","text":"<p>NDArrayReal     Array containing cut segments with shape (n_segments, cut_len).</p> Source code in <code>wandas/utils/util.py</code> <pre><code>def cut_sig(\n    data: \"NDArrayReal\",\n    point_list: list[int],\n    cut_len: int,\n    taper_rate: float = 0,\n    dc_cut: bool = False,\n) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Cut segments from signal at specified points.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    point_list : list of int\n        List of starting points for cutting.\n    cut_len : int\n        Length of each segment to cut.\n    taper_rate : float, default=0\n        Taper rate for Tukey window applied to segments.\n        A value of 0 means no tapering, 1 means full tapering.\n    dc_cut : bool, default=False\n        Whether to remove DC component (mean) from segments.\n\n    Returns\n    -------\n    NDArrayReal\n        Array containing cut segments with shape (n_segments, cut_len).\n    \"\"\"\n    length = len(data)\n    point_list_ = [p for p in point_list if p &gt;= 0 and p + cut_len &lt;= length]\n    trial: NDArrayReal = np.zeros((len(point_list_), cut_len))\n\n    for i, v in enumerate(point_list_):\n        trial[i] = data[v : v + cut_len]\n        if dc_cut:\n            trial[i] = trial[i] - trial[i].mean()\n\n    win: NDArrayReal = tukey(cut_len, taper_rate).astype(trial.dtype)[np.newaxis, :]\n    trial = trial * win\n    return trial\n</code></pre>"},{"location":"api/visualization/","title":"\u53ef\u8996\u5316\u30e2\u30b8\u30e5\u30fc\u30eb","text":"<p><code>wandas.visualization</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u3092\u8996\u899a\u7684\u306b\u8868\u73fe\u3059\u308b\u305f\u3081\u306e\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/visualization/#_2","title":"\u30d7\u30ed\u30c3\u30c6\u30a3\u30f3\u30b0","text":"<p>\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u3092\u8996\u899a\u5316\u3059\u308b\u305f\u3081\u306e\u30d7\u30ed\u30c3\u30c6\u30a3\u30f3\u30b0\u95a2\u6570\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api/visualization/#wandas.visualization.plotting","title":"<code>wandas.visualization.plotting</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.TFrame","title":"<code>TFrame = TypeVar('TFrame', bound='BaseFrame[Any]')</code>  <code>module-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting-classes","title":"Classes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.PlotStrategy","title":"<code>PlotStrategy</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TFrame]</code></p> <p>Base class for plotting strategies</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class PlotStrategy(abc.ABC, Generic[TFrame]):\n    \"\"\"Base class for plotting strategies\"\"\"\n\n    name: ClassVar[str]\n\n    @abc.abstractmethod\n    def channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass\n\n    @abc.abstractmethod\n    def plot(\n        self,\n        bf: TFrame,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Implementation of plotting\"\"\"\n        pass\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.PlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.PlotStrategy.name","title":"<code>name</code>  <code>class-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.PlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.PlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax)</code>  <code>abstractmethod</code>","text":"<p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.PlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Implementation of plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef plot(\n    self,\n    bf: TFrame,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of plotting\"\"\"\n    pass\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy","title":"<code>WaveformPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['ChannelFrame']</code></p> <p>Strategy for waveform plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class WaveformPlotStrategy(PlotStrategy[\"ChannelFrame\"]):\n    \"\"\"Strategy for waveform plotting\"\"\"\n\n    name = \"waveform\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.plot(x, y, **kwargs)\n        ax.set_ylabel(\"Amplitude\")\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"ChannelFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Waveform plotting\"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n        xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(\n            Line2D,\n            kwargs,\n            strict_mode=True,\n        )\n        ax_set = filter_kwargs(\n            Axes.set,\n            kwargs,\n            strict_mode=True,\n        )\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        data = bf.data\n        data = _reshape_to_2d(data)\n        if overlay:\n            if ax is None:\n                fig, ax = plt.subplots(figsize=(10, 4))\n\n            self.channel_plot(\n                bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n            )\n            ax.set(\n                ylabel=ylabel,\n                title=title or bf.label or \"Channel Data\",\n                xlabel=xlabel,\n                **ax_set,\n            )\n            if ax is None:\n                fig.suptitle(title or bf.label or None)\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n                )\n                ax_i.set(\n                    ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                    title=ch_meta.label,\n                    **ax_set,\n                )\n\n            axes_list[-1].set(\n                xlabel=\"Time [s]\",\n            )\n            fig.suptitle(title or bf.label or \"Channel Data\")\n\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n\n            return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy.name","title":"<code>name = 'waveform'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.set_ylabel(\"Amplitude\")\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Waveform plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Waveform plotting\"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n    xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(\n        Line2D,\n        kwargs,\n        strict_mode=True,\n    )\n    ax_set = filter_kwargs(\n        Axes.set,\n        kwargs,\n        strict_mode=True,\n    )\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    data = bf.data\n    data = _reshape_to_2d(data)\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(10, 4))\n\n        self.channel_plot(\n            bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n        )\n        ax.set(\n            ylabel=ylabel,\n            title=title or bf.label or \"Channel Data\",\n            xlabel=xlabel,\n            **ax_set,\n        )\n        if ax is None:\n            fig.suptitle(title or bf.label or None)\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n            )\n            ax_i.set(\n                ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                title=ch_meta.label,\n                **ax_set,\n            )\n\n        axes_list[-1].set(\n            xlabel=\"Time [s]\",\n        )\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy","title":"<code>FrequencyPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectralFrame']</code></p> <p>Strategy for frequency domain plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class FrequencyPlotStrategy(PlotStrategy[\"SpectralFrame\"]):\n    \"\"\"Strategy for frequency domain plotting\"\"\"\n\n    name = \"frequency\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.plot(x, y, **kwargs)\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"SpectralFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Frequency domain plotting\"\"\"\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n        if (\n            len(bf.operation_history) &gt; 0\n            and bf.operation_history[-1][\"operation\"] == \"coherence\"\n        ):\n            unit = \"\"\n            data = bf.magnitude\n            ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n        else:\n            if is_aw:\n                unit = \"dBA\"\n                data = bf.dBA\n            else:\n                unit = \"dB\"\n                data = bf.dB\n            ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n        data = _reshape_to_2d(data)\n        xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                _, ax = plt.subplots(figsize=(10, 4))\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,\n                label=bf.labels,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax.set(\n                ylabel=ylabel,\n                xlabel=xlabel,\n                title=title or bf.label or \"Channel Data\",\n                **ax_set,\n            )\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    label=ch_meta.label,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(\n                    ylabel=ylabel,\n                    title=ch_meta.label,\n                    xlabel=xlabel,\n                    **ax_set,\n                )\n            axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n            fig.suptitle(title or bf.label or \"Channel Data\")\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy.name","title":"<code>name = 'frequency'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Frequency domain plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Frequency domain plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    data = _reshape_to_2d(data)\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=title or bf.label or \"Channel Data\",\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.NOctPlotStrategy","title":"<code>NOctPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['NOctFrame']</code></p> <p>Strategy for N-octave band analysis plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class NOctPlotStrategy(PlotStrategy[\"NOctFrame\"]):\n    \"\"\"Strategy for N-octave band analysis plotting\"\"\"\n\n    name = \"noct\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.step(x, y, **kwargs)\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"NOctFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"N-octave band analysis plotting\"\"\"\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n\n        if is_aw:\n            unit = \"dBrA\"\n            data = bf.dBA\n        else:\n            unit = \"dBr\"\n            data = bf.dB\n        data = _reshape_to_2d(data)\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n        xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                _, ax = plt.subplots(figsize=(10, 4))\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,\n                label=bf.labels,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n            actual_title = title if title else (bf.label or default_title)\n            ax.set(\n                ylabel=ylabel,\n                xlabel=xlabel,\n                title=actual_title,\n                **ax_set,\n            )\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    label=ch_meta.label,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(\n                    ylabel=ylabel,\n                    title=ch_meta.label,\n                    xlabel=xlabel,\n                    **ax_set,\n                )\n            axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n            fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.NOctPlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.NOctPlotStrategy.name","title":"<code>name = 'noct'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.NOctPlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.NOctPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.step(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.NOctPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>N-octave band analysis plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"NOctFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"N-octave band analysis plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n\n    if is_aw:\n        unit = \"dBrA\"\n        data = bf.dBA\n    else:\n        unit = \"dBr\"\n        data = bf.dB\n    data = _reshape_to_2d(data)\n    ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n        actual_title = title if title else (bf.label or default_title)\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=actual_title,\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy","title":"<code>SpectrogramPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectrogramFrame']</code></p> <p>Strategy for spectrogram plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class SpectrogramPlotStrategy(PlotStrategy[\"SpectrogramFrame\"]):\n    \"\"\"Strategy for spectrogram plotting\"\"\"\n\n    name = \"spectrogram\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass\n\n    def plot(\n        self,\n        bf: \"SpectrogramFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Spectrogram plotting\"\"\"\n        # Explicit overlay mode is not supported for spectrograms\n        if overlay:\n            raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n        # If an Axes is provided, allow drawing into it only for single-channel frames\n        if ax is not None and bf.n_channels &gt; 1:\n            raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n        kwargs = kwargs or {}\n\n        is_aw = kwargs.pop(\"Aw\", False)\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        data = _reshape_spectrogram_data(data)\n        specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n        ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n        cmap = kwargs.pop(\"cmap\", \"jet\")\n        vmin = kwargs.pop(\"vmin\", None)\n        vmax = kwargs.pop(\"vmax\", None)\n\n        if ax is not None:\n            img = display.specshow(\n                data=data[0],\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                cmap=cmap,\n                ax=ax,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax.set(\n                title=title or bf.label or \"Spectrogram\",\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n\n            fig = ax.figure\n            if fig is not None:\n                try:\n                    cbar = fig.colorbar(img, ax=ax)\n                    cbar.set_label(f\"Spectrum level [{unit}]\")\n                except (ValueError, AttributeError) as e:\n                    # Handle case where img doesn't have proper colorbar properties\n                    logger.warning(\n                        f\"Failed to create colorbar for spectrogram: \"\n                        f\"{type(e).__name__}: {e}\"\n                    )\n            return ax\n\n        else:\n            # Create a new figure if ax is None\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n            )\n            if not isinstance(fig, Figure):\n                raise ValueError(\"fig must be a matplotlib Figure object.\")\n            # Convert axs to array if it is a single Axes object\n            if not isinstance(axs, np.ndarray):\n                axs = np.array([axs])\n\n            for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n                img = display.specshow(\n                    data=channel_data,\n                    sr=bf.sampling_rate,\n                    hop_length=bf.hop_length,\n                    n_fft=bf.n_fft,\n                    win_length=bf.win_length,\n                    x_axis=\"time\",\n                    y_axis=\"linear\",\n                    ax=ax_i,\n                    cmap=cmap,\n                    vmin=vmin,\n                    vmax=vmax,\n                    **specshow_kwargs,\n                )\n                ax_i.set(\n                    title=ch_meta.label,\n                    ylabel=\"Frequency [Hz]\",\n                    xlabel=\"Time [s]\",\n                    **ax_set_kwargs,\n                )\n                try:\n                    cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                    cbar.set_label(f\"Spectrum level [{unit}]\")\n                except (ValueError, AttributeError) as e:\n                    # Handle case where img doesn't have proper colorbar properties\n                    logger.warning(\n                        f\"Failed to create colorbar for spectrogram: \"\n                        f\"{type(e).__name__}: {e}\"\n                    )\n                fig.suptitle(title or \"Spectrogram Data\")\n            plt.tight_layout()\n            plt.show()\n\n            return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy.name","title":"<code>name = 'spectrogram'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Spectrogram plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectrogramFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Spectrogram plotting\"\"\"\n    # Explicit overlay mode is not supported for spectrograms\n    if overlay:\n        raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n    # If an Axes is provided, allow drawing into it only for single-channel frames\n    if ax is not None and bf.n_channels &gt; 1:\n        raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n    kwargs = kwargs or {}\n\n    is_aw = kwargs.pop(\"Aw\", False)\n    if is_aw:\n        unit = \"dBA\"\n        data = bf.dBA\n    else:\n        unit = \"dB\"\n        data = bf.dB\n    data = _reshape_spectrogram_data(data)\n    specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n    ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n\n    if ax is not None:\n        img = display.specshow(\n            data=data[0],\n            sr=bf.sampling_rate,\n            hop_length=bf.hop_length,\n            n_fft=bf.n_fft,\n            win_length=bf.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            cmap=cmap,\n            ax=ax,\n            vmin=vmin,\n            vmax=vmax,\n            **specshow_kwargs,\n        )\n        ax.set(\n            title=title or bf.label or \"Spectrogram\",\n            ylabel=\"Frequency [Hz]\",\n            xlabel=\"Time [s]\",\n            **ax_set_kwargs,\n        )\n\n        fig = ax.figure\n        if fig is not None:\n            try:\n                cbar = fig.colorbar(img, ax=ax)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n        return ax\n\n    else:\n        # Create a new figure if ax is None\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n        )\n        if not isinstance(fig, Figure):\n            raise ValueError(\"fig must be a matplotlib Figure object.\")\n        # Convert axs to array if it is a single Axes object\n        if not isinstance(axs, np.ndarray):\n            axs = np.array([axs])\n\n        for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n            img = display.specshow(\n                data=channel_data,\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                ax=ax_i,\n                cmap=cmap,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax_i.set(\n                title=ch_meta.label,\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n            try:\n                cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n            fig.suptitle(title or \"Spectrogram Data\")\n        plt.tight_layout()\n        plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.DescribePlotStrategy","title":"<code>DescribePlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['ChannelFrame']</code></p> <p>Strategy for visualizing ChannelFrame data with describe plot</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class DescribePlotStrategy(PlotStrategy[\"ChannelFrame\"]):\n    \"\"\"Strategy for visualizing ChannelFrame data with describe plot\"\"\"\n\n    name = \"describe\"\n\n    def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass  # This method is not used for describe plot\n\n    def plot(\n        self,\n        bf: \"ChannelFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n        fmin = kwargs.pop(\"fmin\", 0)\n        fmax = kwargs.pop(\"fmax\", None)\n        cmap = kwargs.pop(\"cmap\", \"jet\")\n        vmin = kwargs.pop(\"vmin\", None)\n        vmax = kwargs.pop(\"vmax\", None)\n        xlim = kwargs.pop(\"xlim\", None)\n        ylim = kwargs.pop(\"ylim\", None)\n        is_aw = kwargs.pop(\"Aw\", False)\n        waveform = kwargs.pop(\"waveform\", {})\n        spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n        gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n        gs.update(wspace=0.2)\n\n        fig = plt.figure(figsize=(12, 6))\n        fig.subplots_adjust(wspace=0.0001)\n\n        # First subplot (Time Plot)\n        ax_1 = fig.add_subplot(gs[0])\n        bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n        ax_1.set(**waveform)\n        ax_1.legend().set_visible(False)\n        ax_1.set(xlabel=\"\", title=\"\")\n\n        # Second subplot (STFT Plot)\n        ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n        stft_ch = bf.stft()\n        if is_aw:\n            unit = \"dBA\"\n            channel_data = stft_ch.dBA\n        else:\n            unit = \"dB\"\n            channel_data = stft_ch.dB\n        if channel_data.ndim == 3:\n            channel_data = channel_data[0]\n        # Get the maximum value of the data and round it to a convenient value\n        if vmax is None:\n            data_max = np.nanmax(channel_data)\n            # Round to a convenient number with increments of 10, 5, or 2\n            for step in [10, 5, 2]:\n                rounded_max = np.ceil(data_max / step) * step\n                if rounded_max &gt;= data_max:\n                    vmax = rounded_max\n                    vmin = vmax - 180\n                    break\n        img = display.specshow(\n            data=channel_data,\n            sr=bf.sampling_rate,\n            hop_length=stft_ch.hop_length,\n            n_fft=stft_ch.n_fft,\n            win_length=stft_ch.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            ax=ax_2,\n            fmin=fmin,\n            fmax=fmax,\n            cmap=cmap,\n            vmin=vmin,\n            vmax=vmax,\n        )\n        ax_2.set(xlim=xlim, ylim=ylim)\n\n        # Third subplot\n        ax_3 = fig.add_subplot(gs[1])\n        ax_3.axis(\"off\")\n\n        # Fourth subplot (Welch Plot)\n        ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n        welch_ch = bf.welch()\n        if is_aw:\n            unit = \"dBA\"\n            data_db = welch_ch.dBA\n        else:\n            unit = \"dB\"\n            data_db = welch_ch.dB\n        ax_4.plot(data_db.T, welch_ch.freqs.T)\n        ax_4.grid(True)\n        ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n        cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n        cbar.set_label(unit)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.DescribePlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.DescribePlotStrategy.name","title":"<code>name = 'describe'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.DescribePlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.DescribePlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass  # This method is not used for describe plot\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.DescribePlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Implementation of describe method for visualizing ChannelFrame data</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n    fmin = kwargs.pop(\"fmin\", 0)\n    fmax = kwargs.pop(\"fmax\", None)\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n    xlim = kwargs.pop(\"xlim\", None)\n    ylim = kwargs.pop(\"ylim\", None)\n    is_aw = kwargs.pop(\"Aw\", False)\n    waveform = kwargs.pop(\"waveform\", {})\n    spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n    gs.update(wspace=0.2)\n\n    fig = plt.figure(figsize=(12, 6))\n    fig.subplots_adjust(wspace=0.0001)\n\n    # First subplot (Time Plot)\n    ax_1 = fig.add_subplot(gs[0])\n    bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n    ax_1.set(**waveform)\n    ax_1.legend().set_visible(False)\n    ax_1.set(xlabel=\"\", title=\"\")\n\n    # Second subplot (STFT Plot)\n    ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n    stft_ch = bf.stft()\n    if is_aw:\n        unit = \"dBA\"\n        channel_data = stft_ch.dBA\n    else:\n        unit = \"dB\"\n        channel_data = stft_ch.dB\n    if channel_data.ndim == 3:\n        channel_data = channel_data[0]\n    # Get the maximum value of the data and round it to a convenient value\n    if vmax is None:\n        data_max = np.nanmax(channel_data)\n        # Round to a convenient number with increments of 10, 5, or 2\n        for step in [10, 5, 2]:\n            rounded_max = np.ceil(data_max / step) * step\n            if rounded_max &gt;= data_max:\n                vmax = rounded_max\n                vmin = vmax - 180\n                break\n    img = display.specshow(\n        data=channel_data,\n        sr=bf.sampling_rate,\n        hop_length=stft_ch.hop_length,\n        n_fft=stft_ch.n_fft,\n        win_length=stft_ch.win_length,\n        x_axis=\"time\",\n        y_axis=\"linear\",\n        ax=ax_2,\n        fmin=fmin,\n        fmax=fmax,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n    ax_2.set(xlim=xlim, ylim=ylim)\n\n    # Third subplot\n    ax_3 = fig.add_subplot(gs[1])\n    ax_3.axis(\"off\")\n\n    # Fourth subplot (Welch Plot)\n    ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n    welch_ch = bf.welch()\n    if is_aw:\n        unit = \"dBA\"\n        data_db = welch_ch.dBA\n    else:\n        unit = \"dB\"\n        data_db = welch_ch.dB\n    ax_4.plot(data_db.T, welch_ch.freqs.T)\n    ax_4.grid(True)\n    ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n    cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n    cbar.set_label(unit)\n    fig.suptitle(title or bf.label or \"Channel Data\")\n\n    return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy","title":"<code>MatrixPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectralFrame']</code></p> <p>Strategy for displaying relationships between channels in matrix format</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class MatrixPlotStrategy(PlotStrategy[\"SpectralFrame\"]):\n    \"\"\"Strategy for displaying relationships between channels in matrix format\"\"\"\n\n    name = \"matrix\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        title: str | None = None,\n        ylabel: str = \"\",\n        xlabel: str = \"Frequency [Hz]\",\n        alpha: float = 0,\n        **kwargs: Any,\n    ) -&gt; None:\n        ax.plot(x, y, **kwargs)\n        ax.grid(True)\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.set_title(title or \"\")\n\n    def plot(\n        self,\n        bf: \"SpectralFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n        if (\n            len(bf.operation_history) &gt; 0\n            and bf.operation_history[-1][\"operation\"] == \"coherence\"\n        ):\n            unit = \"\"\n            data = bf.magnitude\n            ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n        else:\n            if is_aw:\n                unit = \"dBA\"\n                data = bf.dBA\n            else:\n                unit = \"dB\"\n                data = bf.dB\n            ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n        data = _reshape_to_2d(data)\n\n        xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        num_channels = bf.n_channels\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n            else:\n                fig = ax.figure\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n                title=title or bf.label or \"Spectral Data\",\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax.set(**ax_set)\n            if fig is not None:\n                fig.suptitle(title or bf.label or \"Spectral Data\")\n            if ax.figure != fig:  # Only show if we created the figure\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_rows = int(np.ceil(np.sqrt(num_channels)))\n            fig, axs = plt.subplots(\n                num_rows,\n                num_rows,\n                figsize=(3 * num_rows, 3 * num_rows),\n                sharex=True,\n                sharey=True,\n            )\n            if isinstance(axs, np.ndarray):\n                axes_list = axs.flatten().tolist()\n            elif isinstance(axs, list):\n                import itertools\n\n                axes_list = list(itertools.chain.from_iterable(axs))\n            else:\n                axes_list = [axs]\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    title=ch_meta.label,\n                    ylabel=ylabel,\n                    xlabel=xlabel,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(**ax_set)\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n            plt.tight_layout()\n            plt.show()\n            return _return_axes_iterator(fig.axes)\n\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy-attributes","title":"Attributes","text":""},{"location":"api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy.name","title":"<code>name = 'matrix'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, title=None, ylabel='', xlabel='Frequency [Hz]', alpha=0, **kwargs)</code>","text":"Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    title: str | None = None,\n    ylabel: str = \"\",\n    xlabel: str = \"Frequency [Hz]\",\n    alpha: float = 0,\n    **kwargs: Any,\n) -&gt; None:\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_title(title or \"\")\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n    data = _reshape_to_2d(data)\n\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    num_channels = bf.n_channels\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n        else:\n            fig = ax.figure\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n            title=title or bf.label or \"Spectral Data\",\n            ylabel=ylabel,\n            xlabel=xlabel,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(**ax_set)\n        if fig is not None:\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n        if ax.figure != fig:  # Only show if we created the figure\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_rows = int(np.ceil(np.sqrt(num_channels)))\n        fig, axs = plt.subplots(\n            num_rows,\n            num_rows,\n            figsize=(3 * num_rows, 3 * num_rows),\n            sharex=True,\n            sharey=True,\n        )\n        if isinstance(axs, np.ndarray):\n            axes_list = axs.flatten().tolist()\n        elif isinstance(axs, list):\n            import itertools\n\n            axes_list = list(itertools.chain.from_iterable(axs))\n        else:\n            axes_list = [axs]\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                title=ch_meta.label,\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(**ax_set)\n        fig.suptitle(title or bf.label or \"Spectral Data\")\n        plt.tight_layout()\n        plt.show()\n        return _return_axes_iterator(fig.axes)\n\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting-functions","title":"Functions","text":""},{"location":"api/visualization/#wandas.visualization.plotting.register_plot_strategy","title":"<code>register_plot_strategy(strategy_cls)</code>","text":"<p>Register a new plot strategy from a class</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def register_plot_strategy(strategy_cls: type) -&gt; None:\n    \"\"\"Register a new plot strategy from a class\"\"\"\n    if not issubclass(strategy_cls, PlotStrategy):\n        raise TypeError(\"Strategy class must inherit from PlotStrategy.\")\n    if inspect.isabstract(strategy_cls):\n        raise TypeError(\"Cannot register abstract PlotStrategy class.\")\n    _plot_strategies[strategy_cls.name] = strategy_cls\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.get_plot_strategy","title":"<code>get_plot_strategy(name)</code>","text":"<p>Get plot strategy by name</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def get_plot_strategy(name: str) -&gt; type[PlotStrategy[Any]]:\n    \"\"\"Get plot strategy by name\"\"\"\n    if name not in _plot_strategies:\n        raise ValueError(f\"Unknown plot type: {name}\")\n    return _plot_strategies[name]\n</code></pre>"},{"location":"api/visualization/#wandas.visualization.plotting.create_operation","title":"<code>create_operation(name, **params)</code>","text":"<p>Create operation instance from operation name and parameters</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>def create_operation(name: str, **params: Any) -&gt; PlotStrategy[Any]:\n    \"\"\"Create operation instance from operation name and parameters\"\"\"\n    operation_class = get_plot_strategy(name)\n    return operation_class(**params)\n</code></pre>"},{"location":"api/wdf_io/","title":"WDF\u30d5\u30a1\u30a4\u30eb\u5165\u51fa\u529b","text":"<p><code>wandas.io.wdf_io</code> \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001<code>ChannelFrame</code> \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092 WDF (Wandas Data File) \u5f62\u5f0f\u3067\u4fdd\u5b58\u30fb\u8aad\u307f\u8fbc\u307f\u3059\u308b\u305f\u3081\u306e\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002 WDF\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f HDF5 \u3092\u30d9\u30fc\u30b9\u3068\u3057\u3001\u30c7\u30fc\u30bf\u3060\u3051\u3067\u306a\u304f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u3001\u5358\u4f4d\u3001\u30c1\u30e3\u30f3\u30cd\u30eb\u30e9\u30d9\u30eb\u306a\u3069\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3082\u5b8c\u5168\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002</p>"},{"location":"api/wdf_io/#wdf_1","title":"WDF\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u6982\u8981","text":"<p>WDF\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f\u4ee5\u4e0b\u306e\u7279\u5fb4\u3092\u6301\u3061\u307e\u3059:</p> <ul> <li>HDF5\u30d9\u30fc\u30b9\u306e\u968e\u5c64\u7684\u306a\u30c7\u30fc\u30bf\u69cb\u9020</li> <li>\u30c1\u30e3\u30f3\u30cd\u30eb\u30c7\u30fc\u30bf\u3068\u30e1\u30bf\u30c7\u30fc\u30bf\u306e\u5b8c\u5168\u306a\u4fdd\u6301</li> <li>\u30c7\u30fc\u30bf\u5727\u7e2e\u3068\u30c1\u30e3\u30f3\u30af\u5316\u306b\u3088\u308b\u30b5\u30a4\u30ba\u6700\u9069\u5316</li> <li>\u5c06\u6765\u306e\u62e1\u5f35\u306b\u5bfe\u5fdc\u3059\u308b\u30d0\u30fc\u30b8\u30e7\u30f3\u7ba1\u7406</li> </ul> <p>\u30d5\u30a1\u30a4\u30eb\u69cb\u9020:</p> <pre><code>/meta           : Frame \u5168\u4f53\u306e\u30e1\u30bf\u30c7\u30fc\u30bf (JSON\u5f62\u5f0f)\n/channels/{i}   : \u500b\u3005\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u30c7\u30fc\u30bf\u3068\u30e1\u30bf\u30c7\u30fc\u30bf\n    \u251c\u2500 data           : \u6ce2\u5f62\u30c7\u30fc\u30bf (numpy array)\n    \u2514\u2500 attrs          : \u30c1\u30e3\u30f3\u30cd\u30eb\u5c5e\u6027 (\u30e9\u30d9\u30eb\u3001\u5358\u4f4d\u306a\u3069)\n</code></pre>"},{"location":"api/wdf_io/#wdf_2","title":"WDF\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58","text":""},{"location":"api/wdf_io/#wandas.io.wdf_io.save","title":"<code>wandas.io.wdf_io.save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> required <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> required <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"api/wdf_io/#wdf_3","title":"WDF\u30d5\u30a1\u30a4\u30eb\u8aad\u307f\u8fbc\u307f","text":""},{"location":"api/wdf_io/#wandas.io.wdf_io.load","title":"<code>wandas.io.wdf_io.load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> required <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>Returns:</p> Type Description <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> Source code in <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"api/wdf_io/#_1","title":"\u5229\u7528\u4f8b","text":"<pre><code># ChannelFrame \u3092 WDF\u5f62\u5f0f\u3067\u4fdd\u5b58\ncf = wd.read_wav(\"audio.wav\")\ncf.save(\"audio_data.wdf\")\n\n# \u4fdd\u5b58\u6642\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u6307\u5b9a\ncf.save(\n    \"high_quality.wdf\",\n    compress=\"gzip\",  # \u5727\u7e2e\u65b9\u5f0f\n    dtype=\"float64\",  # \u30c7\u30fc\u30bf\u578b\n    overwrite=True    # \u4e0a\u66f8\u304d\u8a31\u53ef\n)\n\n# WDF\u30d5\u30a1\u30a4\u30eb\u304b\u3089 ChannelFrame \u3092\u8aad\u307f\u8fbc\u307f\ncf2 = wd.ChannelFrame.load(\"audio_data.wdf\")\n</code></pre> <p>\u8a73\u7d30\u306a\u4f7f\u7528\u4f8b\u306f \u30d5\u30a1\u30a4\u30eb\u5165\u51fa\u529b\u30ac\u30a4\u30c9 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"explanation/","title":"\u7406\u8ad6\u80cc\u666f\u3068\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8a2d\u8a08\u601d\u60f3\u3001\u5185\u90e8\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3001\u304a\u3088\u3073\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u7406\u8ad6\u7684\u80cc\u666f\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"explanation/#_2","title":"\u8a2d\u8a08\u601d\u60f3","text":"<p>Wandas\u306f\u4ee5\u4e0b\u306e\u8a2d\u8a08\u539f\u5247\u306b\u57fa\u3065\u3044\u3066\u958b\u767a\u3055\u308c\u3066\u3044\u307e\u3059\uff1a</p> <ol> <li>\u76f4\u611f\u7684\u306aAPI\u8a2d\u8a08 - \u30e6\u30fc\u30b6\u30fc\u304c\u7c21\u5358\u306b\u4f7f\u3048\u308b\u4e00\u8cab\u6027\u306e\u3042\u308b\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</li> <li>\u52b9\u7387\u7684\u306a\u30e1\u30e2\u30ea\u4f7f\u7528 - \u5927\u898f\u6a21\u30c7\u30fc\u30bf\u306e\u51e6\u7406\u306b\u9069\u3057\u305f\u30e1\u30e2\u30ea\u52b9\u7387\u306e\u826f\u3044\u5b9f\u88c5</li> <li>\u62e1\u5f35\u6027 - \u65b0\u3057\u3044\u6a5f\u80fd\u3084\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u8ffd\u52a0\u3057\u3084\u3059\u3044\u62e1\u5f35\u53ef\u80fd\u306a\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> <li>\u79d1\u5b66\u7684\u6b63\u78ba\u6027 - \u97f3\u97ff\u4fe1\u53f7\u51e6\u7406\u306e\u7406\u8ad6\u306b\u57fa\u3065\u304f\u6b63\u78ba\u306a\u5b9f\u88c5</li> </ol>"},{"location":"explanation/#_3","title":"\u30b3\u30a2\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"explanation/#_4","title":"\u30c7\u30fc\u30bf\u30e2\u30c7\u30eb","text":"<p>Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u4e2d\u5fc3\u3068\u306a\u308b\u30c7\u30fc\u30bf\u30e2\u30c7\u30eb\u306f\u968e\u5c64\u7684\u306b\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\uff1a</p> <pre><code>BaseChannel (\u57fa\u5e95\u30af\u30e9\u30b9)\n \u251c\u2500\u2500 Channel (\u6642\u9593\u9818\u57df\u4fe1\u53f7)\n \u2502    \u2514\u2500\u2500 FrequencyChannel (\u5468\u6ce2\u6570\u9818\u57df\u4fe1\u53f7)\n \u2502         \u2514\u2500\u2500 TimeFrequencyChannel (\u6642\u9593-\u5468\u6ce2\u6570\u9818\u57df\u4fe1\u53f7)\n \u2514\u2500\u2500 ChannelFrame (\u8907\u6570\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u30b3\u30f3\u30c6\u30ca)\n      \u251c\u2500\u2500 FileFrame (\u30d5\u30a1\u30a4\u30eb\u30d9\u30fc\u30b9\u306e\u8907\u6570\u30c1\u30e3\u30f3\u30cd\u30eb)\n      \u2514\u2500\u2500 FrequencyChannelFrame (\u5468\u6ce2\u6570\u9818\u57df\u306e\u8907\u6570\u30c1\u30e3\u30f3\u30cd\u30eb)\n</code></pre> <p>\u5404\u30af\u30e9\u30b9\u306e\u8cac\u4efb\uff1a</p> <ul> <li>BaseChannel: \u3059\u3079\u3066\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u57fa\u5e95\u30af\u30e9\u30b9\u3002\u30c7\u30fc\u30bf\u30a2\u30af\u30bb\u30b9\u3001\u30e1\u30bf\u30c7\u30fc\u30bf\u7ba1\u7406\u306e\u57fa\u672c\u6a5f\u80fd\u3092\u63d0\u4f9b</li> <li>Channel: \u6642\u9593\u9818\u57df\u306e\u4fe1\u53f7\u30c7\u30fc\u30bf\u3068\u3001\u305d\u308c\u306b\u5bfe\u3059\u308b\u51e6\u7406\u30e1\u30bd\u30c3\u30c9\u3092\u5b9f\u88c5</li> <li>FrequencyChannel: FFT\u30d9\u30fc\u30b9\u306e\u5468\u6ce2\u6570\u9818\u57df\u30c7\u30fc\u30bf\u3068\u51e6\u7406\u3092\u5b9f\u88c5</li> <li>TimeFrequencyChannel: \u77ed\u6642\u9593\u30d5\u30fc\u30ea\u30a8\u5909\u63db\uff08STFT\uff09\u306a\u3069\u306e\u6642\u9593-\u5468\u6ce2\u6570\u9818\u57df\u8868\u73fe\u3092\u5b9f\u88c5</li> <li>ChannelFrame: \u8907\u6570\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u7ba1\u7406\u3057\u3001\u4e00\u62ec\u51e6\u7406\u3092\u53ef\u80fd\u306b\u3059\u308b\u30b3\u30f3\u30c6\u30ca</li> </ul>"},{"location":"explanation/#_5","title":"\u30c7\u30fc\u30bf\u51e6\u7406\u30d5\u30ed\u30fc","text":"<ol> <li>\u5165\u529b\u6bb5\u968e: WAV\u3084CSV\u306a\u3069\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u3089<code>Channel</code>\u307e\u305f\u306f<code>ChannelFrame</code>\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u751f\u6210</li> <li>\u51e6\u7406\u6bb5\u968e: \u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3001\u30ea\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u306a\u3069\u306e\u51e6\u7406\u3092\u9069\u7528</li> <li>\u5206\u6790\u6bb5\u968e: \u4fe1\u53f7\u306e\u7279\u6027\uff08\u30b9\u30da\u30af\u30c8\u30eb\u3001\u30ec\u30d9\u30eb\u7b49\uff09\u3092\u5206\u6790</li> <li>\u51fa\u529b\u6bb5\u968e: \u51e6\u7406\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u307e\u305f\u306f\u30b0\u30e9\u30d5\u3068\u3057\u3066\u53ef\u8996\u5316</li> </ol>"},{"location":"explanation/#_6","title":"\u5b9f\u88c5\u8a73\u7d30","text":""},{"location":"explanation/#_7","title":"\u30e1\u30e2\u30ea\u52b9\u7387","text":"<p>Wandas\u306f\u5927\u898f\u6a21\u306a\u30aa\u30fc\u30c7\u30a3\u30aa\u30c7\u30fc\u30bf\u3092\u6271\u3046\u305f\u3081\u306b\u3001\u4ee5\u4e0b\u306e\u65b9\u6cd5\u3067\u30e1\u30e2\u30ea\u52b9\u7387\u3092\u78ba\u4fdd\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ul> <li>\u9045\u5ef6\u8a55\u4fa1: \u5fc5\u8981\u306b\u306a\u308b\u307e\u3067\u8a08\u7b97\u3092\u9045\u5ef6\u3055\u305b\u308b\u4ed5\u7d44\u307f</li> <li>\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0: \u5927\u304d\u306a\u30d5\u30a1\u30a4\u30eb\u3067\u3082\u30e1\u30e2\u30ea\u306b\u5168\u3066\u8aad\u307f\u8fbc\u307e\u305a\u306b\u30a2\u30af\u30bb\u30b9</li> <li>dask\u3068H5PY: \u5927\u898f\u6a21\u30c7\u30fc\u30bf\u306e\u51e6\u7406\u306b\u9069\u3057\u305f\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u6d3b\u7528</li> </ul>"},{"location":"explanation/#_8","title":"\u4fe1\u53f7\u51e6\u7406\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0","text":"<p>Wandas\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u4fe1\u53f7\u51e6\u7406\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ul> <li>\u30c7\u30b8\u30bf\u30eb\u30d5\u30a3\u30eb\u30bf: \u30d0\u30bf\u30fc\u30ef\u30fc\u30b9\u30d5\u30a3\u30eb\u30bf\u306a\u3069\u306eIIR/FIR\u30d5\u30a3\u30eb\u30bf</li> <li>\u30b9\u30da\u30af\u30c8\u30eb\u5206\u6790: \u9ad8\u901f\u30d5\u30fc\u30ea\u30a8\u5909\u63db\uff08FFT\uff09\u306b\u57fa\u3065\u304f\u5468\u6ce2\u6570\u5206\u6790</li> <li>\u6642\u9593-\u5468\u6ce2\u6570\u5206\u6790: \u77ed\u6642\u9593\u30d5\u30fc\u30ea\u30a8\u5909\u63db\uff08STFT\uff09\u3001\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0</li> <li>\u7d71\u8a08\u7684\u5206\u6790: RMS\u3001\u30d4\u30fc\u30af\u5024\u3001\u30af\u30ec\u30b9\u30c8\u30d5\u30a1\u30af\u30bf\u30fc\u306a\u3069\u306e\u4fe1\u53f7\u7279\u6027\u306e\u8a08\u7b97</li> </ul>"},{"location":"explanation/#_9","title":"\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u8003\u616e\u4e8b\u9805","text":"<p>Wandas\u3092\u4f7f\u7528\u3059\u308b\u969b\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u95a2\u3059\u308b\u8003\u616e\u4e8b\u9805\uff1a</p> <ul> <li>\u5927\u91cf\u306e\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3059\u308b\u5834\u5408\u306f\u3001\u51e6\u7406\u3092\u30c1\u30e3\u30f3\u30af\u5358\u4f4d\u3067\u884c\u3046\u3053\u3068\u3092\u691c\u8a0e</li> <li>\u8907\u96d1\u306a\u51e6\u7406\u30c1\u30a7\u30fc\u30f3\u3092\u69cb\u7bc9\u3059\u308b\u5834\u5408\u306f\u3001\u4e2d\u9593\u7d50\u679c\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u3059\u308b\u3053\u3068\u3067\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a</li> <li>\u30de\u30eb\u30c1\u30c1\u30e3\u30f3\u30cd\u30eb\u51e6\u7406\u306f\u30de\u30eb\u30c1\u30b3\u30a2\u30d7\u30ed\u30bb\u30c3\u30b5\u3092\u52b9\u7387\u7684\u306b\u6d3b\u7528</li> </ul>"},{"location":"explanation/#_10","title":"\u5fc3\u7406\u97f3\u97ff\u30e1\u30c8\u30ea\u30af\u30b9","text":"<p>Wandas\u306f\u3001\u4eba\u9593\u306e\u77e5\u899a\u306b\u57fa\u3065\u304f\u97f3\u97ff\u4fe1\u53f7\u3092\u5206\u6790\u3059\u308b\u305f\u3081\u306e\u5fc3\u7406\u97f3\u97ff\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p> <ul> <li>\u30e9\u30a6\u30c9\u30cd\u30b9\u8a08\u7b97: ISO 532-1:2017\u306b\u6e96\u62e0\u3057\u305fZwicker\u6cd5\u306b\u3088\u308b\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u8a08\u7b97</li> </ul>"},{"location":"explanation/#_11","title":"\u53c2\u8003\u6587\u732e","text":"<ol> <li>Smith, J. O. (2011). Spectral Audio Signal Processing. W3K Publishing.</li> <li>M\u00fcller, M. (2015). Fundamentals of Music Processing: Audio, Analysis, Algorithms, Applications. Springer.</li> <li>Z\u00f6lzer, U. (2008). Digital Audio Signal Processing. Wiley.</li> </ol>"},{"location":"explanation/psychoacoustic_metrics/","title":"\u5fc3\u7406\u97f3\u97ff\u30e1\u30c8\u30ea\u30af\u30b9","text":"<p>Wandas\u306f\u3001\u4eba\u9593\u306e\u77e5\u899a\u306b\u57fa\u3065\u304f\u97f3\u97ff\u4fe1\u53f7\u3092\u5206\u6790\u3059\u308b\u305f\u3081\u306e\u5fc3\u7406\u97f3\u97ff\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u30e1\u30c8\u30ea\u30af\u30b9\u306f\u3001\u6a19\u6e96\u5316\u3055\u308c\u305f\u624b\u6cd5\u3068MoSQITo\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f7f\u7528\u3057\u3066\u8a08\u7b97\u3055\u308c\u307e\u3059\u3002</p>"},{"location":"explanation/psychoacoustic_metrics/#_2","title":"\u30e9\u30a6\u30c9\u30cd\u30b9\uff08\u975e\u5b9a\u5e38\u4fe1\u53f7\uff09","text":""},{"location":"explanation/psychoacoustic_metrics/#_3","title":"\u6982\u8981","text":"<p><code>loudness_zwtv()</code> \u30e1\u30bd\u30c3\u30c9\u306f\u3001ISO 532-1:2017\u306b\u5f93\u3063\u305fZwicker\u6cd5\u3092\u4f7f\u7528\u3057\u3066\u3001\u975e\u5b9a\u5e38\u4fe1\u53f7\u306e\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u65b9\u6cd5\u306f\u3001\u4eba\u9593\u306e\u77e5\u899a\u3068\u3088\u304f\u76f8\u95a2\u3059\u308b\u77e5\u899a\u30e9\u30a6\u30c9\u30cd\u30b9\u306e\u5c3a\u5ea6\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"explanation/psychoacoustic_metrics/#_4","title":"\u30e9\u30a6\u30c9\u30cd\u30b9\u3068\u306f\uff1f","text":"<p>\u30e9\u30a6\u30c9\u30cd\u30b9\u306f \u30bd\u30fc\u30f3\uff08sone\uff09 \u3067\u6e2c\u5b9a\u3055\u308c\u308b\u77e5\u899a\u5358\u4f4d\u3067\u3059\uff1a</p> <ul> <li>1 sone \u306f40 phon\uff08\u7d0440 dB SPL\u306e1 kHz\u7d14\u97f3\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\uff09\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u30ec\u30d9\u30eb\u306b\u76f8\u5f53</li> <li>\u30bd\u30fc\u30f3\u304c2\u500d \u306b\u306a\u308b\u3068\u3001\u77e5\u899a\u30e9\u30a6\u30c9\u30cd\u30b9\u30822\u500d\u306b\u306a\u308a\u307e\u3059</li> <li>\u95a2\u4fc2\u5f0f\uff1a\u97f3A\u306e\u30bd\u30fc\u30f3\u5024\u304c\u97f3B\u306e2\u500d\u3067\u3042\u308c\u3070\u30012\u500d\u306e\u5927\u304d\u3055\u306b\u805e\u3053\u3048\u307e\u3059</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_5","title":"\u5178\u578b\u7684\u306a\u30e9\u30a6\u30c9\u30cd\u30b9\u5024","text":"\u74b0\u5883/\u97f3\u6e90 \u304a\u304a\u3088\u305d\u306e\u30e9\u30a6\u30c9\u30cd\u30b9 \u9759\u304b\u306a\u56f3\u66f8\u9928 ~0.5-1 sone \u9759\u304b\u306a\u4f1a\u8a71 ~2-4 sones \u901a\u5e38\u306e\u4f1a\u8a71 ~4-8 sones \u8cd1\u3084\u304b\u306a\u30aa\u30d5\u30a3\u30b9 ~8-16 sones \u5927\u97f3\u91cf\u306e\u97f3\u697d ~32+ sones \u975e\u5e38\u306b\u5927\u304d\u306a\u9a12\u97f3 ~100+ sones"},{"location":"explanation/psychoacoustic_metrics/#_6","title":"\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"explanation/psychoacoustic_metrics/#_7","title":"\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9","text":"<pre><code>import wandas as wd\n\n# \u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\nsignal = wd.read_wav(\"audio.wav\")\n\n# \u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u81ea\u7531\u97f3\u5834\uff09\nloudness = signal.loudness_zwtv()\n\n# \u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u30d7\u30ed\u30c3\u30c8\nloudness.plot(title=\"\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_8","title":"\u97f3\u5834\u30bf\u30a4\u30d7\u306e\u9078\u629e","text":"<p>\u3053\u306e\u30e1\u30bd\u30c3\u30c9\u306f2\u7a2e\u985e\u306e\u97f3\u5834\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ul> <li>\u81ea\u7531\u97f3\u5834 (<code>field_type=\"free\"</code>): \u7279\u5b9a\u306e\u65b9\u5411\u304b\u3089\u5230\u6765\u3059\u308b\u97f3\uff08\u4f8b\uff1a\u30ea\u30b9\u30ca\u30fc\u306e\u524d\u65b9\u306b\u3042\u308b\u30b9\u30d4\u30fc\u30ab\u30fc\uff09</li> <li>\u62e1\u6563\u97f3\u5834 (<code>field_type=\"diffuse\"</code>): \u5168\u65b9\u5411\u304b\u3089\u5747\u4e00\u306b\u5230\u6765\u3059\u308b\u97f3\uff08\u4f8b\uff1a\u6b8b\u97ff\u5ba4\uff09</li> </ul> <pre><code># \u81ea\u7531\u97f3\u5834\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\nloudness_free = signal.loudness_zwtv(field_type=\"free\")\n\n# \u62e1\u6563\u97f3\u5834\nloudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_9","title":"\u30e1\u30bd\u30c3\u30c9\u30b7\u30b0\u30cd\u30c1\u30e3","text":"<pre><code>def loudness_zwtv(self, field_type: str = \"free\") -&gt; ChannelFrame:\n    \"\"\"\n    Zwicker\u6cd5\u3092\u4f7f\u7528\u3057\u3066\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\n\n    Parameters\n    ----------\n    field_type : str, default=\"free\"\n        \u97f3\u5834\u306e\u30bf\u30a4\u30d7\uff08'free' \u307e\u305f\u306f 'diffuse'\uff09\n\n    Returns\n    -------\n    ChannelFrame\n        \u30bd\u30fc\u30f3\u5358\u4f4d\u306e\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\n    \"\"\"\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_10","title":"\u51fa\u529b","text":"<p>\u3053\u306e\u30e1\u30bd\u30c3\u30c9\u306f\u4ee5\u4e0b\u3092\u542b\u3080 <code>ChannelFrame</code> \u3092\u8fd4\u3057\u307e\u3059\uff1a</p> <ul> <li>\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\uff08\u30bd\u30fc\u30f3\u5358\u4f4d\uff09</li> <li>\u6642\u9593\u5206\u89e3\u80fd: \u7d042ms\uff080.002\u79d2\uff09</li> <li>\u30de\u30eb\u30c1\u30c1\u30e3\u30f3\u30cd\u30eb\u51e6\u7406: \u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u304c\u72ec\u7acb\u3057\u3066\u51e6\u7406\u3055\u308c\u307e\u3059</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_11","title":"\u4f7f\u7528\u4f8b","text":""},{"location":"explanation/psychoacoustic_metrics/#1","title":"\u4f8b1: \u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9","text":"<pre><code>import wandas as wd\nimport numpy as np\n\n# \u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\nsignal = wd.read_wav(\"audio.wav\")\n\n# \u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\u306f\u81ea\u7531\u97f3\u5834\uff09\nloudness = signal.loudness_zwtv()\n\n# \u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u30d7\u30ed\u30c3\u30c8\nloudness.plot(title=\"\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\uff08sone\uff09\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#2","title":"\u4f8b2: \u30c6\u30b9\u30c8\u4fe1\u53f7\u306e\u751f\u6210","text":"<pre><code>import wandas as wd\nimport numpy as np\n\n# 1 kHz \u6b63\u5f26\u6ce2\u3092\u4e2d\u7a0b\u5ea6\u306e\u30ec\u30d9\u30eb\u3067\u751f\u6210\nsignal = wd.generate_sin(freqs=[1000], duration=2.0, sampling_rate=48000)\n\n# \u7d0470 dB SPL\u306b\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\nsignal = signal * 0.063\n\n# \u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\nloudness = signal.loudness_zwtv()\n\n# \u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\nprint(f\"\u5e73\u5747\u30e9\u30a6\u30c9\u30cd\u30b9: {loudness.mean():.2f} sones\")\nprint(f\"\u6700\u5927\u30e9\u30a6\u30c9\u30cd\u30b9: {loudness.max():.2f} sones\")\nprint(f\"\u6700\u5c0f\u30e9\u30a6\u30c9\u30cd\u30b9: {loudness.min():.2f} sones\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#3","title":"\u4f8b3: \u81ea\u7531\u97f3\u5834\u3068\u62e1\u6563\u97f3\u5834\u306e\u6bd4\u8f03","text":"<pre><code>import wandas as wd\nimport matplotlib.pyplot as plt\n\n# \u4fe1\u53f7\u3092\u8aad\u307f\u8fbc\u3080\nsignal = wd.read_wav(\"audio.wav\")\n\n# \u4e21\u65b9\u306e\u97f3\u5834\u30bf\u30a4\u30d7\u3067\u8a08\u7b97\nloudness_free = signal.loudness_zwtv(field_type=\"free\")\nloudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n# \u6bd4\u8f03\u30d7\u30ed\u30c3\u30c8\nfig, axes = plt.subplots(2, 1, figsize=(12, 8))\nloudness_free.plot(ax=axes[0], title=\"\u81ea\u7531\u97f3\u5834\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\")\nloudness_diffuse.plot(ax=axes[1], title=\"\u62e1\u6563\u97f3\u5834\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#4","title":"\u4f8b4: \u30de\u30eb\u30c1\u30c1\u30e3\u30f3\u30cd\u30eb\u51e6\u7406","text":"<pre><code>import wandas as wd\n\n# \u30b9\u30c6\u30ec\u30aa\u97f3\u58f0\u3092\u8aad\u307f\u8fbc\u3080\nstereo_signal = wd.read_wav(\"stereo_audio.wav\")\n\n# \u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u304c\u72ec\u7acb\u3057\u3066\u51e6\u7406\u3055\u308c\u308b\uff09\nloudness = stereo_signal.loudness_zwtv()\n\n# \u500b\u3005\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u306b\u30a2\u30af\u30bb\u30b9\nleft_loudness = loudness[0]\nright_loudness = loudness[1]\n\n# \u4e21\u65b9\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u30d7\u30ed\u30c3\u30c8\nloudness.plot(overlay=True, title=\"\u30b9\u30c6\u30ec\u30aa\u30e9\u30a6\u30c9\u30cd\u30b9\u6bd4\u8f03\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#5-mosqito","title":"\u4f8b5: MoSQITo\u3092\u76f4\u63a5\u4f7f\u7528","text":"<p>\u3088\u308a\u8a73\u7d30\u306a\u51fa\u529b\uff08\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9\u3001\u30d0\u30fc\u30af\u8ef8\u306a\u3069\uff09\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u3001MoSQITo\u3092\u76f4\u63a5\u4f7f\u7528\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>from mosqito.sq_metrics.loudness.loudness_zwtv import loudness_zwtv\nimport wandas as wd\n\nsignal = wd.read_wav(\"audio.wav\")\ndata = signal.data[0]  # \u6700\u521d\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u53d6\u5f97\n\n# MoSQITo\u3092\u76f4\u63a5\u547c\u3073\u51fa\u3059\nN, N_spec, bark_axis, time_axis = loudness_zwtv(\n    data, signal.sampling_rate, field_type=\"free\"\n)\n\nprint(f\"\u30e9\u30a6\u30c9\u30cd\u30b9\u306e\u5f62\u72b6: {N.shape}\")\nprint(f\"\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9\u306e\u5f62\u72b6: {N_spec.shape}\")\nprint(f\"\u6642\u9593\u8ef8: {time_axis[:10]}...\")  # \u6700\u521d\u306e10\u500b\u306e\u6642\u9593\u70b9\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_12","title":"\u6280\u8853\u7684\u8a73\u7d30","text":""},{"location":"explanation/psychoacoustic_metrics/#_13","title":"\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0","text":"<p>\u3053\u306e\u5b9f\u88c5\u306f\u3001MoSQITo\u306e <code>loudness_zwtv</code> \u95a2\u6570\u3092\u4f7f\u7528\u3057\u3066\u304a\u308a\u3001\u4ee5\u4e0b\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ol> <li>\u5916\u8033\u4f1d\u9054\u95a2\u6570: \u5916\u8033\u306e\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u52b9\u679c\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8</li> <li>\u4e2d\u8033\u4f1d\u9054\u95a2\u6570: \u4e2d\u8033\u306e\u4f1d\u9054\u3092\u30e2\u30c7\u30eb\u5316</li> <li>\u52b1\u8d77\u30d1\u30bf\u30fc\u30f3: \u57fa\u5e95\u819c\u306b\u6cbf\u3063\u305f\u52b1\u8d77\u3092\u8a08\u7b97</li> <li>\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9: \u5404\u81e8\u754c\u5e2f\u57df\u3067\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u6c7a\u5b9a</li> <li>\u7dcf\u30e9\u30a6\u30c9\u30cd\u30b9: \u3059\u3079\u3066\u306e\u81e8\u754c\u5e2f\u57df\u306b\u308f\u305f\u3063\u3066\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u7a4d\u5206</li> </ol>"},{"location":"explanation/psychoacoustic_metrics/#_14","title":"\u6642\u9593\u5206\u89e3\u80fd","text":"<p>\u30e9\u30a6\u30c9\u30cd\u30b9\u8a08\u7b97\u306f\u7d042ms\u306e\u6642\u9593\u5206\u89e3\u80fd\u3067\u5024\u3092\u751f\u6210\u3057\u307e\u3059\u30021\u79d2\u306e\u4fe1\u53f7\u306b\u5bfe\u3057\u3066\u3001\u7d04500\u500b\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\u304c\u671f\u5f85\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"explanation/psychoacoustic_metrics/#_15","title":"\u8a08\u7b97\u306e\u8907\u96d1\u3055","text":"<ul> <li>\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u52b9\u7387\u6027\u306e\u305f\u3081\u30d6\u30ed\u30c3\u30af\u5358\u4f4d\u3067\u4fe1\u53f7\u3092\u51e6\u7406\u3057\u307e\u3059</li> <li>\u51e6\u7406\u6642\u9593\u306f\u4fe1\u53f7\u306e\u9577\u3055\u306b\u5bfe\u3057\u3066\u7dda\u5f62\u306b\u30b9\u30b1\u30fc\u30eb\u3057\u307e\u3059</li> <li>\u30e1\u30e2\u30ea\u4f7f\u7528\u91cf\u306f\u4e2d\u7a0b\u5ea6\uff08\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\u3092\u4fdd\u5b58\uff09</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_16","title":"\u5236\u9650\u4e8b\u9805","text":"<ol> <li>\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8: 44.1 kHz\u4ee5\u4e0a\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u3067\u6700\u826f\u306e\u7d50\u679c\u304c\u5f97\u3089\u308c\u307e\u3059</li> <li>\u4fe1\u53f7\u30ec\u30d9\u30eb: \u53ef\u8074\u7bc4\u56f2\u5185\u306e\u4fe1\u53f7\uff08\u901a\u5e3820-100 dB SPL\uff09\u3067\u6b63\u78ba\u3067\u3059</li> <li>\u5b9a\u5e38\u6027\u306e\u4eee\u5b9a: \u975e\u5b9a\u5e38\u4fe1\u53f7\u7528\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u6975\u7aef\u306b\u6025\u6fc0\u306a\u904e\u6e21\u73fe\u8c61\u306f\u5b8c\u5168\u306b\u306f\u6349\u3048\u3089\u308c\u306a\u3044\u5834\u5408\u304c\u3042\u308a\u307e\u3059</li> <li>\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3: \u7269\u7406\u5358\u4f4d\uff08Pa\uff09\u3078\u306e\u9069\u5207\u306a\u4fe1\u53f7\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u524d\u63d0\u3068\u3057\u3066\u3044\u307e\u3059</li> </ol>"},{"location":"explanation/psychoacoustic_metrics/#_17","title":"\u6a19\u6e96\u3068\u53c2\u8003\u6587\u732e","text":"<ul> <li>ISO 532-1:2017: \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</li> <li>Zwicker, E., &amp; Fastl, H. (1999): Psychoacoustics: Facts and models (2nd ed.). Springer.</li> <li>MoSQITo\u30e9\u30a4\u30d6\u30e9\u30ea: https://mosqito.readthedocs.io/en/latest/</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_18","title":"\u30e9\u30a6\u30c9\u30cd\u30b9\uff08\u5b9a\u5e38\u4fe1\u53f7\uff09","text":""},{"location":"explanation/psychoacoustic_metrics/#_19","title":"\u6982\u8981","text":"<p><code>loudness_zwst()</code> \u30e1\u30bd\u30c3\u30c9\u306f\u3001ISO 532-1:2017\u306b\u5f93\u3063\u305fZwicker\u6cd5\u3092\u4f7f\u7528\u3057\u3066\u3001\u5b9a\u5e38\u4fe1\u53f7\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u30e1\u30bd\u30c3\u30c9\u306f\u3001\u30d5\u30a1\u30f3\u30ce\u30a4\u30ba\u3001\u5b9a\u5e38\u7684\u306a\u6a5f\u68b0\u97f3\u306a\u3069\u306e\u6301\u7d9a\u7684\u306a\u97f3\u306e\u8a55\u4fa1\u306b\u9069\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"explanation/psychoacoustic_metrics/#_20","title":"\u975e\u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3068\u306e\u9055\u3044","text":"\u7279\u6027 \u6642\u9593\u5909\u5316\uff08<code>loudness_zwtv</code>\uff09 \u5b9a\u5e38\uff08<code>loudness_zwst</code>\uff09 \u5bfe\u8c61\u4fe1\u53f7 \u975e\u5b9a\u5e38\uff08\u6642\u9593\u5909\u5316\u3059\u308b\u97f3\uff09 \u5b9a\u5e38\uff08\u6301\u7d9a\u7684\u306a\u97f3\uff09 \u4f7f\u7528\u4f8b \u97f3\u58f0\u3001\u97f3\u697d\u3001\u904e\u6e21\u97f3 \u30d5\u30a1\u30f3\u30ce\u30a4\u30ba\u3001\u5b9a\u5e38\u6a5f\u68b0\u97f3 \u51fa\u529b \u6642\u7cfb\u5217\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u5024 \u5358\u4e00\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u5024 \u51fa\u529b\u5f62\u72b6 (channels, time_samples) (n_channels,) \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8 ~500 Hz\u306b\u66f4\u65b0 \u5909\u66f4\u306a\u3057\uff08\u5358\u4e00\u5024\uff09"},{"location":"explanation/psychoacoustic_metrics/#_21","title":"\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"explanation/psychoacoustic_metrics/#_22","title":"\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9","text":"<pre><code>import wandas as wd\n\n# \u5b9a\u5e38\u4fe1\u53f7\u3092\u8aad\u307f\u8fbc\u3080\uff08\u30d5\u30a1\u30f3\u30ce\u30a4\u30ba\u306a\u3069\uff09\nsignal = wd.read_wav(\"fan_noise.wav\")\n\n# \u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u81ea\u7531\u97f3\u5834\uff09\nloudness = signal.loudness_zwst()\n\n# \u7d50\u679c\u3092\u8868\u793a\nprint(f\"\u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9: {loudness[0]:.2f} sones\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_23","title":"\u97f3\u5834\u30bf\u30a4\u30d7\u306e\u9078\u629e","text":"<p>\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3068\u540c\u69d8\u306b\u30012\u7a2e\u985e\u306e\u97f3\u5834\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\uff1a</p> <pre><code># \u81ea\u7531\u97f3\u5834\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\nloudness_free = signal.loudness_zwst(field_type=\"free\")\n\n# \u62e1\u6563\u97f3\u5834\nloudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n\nprint(f\"\u81ea\u7531\u97f3\u5834: {loudness_free[0]:.2f} sones\")\nprint(f\"\u62e1\u6563\u97f3\u5834: {loudness_diffuse[0]:.2f} sones\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_24","title":"\u30e1\u30bd\u30c3\u30c9\u30b7\u30b0\u30cd\u30c1\u30e3","text":"<pre><code>def loudness_zwst(self, field_type: str = \"free\") -&gt; NDArrayReal:\n    \"\"\"\n    Zwicker\u6cd5\u3092\u4f7f\u7528\u3057\u3066\u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\n\n    Parameters\n    ----------\n    field_type : str, default=\"free\"\n        \u97f3\u5834\u306e\u30bf\u30a4\u30d7\uff08'free' \u307e\u305f\u306f 'diffuse'\uff09\n\n    Returns\n    -------\n    NDArrayReal\n        \u30bd\u30fc\u30f3\u5358\u4f4d\u306e\u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\uff08\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u3054\u3068\u306b1\u3064\u306e\u5024\uff09\n        \u5f62\u72b6: (n_channels,)\n    \"\"\"\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_25","title":"\u51fa\u529b","text":"<p>\u3053\u306e\u30e1\u30bd\u30c3\u30c9\u306f\u4ee5\u4e0b\u3092\u542b\u3080 <code>NDArrayReal</code> \u3092\u8fd4\u3057\u307e\u3059\uff1a</p> <ul> <li>\u5358\u4e00\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\uff08\u30bd\u30fc\u30f3\u5358\u4f4d\u3001\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u3054\u3068\uff09</li> <li>\u51fa\u529b\u5f62\u72b6: (n_channels,) - 1D\u914d\u5217</li> <li>\u30de\u30eb\u30c1\u30c1\u30e3\u30f3\u30cd\u30eb\u51e6\u7406: \u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u304c\u72ec\u7acb\u3057\u3066\u51e6\u7406\u3055\u308c\u307e\u3059</li> <li>NumPy\u4e92\u63db: \u76f4\u63a5NumPy\u64cd\u4f5c\u304c\u53ef\u80fd\uff08<code>loudness[0]</code>, <code>loudness.mean()</code>\u306a\u3069\uff09</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_26","title":"\u4f7f\u7528\u4f8b","text":""},{"location":"explanation/psychoacoustic_metrics/#1_1","title":"\u4f8b1: \u30d5\u30a1\u30f3\u30ce\u30a4\u30ba\u306e\u8a55\u4fa1","text":"<pre><code>import wandas as wd\n\n# \u30d5\u30a1\u30f3\u30ce\u30a4\u30ba\u3092\u8aad\u307f\u8fbc\u3080\nfan_signal = wd.read_wav(\"fan_noise.wav\")\n\n# \u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\nloudness = fan_signal.loudness_zwst(field_type=\"free\")\n\n# \u7d50\u679c\u3092\u8868\u793a\nprint(f\"\u30d5\u30a1\u30f3\u30ce\u30a4\u30ba\u306e\u30e9\u30a6\u30c9\u30cd\u30b9: {loudness[0]:.2f} sones\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#2_1","title":"\u4f8b2: \u8907\u6570\u306e\u5b9a\u5e38\u97f3\u6e90\u306e\u6bd4\u8f03","text":"<pre><code>import wandas as wd\n\n# \u7570\u306a\u308b\u5b9a\u5e38\u97f3\u6e90\u3092\u8aad\u307f\u8fbc\u3080\nfan1 = wd.read_wav(\"fan1.wav\")\nfan2 = wd.read_wav(\"fan2.wav\")\n\n# \u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\nloudness1 = fan1.loudness_zwst()\nloudness2 = fan2.loudness_zwst()\n\n# \u6bd4\u8f03\nprint(f\"Fan 1: {loudness1[0]:.2f} sones\")\nprint(f\"Fan 2: {loudness2[0]:.2f} sones\")\n\nif loudness1[0] &gt; loudness2[0]:\n    print(\"Fan 1 is louder\")\nelse:\n    print(\"Fan 2 is louder\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#3_1","title":"\u4f8b3: \u30b9\u30c6\u30ec\u30aa\u5b9a\u5e38\u97f3\u6e90\u306e\u51e6\u7406","text":"<pre><code>import wandas as wd\n\n# \u30b9\u30c6\u30ec\u30aa\u306e\u5b9a\u5e38\u97f3\u6e90\u3092\u8aad\u307f\u8fbc\u3080\nstereo_signal = wd.read_wav(\"stereo_steady_noise.wav\")\n\n# \u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u72ec\u7acb\uff09\nloudness = stereo_signal.loudness_zwst()\n\n# \u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u7d50\u679c\u3092\u8868\u793a\nprint(f\"\u5de6\u30c1\u30e3\u30f3\u30cd\u30eb: {loudness[0]:.2f} sones\")\nprint(f\"\u53f3\u30c1\u30e3\u30f3\u30cd\u30eb: {loudness[1]:.2f} sones\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#4_1","title":"\u4f8b4: \u81ea\u7531\u97f3\u5834\u3068\u62e1\u6563\u97f3\u5834\u306e\u6bd4\u8f03","text":"<pre><code>import wandas as wd\n\n# \u5b9a\u5e38\u4fe1\u53f7\u3092\u8aad\u307f\u8fbc\u3080\nsignal = wd.read_wav(\"steady_noise.wav\")\n\n# \u4e21\u65b9\u306e\u97f3\u5834\u30bf\u30a4\u30d7\u3067\u8a08\u7b97\nloudness_free = signal.loudness_zwst(field_type=\"free\")\nloudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n\n# \u6bd4\u8f03\nprint(f\"\u81ea\u7531\u97f3\u5834: {loudness_free[0]:.2f} sones\")\nprint(f\"\u62e1\u6563\u97f3\u5834: {loudness_diffuse[0]:.2f} sones\")\nprint(f\"\u5dee: {abs(loudness_free[0] - loudness_diffuse[0]):.2f} sones\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#5-mosqito_1","title":"\u4f8b5: MoSQITo\u3092\u76f4\u63a5\u4f7f\u7528","text":"<p>\u3088\u308a\u8a73\u7d30\u306a\u51fa\u529b\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u3001MoSQITo\u3092\u76f4\u63a5\u4f7f\u7528\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>from mosqito.sq_metrics.loudness.loudness_zwst import loudness_zwst\nimport wandas as wd\n\nsignal = wd.read_wav(\"steady_noise.wav\")\ndata = signal.data[0]  # \u6700\u521d\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u53d6\u5f97\n\n# MoSQITo\u3092\u76f4\u63a5\u547c\u3073\u51fa\u3059\nN, N_spec, bark_axis = loudness_zwst(\n    data, signal.sampling_rate, field_type=\"free\"\n)\n\nprint(f\"\u30e9\u30a6\u30c9\u30cd\u30b9: {N:.2f} sones\")\nprint(f\"\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9\u306e\u5f62\u72b6: {N_spec.shape}\")\nprint(f\"\u30d0\u30fc\u30af\u8ef8: {bark_axis}\")\n</code></pre>"},{"location":"explanation/psychoacoustic_metrics/#_27","title":"\u6280\u8853\u7684\u8a73\u7d30","text":""},{"location":"explanation/psychoacoustic_metrics/#_28","title":"\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0","text":"<p>\u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u306e\u8a08\u7b97\u306f\u3001\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3068\u540c\u3058Zwicker\u6cd5\u306b\u57fa\u3065\u3044\u3066\u3044\u307e\u3059\u304c\u3001\u5358\u4e00\u306e\u4ee3\u8868\u5024\u3092\u51fa\u529b\u3057\u307e\u3059\uff1a</p> <ol> <li>\u5916\u8033\u4f1d\u9054\u95a2\u6570: \u5916\u8033\u306e\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u52b9\u679c\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8</li> <li>\u4e2d\u8033\u4f1d\u9054\u95a2\u6570: \u4e2d\u8033\u306e\u4f1d\u9054\u3092\u30e2\u30c7\u30eb\u5316</li> <li>\u52b1\u8d77\u30d1\u30bf\u30fc\u30f3: \u57fa\u5e95\u819c\u306b\u6cbf\u3063\u305f\u52b1\u8d77\u3092\u8a08\u7b97</li> <li>\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9: \u5404\u81e8\u754c\u5e2f\u57df\u3067\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u6c7a\u5b9a</li> <li>\u7dcf\u30e9\u30a6\u30c9\u30cd\u30b9: \u3059\u3079\u3066\u306e\u81e8\u754c\u5e2f\u57df\u306b\u308f\u305f\u3063\u3066\u7279\u5b9a\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u7a4d\u5206</li> </ol>"},{"location":"explanation/psychoacoustic_metrics/#_29","title":"\u8a08\u7b97\u306e\u8907\u96d1\u3055","text":"<ul> <li>\u5b9a\u5e38\u4fe1\u53f7\u3092\u60f3\u5b9a\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3088\u308a\u3082\u8a08\u7b97\u304c\u7c21\u7565\u5316\u3055\u308c\u307e\u3059</li> <li>\u51e6\u7406\u6642\u9593\u306f\u4fe1\u53f7\u306e\u9577\u3055\u306b\u4f9d\u5b58\u3057\u307e\u3059\u304c\u3001\u5358\u4e00\u306e\u5024\u306e\u307f\u3092\u51fa\u529b\u3057\u307e\u3059</li> <li>\u30e1\u30e2\u30ea\u4f7f\u7528\u91cf\u306f\u5c0f\u3055\u3044\uff08\u5358\u4e00\u306e\u30e9\u30a6\u30c9\u30cd\u30b9\u5024\u306e\u307f\u3092\u4fdd\u5b58\uff09</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_30","title":"\u5236\u9650\u4e8b\u9805","text":"<ol> <li>\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8: 44.1 kHz\u4ee5\u4e0a\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u3067\u6700\u826f\u306e\u7d50\u679c\u304c\u5f97\u3089\u308c\u307e\u3059</li> <li>\u4fe1\u53f7\u30ec\u30d9\u30eb: \u53ef\u8074\u7bc4\u56f2\u5185\u306e\u4fe1\u53f7\uff08\u901a\u5e3820-100 dB SPL\uff09\u3067\u6b63\u78ba\u3067\u3059</li> <li>\u5b9a\u5e38\u6027\u306e\u4eee\u5b9a: \u3053\u306e\u30e1\u30bd\u30c3\u30c9\u306f\u5b9a\u5e38\u4fe1\u53f7\u7528\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u6642\u9593\u5909\u5316\u3059\u308b\u4fe1\u53f7\u306b\u306f <code>loudness_zwtv()</code> \u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044</li> <li>\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3: \u7269\u7406\u5358\u4f4d\uff08Pa\uff09\u3078\u306e\u9069\u5207\u306a\u4fe1\u53f7\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u524d\u63d0\u3068\u3057\u3066\u3044\u307e\u3059</li> </ol>"},{"location":"explanation/psychoacoustic_metrics/#_31","title":"\u6a19\u6e96\u3068\u53c2\u8003\u6587\u732e","text":"<ul> <li>ISO 532-1:2017: \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</li> <li>Zwicker, E., &amp; Fastl, H. (1999): Psychoacoustics: Facts and models (2nd ed.). Springer.</li> <li>MoSQITo\u30e9\u30a4\u30d6\u30e9\u30ea: https://mosqito.readthedocs.io/en/latest/</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_32","title":"\u95a2\u9023\u3059\u308b\u64cd\u4f5c","text":"<ul> <li><code>loudness_zwtv()</code>: \u6642\u9593\u5909\u5316\u3059\u308b\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u975e\u5b9a\u5e38\u4fe1\u53f7\u7528\uff09</li> <li><code>loudness_zwst()</code>: \u5b9a\u5e38\u30e9\u30a6\u30c9\u30cd\u30b9\u3092\u8a08\u7b97\uff08\u5b9a\u5e38\u4fe1\u53f7\u7528\uff09</li> <li><code>a_weighting()</code>: A\u7279\u6027\u30d5\u30a3\u30eb\u30bf\u3092\u9069\u7528\uff08\u4eba\u9593\u306e\u8074\u899a\u3092\u8fd1\u4f3c\u3059\u308b\u5468\u6ce2\u6570\u91cd\u307f\u4ed8\u3051\uff09</li> <li><code>noct_spectrum()</code>: N\u30aa\u30af\u30bf\u30fc\u30d6\u30d0\u30f3\u30c9\u30b9\u30da\u30af\u30c8\u30eb\u3092\u8a08\u7b97</li> <li><code>rms_trend()</code>: \u6642\u9593\u306b\u6cbf\u3063\u305fRMS\u30c8\u30ec\u30f3\u30c9\u3092\u8a08\u7b97</li> </ul>"},{"location":"explanation/psychoacoustic_metrics/#_33","title":"\u53c2\u7167","text":"<ul> <li>MoSQITo Documentation</li> <li>ISO 532-1:2017 Standard</li> <li>Psychoacoustics Fundamentals</li> </ul>"},{"location":"tutorial/","title":"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb","text":"<p>\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\u30925\u5206\u3067\u5b66\u3079\u307e\u3059\u3002</p>"},{"location":"tutorial/#_2","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code>pip install git+https://github.com/endolith/waveform-analysis.git@master\npip install wandas\n</code></pre>"},{"location":"tutorial/#_3","title":"\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9","text":""},{"location":"tutorial/#1","title":"1. \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","text":"<pre><code>import wandas as wd\n</code></pre>"},{"location":"tutorial/#2","title":"2. \u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f","text":"<pre><code># URL\u304b\u3089\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\nurl = \"https://github.com/kasahart/wandas/raw/main/examples/data/summer_streets1.wav\"\n\naudio = wd.read_wav(url)\nprint(f\"\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8: {audio.sampling_rate} Hz\")\nprint(f\"\u30c1\u30e3\u30f3\u30cd\u30eb\u6570: {audio.n_channels}\")\nprint(f\"\u9577\u3055: {audio.duration} s\")\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: session wd_demo; n3&gt;\", line 4, in &lt;module&gt;\n    audio = wd.read_wav(url)\n  File \"/home/runner/work/wandas/wandas/wandas/io/wav_io.py\", line 44, in read_wav\n    sampling_rate, data = wavfile.read(file_obj)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/scipy/io/wavfile.py\", line 677, in read\n    file_size, is_big_endian, is_rf64 = _read_riff_chunk(fid)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/scipy/io/wavfile.py\", line 536, in _read_riff_chunk\n    raise ValueError(f\"File format {repr(str1)} not understood. Only \"\nValueError: File format b'\\n\\n\\n\\n' not understood. Only 'RIFF', 'RIFX', and 'RF64' supported.\n</code></pre>"},{"location":"tutorial/#3","title":"3. \u4fe1\u53f7\u306e\u53ef\u8996\u5316","text":"<pre><code># \u6ce2\u5f62\u3092\u8868\u793a\naudio.describe()\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: session wd_demo; n4&gt;\", line 1, in &lt;module&gt;\n    audio.describe(is_close=False)\nNameError: name 'audio' is not defined\n</code></pre>"},{"location":"tutorial/#4","title":"4. \u57fa\u672c\u7684\u306a\u4fe1\u53f7\u51e6\u7406","text":"<pre><code># \u30ed\u30fc\u30d1\u30b9\u30d5\u30a3\u30eb\u30bf\u3092\u9069\u7528\uff081kHz\u4ee5\u4e0b\u306e\u5468\u6ce2\u6570\u3092\u901a\u904e\uff09\nfiltered = audio.low_pass_filter(cutoff=1000)\n\n# \u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u3066\u6bd4\u8f03\nfiltered.previous.plot(title=\"Original\")\nfiltered.plot(title=\"filtered\")\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: session wd_demo; n5&gt;\", line 1, in &lt;module&gt;\n    filtered = audio.low_pass_filter(cutoff=1000)\nNameError: name 'audio' is not defined\n</code></pre>"},{"location":"tutorial/#_4","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 \u3067\u8a73\u7d30\u306a\u6a5f\u80fd\u3092\u8abf\u3079\u308b</li> <li>\u7406\u8ad6\u80cc\u666f \u3067\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8a2d\u8a08\u601d\u60f3\u3092\u7406\u89e3\u3059\u308b</li> </ul>"},{"location":"tutorial/#_5","title":"\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u5225\u30ec\u30b7\u30d4","text":"<p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001Wandas\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u3088\u308a\u8a73\u7d30\u306a\u6a5f\u80fd\u3084\u5fdc\u7528\u4f8b\u3092\u3001\u4ee5\u4e0b\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u901a\u3058\u3066\u5b66\u3076\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <ul> <li>00_setup.ipynb: \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3068\u57fa\u672c\u7684\u306a\u8a2d\u5b9a</li> <li>01_io_basics.ipynb: \u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u66f8\u304d\u3068\u57fa\u672c\u7684\u306a\u64cd\u4f5c</li> <li>02_signal_processing_basics.ipynb:\u57fa\u672c\u7684\u306a\u4fe1\u53f7\u51e6\u7406</li> <li>03_visualization.ipynb: \u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316</li> <li>04_time_frequency.ipynb: \u6642\u9593\u5468\u6ce2\u6570\u5206\u6790</li> <li>05_lazy_and_dask.ipynb: \u9045\u5ef6\u8a55\u4fa1\u3068Dask\u306b\u3088\u308b\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u51e6\u7406</li> <li>06_metadata_history.ipynb: \u30e1\u30bf\u30c7\u30fc\u30bf\u3068\u51e6\u7406\u5c65\u6b74\u306e\u6d3b\u7528</li> <li>07_batch_processing.ipynb: \u8907\u6570\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u4e00\u62ec\u51e6\u7406</li> <li>08_frame_dataset_usage.ipynb: FrameDataset \u4f7f\u7528\u30ac\u30a4\u30c9 - \u30d5\u30a9\u30eb\u30c0\u5185\u306e\u8907\u6570\u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u306e\u52b9\u7387\u7684\u306a\u51e6\u7406</li> <li>09_extending_api.ipynb: \u30ab\u30b9\u30bf\u30e0\u95a2\u6570\u306e\u8ffd\u52a0\u3068API\u306e\u62e1\u5f35</li> <li>10_interoperability.ipynb: \u4ed6\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e\u9023\u643a</li> <li>11_case_studies.ipynb: \u5b9f\u8df5\u7684\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u30b9\u30bf\u30c7\u30a3</li> </ul> <p>\u30d2\u30f3\u30c8</p> <p>\u5404\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306f\u7279\u5b9a\u306e\u30c8\u30d4\u30c3\u30af\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002\u8208\u5473\u306e\u3042\u308b\u3082\u306e\u304b\u3089\u9806\u306b\u3001\u307e\u305f\u306f\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002Wandas\u306e\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\u306b\u3064\u3044\u3066\u306f\u3001\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u5192\u982d\u90e8\u5206\u3082\u5408\u308f\u305b\u3066\u3054\u89a7\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"en/","title":"Wandas: Waveform Analysis Data Structures","text":"<p>Wandas is an open-source library for efficient signal analysis in Python. Wandas provides comprehensive functionality for signal processing and seamless integration with Matplotlib.</p>"},{"location":"en/#features","title":"Features","text":"<ul> <li>Comprehensive Signal Processing Functions: Easily perform basic signal processing operations including filtering, Fourier transforms, and STFT</li> <li>Integration with Visualization Libraries: Seamlessly integrate with Matplotlib for easy data visualization</li> <li>Lazy Evaluation: Efficiently process large data using dask</li> <li>Various Analysis Tools: Frequency analysis, octave band analysis, time-frequency analysis, and more</li> </ul>"},{"location":"en/#usage-examples","title":"Usage Examples","text":""},{"location":"en/#loading-and-visualizing-audio-files","title":"Loading and Visualizing Audio Files","text":"<pre><code>import wandas as wd\n\ncf = wd.read_wav(\"data/sample.wav\")\ncf.describe()\n</code></pre>"},{"location":"en/#filtering","title":"Filtering","text":"<pre><code>signal = wd.generate_sin(freqs=[5000, 1000], duration=1)\n# Apply low pass filter\nsignal.low_pass_filter(cutoff=1000).fft().plot()\n</code></pre> <p>For detailed documentation and usage examples, see the Tutorial.</p>"},{"location":"en/#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Tutorial - 5-minute getting started guide and recipe collection for common tasks</li> <li>API Reference - Detailed API specifications</li> <li>Theory &amp; Architecture - Design philosophy and algorithm explanations</li> <li>Contributing Guide - Rules and methods for contribution</li> </ul>"},{"location":"en/#next-steps","title":"Next Steps","text":"<ul> <li>Explore detailed features in the API Reference</li> <li>Understand the library's design philosophy in the Explanation</li> <li>See Contributing Guidelines if you want to contribute.</li> </ul>"},{"location":"en/#for-more-information","title":"For More Information","text":"<ul> <li>Visit the Wandas GitHub Repository for source code and issues</li> <li>Check the Wandas Documentation for hosted documentation</li> <li>Join the Wandas Discussion Forum for community support and discussions</li> </ul>"},{"location":"en/api/","title":"API Reference","text":"<p>API reference for the main components and functions of the Wandas library.</p>"},{"location":"en/api/#core-module","title":"Core Module","text":"<p>The core module provides the basic functionality of Wandas.</p>"},{"location":"en/api/#wandas.core.BaseFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n):\n    self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n    if self._data.ndim == 1:\n        self._data = self._data.reshape((1, -1))\n    self.sampling_rate = sampling_rate\n    self.label = label or \"unnamed_frame\"\n    self.metadata = metadata or {}\n    self.operation_history = operation_history or []\n    self._previous = previous\n\n    if channel_metadata:\n        # Pydantic handles both ChannelMetadata objects and dicts\n        def _to_channel_metadata(\n            ch: ChannelMetadata | dict[str, Any], index: int\n        ) -&gt; ChannelMetadata:\n            if isinstance(ch, ChannelMetadata):\n                return copy.deepcopy(ch)\n            elif isinstance(ch, dict):\n                try:\n                    return ChannelMetadata(**ch)\n                except ValidationError as e:\n                    raise ValueError(\n                        f\"Invalid channel_metadata at index {index}\\n\"\n                        f\"  Got: {ch}\\n\"\n                        f\"  Validation error: {e}\\n\"\n                        f\"Ensure all dict keys match ChannelMetadata fields \"\n                        f\"(label, unit, ref, extra) and have correct types.\"\n                    ) from e\n            else:\n                raise TypeError(\n                    f\"Invalid type in channel_metadata at index {index}\\n\"\n                    f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                    f\"  Expected: ChannelMetadata or dict\\n\"\n                    f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                )\n\n        self._channel_metadata = [\n            _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n            for i, ch in enumerate(channel_metadata)\n        ]\n    else:\n        self._channel_metadata = [\n            ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n            for i in range(self._n_channels)\n        ]\n\n    try:\n        # Display information for newer dask versions\n        logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n        logger.debug(\n            f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n        )\n    except Exception as e:\n        logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.get_channel--examples","title":"Examples","text":"<p>frame.get_channel(0)  # Single channel frame.get_channel([0, 2, 3])  # Multiple channels frame.get_channel((-1, -2))  # Last two channels frame.get_channel(np.array([1, 2]))  # NumPy array of indices</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def get_channel(\n    self: S,\n    channel_idx: int\n    | list[int]\n    | tuple[int, ...]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index.\n\n    Parameters\n    ----------\n    channel_idx : int or sequence of int\n        Single channel index or sequence of channel indices.\n        Supports negative indices (e.g., -1 for the last channel).\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n    &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n    &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n    &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n    \"\"\"\n    if isinstance(channel_idx, int):\n        # Convert single channel to a list.\n        channel_idx_list: list[int] = [channel_idx]\n    else:\n        channel_idx_list = list(channel_idx)\n\n    new_data = self._data[channel_idx_list]\n    new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n    return self._create_new_instance(\n        data=new_data,\n        operation_history=self.operation_history,\n        channel_metadata=new_channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of channels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of channels.\n    \"\"\"\n    return len(self._channel_metadata)\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__iter__","title":"<code>__iter__()</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __iter__(self: S) -&gt; Iterator[S]:\n    for idx in range(len(self)):\n        yield self[idx]\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__getitem__--examples","title":"Examples","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __getitem__(\n    self: S,\n    key: int\n    | str\n    | slice\n    | list[int]\n    | list[str]\n    | tuple[\n        int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n        ...,\n    ]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index, label, or advanced indexing.\n\n    This method supports multiple indexing patterns similar to NumPy and pandas:\n\n    - Single channel by index: `frame[0]`\n    - Single channel by label: `frame[\"ch0\"]`\n    - Slice of channels: `frame[0:3]`\n    - Multiple channels by indices: `frame[[0, 2, 5]]`\n    - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n    - NumPy integer array: `frame[np.array([0, 2])]`\n    - Boolean mask: `frame[mask]` where mask is a boolean array\n    - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n    Parameters\n    ----------\n    key : int, str, slice, list, tuple, or ndarray\n        - int: Single channel index (supports negative indexing)\n        - str: Single channel label\n        - slice: Range of channels\n        - list[int]: Multiple channel indices\n        - list[str]: Multiple channel labels\n        - tuple: Multidimensional indexing (channel_key, time_key, ...)\n        - ndarray[int]: NumPy array of channel indices\n        - ndarray[bool]: Boolean mask for channel selection\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Raises\n    ------\n    ValueError\n        If the key length is invalid for the shape or if boolean mask\n        length doesn't match number of channels.\n    IndexError\n        If the channel index is out of range.\n    TypeError\n        If the key type is invalid or list contains mixed types.\n    KeyError\n        If a channel label is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Single channel selection\n    &gt;&gt;&gt; frame[0]  # First channel\n    &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n    &gt;&gt;&gt; frame[-1]  # Last channel\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Multiple channel selection\n    &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n    &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n    &gt;&gt;&gt; frame[0:3]  # Slice\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # NumPy array indexing\n    &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n    &gt;&gt;&gt; mask = np.array([True, False, True])\n    &gt;&gt;&gt; frame[mask]  # Boolean mask\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Time slicing (multidimensional)\n    &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n    &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n    \"\"\"\n\n    # Single index (int)\n    if isinstance(key, numbers.Integral):\n        # Ensure we pass a plain Python int to satisfy the type checker\n        return self.get_channel(int(key))\n\n    # Single label (str)\n    if isinstance(key, str):\n        index = self.label2index(key)\n        return self.get_channel(index)\n\n    # Phase 2: NumPy array support (bool mask and int array)\n    if isinstance(key, np.ndarray):\n        if key.dtype == bool or key.dtype == np.bool_:\n            # Boolean mask\n            if len(key) != self.n_channels:\n                raise ValueError(\n                    f\"Boolean mask length {len(key)} does not match \"\n                    f\"number of channels {self.n_channels}\"\n                )\n            indices = np.where(key)[0]\n            return self.get_channel(indices)\n        elif np.issubdtype(key.dtype, np.integer):\n            # Integer array\n            return self.get_channel(key)\n        else:\n            raise TypeError(\n                f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n            )\n\n    # Phase 1: List support (int or str)\n    if isinstance(key, list):\n        if len(key) == 0:\n            raise ValueError(\"Cannot index with an empty list\")\n\n        # Check if all elements are strings\n        if all(isinstance(k, str) for k in key):\n            # Multiple labels - type narrowing for mypy\n            str_list = cast(list[str], key)\n            indices_from_labels = [self.label2index(label) for label in str_list]\n            return self.get_channel(indices_from_labels)\n\n        # Check if all elements are integers\n        elif all(isinstance(k, int | np.integer) for k in key):\n            # Multiple indices - convert to list[int] for type safety\n            int_list = [int(k) for k in key]\n            return self.get_channel(int_list)\n\n        else:\n            raise TypeError(\n                f\"List must contain all str or all int, got mixed types: \"\n                f\"{[type(k).__name__ for k in key]}\"\n            )\n\n    # Tuple: multidimensional indexing\n    if isinstance(key, tuple):\n        return self._handle_multidim_indexing(key)\n\n    # Slice\n    if isinstance(key, slice):\n        new_data = self._data[key]\n        new_channel_metadata = self._channel_metadata[key]\n        if isinstance(new_channel_metadata, ChannelMetadata):\n            new_channel_metadata = [new_channel_metadata]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    raise TypeError(\n        f\"Invalid key type: {type(key).__name__}. \"\n        f\"Expected int, str, slice, list, tuple, or ndarray.\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.label2index--raises","title":"Raises","text":"<p>KeyError     If the channel label is not found.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n\n    Parameters\n    ----------\n    label : str\n        Channel label.\n\n    Returns\n    -------\n    int\n        Corresponding index.\n\n    Raises\n    ------\n    KeyError\n        If the channel label is not found.\n    \"\"\"\n    for idx, ch in enumerate(self._channel_metadata):\n        if ch.label == label:\n            return idx\n    raise KeyError(f\"Channel label '{label}' not found.\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.compute--raises","title":"Raises","text":"<p>ValueError     If the computed result is not a NumPy array.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def compute(self) -&gt; T:\n    \"\"\"\n    Compute and return the data.\n    This method materializes lazily computed data into a concrete NumPy array.\n\n    Returns\n    -------\n    NDArrayReal\n        The computed data.\n\n    Raises\n    ------\n    ValueError\n        If the computed result is not a NumPy array.\n    \"\"\"\n    logger.debug(\n        \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n    )\n    result = self._data.compute()\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n    logger.debug(f\"Computation complete, result shape: {result.shape}\")\n    return cast(T, result)\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.plot","title":"<code>plot(plot_type='default', ax=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Plot the data</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>@abstractmethod\ndef plot(\n    self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the data\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.persist","title":"<code>persist()</code>","text":"<p>Persist the data in memory</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def persist(self: S) -&gt; S:\n    \"\"\"Persist the data in memory\"\"\"\n    persisted_data = self._data.persist()\n    return self._create_new_instance(data=persisted_data)\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__array__","title":"<code>__array__(dtype=None)</code>","text":"<p>Implicit conversion to NumPy array</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n    \"\"\"Implicit conversion to NumPy array\"\"\"\n    result = self.compute()\n    if dtype is not None:\n        return result.astype(dtype)\n    return result\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.visualize_graph--see-also","title":"See Also","text":"<p>debug_info : Print detailed debug information about the frame</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n    \"\"\"\n    Visualize the computation graph and save it to a file.\n\n    This method creates a visual representation of the Dask computation graph.\n    In Jupyter notebooks, it returns an IPython.display.Image object that\n    will be displayed inline. In other environments, it saves the graph to\n    a file and returns None.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Output filename for the graph image. If None, a unique filename\n        is generated using UUID. The file is saved in the current working\n        directory.\n\n    Returns\n    -------\n    IPython.display.Image or None\n        In Jupyter environments: Returns an IPython.display.Image object\n        that can be displayed inline.\n        In other environments: Returns None after saving the graph to file.\n        Returns None if visualization fails.\n\n    Notes\n    -----\n    This method requires graphviz to be installed on your system:\n    - Ubuntu/Debian: `sudo apt-get install graphviz`\n    - macOS: `brew install graphviz`\n    - Windows: Download from https://graphviz.org/download/\n\n    The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n    making it easier to understand the processing pipeline.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n    &gt;&gt;&gt; # In Jupyter: displays graph inline\n    &gt;&gt;&gt; processed.visualize_graph()\n    &gt;&gt;&gt; # Save to specific file\n    &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n    See Also\n    --------\n    debug_info : Print detailed debug information about the frame\n    \"\"\"\n    try:\n        filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n        return self._data.visualize(filename=filename)\n    except Exception as e:\n        logger.warning(f\"Failed to visualize the graph: {e}\")\n        return None\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__add__","title":"<code>__add__(other)</code>","text":"<p>Addition operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Addition operator\"\"\"\n    return self._binary_op(other, lambda x, y: x + y, \"+\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtraction operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Subtraction operator\"\"\"\n    return self._binary_op(other, lambda x, y: x - y, \"-\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiplication operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Multiplication operator\"\"\"\n    return self._binary_op(other, lambda x, y: x * y, \"*\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Division operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Division operator\"\"\"\n    return self._binary_op(other, lambda x, y: x / y, \"/\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.__pow__","title":"<code>__pow__(other)</code>","text":"<p>Power operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Power operator\"\"\"\n    return self._binary_op(other, lambda x, y: x**y, \"**\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.apply_operation--returns","title":"Returns","text":"<p>S     A new instance with the operation applied.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n    \"\"\"\n    Apply a named operation.\n\n    Parameters\n    ----------\n    operation_name : str\n        Name of the operation to apply.\n    **params : Any\n        Parameters to pass to the operation.\n\n    Returns\n    -------\n    S\n        A new instance with the operation applied.\n    \"\"\"\n    # Apply the operation through abstract method\n    return self._apply_operation_impl(operation_name, **params)\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.debug_info","title":"<code>debug_info()</code>","text":"<p>Output detailed debug information</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def debug_info(self) -&gt; None:\n    \"\"\"Output detailed debug information\"\"\"\n    logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n    logger.debug(f\"Label: {self.label}\")\n    logger.debug(f\"Shape: {self.shape}\")\n    logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n    logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n    self._debug_info_impl()\n    logger.debug(\"=== End Debug Info ===\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.print_operation_history--examples","title":"Examples","text":"<p>cf.print_operation_history() 1: normalize {} 2: low_pass_filter {'cutoff': 1000}</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def print_operation_history(self) -&gt; None:\n    \"\"\"\n    Print the operation history to standard output in a readable format.\n\n    This method writes a human-friendly representation of the\n    `operation_history` list to stdout. Each operation is printed on its\n    own line with an index, the operation name (if available), and the\n    parameters used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf.print_operation_history()\n    1: normalize {}\n    2: low_pass_filter {'cutoff': 1000}\n    \"\"\"\n    if not self.operation_history:\n        print(\"Operation history: &lt;empty&gt;\")\n        return\n\n    print(f\"Operation history ({len(self.operation_history)}):\")\n    for i, record in enumerate(self.operation_history, start=1):\n        # record is expected to be a dict with at least a 'operation' key\n        op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n        # Copy params for display - exclude the 'operation'/'name' keys\n        params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n        print(f\"{i}: {op_name} {params}\")\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.to_numpy--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") data = cf.to_numpy() print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def to_numpy(self) -&gt; T:\n    \"\"\"Convert the frame data to a NumPy array.\n\n    This method computes the Dask array and returns it as a concrete NumPy array.\n    The returned array has the same shape as the frame's data.\n\n    Returns\n    -------\n    T\n        NumPy array containing the frame data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; data = cf.to_numpy()\n    &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n    \"\"\"\n    return self.data\n</code></pre>"},{"location":"en/api/#wandas.core.BaseFrame.to_dataframe--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") df = cf.to_dataframe() print(df.head())</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"Convert the frame data to a pandas DataFrame.\n\n    This method provides a common implementation for converting frame data\n    to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with appropriate index and columns.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; df = cf.to_dataframe()\n    &gt;&gt;&gt; print(df.head())\n    \"\"\"\n    # Get data as numpy array\n    data = self.to_numpy()\n\n    # Get column names from subclass\n    columns = self._get_dataframe_columns()\n\n    # Get index from subclass\n    index = self._get_dataframe_index()\n\n    # Create DataFrame\n    if data.ndim == 1:\n        # Single channel case - reshape to 2D\n        df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n    else:\n        # Multi-channel case - transpose to (n_samples, n_channels)\n        df = pd.DataFrame(data.T, columns=columns, index=index)\n\n    return df\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame--attributes","title":"Attributes","text":"<p>sampling_rate : float     The sampling rate of the signal in Hz. label : str     The label of the frame. metadata : dict     Additional metadata for the frame. operation_history : list[dict]     History of operations performed on this frame.</p> Source code in <code>wandas/core/base_frame.py</code> <pre><code>class BaseFrame(ABC, Generic[T]):\n    \"\"\"\n    Abstract base class for all signal frame types.\n\n    This class provides the common interface and functionality for all frame types\n    used in signal processing. It implements basic operations like indexing, iteration,\n    and data manipulation that are shared across all frame types.\n\n    Parameters\n    ----------\n    data : DaArray\n        The signal data to process. Must be a dask array.\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str, optional\n        A label for the frame. If not provided, defaults to \"unnamed_frame\".\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata | dict], optional\n        Metadata for each channel in the frame. Can be ChannelMetadata objects\n        or dicts that will be validated by Pydantic.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    sampling_rate : float\n        The sampling rate of the signal in Hz.\n    label : str\n        The label of the frame.\n    metadata : dict\n        Additional metadata for the frame.\n    operation_history : list[dict]\n        History of operations performed on this frame.\n    \"\"\"\n\n    _data: DaArray\n    sampling_rate: float\n    label: str\n    metadata: dict[str, Any]\n    operation_history: list[dict[str, Any]]\n    _channel_metadata: list[ChannelMetadata]\n    _previous: Optional[\"BaseFrame[Any]\"]\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ):\n        self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n        if self._data.ndim == 1:\n            self._data = self._data.reshape((1, -1))\n        self.sampling_rate = sampling_rate\n        self.label = label or \"unnamed_frame\"\n        self.metadata = metadata or {}\n        self.operation_history = operation_history or []\n        self._previous = previous\n\n        if channel_metadata:\n            # Pydantic handles both ChannelMetadata objects and dicts\n            def _to_channel_metadata(\n                ch: ChannelMetadata | dict[str, Any], index: int\n            ) -&gt; ChannelMetadata:\n                if isinstance(ch, ChannelMetadata):\n                    return copy.deepcopy(ch)\n                elif isinstance(ch, dict):\n                    try:\n                        return ChannelMetadata(**ch)\n                    except ValidationError as e:\n                        raise ValueError(\n                            f\"Invalid channel_metadata at index {index}\\n\"\n                            f\"  Got: {ch}\\n\"\n                            f\"  Validation error: {e}\\n\"\n                            f\"Ensure all dict keys match ChannelMetadata fields \"\n                            f\"(label, unit, ref, extra) and have correct types.\"\n                        ) from e\n                else:\n                    raise TypeError(\n                        f\"Invalid type in channel_metadata at index {index}\\n\"\n                        f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                        f\"  Expected: ChannelMetadata or dict\\n\"\n                        f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                    )\n\n            self._channel_metadata = [\n                _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n                for i, ch in enumerate(channel_metadata)\n            ]\n        else:\n            self._channel_metadata = [\n                ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n                for i in range(self._n_channels)\n            ]\n\n        try:\n            # Display information for newer dask versions\n            logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n            logger.debug(\n                f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n            )\n        except Exception as e:\n            logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n\n    @property\n    @abstractmethod\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n\n    @property\n    def n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return self._n_channels\n\n    @property\n    def channels(self) -&gt; list[ChannelMetadata]:\n        \"\"\"Property to access channel metadata.\"\"\"\n        return self._channel_metadata\n\n    @property\n    def previous(self) -&gt; Optional[\"BaseFrame[Any]\"]:\n        \"\"\"\n        Returns the previous frame.\n        \"\"\"\n        return self._previous\n\n    def get_channel(\n        self: S,\n        channel_idx: int\n        | list[int]\n        | tuple[int, ...]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index.\n\n        Parameters\n        ----------\n        channel_idx : int or sequence of int\n            Single channel index or sequence of channel indices.\n            Supports negative indices (e.g., -1 for the last channel).\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n        &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n        &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n        &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n        \"\"\"\n        if isinstance(channel_idx, int):\n            # Convert single channel to a list.\n            channel_idx_list: list[int] = [channel_idx]\n        else:\n            channel_idx_list = list(channel_idx)\n\n        new_data = self._data[channel_idx_list]\n        new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Returns the number of channels.\n        \"\"\"\n        return len(self._channel_metadata)\n\n    def __iter__(self: S) -&gt; Iterator[S]:\n        for idx in range(len(self)):\n            yield self[idx]\n\n    def __getitem__(\n        self: S,\n        key: int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n    ) -&gt; S:\n        \"\"\"\n        Get channel(s) by index, label, or advanced indexing.\n\n        This method supports multiple indexing patterns similar to NumPy and pandas:\n\n        - Single channel by index: `frame[0]`\n        - Single channel by label: `frame[\"ch0\"]`\n        - Slice of channels: `frame[0:3]`\n        - Multiple channels by indices: `frame[[0, 2, 5]]`\n        - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n        - NumPy integer array: `frame[np.array([0, 2])]`\n        - Boolean mask: `frame[mask]` where mask is a boolean array\n        - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n        Parameters\n        ----------\n        key : int, str, slice, list, tuple, or ndarray\n            - int: Single channel index (supports negative indexing)\n            - str: Single channel label\n            - slice: Range of channels\n            - list[int]: Multiple channel indices\n            - list[str]: Multiple channel labels\n            - tuple: Multidimensional indexing (channel_key, time_key, ...)\n            - ndarray[int]: NumPy array of channel indices\n            - ndarray[bool]: Boolean mask for channel selection\n\n        Returns\n        -------\n        S\n            New instance containing the selected channel(s).\n\n        Raises\n        ------\n        ValueError\n            If the key length is invalid for the shape or if boolean mask\n            length doesn't match number of channels.\n        IndexError\n            If the channel index is out of range.\n        TypeError\n            If the key type is invalid or list contains mixed types.\n        KeyError\n            If a channel label is not found.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Single channel selection\n        &gt;&gt;&gt; frame[0]  # First channel\n        &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n        &gt;&gt;&gt; frame[-1]  # Last channel\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Multiple channel selection\n        &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n        &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n        &gt;&gt;&gt; frame[0:3]  # Slice\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # NumPy array indexing\n        &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n        &gt;&gt;&gt; mask = np.array([True, False, True])\n        &gt;&gt;&gt; frame[mask]  # Boolean mask\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Time slicing (multidimensional)\n        &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n        &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n        \"\"\"\n\n        # Single index (int)\n        if isinstance(key, numbers.Integral):\n            # Ensure we pass a plain Python int to satisfy the type checker\n            return self.get_channel(int(key))\n\n        # Single label (str)\n        if isinstance(key, str):\n            index = self.label2index(key)\n            return self.get_channel(index)\n\n        # Phase 2: NumPy array support (bool mask and int array)\n        if isinstance(key, np.ndarray):\n            if key.dtype == bool or key.dtype == np.bool_:\n                # Boolean mask\n                if len(key) != self.n_channels:\n                    raise ValueError(\n                        f\"Boolean mask length {len(key)} does not match \"\n                        f\"number of channels {self.n_channels}\"\n                    )\n                indices = np.where(key)[0]\n                return self.get_channel(indices)\n            elif np.issubdtype(key.dtype, np.integer):\n                # Integer array\n                return self.get_channel(key)\n            else:\n                raise TypeError(\n                    f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n                )\n\n        # Phase 1: List support (int or str)\n        if isinstance(key, list):\n            if len(key) == 0:\n                raise ValueError(\"Cannot index with an empty list\")\n\n            # Check if all elements are strings\n            if all(isinstance(k, str) for k in key):\n                # Multiple labels - type narrowing for mypy\n                str_list = cast(list[str], key)\n                indices_from_labels = [self.label2index(label) for label in str_list]\n                return self.get_channel(indices_from_labels)\n\n            # Check if all elements are integers\n            elif all(isinstance(k, int | np.integer) for k in key):\n                # Multiple indices - convert to list[int] for type safety\n                int_list = [int(k) for k in key]\n                return self.get_channel(int_list)\n\n            else:\n                raise TypeError(\n                    f\"List must contain all str or all int, got mixed types: \"\n                    f\"{[type(k).__name__ for k in key]}\"\n                )\n\n        # Tuple: multidimensional indexing\n        if isinstance(key, tuple):\n            return self._handle_multidim_indexing(key)\n\n        # Slice\n        if isinstance(key, slice):\n            new_data = self._data[key]\n            new_channel_metadata = self._channel_metadata[key]\n            if isinstance(new_channel_metadata, ChannelMetadata):\n                new_channel_metadata = [new_channel_metadata]\n            return self._create_new_instance(\n                data=new_data,\n                operation_history=self.operation_history,\n                channel_metadata=new_channel_metadata,\n            )\n\n        raise TypeError(\n            f\"Invalid key type: {type(key).__name__}. \"\n            f\"Expected int, str, slice, list, tuple, or ndarray.\"\n        )\n\n    def _handle_multidim_indexing(\n        self: S,\n        key: tuple[\n            int\n            | str\n            | slice\n            | list[int]\n            | list[str]\n            | npt.NDArray[np.int_]\n            | npt.NDArray[np.bool_],\n            ...,\n        ],\n    ) -&gt; S:\n        \"\"\"\n        Handle multidimensional indexing (channel + time axis).\n\n        Parameters\n        ----------\n        key : tuple\n            Tuple of indices where the first element selects channels\n            and subsequent elements select along other dimensions (e.g., time).\n\n        Returns\n        -------\n        S\n            New instance with selected channels and time range.\n\n        Raises\n        ------\n        ValueError\n            If the key length exceeds the data dimensions.\n        \"\"\"\n        if len(key) &gt; self._data.ndim:\n            raise ValueError(f\"Invalid key length: {len(key)} for shape {self.shape}\")\n\n        # First element: channel selection\n        channel_key = key[0]\n        time_keys = key[1:] if len(key) &gt; 1 else ()\n\n        # Select channels first (recursively call __getitem__)\n        if isinstance(channel_key, list | np.ndarray):\n            selected = self[channel_key]\n        elif isinstance(channel_key, int | str | slice):\n            selected = self[channel_key]\n        else:\n            raise TypeError(\n                f\"Invalid channel key type in tuple: {type(channel_key).__name__}\"\n            )\n\n        # Apply time indexing if present\n        if time_keys:\n            new_data = selected._data[(slice(None),) + time_keys]\n            return selected._create_new_instance(\n                data=new_data,\n                operation_history=selected.operation_history,\n                channel_metadata=selected._channel_metadata,\n            )\n\n        return selected\n\n    def label2index(self, label: str) -&gt; int:\n        \"\"\"\n        Get the index from a channel label.\n\n        Parameters\n        ----------\n        label : str\n            Channel label.\n\n        Returns\n        -------\n        int\n            Corresponding index.\n\n        Raises\n        ------\n        KeyError\n            If the channel label is not found.\n        \"\"\"\n        for idx, ch in enumerate(self._channel_metadata):\n            if ch.label == label:\n                return idx\n        raise KeyError(f\"Channel label '{label}' not found.\")\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        _shape: tuple[int, ...] = self._data.shape\n        if _shape[0] == 1:\n            return _shape[1:]\n        return _shape\n\n    @property\n    def data(self) -&gt; T:\n        \"\"\"\n        Returns the computed data.\n        Calculation is executed the first time this is accessed.\n        \"\"\"\n        data = self.compute()\n        if self.n_channels == 1:\n            return data.squeeze(axis=0)\n        return data\n\n    @property\n    def labels(self) -&gt; list[str]:\n        \"\"\"Get a list of all channel labels.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def compute(self) -&gt; T:\n        \"\"\"\n        Compute and return the data.\n        This method materializes lazily computed data into a concrete NumPy array.\n\n        Returns\n        -------\n        NDArrayReal\n            The computed data.\n\n        Raises\n        ------\n        ValueError\n            If the computed result is not a NumPy array.\n        \"\"\"\n        logger.debug(\n            \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n        )\n        result = self._data.compute()\n\n        if not isinstance(result, np.ndarray):\n            raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n        logger.debug(f\"Computation complete, result shape: {result.shape}\")\n        return cast(T, result)\n\n    @abstractmethod\n    def plot(\n        self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the data\"\"\"\n        pass\n\n    def persist(self: S) -&gt; S:\n        \"\"\"Persist the data in memory\"\"\"\n        persisted_data = self._data.persist()\n        return self._create_new_instance(data=persisted_data)\n\n    @abstractmethod\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Abstract method for derived classes to provide\n        additional initialization arguments.\n        \"\"\"\n        pass\n\n    def _create_new_instance(self: S, data: DaArray, **kwargs: Any) -&gt; S:\n        \"\"\"\n        Create a new channel instance based on an existing channel.\n        Keyword arguments can override or extend the original attributes.\n        \"\"\"\n\n        sampling_rate = kwargs.pop(\"sampling_rate\", self.sampling_rate)\n        # if not isinstance(sampling_rate, int):\n        #     raise TypeError(\"Sampling rate must be an integer\")\n\n        label = kwargs.pop(\"label\", self.label)\n        if not isinstance(label, str):\n            raise TypeError(\"Label must be a string\")\n\n        metadata = kwargs.pop(\"metadata\", copy.deepcopy(self.metadata))\n        if not isinstance(metadata, dict):\n            raise TypeError(\"Metadata must be a dictionary\")\n\n        channel_metadata = kwargs.pop(\n            \"channel_metadata\", copy.deepcopy(self._channel_metadata)\n        )\n        if not isinstance(channel_metadata, list):\n            raise TypeError(\"Channel metadata must be a list\")\n\n        # Get additional initialization arguments from derived classes\n        additional_kwargs = self._get_additional_init_kwargs()\n        kwargs.update(additional_kwargs)\n\n        return type(self)(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            channel_metadata=channel_metadata,\n            previous=self,\n            **kwargs,\n        )\n\n    def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n        \"\"\"Implicit conversion to NumPy array\"\"\"\n        result = self.compute()\n        if dtype is not None:\n            return result.astype(dtype)\n        return result\n\n    def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n        \"\"\"\n        Visualize the computation graph and save it to a file.\n\n        This method creates a visual representation of the Dask computation graph.\n        In Jupyter notebooks, it returns an IPython.display.Image object that\n        will be displayed inline. In other environments, it saves the graph to\n        a file and returns None.\n\n        Parameters\n        ----------\n        filename : str, optional\n            Output filename for the graph image. If None, a unique filename\n            is generated using UUID. The file is saved in the current working\n            directory.\n\n        Returns\n        -------\n        IPython.display.Image or None\n            In Jupyter environments: Returns an IPython.display.Image object\n            that can be displayed inline.\n            In other environments: Returns None after saving the graph to file.\n            Returns None if visualization fails.\n\n        Notes\n        -----\n        This method requires graphviz to be installed on your system:\n        - Ubuntu/Debian: `sudo apt-get install graphviz`\n        - macOS: `brew install graphviz`\n        - Windows: Download from https://graphviz.org/download/\n\n        The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n        making it easier to understand the processing pipeline.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n        &gt;&gt;&gt; # In Jupyter: displays graph inline\n        &gt;&gt;&gt; processed.visualize_graph()\n        &gt;&gt;&gt; # Save to specific file\n        &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n        See Also\n        --------\n        debug_info : Print detailed debug information about the frame\n        \"\"\"\n        try:\n            filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n            return self._data.visualize(filename=filename)\n        except Exception as e:\n            logger.warning(f\"Failed to visualize the graph: {e}\")\n            return None\n\n    @abstractmethod\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"Basic implementation of binary operations\"\"\"\n        # Basic logic\n        # Actual implementation is left to derived classes\n        pass\n\n    def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Addition operator\"\"\"\n        return self._binary_op(other, lambda x, y: x + y, \"+\")\n\n    def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Subtraction operator\"\"\"\n        return self._binary_op(other, lambda x, y: x - y, \"-\")\n\n    def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Multiplication operator\"\"\"\n        return self._binary_op(other, lambda x, y: x * y, \"*\")\n\n    def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Division operator\"\"\"\n        return self._binary_op(other, lambda x, y: x / y, \"/\")\n\n    def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n        \"\"\"Power operator\"\"\"\n        return self._binary_op(other, lambda x, y: x**y, \"**\")\n\n    def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply a named operation.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters to pass to the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        # Apply the operation through abstract method\n        return self._apply_operation_impl(operation_name, **params)\n\n    @abstractmethod\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"Implementation of operation application\"\"\"\n        pass\n\n    def _relabel_channels(\n        self,\n        operation_name: str,\n        display_name: str | None = None,\n    ) -&gt; list[ChannelMetadata]:\n        \"\"\"\n        Update channel labels to reflect applied operation.\n\n        This method creates new channel metadata with labels that include\n        the operation name, making it easier to track processing history\n        and distinguish frames in plots.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation (e.g., \"normalize\", \"lowpass_filter\")\n        display_name : str, optional\n            Display name for the operation. If None, uses operation_name.\n            This allows operations to provide custom, more readable labels.\n\n        Returns\n        -------\n        list[ChannelMetadata]\n            New channel metadata with updated labels.\n            Original metadata is deep-copied and only labels are modified.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Original label: \"ch0\"\n        &gt;&gt;&gt; # After normalize: \"normalize(ch0)\"\n        &gt;&gt;&gt; # After chained ops: \"lowpass_filter(normalize(ch0))\"\n\n        Notes\n        -----\n        Labels are nested for chained operations, allowing full\n        traceability of the processing pipeline.\n        \"\"\"\n        display = display_name or operation_name\n        new_metadata = []\n        for ch in self._channel_metadata:\n            # All channel metadata are ChannelMetadata objects at this point\n            new_ch = ch.model_copy(deep=True)\n            new_ch.label = f\"{display}({ch.label})\"\n            new_metadata.append(new_ch)\n        return new_metadata\n\n    def debug_info(self) -&gt; None:\n        \"\"\"Output detailed debug information\"\"\"\n        logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n        logger.debug(f\"Label: {self.label}\")\n        logger.debug(f\"Shape: {self.shape}\")\n        logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n        logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n        self._debug_info_impl()\n        logger.debug(\"=== End Debug Info ===\")\n\n    def print_operation_history(self) -&gt; None:\n        \"\"\"\n        Print the operation history to standard output in a readable format.\n\n        This method writes a human-friendly representation of the\n        `operation_history` list to stdout. Each operation is printed on its\n        own line with an index, the operation name (if available), and the\n        parameters used.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf.print_operation_history()\n        1: normalize {}\n        2: low_pass_filter {'cutoff': 1000}\n        \"\"\"\n        if not self.operation_history:\n            print(\"Operation history: &lt;empty&gt;\")\n            return\n\n        print(f\"Operation history ({len(self.operation_history)}):\")\n        for i, record in enumerate(self.operation_history, start=1):\n            # record is expected to be a dict with at least a 'operation' key\n            op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n            # Copy params for display - exclude the 'operation'/'name' keys\n            params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n            print(f\"{i}: {op_name} {params}\")\n\n    def to_numpy(self) -&gt; T:\n        \"\"\"Convert the frame data to a NumPy array.\n\n        This method computes the Dask array and returns it as a concrete NumPy array.\n        The returned array has the same shape as the frame's data.\n\n        Returns\n        -------\n        T\n            NumPy array containing the frame data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; data = cf.to_numpy()\n        &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n        \"\"\"\n        return self.data\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"Convert the frame data to a pandas DataFrame.\n\n        This method provides a common implementation for converting frame data\n        to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame with appropriate index and columns.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; df = cf.to_dataframe()\n        &gt;&gt;&gt; print(df.head())\n        \"\"\"\n        # Get data as numpy array\n        data = self.to_numpy()\n\n        # Get column names from subclass\n        columns = self._get_dataframe_columns()\n\n        # Get index from subclass\n        index = self._get_dataframe_index()\n\n        # Create DataFrame\n        if data.ndim == 1:\n            # Single channel case - reshape to 2D\n            df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n        else:\n            # Multi-channel case - transpose to (n_samples, n_channels)\n            df = pd.DataFrame(data.T, columns=columns, index=index)\n\n        return df\n\n    @abstractmethod\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get column names for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate column names for the DataFrame.\n\n        Returns\n        -------\n        list[str]\n            List of column names.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get index for DataFrame.\n\n        This method should be implemented by subclasses to provide\n        appropriate index for the DataFrame based on the frame type.\n\n        Returns\n        -------\n        pd.Index\n            Index for the DataFrame.\n        \"\"\"\n        pass\n\n    def _debug_info_impl(self) -&gt; None:\n        \"\"\"Implement derived class-specific debug information\"\"\"\n        pass\n\n    def _print_operation_history(self) -&gt; None:\n        \"\"\"Print the operation history information.\n\n        This is a helper method for info() implementations to display\n        the number of operations applied to the frame in a consistent format.\n        \"\"\"\n        if self.operation_history:\n            print(f\"  Operations Applied: {len(self.operation_history)}\")\n        else:\n            print(\"  Operations Applied: None\")\n</code></pre> Attributes\u00b6 <code></code> <code>sampling_rate = sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>label = label or 'unnamed_frame'</code> <code>instance-attribute</code> \u00b6 <code></code> <code>metadata = metadata or {}</code> <code>instance-attribute</code> \u00b6 <code></code> <code>operation_history = operation_history or []</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_channels</code> <code>property</code> \u00b6 <p>Returns the number of channels.</p> <code></code> <code>channels</code> <code>property</code> \u00b6 <p>Property to access channel metadata.</p> <code></code> <code>previous</code> <code>property</code> \u00b6 <p>Returns the previous frame.</p> <code></code> <code>shape</code> <code>property</code> \u00b6 <code></code> <code>data</code> <code>property</code> \u00b6 <p>Returns the computed data. Calculation is executed the first time this is accessed.</p> <code></code> <code>labels</code> <code>property</code> \u00b6 <p>Get a list of all channel labels.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n):\n    self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n    if self._data.ndim == 1:\n        self._data = self._data.reshape((1, -1))\n    self.sampling_rate = sampling_rate\n    self.label = label or \"unnamed_frame\"\n    self.metadata = metadata or {}\n    self.operation_history = operation_history or []\n    self._previous = previous\n\n    if channel_metadata:\n        # Pydantic handles both ChannelMetadata objects and dicts\n        def _to_channel_metadata(\n            ch: ChannelMetadata | dict[str, Any], index: int\n        ) -&gt; ChannelMetadata:\n            if isinstance(ch, ChannelMetadata):\n                return copy.deepcopy(ch)\n            elif isinstance(ch, dict):\n                try:\n                    return ChannelMetadata(**ch)\n                except ValidationError as e:\n                    raise ValueError(\n                        f\"Invalid channel_metadata at index {index}\\n\"\n                        f\"  Got: {ch}\\n\"\n                        f\"  Validation error: {e}\\n\"\n                        f\"Ensure all dict keys match ChannelMetadata fields \"\n                        f\"(label, unit, ref, extra) and have correct types.\"\n                    ) from e\n            else:\n                raise TypeError(\n                    f\"Invalid type in channel_metadata at index {index}\\n\"\n                    f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                    f\"  Expected: ChannelMetadata or dict\\n\"\n                    f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                )\n\n        self._channel_metadata = [\n            _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n            for i, ch in enumerate(channel_metadata)\n        ]\n    else:\n        self._channel_metadata = [\n            ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n            for i in range(self._n_channels)\n        ]\n\n    try:\n        # Display information for newer dask versions\n        logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n        logger.debug(\n            f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n        )\n    except Exception as e:\n        logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n</code></pre> <code></code> <code>get_channel(channel_idx)</code> \u00b6 <p>Get channel(s) by index.</p> <code></code> <code>__len__()</code> \u00b6 <p>Returns the number of channels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of channels.\n    \"\"\"\n    return len(self._channel_metadata)\n</code></pre> <code></code> <code>__iter__()</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __iter__(self: S) -&gt; Iterator[S]:\n    for idx in range(len(self)):\n        yield self[idx]\n</code></pre> <code></code> <code>__getitem__(key)</code> \u00b6 <p>Get channel(s) by index, label, or advanced indexing.</p> <p>This method supports multiple indexing patterns similar to NumPy and pandas:</p> <ul> <li>Single channel by index: <code>frame[0]</code></li> <li>Single channel by label: <code>frame[\"ch0\"]</code></li> <li>Slice of channels: <code>frame[0:3]</code></li> <li>Multiple channels by indices: <code>frame[[0, 2, 5]]</code></li> <li>Multiple channels by labels: <code>frame[[\"ch0\", \"ch2\"]]</code></li> <li>NumPy integer array: <code>frame[np.array([0, 2])]</code></li> <li>Boolean mask: <code>frame[mask]</code> where mask is a boolean array</li> <li>Multidimensional indexing: <code>frame[0, 100:200]</code> (channel + time)</li> </ul> <code></code> <code>label2index(label)</code> \u00b6 <p>Get the index from a channel label.</p> <code></code> <code>compute()</code> \u00b6 <p>Compute and return the data. This method materializes lazily computed data into a concrete NumPy array.</p> <code></code> <code>plot(plot_type='default', ax=None, **kwargs)</code> <code>abstractmethod</code> \u00b6 <p>Plot the data</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>@abstractmethod\ndef plot(\n    self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the data\"\"\"\n    pass\n</code></pre> <code></code> <code>persist()</code> \u00b6 <p>Persist the data in memory</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def persist(self: S) -&gt; S:\n    \"\"\"Persist the data in memory\"\"\"\n    persisted_data = self._data.persist()\n    return self._create_new_instance(data=persisted_data)\n</code></pre> <code></code> <code>__array__(dtype=None)</code> \u00b6 <p>Implicit conversion to NumPy array</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n    \"\"\"Implicit conversion to NumPy array\"\"\"\n    result = self.compute()\n    if dtype is not None:\n        return result.astype(dtype)\n    return result\n</code></pre> <code></code> <code>visualize_graph(filename=None)</code> \u00b6 <p>Visualize the computation graph and save it to a file.</p> <p>This method creates a visual representation of the Dask computation graph. In Jupyter notebooks, it returns an IPython.display.Image object that will be displayed inline. In other environments, it saves the graph to a file and returns None.</p> <code></code> <code>__add__(other)</code> \u00b6 <p>Addition operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Addition operator\"\"\"\n    return self._binary_op(other, lambda x, y: x + y, \"+\")\n</code></pre> <code></code> <code>__sub__(other)</code> \u00b6 <p>Subtraction operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Subtraction operator\"\"\"\n    return self._binary_op(other, lambda x, y: x - y, \"-\")\n</code></pre> <code></code> <code>__mul__(other)</code> \u00b6 <p>Multiplication operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Multiplication operator\"\"\"\n    return self._binary_op(other, lambda x, y: x * y, \"*\")\n</code></pre> <code></code> <code>__truediv__(other)</code> \u00b6 <p>Division operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Division operator\"\"\"\n    return self._binary_op(other, lambda x, y: x / y, \"/\")\n</code></pre> <code></code> <code>__pow__(other)</code> \u00b6 <p>Power operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Power operator\"\"\"\n    return self._binary_op(other, lambda x, y: x**y, \"**\")\n</code></pre> <code></code> <code>apply_operation(operation_name, **params)</code> \u00b6 <p>Apply a named operation.</p> <code></code> <code>debug_info()</code> \u00b6 <p>Output detailed debug information</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def debug_info(self) -&gt; None:\n    \"\"\"Output detailed debug information\"\"\"\n    logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n    logger.debug(f\"Label: {self.label}\")\n    logger.debug(f\"Shape: {self.shape}\")\n    logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n    logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n    self._debug_info_impl()\n    logger.debug(\"=== End Debug Info ===\")\n</code></pre> <code></code> <code>print_operation_history()</code> \u00b6 <p>Print the operation history to standard output in a readable format.</p> <p>This method writes a human-friendly representation of the <code>operation_history</code> list to stdout. Each operation is printed on its own line with an index, the operation name (if available), and the parameters used.</p> <code></code> <code>to_numpy()</code> \u00b6 <p>Convert the frame data to a NumPy array.</p> <p>This method computes the Dask array and returns it as a concrete NumPy array. The returned array has the same shape as the frame's data.</p> <code></code> <code>to_dataframe()</code> \u00b6 <p>Convert the frame data to a pandas DataFrame.</p> <p>This method provides a common implementation for converting frame data to pandas DataFrame. Subclasses can override this method for custom behavior.</p>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.get_channel--examples","title":"Examples","text":"<p>frame.get_channel(0)  # Single channel frame.get_channel([0, 2, 3])  # Multiple channels frame.get_channel((-1, -2))  # Last two channels frame.get_channel(np.array([1, 2]))  # NumPy array of indices</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def get_channel(\n    self: S,\n    channel_idx: int\n    | list[int]\n    | tuple[int, ...]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index.\n\n    Parameters\n    ----------\n    channel_idx : int or sequence of int\n        Single channel index or sequence of channel indices.\n        Supports negative indices (e.g., -1 for the last channel).\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n    &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n    &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n    &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n    \"\"\"\n    if isinstance(channel_idx, int):\n        # Convert single channel to a list.\n        channel_idx_list: list[int] = [channel_idx]\n    else:\n        channel_idx_list = list(channel_idx)\n\n    new_data = self._data[channel_idx_list]\n    new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n    return self._create_new_instance(\n        data=new_data,\n        operation_history=self.operation_history,\n        channel_metadata=new_channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.__getitem__--examples","title":"Examples","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __getitem__(\n    self: S,\n    key: int\n    | str\n    | slice\n    | list[int]\n    | list[str]\n    | tuple[\n        int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n        ...,\n    ]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index, label, or advanced indexing.\n\n    This method supports multiple indexing patterns similar to NumPy and pandas:\n\n    - Single channel by index: `frame[0]`\n    - Single channel by label: `frame[\"ch0\"]`\n    - Slice of channels: `frame[0:3]`\n    - Multiple channels by indices: `frame[[0, 2, 5]]`\n    - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n    - NumPy integer array: `frame[np.array([0, 2])]`\n    - Boolean mask: `frame[mask]` where mask is a boolean array\n    - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n    Parameters\n    ----------\n    key : int, str, slice, list, tuple, or ndarray\n        - int: Single channel index (supports negative indexing)\n        - str: Single channel label\n        - slice: Range of channels\n        - list[int]: Multiple channel indices\n        - list[str]: Multiple channel labels\n        - tuple: Multidimensional indexing (channel_key, time_key, ...)\n        - ndarray[int]: NumPy array of channel indices\n        - ndarray[bool]: Boolean mask for channel selection\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Raises\n    ------\n    ValueError\n        If the key length is invalid for the shape or if boolean mask\n        length doesn't match number of channels.\n    IndexError\n        If the channel index is out of range.\n    TypeError\n        If the key type is invalid or list contains mixed types.\n    KeyError\n        If a channel label is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Single channel selection\n    &gt;&gt;&gt; frame[0]  # First channel\n    &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n    &gt;&gt;&gt; frame[-1]  # Last channel\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Multiple channel selection\n    &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n    &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n    &gt;&gt;&gt; frame[0:3]  # Slice\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # NumPy array indexing\n    &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n    &gt;&gt;&gt; mask = np.array([True, False, True])\n    &gt;&gt;&gt; frame[mask]  # Boolean mask\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Time slicing (multidimensional)\n    &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n    &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n    \"\"\"\n\n    # Single index (int)\n    if isinstance(key, numbers.Integral):\n        # Ensure we pass a plain Python int to satisfy the type checker\n        return self.get_channel(int(key))\n\n    # Single label (str)\n    if isinstance(key, str):\n        index = self.label2index(key)\n        return self.get_channel(index)\n\n    # Phase 2: NumPy array support (bool mask and int array)\n    if isinstance(key, np.ndarray):\n        if key.dtype == bool or key.dtype == np.bool_:\n            # Boolean mask\n            if len(key) != self.n_channels:\n                raise ValueError(\n                    f\"Boolean mask length {len(key)} does not match \"\n                    f\"number of channels {self.n_channels}\"\n                )\n            indices = np.where(key)[0]\n            return self.get_channel(indices)\n        elif np.issubdtype(key.dtype, np.integer):\n            # Integer array\n            return self.get_channel(key)\n        else:\n            raise TypeError(\n                f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n            )\n\n    # Phase 1: List support (int or str)\n    if isinstance(key, list):\n        if len(key) == 0:\n            raise ValueError(\"Cannot index with an empty list\")\n\n        # Check if all elements are strings\n        if all(isinstance(k, str) for k in key):\n            # Multiple labels - type narrowing for mypy\n            str_list = cast(list[str], key)\n            indices_from_labels = [self.label2index(label) for label in str_list]\n            return self.get_channel(indices_from_labels)\n\n        # Check if all elements are integers\n        elif all(isinstance(k, int | np.integer) for k in key):\n            # Multiple indices - convert to list[int] for type safety\n            int_list = [int(k) for k in key]\n            return self.get_channel(int_list)\n\n        else:\n            raise TypeError(\n                f\"List must contain all str or all int, got mixed types: \"\n                f\"{[type(k).__name__ for k in key]}\"\n            )\n\n    # Tuple: multidimensional indexing\n    if isinstance(key, tuple):\n        return self._handle_multidim_indexing(key)\n\n    # Slice\n    if isinstance(key, slice):\n        new_data = self._data[key]\n        new_channel_metadata = self._channel_metadata[key]\n        if isinstance(new_channel_metadata, ChannelMetadata):\n            new_channel_metadata = [new_channel_metadata]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    raise TypeError(\n        f\"Invalid key type: {type(key).__name__}. \"\n        f\"Expected int, str, slice, list, tuple, or ndarray.\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.label2index--raises","title":"Raises","text":"<p>KeyError     If the channel label is not found.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n\n    Parameters\n    ----------\n    label : str\n        Channel label.\n\n    Returns\n    -------\n    int\n        Corresponding index.\n\n    Raises\n    ------\n    KeyError\n        If the channel label is not found.\n    \"\"\"\n    for idx, ch in enumerate(self._channel_metadata):\n        if ch.label == label:\n            return idx\n    raise KeyError(f\"Channel label '{label}' not found.\")\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.compute--raises","title":"Raises","text":"<p>ValueError     If the computed result is not a NumPy array.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def compute(self) -&gt; T:\n    \"\"\"\n    Compute and return the data.\n    This method materializes lazily computed data into a concrete NumPy array.\n\n    Returns\n    -------\n    NDArrayReal\n        The computed data.\n\n    Raises\n    ------\n    ValueError\n        If the computed result is not a NumPy array.\n    \"\"\"\n    logger.debug(\n        \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n    )\n    result = self._data.compute()\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n    logger.debug(f\"Computation complete, result shape: {result.shape}\")\n    return cast(T, result)\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.visualize_graph--see-also","title":"See Also","text":"<p>debug_info : Print detailed debug information about the frame</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n    \"\"\"\n    Visualize the computation graph and save it to a file.\n\n    This method creates a visual representation of the Dask computation graph.\n    In Jupyter notebooks, it returns an IPython.display.Image object that\n    will be displayed inline. In other environments, it saves the graph to\n    a file and returns None.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Output filename for the graph image. If None, a unique filename\n        is generated using UUID. The file is saved in the current working\n        directory.\n\n    Returns\n    -------\n    IPython.display.Image or None\n        In Jupyter environments: Returns an IPython.display.Image object\n        that can be displayed inline.\n        In other environments: Returns None after saving the graph to file.\n        Returns None if visualization fails.\n\n    Notes\n    -----\n    This method requires graphviz to be installed on your system:\n    - Ubuntu/Debian: `sudo apt-get install graphviz`\n    - macOS: `brew install graphviz`\n    - Windows: Download from https://graphviz.org/download/\n\n    The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n    making it easier to understand the processing pipeline.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n    &gt;&gt;&gt; # In Jupyter: displays graph inline\n    &gt;&gt;&gt; processed.visualize_graph()\n    &gt;&gt;&gt; # Save to specific file\n    &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n    See Also\n    --------\n    debug_info : Print detailed debug information about the frame\n    \"\"\"\n    try:\n        filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n        return self._data.visualize(filename=filename)\n    except Exception as e:\n        logger.warning(f\"Failed to visualize the graph: {e}\")\n        return None\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.apply_operation--returns","title":"Returns","text":"<p>S     A new instance with the operation applied.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n    \"\"\"\n    Apply a named operation.\n\n    Parameters\n    ----------\n    operation_name : str\n        Name of the operation to apply.\n    **params : Any\n        Parameters to pass to the operation.\n\n    Returns\n    -------\n    S\n        A new instance with the operation applied.\n    \"\"\"\n    # Apply the operation through abstract method\n    return self._apply_operation_impl(operation_name, **params)\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.print_operation_history--examples","title":"Examples","text":"<p>cf.print_operation_history() 1: normalize {} 2: low_pass_filter {'cutoff': 1000}</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def print_operation_history(self) -&gt; None:\n    \"\"\"\n    Print the operation history to standard output in a readable format.\n\n    This method writes a human-friendly representation of the\n    `operation_history` list to stdout. Each operation is printed on its\n    own line with an index, the operation name (if available), and the\n    parameters used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf.print_operation_history()\n    1: normalize {}\n    2: low_pass_filter {'cutoff': 1000}\n    \"\"\"\n    if not self.operation_history:\n        print(\"Operation history: &lt;empty&gt;\")\n        return\n\n    print(f\"Operation history ({len(self.operation_history)}):\")\n    for i, record in enumerate(self.operation_history, start=1):\n        # record is expected to be a dict with at least a 'operation' key\n        op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n        # Copy params for display - exclude the 'operation'/'name' keys\n        params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n        print(f\"{i}: {op_name} {params}\")\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.to_numpy--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") data = cf.to_numpy() print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def to_numpy(self) -&gt; T:\n    \"\"\"Convert the frame data to a NumPy array.\n\n    This method computes the Dask array and returns it as a concrete NumPy array.\n    The returned array has the same shape as the frame's data.\n\n    Returns\n    -------\n    T\n        NumPy array containing the frame data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; data = cf.to_numpy()\n    &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n    \"\"\"\n    return self.data\n</code></pre>"},{"location":"en/api/#wandas.core.base_frame.BaseFrame.to_dataframe--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") df = cf.to_dataframe() print(df.head())</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"Convert the frame data to a pandas DataFrame.\n\n    This method provides a common implementation for converting frame data\n    to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with appropriate index and columns.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; df = cf.to_dataframe()\n    &gt;&gt;&gt; print(df.head())\n    \"\"\"\n    # Get data as numpy array\n    data = self.to_numpy()\n\n    # Get column names from subclass\n    columns = self._get_dataframe_columns()\n\n    # Get index from subclass\n    index = self._get_dataframe_index()\n\n    # Create DataFrame\n    if data.ndim == 1:\n        # Single channel case - reshape to 2D\n        df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n    else:\n        # Multi-channel case - transpose to (n_samples, n_channels)\n        df = pd.DataFrame(data.T, columns=columns, index=index)\n\n    return df\n</code></pre>"},{"location":"en/api/#wandas.core.metadata.ChannelMetadata","title":"<code>ChannelMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data class for storing channel metadata</p> Source code in <code>wandas/core/metadata.py</code> <pre><code>class ChannelMetadata(BaseModel):\n    \"\"\"\n    Data class for storing channel metadata\n    \"\"\"\n\n    label: str = \"\"\n    unit: str = \"\"\n    ref: float = 1.0\n    # Additional metadata for extensibility\n    extra: dict[str, Any] = Field(default_factory=dict)\n\n    def __init__(self, **data: Any):\n        super().__init__(**data)\n        # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n        if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n            self.ref = unit_to_ref(self.unit)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n        super().__setattr__(name, value)\n        # Only proceed if unit is being set to a non-empty value\n        if name == \"unit\" and value and isinstance(value, str):\n            super().__setattr__(\"ref\", unit_to_ref(value))\n\n    @property\n    def label_value(self) -&gt; str:\n        \"\"\"Get the label value\"\"\"\n        return self.label\n\n    @property\n    def unit_value(self) -&gt; str:\n        \"\"\"Get the unit value\"\"\"\n        return self.unit\n\n    @property\n    def ref_value(self) -&gt; float:\n        \"\"\"Get the ref value\"\"\"\n        return self.ref\n\n    @property\n    def extra_data(self) -&gt; dict[str, Any]:\n        \"\"\"Get the extra metadata dictionary\"\"\"\n        return self.extra\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Provide dictionary-like behavior\"\"\"\n        if key == \"label\":\n            return self.label\n        elif key == \"unit\":\n            return self.unit\n        elif key == \"ref\":\n            return self.ref\n        else:\n            return self.extra.get(key)\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        \"\"\"Provide dictionary-like behavior\"\"\"\n        if key == \"label\":\n            self.label = value\n        elif key == \"unit\":\n            self.unit = value\n            self.ref = unit_to_ref(value)\n        elif key == \"ref\":\n            self.ref = value\n        else:\n            self.extra[key] = value\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert to JSON format\"\"\"\n        json_data: str = self.model_dump_json(indent=4)\n        return json_data\n\n    @classmethod\n    def from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n        \"\"\"Convert from JSON format\"\"\"\n        root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n        return root_model\n</code></pre> Attributes\u00b6 <code></code> <code>label = ''</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>unit = ''</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ref = 1.0</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>extra = Field(default_factory=dict)</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>label_value</code> <code>property</code> \u00b6 <p>Get the label value</p> <code></code> <code>unit_value</code> <code>property</code> \u00b6 <p>Get the unit value</p> <code></code> <code>ref_value</code> <code>property</code> \u00b6 <p>Get the ref value</p> <code></code> <code>extra_data</code> <code>property</code> \u00b6 <p>Get the extra metadata dictionary</p> Functions\u00b6 <code></code> <code>__init__(**data)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __init__(self, **data: Any):\n    super().__init__(**data)\n    # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n    if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n        self.ref = unit_to_ref(self.unit)\n</code></pre> <code></code> <code>__setattr__(name, value)</code> \u00b6 <p>Override setattr to update ref when unit is changed directly</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n    super().__setattr__(name, value)\n    # Only proceed if unit is being set to a non-empty value\n    if name == \"unit\" and value and isinstance(value, str):\n        super().__setattr__(\"ref\", unit_to_ref(value))\n</code></pre> <code></code> <code>__getitem__(key)</code> \u00b6 <p>Provide dictionary-like behavior</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        return self.label\n    elif key == \"unit\":\n        return self.unit\n    elif key == \"ref\":\n        return self.ref\n    else:\n        return self.extra.get(key)\n</code></pre> <code></code> <code>__setitem__(key, value)</code> \u00b6 <p>Provide dictionary-like behavior</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __setitem__(self, key: str, value: Any) -&gt; None:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        self.label = value\n    elif key == \"unit\":\n        self.unit = value\n        self.ref = unit_to_ref(value)\n    elif key == \"ref\":\n        self.ref = value\n    else:\n        self.extra[key] = value\n</code></pre> <code></code> <code>to_json()</code> \u00b6 <p>Convert to JSON format</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert to JSON format\"\"\"\n    json_data: str = self.model_dump_json(indent=4)\n    return json_data\n</code></pre> <code></code> <code>from_json(json_data)</code> <code>classmethod</code> \u00b6 <p>Convert from JSON format</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n    \"\"\"Convert from JSON format\"\"\"\n    root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n    return root_model\n</code></pre>"},{"location":"en/api/#frames-module","title":"Frames Module","text":"<p>The frames module defines different types of data frames.</p>"},{"location":"en/api/#wandas.frames.ChannelFrame.time","title":"<code>time</code>  <code>property</code>","text":"<p>Get time array for the signal.</p> <p>The time array represents the start time of each sample, calculated as sample_index / sampling_rate. This provides a uniform, evenly-spaced time axis that is consistent across all frame types in wandas.</p> <p>For frames resulting from windowed analysis operations (e.g., FFT, loudness, roughness), each time point corresponds to the start of the analysis window, not the center. This differs from some libraries (e.g., MoSQITo) which use window center times, but does not affect the calculated values themselves.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Array of time points in seconds, starting from 0.0.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; time = signal.time\n&gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n&gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.rms","title":"<code>rms</code>  <code>property</code>","text":"<p>Calculate RMS (Root Mean Square) value for each channel.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Array of RMS values, one per channel.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; rms_values = cf.rms\n&gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n&gt;&gt;&gt; # Select channels with RMS &gt; threshold\n&gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a ChannelFrame.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>Array</code> <p>Dask array containing channel data.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate of the data in Hz. Must be a positive value.</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If data has more than 2 dimensions, or if sampling_rate is not positive.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def __init__(\n    self,\n    data: DaskArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a ChannelFrame.\n\n    Args:\n        data: Dask array containing channel data.\n        Shape should be (n_channels, n_samples).\n        sampling_rate: The sampling rate of the data in Hz.\n            Must be a positive value.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Raises:\n        ValueError: If data has more than 2 dimensions, or if\n            sampling_rate is not positive.\n    \"\"\"\n    # Validate sampling rate\n    validate_sampling_rate(sampling_rate)\n\n    # Validate and reshape data\n    if data.ndim == 1:\n        data = da.reshape(data, (1, -1))\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Invalid data shape for ChannelFrame\\n\"\n            f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n            f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n            f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n            f\"  (1, n_samples).\\n\"\n            f\"For higher-dimensional data, reshape it before creating\\n\"\n            f\"  ChannelFrame:\\n\"\n            f\"  Example: data.reshape(n_channels, -1)\"\n        )\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.info--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.info() Channels: 2 Sampling rate: 44100 Hz Duration: 1.0 s Samples: 44100 Channel labels: ['ch0', 'ch1']</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the ChannelFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - Duration\n    - Number of samples\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; cf.info()\n    Channels: 2\n    Sampling rate: 44100 Hz\n    Duration: 1.0 s\n    Samples: 44100\n    Channel labels: ['ch0', 'ch1']\n    \"\"\"\n    print(\"ChannelFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  Duration: {self.duration:.1f} s\")\n    print(f\"  Samples: {self.n_samples}\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.add","title":"<code>add(other, snr=None)</code>","text":"<p>Add another signal or value to the current signal.</p> <p>If SNR is specified, performs addition with consideration for signal-to-noise ratio.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>other</code> <code>ChannelFrame | int | float | NDArrayReal</code> <p>Signal or value to add.</p> \u5fc5\u9808 <code>snr</code> <code>float | None</code> <p>Signal-to-noise ratio (dB). If specified, adjusts the scale of the other signal based on this SNR. self is treated as the signal, and other as the noise.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new channel frame containing the addition result (lazy execution).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def add(\n    self,\n    other: \"ChannelFrame | int | float | NDArrayReal\",\n    snr: float | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add another signal or value to the current signal.\n\n    If SNR is specified, performs addition with consideration for\n    signal-to-noise ratio.\n\n    Args:\n        other: Signal or value to add.\n        snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n            other signal based on this SNR.\n            self is treated as the signal, and other as the noise.\n\n    Returns:\n        A new channel frame containing the addition result (lazy execution).\n    \"\"\"\n    logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n    if isinstance(other, ChannelFrame):\n        # Check if sampling rates match\n        if self.sampling_rate != other.sampling_rate:\n            raise ValueError(\n                \"Sampling rates do not match. Cannot perform operation.\"\n            )\n\n    elif isinstance(other, np.ndarray):\n        other = ChannelFrame.from_numpy(\n            other, self.sampling_rate, label=\"array_data\"\n        )\n    elif isinstance(other, int | float):\n        return self + other\n    else:\n        raise TypeError(\n            \"Addition target with SNR must be a ChannelFrame or \"\n            f\"NumPy array: {type(other)}\"\n        )\n\n    # If SNR is specified, adjust the length of the other signal\n    if other.duration != self.duration:\n        other = other.fix_length(length=self.n_samples)\n\n    if snr is None:\n        return self + other\n    return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.plot","title":"<code>plot(plot_type='waveform', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, **kwargs)</code>","text":"<p>Plot the frame data.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>plot_type</code> <code>str</code> <p>Type of plot. Default is \"waveform\".</p> <code>'waveform'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot. If None, uses the frame label.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay all channels on a single plot (True) or create separate subplots for each channel (False).</p> <code>False</code> <code>xlabel</code> <code>str | None</code> <p>Label for the x-axis. If None, uses default based on plot type.</p> <code>None</code> <code>ylabel</code> <code>str | None</code> <p>Label for the y-axis. If None, uses default based on plot type.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level for the plot lines (0.0 to 1.0).</p> <code>1.0</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Limits for the x-axis as (min, max) tuple.</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Limits for the y-axis as (min, max) tuple.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional matplotlib Line2D parameters (e.g., color, linewidth, linestyle). These are passed to the underlying matplotlib plot functions.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic plot\n&gt;&gt;&gt; cf.plot()\n&gt;&gt;&gt; # Overlay all channels\n&gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"waveform\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the frame data.\n\n    Args:\n        plot_type: Type of plot. Default is \"waveform\".\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot. If None, uses the frame label.\n        overlay: Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel: Label for the x-axis. If None, uses default based on plot type.\n        ylabel: Label for the y-axis. If None, uses default based on plot type.\n        alpha: Transparency level for the plot lines (0.0 to 1.0).\n        xlim: Limits for the x-axis as (min, max) tuple.\n        ylim: Limits for the y-axis as (min, max) tuple.\n        **kwargs: Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n            These are passed to the underlying matplotlib plot functions.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic plot\n        &gt;&gt;&gt; cf.plot()\n        &gt;&gt;&gt; # Overlay all channels\n        &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n    \"\"\"\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    from ..visualization.plotting import create_operation\n\n    plot_strategy = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.rms_plot","title":"<code>rms_plot(ax=None, title=None, overlay=True, Aw=False, **kwargs)</code>","text":"<p>Generate an RMS plot.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay the plot on the existing axis.</p> <code>True</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the plot() method. Accepts the same arguments as plot() including xlabel, ylabel, alpha, xlim, ylim, and matplotlib Line2D parameters.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic RMS plot\n&gt;&gt;&gt; cf.rms_plot()\n&gt;&gt;&gt; # With A-weighting\n&gt;&gt;&gt; cf.rms_plot(Aw=True)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def rms_plot(\n    self,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = True,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Generate an RMS plot.\n\n    Args:\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot.\n        overlay: Whether to overlay the plot on the existing axis.\n        Aw: Apply A-weighting.\n        **kwargs: Additional arguments passed to the plot() method.\n            Accepts the same arguments as plot() including xlabel, ylabel,\n            alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic RMS plot\n        &gt;&gt;&gt; cf.rms_plot()\n        &gt;&gt;&gt; # With A-weighting\n        &gt;&gt;&gt; cf.rms_plot(Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n    \"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n    rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n    return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.describe","title":"<code>describe(normalize=True, is_close=True, *, fmin=0, fmax=None, cmap='jet', vmin=None, vmax=None, xlim=None, ylim=None, Aw=False, waveform=None, spectral=None, **kwargs)</code>","text":"<p>Display visual and audio representation of the frame.</p> <p>This method creates a comprehensive visualization with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>normalize</code> <code>bool</code> <p>Whether to normalize the audio data for playback. Default: True</p> <code>True</code> <code>is_close</code> <code>bool</code> <p>Whether to close the figure after displaying. Default: True</p> <code>True</code> <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>0</code> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency (sampling_rate / 2)</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>'jet'</code> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots. Format: (start_time, end_time)</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots. Format: (min_freq, max_freq)</p> <code>None</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>False</code> <code>waveform</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for waveform subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>spectral</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for spectral subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Deprecated parameters for backward compatibility only. - axis_config: Old configuration format (use waveform/spectral instead) - cbar_config: Old colorbar configuration (use vmin/vmax instead)</p> <code>{}</code> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom waveform subplot settings\n&gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def describe(\n    self,\n    normalize: bool = True,\n    is_close: bool = True,\n    *,\n    fmin: float = 0,\n    fmax: float | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    waveform: dict[str, Any] | None = None,\n    spectral: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Display visual and audio representation of the frame.\n\n    This method creates a comprehensive visualization with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Args:\n        normalize: Whether to normalize the audio data for playback.\n            Default: True\n        is_close: Whether to close the figure after displaying.\n            Default: True\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency (sampling_rate / 2)\n        cmap: Colormap for the spectrogram.\n            Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n            Format: (start_time, end_time)\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n            Format: (min_freq, max_freq)\n        Aw: Apply A-weighting to the frequency analysis.\n            Default: False\n        waveform: Additional configuration dict for waveform subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        spectral: Additional configuration dict for spectral subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        **kwargs: Deprecated parameters for backward compatibility only.\n            - axis_config: Old configuration format (use waveform/spectral instead)\n            - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom waveform subplot settings\n        &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n    \"\"\"\n    # Prepare kwargs with explicit parameters\n    plot_kwargs: dict[str, Any] = {\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"xlim\": xlim,\n        \"ylim\": ylim,\n        \"Aw\": Aw,\n        \"waveform\": waveform or {},\n        \"spectral\": spectral or {},\n    }\n    # Merge with additional kwargs\n    plot_kwargs.update(kwargs)\n\n    if \"axis_config\" in plot_kwargs:\n        logger.warning(\n            \"axis_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        axis_config = plot_kwargs[\"axis_config\"]\n        if \"time_plot\" in axis_config:\n            plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n        if \"freq_plot\" in axis_config:\n            if \"xlim\" in axis_config[\"freq_plot\"]:\n                vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                plot_kwargs[\"vmin\"] = vlim[0]\n                plot_kwargs[\"vmax\"] = vlim[1]\n            if \"ylim\" in axis_config[\"freq_plot\"]:\n                ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                plot_kwargs[\"ylim\"] = ylim_config\n\n    if \"cbar_config\" in plot_kwargs:\n        logger.warning(\n            \"cbar_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        cbar_config = plot_kwargs[\"cbar_config\"]\n        if \"vmin\" in cbar_config:\n            plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n        if \"vmax\" in cbar_config:\n            plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n    for ch in self:\n        ax: Axes\n        _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n        if isinstance(_ax, Iterator):\n            ax = next(iter(_ax))\n        elif isinstance(_ax, Axes):\n            ax = _ax\n        else:\n            raise TypeError(\n                f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n            )\n        # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n        display(ax.figure)\n        if is_close:\n            plt.close(getattr(ax, \"figure\", None))\n        display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.from_numpy","title":"<code>from_numpy(data, sampling_rate, label=None, metadata=None, ch_labels=None, ch_units=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>NDArrayReal</code> <p>NumPy array containing channel data.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>ch_units</code> <code>list[str] | str | None</code> <p>Units for each channel.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the NumPy data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayReal,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    ch_labels: list[str] | None = None,\n    ch_units: list[str] | str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing channel data.\n        sampling_rate: The sampling rate in Hz.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        ch_labels: Labels for each channel.\n        ch_units: Units for each channel.\n\n    Returns:\n        A new ChannelFrame containing the NumPy data.\n    \"\"\"\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n\n    # Convert NumPy array to dask array\n    dask_data = da_from_array(data)\n    cf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        label=label or \"numpy_data\",\n    )\n    if metadata is not None:\n        cf.metadata = metadata\n    if ch_labels is not None:\n        if len(ch_labels) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel labels does not match the number of channels\"\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    if ch_units is not None:\n        if isinstance(ch_units, str):\n            ch_units = [ch_units] * cf.n_channels\n\n        if len(ch_units) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel units does not match the number of channels\"\n            )\n        for i in range(len(ch_units)):\n            cf._channel_metadata[i].unit = ch_units[i]\n\n    return cf\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.from_ndarray","title":"<code>from_ndarray(array, sampling_rate, labels=None, unit=None, frame_label=None, metadata=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>This method is deprecated. Use from_numpy instead.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>array</code> <code>NDArrayReal</code> <p>Signal data. Each row corresponds to a channel.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>Sampling rate (Hz).</p> \u5fc5\u9808 <code>labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>unit</code> <code>list[str] | str | None</code> <p>Unit of the signal.</p> <code>None</code> <code>frame_label</code> <code>str | None</code> <p>Label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_ndarray(\n    cls,\n    array: NDArrayReal,\n    sampling_rate: float,\n    labels: list[str] | None = None,\n    unit: list[str] | str | None = None,\n    frame_label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    This method is deprecated. Use from_numpy instead.\n\n    Args:\n        array: Signal data. Each row corresponds to a channel.\n        sampling_rate: Sampling rate (Hz).\n        labels: Labels for each channel.\n        unit: Unit of the signal.\n        frame_label: Label for the frame.\n        metadata: Optional metadata dictionary.\n\n    Returns:\n        A new ChannelFrame containing the data.\n    \"\"\"\n    # Redirect to from_numpy for compatibility\n    # However, from_ndarray is deprecated\n    logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n    return cls.from_numpy(\n        data=array,\n        sampling_rate=sampling_rate,\n        label=frame_label,\n        metadata=metadata,\n        ch_labels=labels,\n        ch_units=unit,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.from_file","title":"<code>from_file(path, channel=None, start=None, end=None, chunk_size=None, ch_labels=None, time_column=0, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from an audio file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the audio file.</p> \u5fc5\u9808 <code>channel</code> <code>int | list[int] | None</code> <p>Channel(s) to load.</p> <code>None</code> <code>start</code> <code>float | None</code> <p>Start time in seconds.</p> <code>None</code> <code>end</code> <code>float | None</code> <p>End time in seconds.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Chunk size for processing. Specifies the splitting size for lazy processing.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>time_column</code> <code>int | str</code> <p>For CSV files, index or name of the time column. Default is 0 (first column).</p> <code>0</code> <code>delimiter</code> <code>str</code> <p>For CSV files, delimiter character. Default is \",\".</p> <code>','</code> <code>header</code> <code>int | None</code> <p>For CSV files, row number to use as header. Default is 0 (first row). Set to None if no header.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the loaded audio data.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If channel specification is invalid.</p> <code>TypeError</code> <p>If channel parameter type is invalid.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist at the specified path. Error message includes absolute path, current directory, and troubleshooting suggestions.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; # Load WAV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n&gt;&gt;&gt; # Load specific channels\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n&gt;&gt;&gt; # Load CSV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\n...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n... )\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    channel: int | list[int] | None = None,\n    start: float | None = None,\n    end: float | None = None,\n    chunk_size: int | None = None,\n    ch_labels: list[str] | None = None,\n    # CSV-specific parameters\n    time_column: int | str = 0,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from an audio file.\n\n    Args:\n        path: Path to the audio file.\n        channel: Channel(s) to load.\n        start: Start time in seconds.\n        end: End time in seconds.\n        chunk_size: Chunk size for processing.\n            Specifies the splitting size for lazy processing.\n        ch_labels: Labels for each channel.\n        time_column: For CSV files, index or name of the time column.\n            Default is 0 (first column).\n        delimiter: For CSV files, delimiter character. Default is \",\".\n        header: For CSV files, row number to use as header.\n            Default is 0 (first row). Set to None if no header.\n\n    Returns:\n        A new ChannelFrame containing the loaded audio data.\n\n    Raises:\n        ValueError: If channel specification is invalid.\n        TypeError: If channel parameter type is invalid.\n        FileNotFoundError: If the file doesn't exist at the specified path.\n            Error message includes absolute path, current directory, and\n            troubleshooting suggestions.\n\n    Examples:\n        &gt;&gt;&gt; # Load WAV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n        &gt;&gt;&gt; # Load specific channels\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n        &gt;&gt;&gt; # Load CSV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\n        ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n        ... )\n    \"\"\"\n    from .channel import ChannelFrame\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Audio file not found\\n\"\n            f\"  Path: {path.absolute()}\\n\"\n            f\"  Current directory: {Path.cwd()}\\n\"\n            f\"Please check:\\n\"\n            f\"  - File path is correct\\n\"\n            f\"  - File exists at the specified location\\n\"\n            f\"  - You have read permissions for the file\"\n        )\n\n    # Get file reader\n    reader = get_file_reader(path)\n\n    # Build kwargs for reader\n    reader_kwargs: dict[str, Any] = {}\n    if path.suffix.lower() == \".csv\":\n        reader_kwargs[\"time_column\"] = time_column\n        reader_kwargs[\"delimiter\"] = delimiter\n        if header is not None:\n            reader_kwargs[\"header\"] = header\n\n    # Get file info\n    info = reader.get_file_info(path, **reader_kwargs)\n    sr = info[\"samplerate\"]\n    n_channels = info[\"channels\"]\n    n_frames = info[\"frames\"]\n    ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n    logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n    # Channel selection processing\n    all_channels = list(range(n_channels))\n\n    if channel is None:\n        channels_to_load = all_channels\n        logger.debug(f\"Will load all channels: {channels_to_load}\")\n    elif isinstance(channel, int):\n        if channel &lt; 0 or channel &gt;= n_channels:\n            raise ValueError(\n                f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n            )\n        channels_to_load = [channel]\n        logger.debug(f\"Will load single channel: {channel}\")\n    elif isinstance(channel, list | tuple):\n        for ch in channel:\n            if ch &lt; 0 or ch &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n        channels_to_load = list(channel)\n        logger.debug(f\"Will load specific channels: {channels_to_load}\")\n    else:\n        raise TypeError(\"channel must be int, list, or None\")\n\n    # Index calculation\n    start_idx = 0 if start is None else max(0, int(start * sr))\n    end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n    frames_to_read = end_idx - start_idx\n\n    logger.debug(\n        f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n        f\"start_idx={start_idx}, end_idx={end_idx}\"\n    )\n\n    # Settings for lazy loading\n    expected_shape = (len(channels_to_load), frames_to_read)\n\n    # Define the loading function using the file reader\n    def _load_audio() -&gt; NDArrayReal:\n        logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n        # Use the reader to get audio data with parameters\n        out = reader.get_data(\n            path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n        )\n        if not isinstance(out, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n        return out\n\n    logger.debug(\n        f\"Creating delayed dask task with expected shape: {expected_shape}\"\n    )\n\n    # Create delayed operation\n    delayed_data = dask_delayed(_load_audio)()\n    logger.debug(\"Wrapping delayed function in dask array\")\n\n    # Create dask array from delayed computation\n    dask_array = da_from_delayed(\n        delayed_data, shape=expected_shape, dtype=np.float32\n    )\n\n    if chunk_size is not None:\n        if chunk_size &lt;= 0:\n            raise ValueError(\"Chunk size must be a positive integer\")\n        logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n        dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n    logger.debug(\n        \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n    )\n\n    cf = ChannelFrame(\n        data=dask_array,\n        sampling_rate=sr,\n        label=path.stem,\n        metadata={\n            \"filename\": str(path),\n        },\n    )\n    if ch_labels is not None:\n        if len(ch_labels) != len(cf):\n            raise ValueError(\n                \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    return cf\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.read_wav","title":"<code>read_wav(filename, labels=None)</code>  <code>classmethod</code>","text":"<p>Utility method to read a WAV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>filename</code> <code>str</code> <p>Path to the WAV file.</p> \u5fc5\u9808 <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a WAV file.\n\n    Args:\n        filename: Path to the WAV file.\n        labels: Labels to set for each channel.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(filename, ch_labels=labels)\n    return cf\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.read_csv","title":"<code>read_csv(filename, time_column=0, labels=None, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Utility method to read a CSV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> \u5fc5\u9808 <code>time_column</code> <code>int | str</code> <p>Index or name of the time column.</p> <code>0</code> <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>Delimiter character.</p> <code>','</code> <code>header</code> <code>int | None</code> <p>Row number to use as header.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; # Read CSV with default settings\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n&gt;&gt;&gt; # Read CSV with custom delimiter\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n&gt;&gt;&gt; # Read CSV without header\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_csv(\n    cls,\n    filename: str,\n    time_column: int | str = 0,\n    labels: list[str] | None = None,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a CSV file.\n\n    Args:\n        filename: Path to the CSV file.\n        time_column: Index or name of the time column.\n        labels: Labels to set for each channel.\n        delimiter: Delimiter character.\n        header: Row number to use as header.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n\n    Examples:\n        &gt;&gt;&gt; # Read CSV with default settings\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n        &gt;&gt;&gt; # Read CSV with custom delimiter\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n        &gt;&gt;&gt; # Read CSV without header\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(\n        filename,\n        ch_labels=labels,\n        time_column=time_column,\n        delimiter=delimiter,\n        header=header,\n    )\n    return cf\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.to_wav","title":"<code>to_wav(path, format=None)</code>","text":"<p>Save the audio data to a WAV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to save the file.</p> \u5fc5\u9808 <code>format</code> <code>str | None</code> <p>File format. If None, determined from file extension.</p> <code>None</code> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n    \"\"\"Save the audio data to a WAV file.\n\n    Args:\n        path: Path to save the file.\n        format: File format. If None, determined from file extension.\n    \"\"\"\n    from wandas.io.wav_io import write_wav\n\n    write_wav(str(path), self, format=format)\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.save","title":"<code>save(path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save the ChannelFrame to a WDF (Wandas Data File) format.</p> <p>This saves the complete frame including all channel data and metadata in a format that can be loaded back with full fidelity.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Example <p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.save(\"audio_analysis.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def save(\n    self,\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n    This saves the complete frame including all channel data and metadata\n    in a format that can be loaded back with full fidelity.\n\n    Args:\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import save as wdf_save\n\n    wdf_save(\n        self,\n        path,\n        format=format,\n        compress=compress,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.load","title":"<code>load(path, *, format='hdf5')</code>  <code>classmethod</code>","text":"<p>Load a ChannelFrame from a WDF (Wandas Data File) file.</p> <p>This loads data saved with the save() method, preserving all channel data, metadata, labels, and units.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame with all data and metadata loaded</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>NotImplementedError</code> <p>For unsupported formats</p> Example <p>cf = ChannelFrame.load(\"audio_analysis.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n    This loads data saved with the save() method, preserving all channel data,\n    metadata, labels, and units.\n\n    Args:\n        path: Path to the WDF file\n        format: Format of the file (currently only 'hdf5' is supported)\n\n    Returns:\n        A new ChannelFrame with all data and metadata loaded\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        NotImplementedError: For unsupported formats\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import load as wdf_load\n\n    return wdf_load(path, format=format)\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.add_channel","title":"<code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False)</code>","text":"<p>Add a new channel to the frame.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>ndarray[Any, Any] | Array | ChannelFrame</code> <p>Data to add as a new channel. Can be: - numpy array (1D or 2D) - dask array (1D or 2D) - ChannelFrame (channels will be added)</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>Label for the new channel. If None, generates a default label. Ignored when data is a ChannelFrame (uses its channel labels).</p> <code>None</code> <code>align</code> <code>str</code> <p>How to handle length mismatches: - \"strict\": Raise error if lengths don't match - \"pad\": Pad shorter data with zeros - \"truncate\": Truncate longer data to match</p> <code>'strict'</code> <code>suffix_on_dup</code> <code>str | None</code> <p>Suffix to add to duplicate labels. If None, raises error.</p> <code>None</code> <code>inplace</code> <code>bool</code> <p>If True, modifies the frame in place. Otherwise returns a new frame.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>Modified ChannelFrame (self if inplace=True, new frame otherwise).</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If data length doesn't match and align=\"strict\", or if label is duplicate and suffix_on_dup is None.</p> <code>TypeError</code> <p>If data type is not supported.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Add a numpy array as a new channel\n&gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n&gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n&gt;&gt;&gt; # Add another ChannelFrame's channels\n&gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n&gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def add_channel(\n    self,\n    data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n    label: str | None = None,\n    align: str = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add a new channel to the frame.\n\n    Args:\n        data: Data to add as a new channel. Can be:\n            - numpy array (1D or 2D)\n            - dask array (1D or 2D)\n            - ChannelFrame (channels will be added)\n        label: Label for the new channel. If None, generates a default label.\n            Ignored when data is a ChannelFrame (uses its channel labels).\n        align: How to handle length mismatches:\n            - \"strict\": Raise error if lengths don't match\n            - \"pad\": Pad shorter data with zeros\n            - \"truncate\": Truncate longer data to match\n        suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n        inplace: If True, modifies the frame in place.\n            Otherwise returns a new frame.\n\n    Returns:\n        Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n    Raises:\n        ValueError: If data length doesn't match and align=\"strict\",\n            or if label is duplicate and suffix_on_dup is None.\n        TypeError: If data type is not supported.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Add a numpy array as a new channel\n        &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n        &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n        &gt;&gt;&gt; # Add another ChannelFrame's channels\n        &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n        &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n    \"\"\"\n    # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n    if isinstance(data, ChannelFrame):\n        if self.sampling_rate != data.sampling_rate:\n            raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n        if data.n_samples != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - data.n_samples\n                arr = data._data\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = data._data[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        else:\n            arr = data._data\n        labels = [ch.label for ch in self._channel_metadata]\n        new_labels = []\n        new_metadata_list = []\n        for chmeta in data._channel_metadata:\n            new_label = chmeta.label\n            if new_label in labels or new_label in new_labels:\n                if suffix_on_dup:\n                    new_label += suffix_on_dup\n                else:\n                    raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n            new_labels.append(new_label)\n            # Copy the entire channel_metadata and update only the label\n            new_ch_meta = chmeta.model_copy(deep=True)\n            new_ch_meta.label = new_label\n            new_metadata_list.append(new_ch_meta)\n        new_data = concatenate([self._data, arr], axis=0)\n\n        new_chmeta = self._channel_metadata + new_metadata_list\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n    if isinstance(data, np.ndarray):\n        arr = from_array(data.reshape(1, -1))\n    elif isinstance(data, DaskArray):\n        arr = data[None, ...] if data.ndim == 1 else data\n        if arr.shape[0] != 1:\n            arr = arr.reshape((1, -1))\n    else:\n        raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n    if arr.shape[1] != self.n_samples:\n        if align == \"pad\":\n            pad_len = self.n_samples - arr.shape[1]\n            if pad_len &gt; 0:\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n            else:\n                arr = arr[:, : self.n_samples]\n        elif align == \"truncate\":\n            arr = arr[:, : self.n_samples]\n            if arr.shape[1] &lt; self.n_samples:\n                pad_len = self.n_samples - arr.shape[1]\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n        else:\n            raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n    labels = [ch.label for ch in self._channel_metadata]\n    new_label = label or f\"ch{len(labels)}\"\n    if new_label in labels:\n        if suffix_on_dup:\n            new_label += suffix_on_dup\n        else:\n            raise ValueError(\"label\u91cd\u8907\")\n    new_data = concatenate([self._data, arr], axis=0)\n    from ..core.metadata import ChannelMetadata\n\n    new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"en/api/#wandas.frames.ChannelFrame.remove_channel","title":"<code>remove_channel(key, inplace=False)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n    if isinstance(key, int):\n        if not (0 &lt;= key &lt; self.n_channels):\n            raise IndexError(f\"index {key} out of range\")\n        idx = key\n    else:\n        labels = [ch.label for ch in self._channel_metadata]\n        if key not in labels:\n            raise KeyError(f\"label {key} not found\")\n        idx = labels.index(key)\n    new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n    new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"en/api/#wandas.frames.RoughnessFrame.__init__","title":"<code>__init__(data, sampling_rate, bark_axis, overlap, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a RoughnessFrame.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/roughness.py</code> <pre><code>def __init__(\n    self,\n    data: da.Array,\n    sampling_rate: float,\n    bark_axis: NDArrayReal,\n    overlap: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a RoughnessFrame.\"\"\"\n    # Validate dimensions\n    if data.ndim not in (2, 3):\n        raise ValueError(\n            f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n        )\n\n    # Validate Bark bands\n    if data.shape[-2] != 47:\n        raise ValueError(\n            f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n            f\"(data shape: {data.shape})\"\n        )\n\n    if len(bark_axis) != 47:\n        raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n    # Validate overlap\n    if not 0.0 &lt;= overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n    # Store Bark-specific attributes\n    self._bark_axis = bark_axis\n    self._overlap = overlap\n\n    # Initialize base frame\n    metadata = metadata or {}\n    metadata[\"overlap\"] = overlap\n\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label or \"roughness_spec\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.RoughnessFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/roughness.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n    RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n    which cannot be directly converted to a 2D DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for RoughnessFrame.\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.RoughnessFrame.plot--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"motor.wav\") roughness_spec = signal.roughness_dw_spec(overlap=0.5) roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/roughness.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"heatmap\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"viridis\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlabel: str = \"Time [s]\",\n    ylabel: str = \"Frequency [Bark]\",\n    colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n    **kwargs: Any,\n) -&gt; \"Axes\":\n    \"\"\"\n    Plot Bark-Time-Roughness heatmap.\n\n    For multi-channel signals, the mean across channels is plotted.\n\n    Parameters\n    ----------\n    ax : Axes, optional\n        Matplotlib axes to plot on. If None, a new figure is created.\n    title : str, optional\n        Plot title. If None, a default title is used.\n    cmap : str, default=\"viridis\"\n        Colormap name for the heatmap.\n    vmin, vmax : float, optional\n        Color scale limits. If None, automatic scaling is used.\n    xlabel : str, default=\"Time [s]\"\n        Label for the x-axis.\n    ylabel : str, default=\"Frequency [Bark]\"\n        Label for the y-axis.\n    colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n        Label for the colorbar.\n    **kwargs : Any\n        Additional keyword arguments passed to pcolormesh.\n\n    Returns\n    -------\n    Axes\n        The matplotlib axes object containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=(10, 6))\n\n    # Select data to plot (first channel for mono, mean for multi-channel)\n    # self._data is Dask array, self.data is computed NumPy array\n    computed_data = self.compute()\n\n    if computed_data.ndim == 2:\n        # Mono: (47, n_time)\n        data_to_plot = computed_data\n    else:\n        # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n        data_to_plot = computed_data.mean(axis=0)\n\n    # Create heatmap\n    im = ax.pcolormesh(\n        self.time,\n        self.bark_axis,\n        data_to_plot,\n        shading=\"auto\",\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n        **kwargs,\n    )\n\n    # Labels and title\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    if title is None:\n        title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n    ax.set_title(title)\n\n    # Colorbar\n    plt.colorbar(im, ax=ax, label=colorbar_label)\n\n    return ax\n</code></pre>"},{"location":"en/api/#wandas.frames.channel.ChannelFrame","title":"<code>ChannelFrame</code>","text":"<p>               Bases: <code>BaseFrame[NDArrayReal]</code>, <code>ChannelProcessingMixin</code>, <code>ChannelTransformMixin</code></p> <p>Channel-based data frame for handling audio signals and time series data.</p> <p>This frame represents channel-based data such as audio signals and time series data, with each channel containing data samples in the time domain.</p> Source code in <code>wandas/frames/channel.py</code> <pre><code>class ChannelFrame(\n    BaseFrame[NDArrayReal], ChannelProcessingMixin, ChannelTransformMixin\n):\n    \"\"\"Channel-based data frame for handling audio signals and time series data.\n\n    This frame represents channel-based data such as audio signals and time series data,\n    with each channel containing data samples in the time domain.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: DaskArray,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a ChannelFrame.\n\n        Args:\n            data: Dask array containing channel data.\n            Shape should be (n_channels, n_samples).\n            sampling_rate: The sampling rate of the data in Hz.\n                Must be a positive value.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Raises:\n            ValueError: If data has more than 2 dimensions, or if\n                sampling_rate is not positive.\n        \"\"\"\n        # Validate sampling rate\n        validate_sampling_rate(sampling_rate)\n\n        # Validate and reshape data\n        if data.ndim == 1:\n            data = da.reshape(data, (1, -1))\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Invalid data shape for ChannelFrame\\n\"\n                f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n                f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n                f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n                f\"  (1, n_samples).\\n\"\n                f\"For higher-dimensional data, reshape it before creating\\n\"\n                f\"  ChannelFrame:\\n\"\n                f\"  Example: data.reshape(n_channels, -1)\"\n            )\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"Returns the number of channels.\"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"Get time array for the signal.\n\n        The time array represents the start time of each sample, calculated as\n        sample_index / sampling_rate. This provides a uniform, evenly-spaced\n        time axis that is consistent across all frame types in wandas.\n\n        For frames resulting from windowed analysis operations (e.g., FFT,\n        loudness, roughness), each time point corresponds to the start of\n        the analysis window, not the center. This differs from some libraries\n        (e.g., MoSQITo) which use window center times, but does not affect\n        the calculated values themselves.\n\n        Returns:\n            Array of time points in seconds, starting from 0.0.\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; time = signal.time\n            &gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n            &gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n        \"\"\"\n        return np.arange(self.n_samples) / self.sampling_rate\n\n    @property\n    def n_samples(self) -&gt; int:\n        \"\"\"Returns the number of samples.\"\"\"\n        n: int = self._data.shape[-1]\n        return n\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Returns the duration in seconds.\"\"\"\n        return self.n_samples / self.sampling_rate\n\n    @property\n    def rms(self) -&gt; NDArrayReal:\n        \"\"\"Calculate RMS (Root Mean Square) value for each channel.\n\n        Returns:\n            Array of RMS values, one per channel.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; rms_values = cf.rms\n            &gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n            &gt;&gt;&gt; # Select channels with RMS &gt; threshold\n            &gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n        \"\"\"\n        # Convert to a concrete NumPy ndarray to satisfy numpy.mean typing\n        # and to ensure dask arrays are materialized for this operation.\n        rms_values = da.sqrt((self._data**2).mean(axis=1))\n        return np.array(rms_values.compute())\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the ChannelFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - Duration\n        - Number of samples\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.info()\n        Channels: 2\n        Sampling rate: 44100 Hz\n        Duration: 1.0 s\n        Samples: 44100\n        Channel labels: ['ch0', 'ch1']\n        \"\"\"\n        print(\"ChannelFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  Duration: {self.duration:.1f} s\")\n        print(f\"  Samples: {self.n_samples}\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        # Get metadata updates from operation\n        metadata_updates = operation.get_metadata_updates()\n\n        # Update channel labels to reflect the operation\n        display_name = operation.get_display_name()\n        new_channel_metadata = self._relabel_channels(operation_name, display_name)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # Apply metadata updates (including sampling_rate if specified)\n        creation_params: dict[str, Any] = {\n            \"data\": processed_data,\n            \"metadata\": new_metadata,\n            \"operation_history\": new_history,\n            \"channel_metadata\": new_channel_metadata,\n        }\n        creation_params.update(metadata_updates)\n\n        return self._create_new_instance(**creation_params)\n\n    def _binary_op(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal | DaskArray\",\n        op: Callable[[\"DaskArray\", Any], \"DaskArray\"],\n        symbol: str,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Common implementation for binary operations\n        - utilizing dask's lazy evaluation.\n\n        Args:\n            other: Right operand for the operation.\n            op: Function to execute the operation (e.g., lambda a, b: a + b).\n            symbol: Symbolic representation of the operation (e.g., '+').\n\n        Returns:\n            A new channel containing the operation result (lazy execution).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, ChannelFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Perform operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Merge channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Perform operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly on dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # Operand display string\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return ChannelFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n                previous=self,\n            )\n\n    def add(\n        self,\n        other: \"ChannelFrame | int | float | NDArrayReal\",\n        snr: float | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add another signal or value to the current signal.\n\n        If SNR is specified, performs addition with consideration for\n        signal-to-noise ratio.\n\n        Args:\n            other: Signal or value to add.\n            snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n                other signal based on this SNR.\n                self is treated as the signal, and other as the noise.\n\n        Returns:\n            A new channel frame containing the addition result (lazy execution).\n        \"\"\"\n        logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n        if isinstance(other, ChannelFrame):\n            # Check if sampling rates match\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n        elif isinstance(other, np.ndarray):\n            other = ChannelFrame.from_numpy(\n                other, self.sampling_rate, label=\"array_data\"\n            )\n        elif isinstance(other, int | float):\n            return self + other\n        else:\n            raise TypeError(\n                \"Addition target with SNR must be a ChannelFrame or \"\n                f\"NumPy array: {type(other)}\"\n            )\n\n        # If SNR is specified, adjust the length of the other signal\n        if other.duration != self.duration:\n            other = other.fix_length(length=self.n_samples)\n\n        if snr is None:\n            return self + other\n        return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n\n    def plot(\n        self,\n        plot_type: str = \"waveform\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Plot the frame data.\n\n        Args:\n            plot_type: Type of plot. Default is \"waveform\".\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot. If None, uses the frame label.\n            overlay: Whether to overlay all channels on a single plot (True)\n                or create separate subplots for each channel (False).\n            xlabel: Label for the x-axis. If None, uses default based on plot type.\n            ylabel: Label for the y-axis. If None, uses default based on plot type.\n            alpha: Transparency level for the plot lines (0.0 to 1.0).\n            xlim: Limits for the x-axis as (min, max) tuple.\n            ylim: Limits for the y-axis as (min, max) tuple.\n            **kwargs: Additional matplotlib Line2D parameters\n                (e.g., color, linewidth, linestyle).\n                These are passed to the underlying matplotlib plot functions.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic plot\n            &gt;&gt;&gt; cf.plot()\n            &gt;&gt;&gt; # Overlay all channels\n            &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n        \"\"\"\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        from ..visualization.plotting import create_operation\n\n        plot_strategy = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def rms_plot(\n        self,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = True,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Generate an RMS plot.\n\n        Args:\n            ax: Optional matplotlib axes for plotting.\n            title: Title for the plot.\n            overlay: Whether to overlay the plot on the existing axis.\n            Aw: Apply A-weighting.\n            **kwargs: Additional arguments passed to the plot() method.\n                Accepts the same arguments as plot() including xlabel, ylabel,\n                alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n        Returns:\n            Single Axes object or iterator of Axes objects.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic RMS plot\n            &gt;&gt;&gt; cf.rms_plot()\n            &gt;&gt;&gt; # With A-weighting\n            &gt;&gt;&gt; cf.rms_plot(Aw=True)\n            &gt;&gt;&gt; # Custom styling\n            &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n        \"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n        rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n        return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n\n    def describe(\n        self,\n        normalize: bool = True,\n        is_close: bool = True,\n        *,\n        fmin: float = 0,\n        fmax: float | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        waveform: dict[str, Any] | None = None,\n        spectral: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Display visual and audio representation of the frame.\n\n        This method creates a comprehensive visualization with three plots:\n        1. Time-domain waveform (top)\n        2. Spectrogram (bottom-left)\n        3. Frequency spectrum via Welch method (bottom-right)\n\n        Args:\n            normalize: Whether to normalize the audio data for playback.\n                Default: True\n            is_close: Whether to close the figure after displaying.\n                Default: True\n            fmin: Minimum frequency to display in the spectrogram (Hz).\n                Default: 0\n            fmax: Maximum frequency to display in the spectrogram (Hz).\n                Default: Nyquist frequency (sampling_rate / 2)\n            cmap: Colormap for the spectrogram.\n                Default: 'jet'\n            vmin: Minimum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            vmax: Maximum value for spectrogram color scale (dB).\n                Auto-calculated if None.\n            xlim: Time axis limits (seconds) for all time-based plots.\n                Format: (start_time, end_time)\n            ylim: Frequency axis limits (Hz) for frequency-based plots.\n                Format: (min_freq, max_freq)\n            Aw: Apply A-weighting to the frequency analysis.\n                Default: False\n            waveform: Additional configuration dict for waveform subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            spectral: Additional configuration dict for spectral subplot.\n                Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n            **kwargs: Deprecated parameters for backward compatibility only.\n                - axis_config: Old configuration format (use waveform/spectral instead)\n                - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Basic usage\n            &gt;&gt;&gt; cf.describe()\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom frequency range\n            &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom color scale\n            &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # A-weighted analysis\n            &gt;&gt;&gt; cf.describe(Aw=True)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom time range\n            &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Custom waveform subplot settings\n            &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n        \"\"\"\n        # Prepare kwargs with explicit parameters\n        plot_kwargs: dict[str, Any] = {\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"xlim\": xlim,\n            \"ylim\": ylim,\n            \"Aw\": Aw,\n            \"waveform\": waveform or {},\n            \"spectral\": spectral or {},\n        }\n        # Merge with additional kwargs\n        plot_kwargs.update(kwargs)\n\n        if \"axis_config\" in plot_kwargs:\n            logger.warning(\n                \"axis_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            axis_config = plot_kwargs[\"axis_config\"]\n            if \"time_plot\" in axis_config:\n                plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n            if \"freq_plot\" in axis_config:\n                if \"xlim\" in axis_config[\"freq_plot\"]:\n                    vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                    plot_kwargs[\"vmin\"] = vlim[0]\n                    plot_kwargs[\"vmax\"] = vlim[1]\n                if \"ylim\" in axis_config[\"freq_plot\"]:\n                    ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                    plot_kwargs[\"ylim\"] = ylim_config\n\n        if \"cbar_config\" in plot_kwargs:\n            logger.warning(\n                \"cbar_config is retained for backward compatibility but will \"\n                \"be deprecated in the future.\"\n            )\n            cbar_config = plot_kwargs[\"cbar_config\"]\n            if \"vmin\" in cbar_config:\n                plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n            if \"vmax\" in cbar_config:\n                plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n        for ch in self:\n            ax: Axes\n            _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n            if isinstance(_ax, Iterator):\n                ax = next(iter(_ax))\n            elif isinstance(_ax, Axes):\n                ax = _ax\n            else:\n                raise TypeError(\n                    f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n                )\n            # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n            display(ax.figure)\n            if is_close:\n                plt.close(getattr(ax, \"figure\", None))\n            display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayReal,\n        sampling_rate: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        ch_labels: list[str] | None = None,\n        ch_units: list[str] | str | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing channel data.\n            sampling_rate: The sampling rate in Hz.\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            ch_labels: Labels for each channel.\n            ch_units: Units for each channel.\n\n        Returns:\n            A new ChannelFrame containing the NumPy data.\n        \"\"\"\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n\n        # Convert NumPy array to dask array\n        dask_data = da_from_array(data)\n        cf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=label or \"numpy_data\",\n        )\n        if metadata is not None:\n            cf.metadata = metadata\n        if ch_labels is not None:\n            if len(ch_labels) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel labels does not match the number of channels\"\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        if ch_units is not None:\n            if isinstance(ch_units, str):\n                ch_units = [ch_units] * cf.n_channels\n\n            if len(ch_units) != cf.n_channels:\n                raise ValueError(\n                    \"Number of channel units does not match the number of channels\"\n                )\n            for i in range(len(ch_units)):\n                cf._channel_metadata[i].unit = ch_units[i]\n\n        return cf\n\n    @classmethod\n    def from_ndarray(\n        cls,\n        array: NDArrayReal,\n        sampling_rate: float,\n        labels: list[str] | None = None,\n        unit: list[str] | str | None = None,\n        frame_label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from a NumPy array.\n\n        This method is deprecated. Use from_numpy instead.\n\n        Args:\n            array: Signal data. Each row corresponds to a channel.\n            sampling_rate: Sampling rate (Hz).\n            labels: Labels for each channel.\n            unit: Unit of the signal.\n            frame_label: Label for the frame.\n            metadata: Optional metadata dictionary.\n\n        Returns:\n            A new ChannelFrame containing the data.\n        \"\"\"\n        # Redirect to from_numpy for compatibility\n        # However, from_ndarray is deprecated\n        logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n        return cls.from_numpy(\n            data=array,\n            sampling_rate=sampling_rate,\n            label=frame_label,\n            metadata=metadata,\n            ch_labels=labels,\n            ch_units=unit,\n        )\n\n    @classmethod\n    def from_file(\n        cls,\n        path: str | Path,\n        channel: int | list[int] | None = None,\n        start: float | None = None,\n        end: float | None = None,\n        chunk_size: int | None = None,\n        ch_labels: list[str] | None = None,\n        # CSV-specific parameters\n        time_column: int | str = 0,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Create a ChannelFrame from an audio file.\n\n        Args:\n            path: Path to the audio file.\n            channel: Channel(s) to load.\n            start: Start time in seconds.\n            end: End time in seconds.\n            chunk_size: Chunk size for processing.\n                Specifies the splitting size for lazy processing.\n            ch_labels: Labels for each channel.\n            time_column: For CSV files, index or name of the time column.\n                Default is 0 (first column).\n            delimiter: For CSV files, delimiter character. Default is \",\".\n            header: For CSV files, row number to use as header.\n                Default is 0 (first row). Set to None if no header.\n\n        Returns:\n            A new ChannelFrame containing the loaded audio data.\n\n        Raises:\n            ValueError: If channel specification is invalid.\n            TypeError: If channel parameter type is invalid.\n            FileNotFoundError: If the file doesn't exist at the specified path.\n                Error message includes absolute path, current directory, and\n                troubleshooting suggestions.\n\n        Examples:\n            &gt;&gt;&gt; # Load WAV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n            &gt;&gt;&gt; # Load specific channels\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n            &gt;&gt;&gt; # Load CSV file\n            &gt;&gt;&gt; cf = ChannelFrame.from_file(\n            ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n            ... )\n        \"\"\"\n        from .channel import ChannelFrame\n\n        path = Path(path)\n        if not path.exists():\n            raise FileNotFoundError(\n                f\"Audio file not found\\n\"\n                f\"  Path: {path.absolute()}\\n\"\n                f\"  Current directory: {Path.cwd()}\\n\"\n                f\"Please check:\\n\"\n                f\"  - File path is correct\\n\"\n                f\"  - File exists at the specified location\\n\"\n                f\"  - You have read permissions for the file\"\n            )\n\n        # Get file reader\n        reader = get_file_reader(path)\n\n        # Build kwargs for reader\n        reader_kwargs: dict[str, Any] = {}\n        if path.suffix.lower() == \".csv\":\n            reader_kwargs[\"time_column\"] = time_column\n            reader_kwargs[\"delimiter\"] = delimiter\n            if header is not None:\n                reader_kwargs[\"header\"] = header\n\n        # Get file info\n        info = reader.get_file_info(path, **reader_kwargs)\n        sr = info[\"samplerate\"]\n        n_channels = info[\"channels\"]\n        n_frames = info[\"frames\"]\n        ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n        logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n        # Channel selection processing\n        all_channels = list(range(n_channels))\n\n        if channel is None:\n            channels_to_load = all_channels\n            logger.debug(f\"Will load all channels: {channels_to_load}\")\n        elif isinstance(channel, int):\n            if channel &lt; 0 or channel &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n            channels_to_load = [channel]\n            logger.debug(f\"Will load single channel: {channel}\")\n        elif isinstance(channel, list | tuple):\n            for ch in channel:\n                if ch &lt; 0 or ch &gt;= n_channels:\n                    raise ValueError(\n                        f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                    )\n            channels_to_load = list(channel)\n            logger.debug(f\"Will load specific channels: {channels_to_load}\")\n        else:\n            raise TypeError(\"channel must be int, list, or None\")\n\n        # Index calculation\n        start_idx = 0 if start is None else max(0, int(start * sr))\n        end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n        frames_to_read = end_idx - start_idx\n\n        logger.debug(\n            f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n            f\"start_idx={start_idx}, end_idx={end_idx}\"\n        )\n\n        # Settings for lazy loading\n        expected_shape = (len(channels_to_load), frames_to_read)\n\n        # Define the loading function using the file reader\n        def _load_audio() -&gt; NDArrayReal:\n            logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n            # Use the reader to get audio data with parameters\n            out = reader.get_data(\n                path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n            )\n            if not isinstance(out, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n            return out\n\n        logger.debug(\n            f\"Creating delayed dask task with expected shape: {expected_shape}\"\n        )\n\n        # Create delayed operation\n        delayed_data = dask_delayed(_load_audio)()\n        logger.debug(\"Wrapping delayed function in dask array\")\n\n        # Create dask array from delayed computation\n        dask_array = da_from_delayed(\n            delayed_data, shape=expected_shape, dtype=np.float32\n        )\n\n        if chunk_size is not None:\n            if chunk_size &lt;= 0:\n                raise ValueError(\"Chunk size must be a positive integer\")\n            logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n            dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n        logger.debug(\n            \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n        )\n\n        cf = ChannelFrame(\n            data=dask_array,\n            sampling_rate=sr,\n            label=path.stem,\n            metadata={\n                \"filename\": str(path),\n            },\n        )\n        if ch_labels is not None:\n            if len(ch_labels) != len(cf):\n                raise ValueError(\n                    \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n                )\n            for i in range(len(ch_labels)):\n                cf._channel_metadata[i].label = ch_labels[i]\n        return cf\n\n    @classmethod\n    def read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a WAV file.\n\n        Args:\n            filename: Path to the WAV file.\n            labels: Labels to set for each channel.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(filename, ch_labels=labels)\n        return cf\n\n    @classmethod\n    def read_csv(\n        cls,\n        filename: str,\n        time_column: int | str = 0,\n        labels: list[str] | None = None,\n        delimiter: str = \",\",\n        header: int | None = 0,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Utility method to read a CSV file.\n\n        Args:\n            filename: Path to the CSV file.\n            time_column: Index or name of the time column.\n            labels: Labels to set for each channel.\n            delimiter: Delimiter character.\n            header: Row number to use as header.\n\n        Returns:\n            A new ChannelFrame containing the data (lazy loading).\n\n        Examples:\n            &gt;&gt;&gt; # Read CSV with default settings\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n            &gt;&gt;&gt; # Read CSV with custom delimiter\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n            &gt;&gt;&gt; # Read CSV without header\n            &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n        \"\"\"\n        from .channel import ChannelFrame\n\n        cf = ChannelFrame.from_file(\n            filename,\n            ch_labels=labels,\n            time_column=time_column,\n            delimiter=delimiter,\n            header=header,\n        )\n        return cf\n\n    def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n        \"\"\"Save the audio data to a WAV file.\n\n        Args:\n            path: Path to save the file.\n            format: File format. If None, determined from file extension.\n        \"\"\"\n        from wandas.io.wav_io import write_wav\n\n        write_wav(str(path), self, format=format)\n\n    def save(\n        self,\n        path: str | Path,\n        *,\n        format: str = \"hdf5\",\n        compress: str | None = \"gzip\",\n        overwrite: bool = False,\n        dtype: str | np.dtype[Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n        This saves the complete frame including all channel data and metadata\n        in a format that can be loaded back with full fidelity.\n\n        Args:\n            path: Path to save the file. '.wdf' extension will be added if not present.\n            format: Format to use (currently only 'hdf5' is supported)\n            compress: Compression method ('gzip' by default, None for no compression)\n            overwrite: Whether to overwrite existing file\n            dtype: Optional data type conversion before saving (e.g. 'float32')\n\n        Raises:\n            FileExistsError: If the file exists and overwrite=False.\n            NotImplementedError: For unsupported formats.\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import save as wdf_save\n\n        wdf_save(\n            self,\n            path,\n            format=format,\n            compress=compress,\n            overwrite=overwrite,\n            dtype=dtype,\n        )\n\n    @classmethod\n    def load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n        \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n        This loads data saved with the save() method, preserving all channel data,\n        metadata, labels, and units.\n\n        Args:\n            path: Path to the WDF file\n            format: Format of the file (currently only 'hdf5' is supported)\n\n        Returns:\n            A new ChannelFrame with all data and metadata loaded\n\n        Raises:\n            FileNotFoundError: If the file doesn't exist\n            NotImplementedError: For unsupported formats\n\n        Example:\n            &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n        \"\"\"\n        from ..io.wdf_io import load as wdf_load\n\n        return wdf_load(path, format=format)\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"Provide additional initialization arguments required for ChannelFrame.\"\"\"\n        return {}\n\n    def add_channel(\n        self,\n        data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n        label: str | None = None,\n        align: str = \"strict\",\n        suffix_on_dup: str | None = None,\n        inplace: bool = False,\n    ) -&gt; \"ChannelFrame\":\n        \"\"\"Add a new channel to the frame.\n\n        Args:\n            data: Data to add as a new channel. Can be:\n                - numpy array (1D or 2D)\n                - dask array (1D or 2D)\n                - ChannelFrame (channels will be added)\n            label: Label for the new channel. If None, generates a default label.\n                Ignored when data is a ChannelFrame (uses its channel labels).\n            align: How to handle length mismatches:\n                - \"strict\": Raise error if lengths don't match\n                - \"pad\": Pad shorter data with zeros\n                - \"truncate\": Truncate longer data to match\n            suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n            inplace: If True, modifies the frame in place.\n                Otherwise returns a new frame.\n\n        Returns:\n            Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n        Raises:\n            ValueError: If data length doesn't match and align=\"strict\",\n                or if label is duplicate and suffix_on_dup is None.\n            TypeError: If data type is not supported.\n\n        Examples:\n            &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Add a numpy array as a new channel\n            &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n            &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n            &gt;&gt;&gt; # Add another ChannelFrame's channels\n            &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n            &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n        \"\"\"\n        # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n        if isinstance(data, ChannelFrame):\n            if self.sampling_rate != data.sampling_rate:\n                raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n            if data.n_samples != self.n_samples:\n                if align == \"pad\":\n                    pad_len = self.n_samples - data.n_samples\n                    arr = data._data\n                    if pad_len &gt; 0:\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                    else:\n                        arr = arr[:, : self.n_samples]\n                elif align == \"truncate\":\n                    arr = data._data[:, : self.n_samples]\n                    if arr.shape[1] &lt; self.n_samples:\n                        pad_len = self.n_samples - arr.shape[1]\n                        arr = concatenate(\n                            [\n                                arr,\n                                from_array(\n                                    np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                                ),\n                            ],\n                            axis=1,\n                        )\n                else:\n                    raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n            else:\n                arr = data._data\n            labels = [ch.label for ch in self._channel_metadata]\n            new_labels = []\n            new_metadata_list = []\n            for chmeta in data._channel_metadata:\n                new_label = chmeta.label\n                if new_label in labels or new_label in new_labels:\n                    if suffix_on_dup:\n                        new_label += suffix_on_dup\n                    else:\n                        raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n                new_labels.append(new_label)\n                # Copy the entire channel_metadata and update only the label\n                new_ch_meta = chmeta.model_copy(deep=True)\n                new_ch_meta.label = new_label\n                new_metadata_list.append(new_ch_meta)\n            new_data = concatenate([self._data, arr], axis=0)\n\n            new_chmeta = self._channel_metadata + new_metadata_list\n            if inplace:\n                self._data = new_data\n                self._channel_metadata = new_chmeta\n                return self\n            else:\n                return ChannelFrame(\n                    data=new_data,\n                    sampling_rate=self.sampling_rate,\n                    label=self.label,\n                    metadata=self.metadata,\n                    operation_history=self.operation_history,\n                    channel_metadata=new_chmeta,\n                    previous=self,\n                )\n        if isinstance(data, np.ndarray):\n            arr = from_array(data.reshape(1, -1))\n        elif isinstance(data, DaskArray):\n            arr = data[None, ...] if data.ndim == 1 else data\n            if arr.shape[0] != 1:\n                arr = arr.reshape((1, -1))\n        else:\n            raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n        if arr.shape[1] != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - arr.shape[1]\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = arr[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        labels = [ch.label for ch in self._channel_metadata]\n        new_label = label or f\"ch{len(labels)}\"\n        if new_label in labels:\n            if suffix_on_dup:\n                new_label += suffix_on_dup\n            else:\n                raise ValueError(\"label\u91cd\u8907\")\n        new_data = concatenate([self._data, arr], axis=0)\n        from ..core.metadata import ChannelMetadata\n\n        new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n        if isinstance(key, int):\n            if not (0 &lt;= key &lt; self.n_channels):\n                raise IndexError(f\"index {key} out of range\")\n            idx = key\n        else:\n            labels = [ch.label for ch in self._channel_metadata]\n            if key not in labels:\n                raise KeyError(f\"label {key} not found\")\n            idx = labels.index(key)\n        new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n        new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get time index for DataFrame.\"\"\"\n        return pd.Index(self.time, name=\"time\")\n</code></pre> Attributes\u00b6 <code></code> <code>time</code> <code>property</code> \u00b6 <p>Get time array for the signal.</p> <p>The time array represents the start time of each sample, calculated as sample_index / sampling_rate. This provides a uniform, evenly-spaced time axis that is consistent across all frame types in wandas.</p> <p>For frames resulting from windowed analysis operations (e.g., FFT, loudness, roughness), each time point corresponds to the start of the analysis window, not the center. This differs from some libraries (e.g., MoSQITo) which use window center times, but does not affect the calculated values themselves.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Array of time points in seconds, starting from 0.0.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; time = signal.time\n&gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n&gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n</code></pre> <code></code> <code>n_samples</code> <code>property</code> \u00b6 <p>Returns the number of samples.</p> <code></code> <code>duration</code> <code>property</code> \u00b6 <p>Returns the duration in seconds.</p> <code></code> <code>rms</code> <code>property</code> \u00b6 <p>Calculate RMS (Root Mean Square) value for each channel.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Array of RMS values, one per channel.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; rms_values = cf.rms\n&gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n&gt;&gt;&gt; # Select channels with RMS &gt; threshold\n&gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n</code></pre> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 <p>Initialize a ChannelFrame.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>Array</code> <p>Dask array containing channel data.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate of the data in Hz. Must be a positive value.</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If data has more than 2 dimensions, or if sampling_rate is not positive.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def __init__(\n    self,\n    data: DaskArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a ChannelFrame.\n\n    Args:\n        data: Dask array containing channel data.\n        Shape should be (n_channels, n_samples).\n        sampling_rate: The sampling rate of the data in Hz.\n            Must be a positive value.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Raises:\n        ValueError: If data has more than 2 dimensions, or if\n            sampling_rate is not positive.\n    \"\"\"\n    # Validate sampling rate\n    validate_sampling_rate(sampling_rate)\n\n    # Validate and reshape data\n    if data.ndim == 1:\n        data = da.reshape(data, (1, -1))\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Invalid data shape for ChannelFrame\\n\"\n            f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n            f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n            f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n            f\"  (1, n_samples).\\n\"\n            f\"For higher-dimensional data, reshape it before creating\\n\"\n            f\"  ChannelFrame:\\n\"\n            f\"  Example: data.reshape(n_channels, -1)\"\n        )\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>info()</code> \u00b6 <p>Display comprehensive information about the ChannelFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - Duration - Number of samples - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p> <code></code> <code>add(other, snr=None)</code> \u00b6 <p>Add another signal or value to the current signal.</p> <p>If SNR is specified, performs addition with consideration for signal-to-noise ratio.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>other</code> <code>ChannelFrame | int | float | NDArrayReal</code> <p>Signal or value to add.</p> \u5fc5\u9808 <code>snr</code> <code>float | None</code> <p>Signal-to-noise ratio (dB). If specified, adjusts the scale of the other signal based on this SNR. self is treated as the signal, and other as the noise.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new channel frame containing the addition result (lazy execution).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def add(\n    self,\n    other: \"ChannelFrame | int | float | NDArrayReal\",\n    snr: float | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add another signal or value to the current signal.\n\n    If SNR is specified, performs addition with consideration for\n    signal-to-noise ratio.\n\n    Args:\n        other: Signal or value to add.\n        snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n            other signal based on this SNR.\n            self is treated as the signal, and other as the noise.\n\n    Returns:\n        A new channel frame containing the addition result (lazy execution).\n    \"\"\"\n    logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n    if isinstance(other, ChannelFrame):\n        # Check if sampling rates match\n        if self.sampling_rate != other.sampling_rate:\n            raise ValueError(\n                \"Sampling rates do not match. Cannot perform operation.\"\n            )\n\n    elif isinstance(other, np.ndarray):\n        other = ChannelFrame.from_numpy(\n            other, self.sampling_rate, label=\"array_data\"\n        )\n    elif isinstance(other, int | float):\n        return self + other\n    else:\n        raise TypeError(\n            \"Addition target with SNR must be a ChannelFrame or \"\n            f\"NumPy array: {type(other)}\"\n        )\n\n    # If SNR is specified, adjust the length of the other signal\n    if other.duration != self.duration:\n        other = other.fix_length(length=self.n_samples)\n\n    if snr is None:\n        return self + other\n    return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n</code></pre> <code></code> <code>plot(plot_type='waveform', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, **kwargs)</code> \u00b6 <p>Plot the frame data.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>plot_type</code> <code>str</code> <p>Type of plot. Default is \"waveform\".</p> <code>'waveform'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot. If None, uses the frame label.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay all channels on a single plot (True) or create separate subplots for each channel (False).</p> <code>False</code> <code>xlabel</code> <code>str | None</code> <p>Label for the x-axis. If None, uses default based on plot type.</p> <code>None</code> <code>ylabel</code> <code>str | None</code> <p>Label for the y-axis. If None, uses default based on plot type.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level for the plot lines (0.0 to 1.0).</p> <code>1.0</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Limits for the x-axis as (min, max) tuple.</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Limits for the y-axis as (min, max) tuple.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional matplotlib Line2D parameters (e.g., color, linewidth, linestyle). These are passed to the underlying matplotlib plot functions.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic plot\n&gt;&gt;&gt; cf.plot()\n&gt;&gt;&gt; # Overlay all channels\n&gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"waveform\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the frame data.\n\n    Args:\n        plot_type: Type of plot. Default is \"waveform\".\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot. If None, uses the frame label.\n        overlay: Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel: Label for the x-axis. If None, uses default based on plot type.\n        ylabel: Label for the y-axis. If None, uses default based on plot type.\n        alpha: Transparency level for the plot lines (0.0 to 1.0).\n        xlim: Limits for the x-axis as (min, max) tuple.\n        ylim: Limits for the y-axis as (min, max) tuple.\n        **kwargs: Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n            These are passed to the underlying matplotlib plot functions.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic plot\n        &gt;&gt;&gt; cf.plot()\n        &gt;&gt;&gt; # Overlay all channels\n        &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n    \"\"\"\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    from ..visualization.plotting import create_operation\n\n    plot_strategy = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre> <code></code> <code>rms_plot(ax=None, title=None, overlay=True, Aw=False, **kwargs)</code> \u00b6 <p>Generate an RMS plot.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay the plot on the existing axis.</p> <code>True</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the plot() method. Accepts the same arguments as plot() including xlabel, ylabel, alpha, xlim, ylim, and matplotlib Line2D parameters.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic RMS plot\n&gt;&gt;&gt; cf.rms_plot()\n&gt;&gt;&gt; # With A-weighting\n&gt;&gt;&gt; cf.rms_plot(Aw=True)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def rms_plot(\n    self,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = True,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Generate an RMS plot.\n\n    Args:\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot.\n        overlay: Whether to overlay the plot on the existing axis.\n        Aw: Apply A-weighting.\n        **kwargs: Additional arguments passed to the plot() method.\n            Accepts the same arguments as plot() including xlabel, ylabel,\n            alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic RMS plot\n        &gt;&gt;&gt; cf.rms_plot()\n        &gt;&gt;&gt; # With A-weighting\n        &gt;&gt;&gt; cf.rms_plot(Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n    \"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n    rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n    return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n</code></pre> <code></code> <code>describe(normalize=True, is_close=True, *, fmin=0, fmax=None, cmap='jet', vmin=None, vmax=None, xlim=None, ylim=None, Aw=False, waveform=None, spectral=None, **kwargs)</code> \u00b6 <p>Display visual and audio representation of the frame.</p> <p>This method creates a comprehensive visualization with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>normalize</code> <code>bool</code> <p>Whether to normalize the audio data for playback. Default: True</p> <code>True</code> <code>is_close</code> <code>bool</code> <p>Whether to close the figure after displaying. Default: True</p> <code>True</code> <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>0</code> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency (sampling_rate / 2)</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>'jet'</code> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots. Format: (start_time, end_time)</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots. Format: (min_freq, max_freq)</p> <code>None</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>False</code> <code>waveform</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for waveform subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>spectral</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for spectral subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Deprecated parameters for backward compatibility only. - axis_config: Old configuration format (use waveform/spectral instead) - cbar_config: Old colorbar configuration (use vmin/vmax instead)</p> <code>{}</code> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom waveform subplot settings\n&gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def describe(\n    self,\n    normalize: bool = True,\n    is_close: bool = True,\n    *,\n    fmin: float = 0,\n    fmax: float | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    waveform: dict[str, Any] | None = None,\n    spectral: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Display visual and audio representation of the frame.\n\n    This method creates a comprehensive visualization with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Args:\n        normalize: Whether to normalize the audio data for playback.\n            Default: True\n        is_close: Whether to close the figure after displaying.\n            Default: True\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency (sampling_rate / 2)\n        cmap: Colormap for the spectrogram.\n            Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n            Format: (start_time, end_time)\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n            Format: (min_freq, max_freq)\n        Aw: Apply A-weighting to the frequency analysis.\n            Default: False\n        waveform: Additional configuration dict for waveform subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        spectral: Additional configuration dict for spectral subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        **kwargs: Deprecated parameters for backward compatibility only.\n            - axis_config: Old configuration format (use waveform/spectral instead)\n            - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom waveform subplot settings\n        &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n    \"\"\"\n    # Prepare kwargs with explicit parameters\n    plot_kwargs: dict[str, Any] = {\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"xlim\": xlim,\n        \"ylim\": ylim,\n        \"Aw\": Aw,\n        \"waveform\": waveform or {},\n        \"spectral\": spectral or {},\n    }\n    # Merge with additional kwargs\n    plot_kwargs.update(kwargs)\n\n    if \"axis_config\" in plot_kwargs:\n        logger.warning(\n            \"axis_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        axis_config = plot_kwargs[\"axis_config\"]\n        if \"time_plot\" in axis_config:\n            plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n        if \"freq_plot\" in axis_config:\n            if \"xlim\" in axis_config[\"freq_plot\"]:\n                vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                plot_kwargs[\"vmin\"] = vlim[0]\n                plot_kwargs[\"vmax\"] = vlim[1]\n            if \"ylim\" in axis_config[\"freq_plot\"]:\n                ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                plot_kwargs[\"ylim\"] = ylim_config\n\n    if \"cbar_config\" in plot_kwargs:\n        logger.warning(\n            \"cbar_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        cbar_config = plot_kwargs[\"cbar_config\"]\n        if \"vmin\" in cbar_config:\n            plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n        if \"vmax\" in cbar_config:\n            plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n    for ch in self:\n        ax: Axes\n        _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n        if isinstance(_ax, Iterator):\n            ax = next(iter(_ax))\n        elif isinstance(_ax, Axes):\n            ax = _ax\n        else:\n            raise TypeError(\n                f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n            )\n        # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n        display(ax.figure)\n        if is_close:\n            plt.close(getattr(ax, \"figure\", None))\n        display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n</code></pre> <code></code> <code>from_numpy(data, sampling_rate, label=None, metadata=None, ch_labels=None, ch_units=None)</code> <code>classmethod</code> \u00b6 <p>Create a ChannelFrame from a NumPy array.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>NDArrayReal</code> <p>NumPy array containing channel data.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>ch_units</code> <code>list[str] | str | None</code> <p>Units for each channel.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the NumPy data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayReal,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    ch_labels: list[str] | None = None,\n    ch_units: list[str] | str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing channel data.\n        sampling_rate: The sampling rate in Hz.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        ch_labels: Labels for each channel.\n        ch_units: Units for each channel.\n\n    Returns:\n        A new ChannelFrame containing the NumPy data.\n    \"\"\"\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n\n    # Convert NumPy array to dask array\n    dask_data = da_from_array(data)\n    cf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        label=label or \"numpy_data\",\n    )\n    if metadata is not None:\n        cf.metadata = metadata\n    if ch_labels is not None:\n        if len(ch_labels) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel labels does not match the number of channels\"\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    if ch_units is not None:\n        if isinstance(ch_units, str):\n            ch_units = [ch_units] * cf.n_channels\n\n        if len(ch_units) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel units does not match the number of channels\"\n            )\n        for i in range(len(ch_units)):\n            cf._channel_metadata[i].unit = ch_units[i]\n\n    return cf\n</code></pre> <code></code> <code>from_ndarray(array, sampling_rate, labels=None, unit=None, frame_label=None, metadata=None)</code> <code>classmethod</code> \u00b6 <p>Create a ChannelFrame from a NumPy array.</p> <p>This method is deprecated. Use from_numpy instead.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>array</code> <code>NDArrayReal</code> <p>Signal data. Each row corresponds to a channel.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>Sampling rate (Hz).</p> \u5fc5\u9808 <code>labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>unit</code> <code>list[str] | str | None</code> <p>Unit of the signal.</p> <code>None</code> <code>frame_label</code> <code>str | None</code> <p>Label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_ndarray(\n    cls,\n    array: NDArrayReal,\n    sampling_rate: float,\n    labels: list[str] | None = None,\n    unit: list[str] | str | None = None,\n    frame_label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    This method is deprecated. Use from_numpy instead.\n\n    Args:\n        array: Signal data. Each row corresponds to a channel.\n        sampling_rate: Sampling rate (Hz).\n        labels: Labels for each channel.\n        unit: Unit of the signal.\n        frame_label: Label for the frame.\n        metadata: Optional metadata dictionary.\n\n    Returns:\n        A new ChannelFrame containing the data.\n    \"\"\"\n    # Redirect to from_numpy for compatibility\n    # However, from_ndarray is deprecated\n    logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n    return cls.from_numpy(\n        data=array,\n        sampling_rate=sampling_rate,\n        label=frame_label,\n        metadata=metadata,\n        ch_labels=labels,\n        ch_units=unit,\n    )\n</code></pre> <code></code> <code>from_file(path, channel=None, start=None, end=None, chunk_size=None, ch_labels=None, time_column=0, delimiter=',', header=0)</code> <code>classmethod</code> \u00b6 <p>Create a ChannelFrame from an audio file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the audio file.</p> \u5fc5\u9808 <code>channel</code> <code>int | list[int] | None</code> <p>Channel(s) to load.</p> <code>None</code> <code>start</code> <code>float | None</code> <p>Start time in seconds.</p> <code>None</code> <code>end</code> <code>float | None</code> <p>End time in seconds.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Chunk size for processing. Specifies the splitting size for lazy processing.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>time_column</code> <code>int | str</code> <p>For CSV files, index or name of the time column. Default is 0 (first column).</p> <code>0</code> <code>delimiter</code> <code>str</code> <p>For CSV files, delimiter character. Default is \",\".</p> <code>','</code> <code>header</code> <code>int | None</code> <p>For CSV files, row number to use as header. Default is 0 (first row). Set to None if no header.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the loaded audio data.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If channel specification is invalid.</p> <code>TypeError</code> <p>If channel parameter type is invalid.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist at the specified path. Error message includes absolute path, current directory, and troubleshooting suggestions.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; # Load WAV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n&gt;&gt;&gt; # Load specific channels\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n&gt;&gt;&gt; # Load CSV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\n...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n... )\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    channel: int | list[int] | None = None,\n    start: float | None = None,\n    end: float | None = None,\n    chunk_size: int | None = None,\n    ch_labels: list[str] | None = None,\n    # CSV-specific parameters\n    time_column: int | str = 0,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from an audio file.\n\n    Args:\n        path: Path to the audio file.\n        channel: Channel(s) to load.\n        start: Start time in seconds.\n        end: End time in seconds.\n        chunk_size: Chunk size for processing.\n            Specifies the splitting size for lazy processing.\n        ch_labels: Labels for each channel.\n        time_column: For CSV files, index or name of the time column.\n            Default is 0 (first column).\n        delimiter: For CSV files, delimiter character. Default is \",\".\n        header: For CSV files, row number to use as header.\n            Default is 0 (first row). Set to None if no header.\n\n    Returns:\n        A new ChannelFrame containing the loaded audio data.\n\n    Raises:\n        ValueError: If channel specification is invalid.\n        TypeError: If channel parameter type is invalid.\n        FileNotFoundError: If the file doesn't exist at the specified path.\n            Error message includes absolute path, current directory, and\n            troubleshooting suggestions.\n\n    Examples:\n        &gt;&gt;&gt; # Load WAV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n        &gt;&gt;&gt; # Load specific channels\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n        &gt;&gt;&gt; # Load CSV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\n        ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n        ... )\n    \"\"\"\n    from .channel import ChannelFrame\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Audio file not found\\n\"\n            f\"  Path: {path.absolute()}\\n\"\n            f\"  Current directory: {Path.cwd()}\\n\"\n            f\"Please check:\\n\"\n            f\"  - File path is correct\\n\"\n            f\"  - File exists at the specified location\\n\"\n            f\"  - You have read permissions for the file\"\n        )\n\n    # Get file reader\n    reader = get_file_reader(path)\n\n    # Build kwargs for reader\n    reader_kwargs: dict[str, Any] = {}\n    if path.suffix.lower() == \".csv\":\n        reader_kwargs[\"time_column\"] = time_column\n        reader_kwargs[\"delimiter\"] = delimiter\n        if header is not None:\n            reader_kwargs[\"header\"] = header\n\n    # Get file info\n    info = reader.get_file_info(path, **reader_kwargs)\n    sr = info[\"samplerate\"]\n    n_channels = info[\"channels\"]\n    n_frames = info[\"frames\"]\n    ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n    logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n    # Channel selection processing\n    all_channels = list(range(n_channels))\n\n    if channel is None:\n        channels_to_load = all_channels\n        logger.debug(f\"Will load all channels: {channels_to_load}\")\n    elif isinstance(channel, int):\n        if channel &lt; 0 or channel &gt;= n_channels:\n            raise ValueError(\n                f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n            )\n        channels_to_load = [channel]\n        logger.debug(f\"Will load single channel: {channel}\")\n    elif isinstance(channel, list | tuple):\n        for ch in channel:\n            if ch &lt; 0 or ch &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n        channels_to_load = list(channel)\n        logger.debug(f\"Will load specific channels: {channels_to_load}\")\n    else:\n        raise TypeError(\"channel must be int, list, or None\")\n\n    # Index calculation\n    start_idx = 0 if start is None else max(0, int(start * sr))\n    end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n    frames_to_read = end_idx - start_idx\n\n    logger.debug(\n        f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n        f\"start_idx={start_idx}, end_idx={end_idx}\"\n    )\n\n    # Settings for lazy loading\n    expected_shape = (len(channels_to_load), frames_to_read)\n\n    # Define the loading function using the file reader\n    def _load_audio() -&gt; NDArrayReal:\n        logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n        # Use the reader to get audio data with parameters\n        out = reader.get_data(\n            path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n        )\n        if not isinstance(out, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n        return out\n\n    logger.debug(\n        f\"Creating delayed dask task with expected shape: {expected_shape}\"\n    )\n\n    # Create delayed operation\n    delayed_data = dask_delayed(_load_audio)()\n    logger.debug(\"Wrapping delayed function in dask array\")\n\n    # Create dask array from delayed computation\n    dask_array = da_from_delayed(\n        delayed_data, shape=expected_shape, dtype=np.float32\n    )\n\n    if chunk_size is not None:\n        if chunk_size &lt;= 0:\n            raise ValueError(\"Chunk size must be a positive integer\")\n        logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n        dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n    logger.debug(\n        \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n    )\n\n    cf = ChannelFrame(\n        data=dask_array,\n        sampling_rate=sr,\n        label=path.stem,\n        metadata={\n            \"filename\": str(path),\n        },\n    )\n    if ch_labels is not None:\n        if len(ch_labels) != len(cf):\n            raise ValueError(\n                \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    return cf\n</code></pre> <code></code> <code>read_wav(filename, labels=None)</code> <code>classmethod</code> \u00b6 <p>Utility method to read a WAV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>filename</code> <code>str</code> <p>Path to the WAV file.</p> \u5fc5\u9808 <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a WAV file.\n\n    Args:\n        filename: Path to the WAV file.\n        labels: Labels to set for each channel.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(filename, ch_labels=labels)\n    return cf\n</code></pre> <code></code> <code>read_csv(filename, time_column=0, labels=None, delimiter=',', header=0)</code> <code>classmethod</code> \u00b6 <p>Utility method to read a CSV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> \u5fc5\u9808 <code>time_column</code> <code>int | str</code> <p>Index or name of the time column.</p> <code>0</code> <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>Delimiter character.</p> <code>','</code> <code>header</code> <code>int | None</code> <p>Row number to use as header.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; # Read CSV with default settings\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n&gt;&gt;&gt; # Read CSV with custom delimiter\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n&gt;&gt;&gt; # Read CSV without header\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_csv(\n    cls,\n    filename: str,\n    time_column: int | str = 0,\n    labels: list[str] | None = None,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a CSV file.\n\n    Args:\n        filename: Path to the CSV file.\n        time_column: Index or name of the time column.\n        labels: Labels to set for each channel.\n        delimiter: Delimiter character.\n        header: Row number to use as header.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n\n    Examples:\n        &gt;&gt;&gt; # Read CSV with default settings\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n        &gt;&gt;&gt; # Read CSV with custom delimiter\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n        &gt;&gt;&gt; # Read CSV without header\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(\n        filename,\n        ch_labels=labels,\n        time_column=time_column,\n        delimiter=delimiter,\n        header=header,\n    )\n    return cf\n</code></pre> <code></code> <code>to_wav(path, format=None)</code> \u00b6 <p>Save the audio data to a WAV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to save the file.</p> \u5fc5\u9808 <code>format</code> <code>str | None</code> <p>File format. If None, determined from file extension.</p> <code>None</code> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n    \"\"\"Save the audio data to a WAV file.\n\n    Args:\n        path: Path to save the file.\n        format: File format. If None, determined from file extension.\n    \"\"\"\n    from wandas.io.wav_io import write_wav\n\n    write_wav(str(path), self, format=format)\n</code></pre> <code></code> <code>save(path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code> \u00b6 <p>Save the ChannelFrame to a WDF (Wandas Data File) format.</p> <p>This saves the complete frame including all channel data and metadata in a format that can be loaded back with full fidelity.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Example <p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.save(\"audio_analysis.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def save(\n    self,\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n    This saves the complete frame including all channel data and metadata\n    in a format that can be loaded back with full fidelity.\n\n    Args:\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import save as wdf_save\n\n    wdf_save(\n        self,\n        path,\n        format=format,\n        compress=compress,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre> <code></code> <code>load(path, *, format='hdf5')</code> <code>classmethod</code> \u00b6 <p>Load a ChannelFrame from a WDF (Wandas Data File) file.</p> <p>This loads data saved with the save() method, preserving all channel data, metadata, labels, and units.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame with all data and metadata loaded</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>NotImplementedError</code> <p>For unsupported formats</p> Example <p>cf = ChannelFrame.load(\"audio_analysis.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n    This loads data saved with the save() method, preserving all channel data,\n    metadata, labels, and units.\n\n    Args:\n        path: Path to the WDF file\n        format: Format of the file (currently only 'hdf5' is supported)\n\n    Returns:\n        A new ChannelFrame with all data and metadata loaded\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        NotImplementedError: For unsupported formats\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import load as wdf_load\n\n    return wdf_load(path, format=format)\n</code></pre> <code></code> <code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False)</code> \u00b6 <p>Add a new channel to the frame.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>ndarray[Any, Any] | Array | ChannelFrame</code> <p>Data to add as a new channel. Can be: - numpy array (1D or 2D) - dask array (1D or 2D) - ChannelFrame (channels will be added)</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>Label for the new channel. If None, generates a default label. Ignored when data is a ChannelFrame (uses its channel labels).</p> <code>None</code> <code>align</code> <code>str</code> <p>How to handle length mismatches: - \"strict\": Raise error if lengths don't match - \"pad\": Pad shorter data with zeros - \"truncate\": Truncate longer data to match</p> <code>'strict'</code> <code>suffix_on_dup</code> <code>str | None</code> <p>Suffix to add to duplicate labels. If None, raises error.</p> <code>None</code> <code>inplace</code> <code>bool</code> <p>If True, modifies the frame in place. Otherwise returns a new frame.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>Modified ChannelFrame (self if inplace=True, new frame otherwise).</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If data length doesn't match and align=\"strict\", or if label is duplicate and suffix_on_dup is None.</p> <code>TypeError</code> <p>If data type is not supported.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Add a numpy array as a new channel\n&gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n&gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n&gt;&gt;&gt; # Add another ChannelFrame's channels\n&gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n&gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def add_channel(\n    self,\n    data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n    label: str | None = None,\n    align: str = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add a new channel to the frame.\n\n    Args:\n        data: Data to add as a new channel. Can be:\n            - numpy array (1D or 2D)\n            - dask array (1D or 2D)\n            - ChannelFrame (channels will be added)\n        label: Label for the new channel. If None, generates a default label.\n            Ignored when data is a ChannelFrame (uses its channel labels).\n        align: How to handle length mismatches:\n            - \"strict\": Raise error if lengths don't match\n            - \"pad\": Pad shorter data with zeros\n            - \"truncate\": Truncate longer data to match\n        suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n        inplace: If True, modifies the frame in place.\n            Otherwise returns a new frame.\n\n    Returns:\n        Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n    Raises:\n        ValueError: If data length doesn't match and align=\"strict\",\n            or if label is duplicate and suffix_on_dup is None.\n        TypeError: If data type is not supported.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Add a numpy array as a new channel\n        &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n        &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n        &gt;&gt;&gt; # Add another ChannelFrame's channels\n        &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n        &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n    \"\"\"\n    # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n    if isinstance(data, ChannelFrame):\n        if self.sampling_rate != data.sampling_rate:\n            raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n        if data.n_samples != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - data.n_samples\n                arr = data._data\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = data._data[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        else:\n            arr = data._data\n        labels = [ch.label for ch in self._channel_metadata]\n        new_labels = []\n        new_metadata_list = []\n        for chmeta in data._channel_metadata:\n            new_label = chmeta.label\n            if new_label in labels or new_label in new_labels:\n                if suffix_on_dup:\n                    new_label += suffix_on_dup\n                else:\n                    raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n            new_labels.append(new_label)\n            # Copy the entire channel_metadata and update only the label\n            new_ch_meta = chmeta.model_copy(deep=True)\n            new_ch_meta.label = new_label\n            new_metadata_list.append(new_ch_meta)\n        new_data = concatenate([self._data, arr], axis=0)\n\n        new_chmeta = self._channel_metadata + new_metadata_list\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n    if isinstance(data, np.ndarray):\n        arr = from_array(data.reshape(1, -1))\n    elif isinstance(data, DaskArray):\n        arr = data[None, ...] if data.ndim == 1 else data\n        if arr.shape[0] != 1:\n            arr = arr.reshape((1, -1))\n    else:\n        raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n    if arr.shape[1] != self.n_samples:\n        if align == \"pad\":\n            pad_len = self.n_samples - arr.shape[1]\n            if pad_len &gt; 0:\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n            else:\n                arr = arr[:, : self.n_samples]\n        elif align == \"truncate\":\n            arr = arr[:, : self.n_samples]\n            if arr.shape[1] &lt; self.n_samples:\n                pad_len = self.n_samples - arr.shape[1]\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n        else:\n            raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n    labels = [ch.label for ch in self._channel_metadata]\n    new_label = label or f\"ch{len(labels)}\"\n    if new_label in labels:\n        if suffix_on_dup:\n            new_label += suffix_on_dup\n        else:\n            raise ValueError(\"label\u91cd\u8907\")\n    new_data = concatenate([self._data, arr], axis=0)\n    from ..core.metadata import ChannelMetadata\n\n    new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre> <code></code> <code>remove_channel(key, inplace=False)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n    if isinstance(key, int):\n        if not (0 &lt;= key &lt; self.n_channels):\n            raise IndexError(f\"index {key} out of range\")\n        idx = key\n    else:\n        labels = [ch.label for ch in self._channel_metadata]\n        if key not in labels:\n            raise KeyError(f\"label {key} not found\")\n        idx = labels.index(key)\n    new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n    new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"en/api/#wandas.frames.channel.ChannelFrame.info--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.info() Channels: 2 Sampling rate: 44100 Hz Duration: 1.0 s Samples: 44100 Channel labels: ['ch0', 'ch1']</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the ChannelFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - Duration\n    - Number of samples\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; cf.info()\n    Channels: 2\n    Sampling rate: 44100 Hz\n    Duration: 1.0 s\n    Samples: 44100\n    Channel labels: ['ch0', 'ch1']\n    \"\"\"\n    print(\"ChannelFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  Duration: {self.duration:.1f} s\")\n    print(f\"  Samples: {self.n_samples}\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/#wandas.frames.mixins.ChannelProcessingMixin","title":"<code>ChannelProcessingMixin</code>","text":"<p>Mixin that provides methods related to signal processing.</p> <p>This mixin provides processing methods applied to audio signals and other time-series data, such as signal processing filters and transformation operations.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>class ChannelProcessingMixin:\n    \"\"\"Mixin that provides methods related to signal processing.\n\n    This mixin provides processing methods applied to audio signals and\n    other time-series data, such as signal processing filters and\n    transformation operations.\n    \"\"\"\n\n    def high_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a high-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def low_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a low-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def band_pass_filter(\n        self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a band-pass filter to the signal.\n\n        Args:\n            low_cutoff: Lower cutoff frequency (Hz)\n            high_cutoff: Higher cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n            f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"bandpass_filter\",\n            low_cutoff=low_cutoff,\n            high_cutoff=high_cutoff,\n            order=order,\n        )\n        return cast(T_Processing, result)\n\n    def normalize(\n        self: T_Processing,\n        norm: float | None = float(\"inf\"),\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Normalize signal levels using librosa.util.normalize.\n\n        This method normalizes the signal amplitude according to the specified norm.\n\n        Args:\n            norm: Norm type. Default is np.inf (maximum absolute value normalization).\n                Supported values:\n                - np.inf: Maximum absolute value normalization\n                - -np.inf: Minimum absolute value normalization\n                - 0: Peak normalization\n                - float: Lp norm\n                - None: No normalization\n            axis: Axis along which to normalize. Default is -1 (time axis).\n                - -1: Normalize along time axis (each channel independently)\n                - None: Global normalization across all axes\n                - int: Normalize along specified axis\n            threshold: Threshold below which values are considered zero.\n                If None, no threshold is applied.\n            fill: Value to fill when the norm is zero.\n                If None, the zero vector remains zero.\n\n        Returns:\n            New ChannelFrame containing the normalized signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n            &gt;&gt;&gt; normalized = signal.normalize()\n            &gt;&gt;&gt; # Global normalization across all channels\n            &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n            &gt;&gt;&gt; # L2 normalization\n            &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n        \"\"\"\n        logger.debug(\n            f\"Setting up normalize: norm={norm}, axis={axis}, \"\n            f\"threshold={threshold}, fill={fill} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        return cast(T_Processing, result)\n\n    def remove_dc(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Remove DC component (DC offset) from the signal.\n\n        This method removes the DC (direct current) component by subtracting\n        the mean value from each channel. This is equivalent to centering the\n        signal around zero.\n\n        Returns:\n            New ChannelFrame with DC component removed\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; # Create signal with DC offset\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n            &gt;&gt;&gt; # Remove DC offset\n            &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n            &gt;&gt;&gt; # Verify DC removal\n            &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n        Notes:\n            - This operation is performed per channel\n            - Equivalent to applying a high-pass filter with very low cutoff\n            - Useful for removing sensor drift or measurement offset\n        \"\"\"\n        logger.debug(\"Setting up DC removal (lazy)\")\n        result = self.apply_operation(\"remove_dc\")\n        return cast(T_Processing, result)\n\n    def a_weighting(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Apply A-weighting filter to the signal.\n\n        A-weighting adjusts the frequency response to approximate human\n        auditory perception, according to the IEC 61672-1:2013 standard.\n\n        Returns:\n            New ChannelFrame containing the A-weighted signal\n        \"\"\"\n        result = self.apply_operation(\"a_weighting\")\n        return cast(T_Processing, result)\n\n    def abs(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Compute the absolute value of the signal.\n\n        Returns:\n            New ChannelFrame containing the absolute values\n        \"\"\"\n        result = self.apply_operation(\"abs\")\n        return cast(T_Processing, result)\n\n    def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n        \"\"\"Compute the power of the signal.\n\n        Args:\n            exponent: Exponent to raise the signal to. Default is 2.0.\n\n        Returns:\n            New ChannelFrame containing the powered signal\n        \"\"\"\n        result = self.apply_operation(\"power\", exponent=exponent)\n        return cast(T_Processing, result)\n\n    def _reduce_channels(self: T_Processing, op: str) -&gt; T_Processing:\n        \"\"\"Helper to reduce all channels with the given operation ('sum' or 'mean').\"\"\"\n        if op == \"sum\":\n            reduced_data = self._data.sum(axis=0, keepdims=True)\n            label = \"sum\"\n        elif op == \"mean\":\n            reduced_data = self._data.mean(axis=0, keepdims=True)\n            label = \"mean\"\n        else:\n            raise ValueError(f\"Unsupported reduction operation: {op}\")\n\n        units = [ch.unit for ch in self._channel_metadata]\n        if all(u == units[0] for u in units):\n            reduced_unit = units[0]\n        else:\n            reduced_unit = \"\"\n\n        reduced_extra = {\"source_extras\": [ch.extra for ch in self._channel_metadata]}\n        new_channel_metadata = [\n            ChannelMetadata(\n                label=label,\n                unit=reduced_unit,\n                extra=reduced_extra,\n            )\n        ]\n        new_history = (\n            self.operation_history.copy() if hasattr(self, \"operation_history\") else []\n        )\n        new_history.append({\"operation\": op})\n        new_metadata = self.metadata.copy() if hasattr(self, \"metadata\") else {}\n        result = self._create_new_instance(\n            data=reduced_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=new_channel_metadata,\n        )\n        return result\n\n    def sum(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Sum all channels.\n\n        Returns:\n            A new ChannelFrame with summed signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n\n    def mean(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Average all channels.\n\n        Returns:\n            A new ChannelFrame with averaged signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n\n    def trim(\n        self: T_Processing,\n        start: float = 0,\n        end: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Trim the signal to the specified time range.\n\n        Args:\n            start: Start time (seconds)\n            end: End time (seconds)\n\n        Returns:\n            New ChannelFrame containing the trimmed signal\n\n        Raises:\n            ValueError: If end time is earlier than start time\n        \"\"\"\n        if end is None:\n            end = self.duration\n        if start &gt; end:\n            raise ValueError(\"start must be less than end\")\n        result = self.apply_operation(\"trim\", start=start, end=end)\n        return cast(T_Processing, result)\n\n    def fix_length(\n        self: T_Processing,\n        length: int | None = None,\n        duration: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Adjust the signal to the specified length.\n\n        Args:\n            duration: Signal length in seconds\n            length: Signal length in samples\n\n        Returns:\n            New ChannelFrame containing the adjusted signal\n        \"\"\"\n\n        result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n        return cast(T_Processing, result)\n\n    def rms_trend(\n        self: T_Processing,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; T_Processing:\n        \"\"\"Compute the RMS trend of the signal.\n\n        This method calculates the root mean square value over a sliding window.\n\n        Args:\n            frame_length: Size of the sliding window in samples. Default is 2048.\n            hop_length: Hop length between windows in samples. Default is 512.\n            dB: Whether to return RMS values in decibels. Default is False.\n            Aw: Whether to apply A-weighting. Default is False.\n\n        Returns:\n            New ChannelFrame containing the RMS trend\n        \"\"\"\n        # Access _channel_metadata to retrieve reference values\n        frame = cast(ProcessingFrameProtocol, self)\n\n        # Ensure _channel_metadata exists before referencing\n        ref_values = []\n        if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n            ref_values = [ch.ref for ch in frame._channel_metadata]\n\n        result = self.apply_operation(\n            \"rms_trend\",\n            frame_length=frame_length,\n            hop_length=hop_length,\n            ref=ref_values,\n            dB=dB,\n            Aw=Aw,\n        )\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def channel_difference(\n        self: T_Processing, other_channel: int | str = 0\n    ) -&gt; T_Processing:\n        \"\"\"Compute the difference between channels.\n\n        Args:\n            other_channel: Index or label of the reference channel. Default is 0.\n\n        Returns:\n            New ChannelFrame containing the channel difference\n        \"\"\"\n        # label2index is a method of BaseFrame\n        if isinstance(other_channel, str):\n            if hasattr(self, \"label2index\"):\n                other_channel = self.label2index(other_channel)\n\n        result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n        return cast(T_Processing, result)\n\n    def resampling(\n        self: T_Processing,\n        target_sr: float,\n        **kwargs: Any,\n    ) -&gt; T_Processing:\n        \"\"\"Resample audio data.\n\n        Args:\n            target_sr: Target sampling rate (Hz)\n            **kwargs: Additional resampling parameters\n\n        Returns:\n            Resampled ChannelFrame\n        \"\"\"\n        return cast(\n            T_Processing,\n            self.apply_operation(\n                \"resampling\",\n                target_sr=target_sr,\n                **kwargs,\n            ),\n        )\n\n    def hpss_harmonic(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract harmonic components using HPSS\n         (Harmonic-Percussive Source Separation).\n\n        This method separates the harmonic (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n            n_fft: Size of FFT window.\n            hop_length: Hop length for STFT.\n            win_length: Window length for STFT.\n            window: Window type for STFT.\n            center: If True, center the frames.\n            pad_mode: Padding mode for STFT.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_harmonic\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def hpss_percussive(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract percussive components using HPSS\n        (Harmonic-Percussive Source Separation).\n\n        This method separates the percussive (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_percussive\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n        \"\"\"\n        Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of non-stationary signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            New ChannelFrame containing time-varying loudness values in sones.\n            Each channel is processed independently.\n            The output sampling rate is adjusted based on the loudness\n            calculation time resolution (typically ~500 Hz for 2ms steps).\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate loudness for a signal:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n        Notes:\n            - The output contains time-varying loudness values in sones\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - The time resolution is approximately 2ms (determined by the algorithm)\n            - For multi-channel signals, loudness is calculated per channel\n            - The output sampling rate is updated to reflect the time resolution\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 2ms analysis step. This differs slightly from the MoSQITo\n            library, which uses the center time of each step. For example:\n\n            - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n            - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n            The difference is very small (~1ms) and does not affect the loudness\n            values themselves. This design choice ensures consistency with\n            wandas's time axis convention across all frame types.\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n        \"\"\"\n        Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of stationary (steady) signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        This method is suitable for analyzing steady sounds such as fan noise,\n        constant machinery sounds, or other stationary signals.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            Loudness values in sones, one per channel. Shape: (n_channels,)\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate steady-state loudness for a fan noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n            &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n        Notes:\n            - Returns a 1D array with one loudness value per channel\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - For multi-channel signals, loudness is calculated independently\n              per channel\n            - This method is designed for stationary signals (constant sounds)\n            - For time-varying signals, use loudness_zwtv() instead\n            - Similar to the rms property, returns NDArrayReal for consistency\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        # Treat self as a ProcessingFrameProtocol so mypy understands\n        # where sampling_rate and data come from.\n        from wandas.processing.psychoacoustic import LoudnessZwst\n        from wandas.utils.types import NDArrayReal\n\n        # Create operation instance\n        operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n        # Get data (triggers computation if lazy)\n        data = self.data\n\n        # Ensure data is 2D (n_channels, n_samples)\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        # Process the array using the public API and materialize to NumPy\n        result = operation.process_array(data).compute()\n\n        # Squeeze to get 1D array (n_channels,)\n        loudness_values: NDArrayReal = result.squeeze()\n\n        # Ensure it's 1D even for single channel\n        if loudness_values.ndim == 0:\n            loudness_values = loudness_values.reshape(1)\n\n        return loudness_values\n\n    def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n        \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n        Roughness is a psychoacoustic metric that quantifies the perceived\n        harshness or roughness of a sound, measured in asper. This method\n        implements the Daniel &amp; Weber (1997) standard calculation.\n\n        The calculation follows the standard formula:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            New ChannelFrame containing time-varying roughness values in asper.\n            The output sampling rate depends on the overlap parameter.\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Calculate roughness for a motor noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n            &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n            &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n            Analyze roughness statistics:\n            &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n            &gt;&gt;&gt; max_roughness = roughness.data.max()\n            &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n            &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n            Compare before and after modification:\n            &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n            &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n            &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n            &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n        Notes:\n            - Returns a ChannelFrame with time-varying roughness values\n            - Typical roughness values: 0-2 asper for most sounds\n            - Higher values indicate rougher, harsher sounds\n            - For multi-channel signals, roughness is calculated independently\n              per channel\n            - This is the standard-compliant total roughness (R)\n            - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 200ms analysis window. This differs from the MoSQITo library,\n            which uses the center time of each window. For example:\n\n            - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n            - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n            The difference is constant (half the window duration = 100ms) and\n            does not affect the roughness values themselves. This design choice\n            ensures consistency with wandas's time axis convention across all\n            frame types.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n        logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n        result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n        return cast(T_Processing, result)\n\n    def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n        \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n        This method returns detailed roughness analysis data organized by\n        Bark frequency bands over time, allowing for frequency-specific\n        roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n        The relationship between total roughness and specific roughness:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            RoughnessFrame containing:\n                - data: Specific roughness by Bark band, shape (47, n_time)\n                        for mono or (n_channels, 47, n_time) for multi-channel\n                - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n                - time: Time axis for each analysis frame\n                - overlap: Overlap coefficient used\n                - plot(): Method for Bark-Time heatmap visualization\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Analyze frequency-specific roughness:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n            &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Plot Bark-Time heatmap\n            &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Find dominant Bark band\n            &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n            &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n            &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Extract specific Bark band time series\n            &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n            &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Verify standard formula\n            &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n            &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n        Notes:\n            - Returns a RoughnessFrame (not ChannelFrame)\n            - Contains 47 Bark bands from 0.5 to 23.5 Bark\n            - Each Bark band corresponds to a critical band of hearing\n            - Useful for identifying which frequencies contribute most to roughness\n            - The specific roughness can be integrated to obtain total roughness\n            - For simple time-series analysis, use roughness_dw() instead\n\n            **Time axis convention:**\n            The time axis represents the start time of each 200ms analysis\n            window, consistent with roughness_dw() and other wandas methods.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n\n        params = {\"overlap\": overlap}\n        operation_name = \"roughness_dw_spec\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance via factory\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing lazily to self._data (Dask)\n        r_spec_dask = operation.process(self._data)\n\n        # Get metadata updates (sampling rate, bark_axis)\n        metadata_updates = operation.get_metadata_updates()\n\n        # Build metadata and history\n        new_metadata = {**self.metadata, **params}\n        new_history = [\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ]\n\n        # Extract bark_axis with proper type handling\n        bark_axis_value = metadata_updates.get(\"bark_axis\")\n        if bark_axis_value is None:\n            raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n        # Create RoughnessFrame. operation.get_metadata_updates() should provide\n        # sampling_rate and bark_axis\n        roughness_frame = RoughnessFrame(\n            data=r_spec_dask,\n            sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n            bark_axis=bark_axis_value,\n            overlap=overlap,\n            label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=cast(\"BaseFrame[NDArrayReal]\", self),\n        )\n\n        logger.debug(\n            \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n            operation_name,\n            r_spec_dask.shape,\n            roughness_frame.sampling_rate,\n        )\n\n        return roughness_frame\n\n    def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n        \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n        This method applies a symmetric fade-in and fade-out envelope to the signal\n        using a Tukey (tapered cosine) window. The fade duration is the same for\n        both the beginning and end of the signal.\n\n        Args:\n            fade_ms: Fade duration in milliseconds for each end of the signal.\n                The total fade duration is 2 * fade_ms. Default is 50 ms.\n                Must be positive and less than half the signal duration.\n\n        Returns:\n            New ChannelFrame containing the faded signal\n\n        Raises:\n            ValueError: If fade_ms is negative or too long for the signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n            &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n            &gt;&gt;&gt; # Apply very short fade (almost no effect)\n            &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n        Notes:\n            - Uses SciPy's Tukey window for smooth fade transitions\n            - Fade is applied symmetrically to both ends of the signal\n            - The Tukey window alpha parameter is computed automatically\n              based on the fade duration and signal length\n            - For multi-channel signals, the same fade envelope is applied\n              to all channels\n            - Lazy evaluation is preserved - computation occurs only when needed\n        \"\"\"\n        logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n        result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n        return cast(T_Processing, result)\n</code></pre> Functions\u00b6 <code></code> <code>high_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a high-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def high_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a high-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>low_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a low-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def low_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a low-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>band_pass_filter(low_cutoff, high_cutoff, order=4)</code> \u00b6 <p>Apply a band-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>low_cutoff</code> <code>float</code> <p>Lower cutoff frequency (Hz)</p> \u5fc5\u9808 <code>high_cutoff</code> <code>float</code> <p>Higher cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def band_pass_filter(\n    self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a band-pass filter to the signal.\n\n    Args:\n        low_cutoff: Lower cutoff frequency (Hz)\n        high_cutoff: Higher cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n        f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"bandpass_filter\",\n        low_cutoff=low_cutoff,\n        high_cutoff=high_cutoff,\n        order=order,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>normalize(norm=float('inf'), axis=-1, threshold=None, fill=None)</code> \u00b6 <p>Normalize signal levels using librosa.util.normalize.</p> <p>This method normalizes the signal amplitude according to the specified norm.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>norm</code> <code>float | None</code> <p>Norm type. Default is np.inf (maximum absolute value normalization). Supported values: - np.inf: Maximum absolute value normalization - -np.inf: Minimum absolute value normalization - 0: Peak normalization - float: Lp norm - None: No normalization</p> <code>float('inf')</code> <code>axis</code> <code>int | None</code> <p>Axis along which to normalize. Default is -1 (time axis). - -1: Normalize along time axis (each channel independently) - None: Global normalization across all axes - int: Normalize along specified axis</p> <code>-1</code> <code>threshold</code> <code>float | None</code> <p>Threshold below which values are considered zero. If None, no threshold is applied.</p> <code>None</code> <code>fill</code> <code>bool | None</code> <p>Value to fill when the norm is zero. If None, the zero vector remains zero.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the normalized signal</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n&gt;&gt;&gt; normalized = signal.normalize()\n&gt;&gt;&gt; # Global normalization across all channels\n&gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n&gt;&gt;&gt; # L2 normalization\n&gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def normalize(\n    self: T_Processing,\n    norm: float | None = float(\"inf\"),\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n) -&gt; T_Processing:\n    \"\"\"Normalize signal levels using librosa.util.normalize.\n\n    This method normalizes the signal amplitude according to the specified norm.\n\n    Args:\n        norm: Norm type. Default is np.inf (maximum absolute value normalization).\n            Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Peak normalization\n            - float: Lp norm\n            - None: No normalization\n        axis: Axis along which to normalize. Default is -1 (time axis).\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold: Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill: Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n    Returns:\n        New ChannelFrame containing the normalized signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n        &gt;&gt;&gt; normalized = signal.normalize()\n        &gt;&gt;&gt; # Global normalization across all channels\n        &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n        &gt;&gt;&gt; # L2 normalization\n        &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n    \"\"\"\n    logger.debug(\n        f\"Setting up normalize: norm={norm}, axis={axis}, \"\n        f\"threshold={threshold}, fill={fill} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>remove_dc()</code> \u00b6 <p>Remove DC component (DC offset) from the signal.</p> <p>This method removes the DC (direct current) component by subtracting the mean value from each channel. This is equivalent to centering the signal around zero.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame with DC component removed</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create signal with DC offset\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n&gt;&gt;&gt; # Remove DC offset\n&gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n&gt;&gt;&gt; # Verify DC removal\n&gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n</code></pre> Notes <ul> <li>This operation is performed per channel</li> <li>Equivalent to applying a high-pass filter with very low cutoff</li> <li>Useful for removing sensor drift or measurement offset</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def remove_dc(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This method removes the DC (direct current) component by subtracting\n    the mean value from each channel. This is equivalent to centering the\n    signal around zero.\n\n    Returns:\n        New ChannelFrame with DC component removed\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # Create signal with DC offset\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n        &gt;&gt;&gt; # Remove DC offset\n        &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n        &gt;&gt;&gt; # Verify DC removal\n        &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n    Notes:\n        - This operation is performed per channel\n        - Equivalent to applying a high-pass filter with very low cutoff\n        - Useful for removing sensor drift or measurement offset\n    \"\"\"\n    logger.debug(\"Setting up DC removal (lazy)\")\n    result = self.apply_operation(\"remove_dc\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>a_weighting()</code> \u00b6 <p>Apply A-weighting filter to the signal.</p> <p>A-weighting adjusts the frequency response to approximate human auditory perception, according to the IEC 61672-1:2013 standard.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the A-weighted signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def a_weighting(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Apply A-weighting filter to the signal.\n\n    A-weighting adjusts the frequency response to approximate human\n    auditory perception, according to the IEC 61672-1:2013 standard.\n\n    Returns:\n        New ChannelFrame containing the A-weighted signal\n    \"\"\"\n    result = self.apply_operation(\"a_weighting\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>abs()</code> \u00b6 <p>Compute the absolute value of the signal.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the absolute values</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def abs(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Compute the absolute value of the signal.\n\n    Returns:\n        New ChannelFrame containing the absolute values\n    \"\"\"\n    result = self.apply_operation(\"abs\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>power(exponent=2.0)</code> \u00b6 <p>Compute the power of the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>exponent</code> <code>float</code> <p>Exponent to raise the signal to. Default is 2.0.</p> <code>2.0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the powered signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n    \"\"\"Compute the power of the signal.\n\n    Args:\n        exponent: Exponent to raise the signal to. Default is 2.0.\n\n    Returns:\n        New ChannelFrame containing the powered signal\n    \"\"\"\n    result = self.apply_operation(\"power\", exponent=exponent)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>sum()</code> \u00b6 <p>Sum all channels.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame with summed signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def sum(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Sum all channels.\n\n    Returns:\n        A new ChannelFrame with summed signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n</code></pre> <code></code> <code>mean()</code> \u00b6 <p>Average all channels.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame with averaged signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def mean(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Average all channels.\n\n    Returns:\n        A new ChannelFrame with averaged signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n</code></pre> <code></code> <code>trim(start=0, end=None)</code> \u00b6 <p>Trim the signal to the specified time range.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>start</code> <code>float</code> <p>Start time (seconds)</p> <code>0</code> <code>end</code> <code>float | None</code> <p>End time (seconds)</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the trimmed signal</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If end time is earlier than start time</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def trim(\n    self: T_Processing,\n    start: float = 0,\n    end: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Trim the signal to the specified time range.\n\n    Args:\n        start: Start time (seconds)\n        end: End time (seconds)\n\n    Returns:\n        New ChannelFrame containing the trimmed signal\n\n    Raises:\n        ValueError: If end time is earlier than start time\n    \"\"\"\n    if end is None:\n        end = self.duration\n    if start &gt; end:\n        raise ValueError(\"start must be less than end\")\n    result = self.apply_operation(\"trim\", start=start, end=end)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>fix_length(length=None, duration=None)</code> \u00b6 <p>Adjust the signal to the specified length.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>duration</code> <code>float | None</code> <p>Signal length in seconds</p> <code>None</code> <code>length</code> <code>int | None</code> <p>Signal length in samples</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the adjusted signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fix_length(\n    self: T_Processing,\n    length: int | None = None,\n    duration: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Adjust the signal to the specified length.\n\n    Args:\n        duration: Signal length in seconds\n        length: Signal length in samples\n\n    Returns:\n        New ChannelFrame containing the adjusted signal\n    \"\"\"\n\n    result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>rms_trend(frame_length=2048, hop_length=512, dB=False, Aw=False)</code> \u00b6 <p>Compute the RMS trend of the signal.</p> <p>This method calculates the root mean square value over a sliding window.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame_length</code> <code>int</code> <p>Size of the sliding window in samples. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int</code> <p>Hop length between windows in samples. Default is 512.</p> <code>512</code> <code>dB</code> <code>bool</code> <p>Whether to return RMS values in decibels. Default is False.</p> <code>False</code> <code>Aw</code> <code>bool</code> <p>Whether to apply A-weighting. Default is False.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the RMS trend</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def rms_trend(\n    self: T_Processing,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; T_Processing:\n    \"\"\"Compute the RMS trend of the signal.\n\n    This method calculates the root mean square value over a sliding window.\n\n    Args:\n        frame_length: Size of the sliding window in samples. Default is 2048.\n        hop_length: Hop length between windows in samples. Default is 512.\n        dB: Whether to return RMS values in decibels. Default is False.\n        Aw: Whether to apply A-weighting. Default is False.\n\n    Returns:\n        New ChannelFrame containing the RMS trend\n    \"\"\"\n    # Access _channel_metadata to retrieve reference values\n    frame = cast(ProcessingFrameProtocol, self)\n\n    # Ensure _channel_metadata exists before referencing\n    ref_values = []\n    if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n        ref_values = [ch.ref for ch in frame._channel_metadata]\n\n    result = self.apply_operation(\n        \"rms_trend\",\n        frame_length=frame_length,\n        hop_length=hop_length,\n        ref=ref_values,\n        dB=dB,\n        Aw=Aw,\n    )\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>channel_difference(other_channel=0)</code> \u00b6 <p>Compute the difference between channels.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>other_channel</code> <code>int | str</code> <p>Index or label of the reference channel. Default is 0.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the channel difference</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def channel_difference(\n    self: T_Processing, other_channel: int | str = 0\n) -&gt; T_Processing:\n    \"\"\"Compute the difference between channels.\n\n    Args:\n        other_channel: Index or label of the reference channel. Default is 0.\n\n    Returns:\n        New ChannelFrame containing the channel difference\n    \"\"\"\n    # label2index is a method of BaseFrame\n    if isinstance(other_channel, str):\n        if hasattr(self, \"label2index\"):\n            other_channel = self.label2index(other_channel)\n\n    result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>resampling(target_sr, **kwargs)</code> \u00b6 <p>Resample audio data.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>target_sr</code> <code>float</code> <p>Target sampling rate (Hz)</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional resampling parameters</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>Resampled ChannelFrame</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def resampling(\n    self: T_Processing,\n    target_sr: float,\n    **kwargs: Any,\n) -&gt; T_Processing:\n    \"\"\"Resample audio data.\n\n    Args:\n        target_sr: Target sampling rate (Hz)\n        **kwargs: Additional resampling parameters\n\n    Returns:\n        Resampled ChannelFrame\n    \"\"\"\n    return cast(\n        T_Processing,\n        self.apply_operation(\n            \"resampling\",\n            target_sr=target_sr,\n            **kwargs,\n        ),\n    )\n</code></pre> <code></code> <code>hpss_harmonic(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract harmonic components using HPSS  (Harmonic-Percussive Source Separation).</p> <p>This method separates the harmonic (tonal) components from the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <code>n_fft</code> <code>int</code> <p>Size of FFT window.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Hop length for STFT.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length for STFT.</p> <code>None</code> <code>window</code> <code>_WindowSpec</code> <p>Window type for STFT.</p> <code>'hann'</code> <code>center</code> <code>bool</code> <p>If True, center the frames.</p> <code>True</code> <code>pad_mode</code> <code>_PadModeSTFT</code> <p>Padding mode for STFT.</p> <code>'constant'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_harmonic(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract harmonic components using HPSS\n     (Harmonic-Percussive Source Separation).\n\n    This method separates the harmonic (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n        n_fft: Size of FFT window.\n        hop_length: Hop length for STFT.\n        win_length: Window length for STFT.\n        window: Window type for STFT.\n        center: If True, center the frames.\n        pad_mode: Padding mode for STFT.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_harmonic\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>hpss_percussive(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract percussive components using HPSS (Harmonic-Percussive Source Separation).</p> <p>This method separates the percussive (tonal) components from the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_percussive(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract percussive components using HPSS\n    (Harmonic-Percussive Source Separation).\n\n    This method separates the percussive (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_percussive\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwtv(field_type='free')</code> \u00b6 <p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing time-varying loudness values in sones.</p> <code>T_Processing</code> <p>Each channel is processed independently.</p> <code>T_Processing</code> <p>The output sampling rate is adjusted based on the loudness</p> <code>T_Processing</code> <p>calculation time resolution (typically ~500 Hz for 2ms steps).</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>\u4f8b\uff1a</p> <p>Calculate loudness for a signal:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre> Notes <ul> <li>The output contains time-varying loudness values in sones</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>The time resolution is approximately 2ms (determined by the algorithm)</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The output sampling rate is updated to reflect the time resolution</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 2ms analysis step. This differs slightly from the MoSQITo library, which uses the center time of each step. For example:</p> <ul> <li>wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)</li> <li>MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)</li> </ul> <p>The difference is very small (~1ms) and does not affect the loudness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        New ChannelFrame containing time-varying loudness values in sones.\n        Each channel is processed independently.\n        The output sampling rate is adjusted based on the loudness\n        calculation time resolution (typically ~500 Hz for 2ms steps).\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate loudness for a signal:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n    Notes:\n        - The output contains time-varying loudness values in sones\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - The time resolution is approximately 2ms (determined by the algorithm)\n        - For multi-channel signals, loudness is calculated per channel\n        - The output sampling rate is updated to reflect the time resolution\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 2ms analysis step. This differs slightly from the MoSQITo\n        library, which uses the center time of each step. For example:\n\n        - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n        - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n        The difference is very small (~1ms) and does not affect the loudness\n        values themselves. This design choice ensures consistency with\n        wandas's time axis convention across all frame types.\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwst(field_type='free')</code> \u00b6 <p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>This method is suitable for analyzing steady sounds such as fan noise, constant machinery sounds, or other stationary signals.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Loudness values in sones, one per channel. Shape: (n_channels,)</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>\u4f8b\uff1a</p> <p>Calculate steady-state loudness for a fan noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n&gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre> Notes <ul> <li>Returns a 1D array with one loudness value per channel</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>For multi-channel signals, loudness is calculated independently   per channel</li> <li>This method is designed for stationary signals (constant sounds)</li> <li>For time-varying signals, use loudness_zwtv() instead</li> <li>Similar to the rms property, returns NDArrayReal for consistency</li> </ul> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    This method is suitable for analyzing steady sounds such as fan noise,\n    constant machinery sounds, or other stationary signals.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        Loudness values in sones, one per channel. Shape: (n_channels,)\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate steady-state loudness for a fan noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n        &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n    Notes:\n        - Returns a 1D array with one loudness value per channel\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - For multi-channel signals, loudness is calculated independently\n          per channel\n        - This method is designed for stationary signals (constant sounds)\n        - For time-varying signals, use loudness_zwtv() instead\n        - Similar to the rms property, returns NDArrayReal for consistency\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    # Treat self as a ProcessingFrameProtocol so mypy understands\n    # where sampling_rate and data come from.\n    from wandas.processing.psychoacoustic import LoudnessZwst\n    from wandas.utils.types import NDArrayReal\n\n    # Create operation instance\n    operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n    # Get data (triggers computation if lazy)\n    data = self.data\n\n    # Ensure data is 2D (n_channels, n_samples)\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    # Process the array using the public API and materialize to NumPy\n    result = operation.process_array(data).compute()\n\n    # Squeeze to get 1D array (n_channels,)\n    loudness_values: NDArrayReal = result.squeeze()\n\n    # Ensure it's 1D even for single channel\n    if loudness_values.ndim == 0:\n        loudness_values = loudness_values.reshape(1)\n\n    return loudness_values\n</code></pre> <code></code> <code>roughness_dw(overlap=0.5)</code> \u00b6 <p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound, measured in asper. This method implements the Daniel &amp; Weber (1997) standard calculation.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing time-varying roughness values in asper.</p> <code>T_Processing</code> <p>The output sampling rate depends on the overlap parameter.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>\u4f8b\uff1a</p> <p>Calculate roughness for a motor noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n&gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n&gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n</code></pre> <p>Analyze roughness statistics:</p> <pre><code>&gt;&gt;&gt; mean_roughness = roughness.data.mean()\n&gt;&gt;&gt; max_roughness = roughness.data.max()\n&gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n&gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n</code></pre> <p>Compare before and after modification:</p> <pre><code>&gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n&gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n&gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n&gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n</code></pre> Notes <ul> <li>Returns a ChannelFrame with time-varying roughness values</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher values indicate rougher, harsher sounds</li> <li>For multi-channel signals, roughness is calculated independently   per channel</li> <li>This is the standard-compliant total roughness (R)</li> <li>For detailed Bark-band analysis, use roughness_dw_spec() instead</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 200ms analysis window. This differs from the MoSQITo library, which uses the center time of each window. For example:</p> <ul> <li>wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)</li> <li>MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)</li> </ul> <p>The difference is constant (half the window duration = 100ms) and does not affect the roughness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n    \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound, measured in asper. This method\n    implements the Daniel &amp; Weber (1997) standard calculation.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        New ChannelFrame containing time-varying roughness values in asper.\n        The output sampling rate depends on the overlap parameter.\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Calculate roughness for a motor noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n        &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n        &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n        Analyze roughness statistics:\n        &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n        &gt;&gt;&gt; max_roughness = roughness.data.max()\n        &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n        &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n        Compare before and after modification:\n        &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n        &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n        &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n        &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n    Notes:\n        - Returns a ChannelFrame with time-varying roughness values\n        - Typical roughness values: 0-2 asper for most sounds\n        - Higher values indicate rougher, harsher sounds\n        - For multi-channel signals, roughness is calculated independently\n          per channel\n        - This is the standard-compliant total roughness (R)\n        - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 200ms analysis window. This differs from the MoSQITo library,\n        which uses the center time of each window. For example:\n\n        - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n        - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n        The difference is constant (half the window duration = 100ms) and\n        does not affect the roughness values themselves. This design choice\n        ensures consistency with wandas's time axis convention across all\n        frame types.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n    logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n    result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>roughness_dw_spec(overlap=0.5)</code> \u00b6 <p>Calculate specific roughness with Bark-band frequency information.</p> <p>This method returns detailed roughness analysis data organized by Bark frequency bands over time, allowing for frequency-specific roughness analysis. It uses the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>RoughnessFrame</code> <p>RoughnessFrame containing: - data: Specific roughness by Bark band, shape (47, n_time)         for mono or (n_channels, 47, n_time) for multi-channel - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5) - time: Time axis for each analysis frame - overlap: Overlap coefficient used - plot(): Method for Bark-Time heatmap visualization</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>\u4f8b\uff1a</p> <p>Analyze frequency-specific roughness:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n&gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot Bark-Time heatmap\n&gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find dominant Bark band\n&gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n&gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n&gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Extract specific Bark band time series\n&gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n&gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify standard formula\n&gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n&gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n</code></pre> Notes <ul> <li>Returns a RoughnessFrame (not ChannelFrame)</li> <li>Contains 47 Bark bands from 0.5 to 23.5 Bark</li> <li>Each Bark band corresponds to a critical band of hearing</li> <li>Useful for identifying which frequencies contribute most to roughness</li> <li>The specific roughness can be integrated to obtain total roughness</li> <li>For simple time-series analysis, use roughness_dw() instead</li> </ul> <p>Time axis convention: The time axis represents the start time of each 200ms analysis window, consistent with roughness_dw() and other wandas methods.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n    \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n    This method returns detailed roughness analysis data organized by\n    Bark frequency bands over time, allowing for frequency-specific\n    roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n    The relationship between total roughness and specific roughness:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        RoughnessFrame containing:\n            - data: Specific roughness by Bark band, shape (47, n_time)\n                    for mono or (n_channels, 47, n_time) for multi-channel\n            - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n            - time: Time axis for each analysis frame\n            - overlap: Overlap coefficient used\n            - plot(): Method for Bark-Time heatmap visualization\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Analyze frequency-specific roughness:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot Bark-Time heatmap\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Find dominant Bark band\n        &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n        &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n        &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Extract specific Bark band time series\n        &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n        &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verify standard formula\n        &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n        &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n    Notes:\n        - Returns a RoughnessFrame (not ChannelFrame)\n        - Contains 47 Bark bands from 0.5 to 23.5 Bark\n        - Each Bark band corresponds to a critical band of hearing\n        - Useful for identifying which frequencies contribute most to roughness\n        - The specific roughness can be integrated to obtain total roughness\n        - For simple time-series analysis, use roughness_dw() instead\n\n        **Time axis convention:**\n        The time axis represents the start time of each 200ms analysis\n        window, consistent with roughness_dw() and other wandas methods.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n\n    params = {\"overlap\": overlap}\n    operation_name = \"roughness_dw_spec\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance via factory\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n\n    # Apply processing lazily to self._data (Dask)\n    r_spec_dask = operation.process(self._data)\n\n    # Get metadata updates (sampling rate, bark_axis)\n    metadata_updates = operation.get_metadata_updates()\n\n    # Build metadata and history\n    new_metadata = {**self.metadata, **params}\n    new_history = [\n        *self.operation_history,\n        {\"operation\": operation_name, \"params\": params},\n    ]\n\n    # Extract bark_axis with proper type handling\n    bark_axis_value = metadata_updates.get(\"bark_axis\")\n    if bark_axis_value is None:\n        raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n    # Create RoughnessFrame. operation.get_metadata_updates() should provide\n    # sampling_rate and bark_axis\n    roughness_frame = RoughnessFrame(\n        data=r_spec_dask,\n        sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n        bark_axis=bark_axis_value,\n        overlap=overlap,\n        label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=cast(\"BaseFrame[NDArrayReal]\", self),\n    )\n\n    logger.debug(\n        \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n        operation_name,\n        r_spec_dask.shape,\n        roughness_frame.sampling_rate,\n    )\n\n    return roughness_frame\n</code></pre> <code></code> <code>fade(fade_ms=50)</code> \u00b6 <p>Apply symmetric fade-in and fade-out to the signal using Tukey window.</p> <p>This method applies a symmetric fade-in and fade-out envelope to the signal using a Tukey (tapered cosine) window. The fade duration is the same for both the beginning and end of the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>fade_ms</code> <code>float</code> <p>Fade duration in milliseconds for each end of the signal. The total fade duration is 2 * fade_ms. Default is 50 ms. Must be positive and less than half the signal duration.</p> <code>50</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the faded signal</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If fade_ms is negative or too long for the signal</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n&gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n&gt;&gt;&gt; # Apply very short fade (almost no effect)\n&gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n</code></pre> Notes <ul> <li>Uses SciPy's Tukey window for smooth fade transitions</li> <li>Fade is applied symmetrically to both ends of the signal</li> <li>The Tukey window alpha parameter is computed automatically   based on the fade duration and signal length</li> <li>For multi-channel signals, the same fade envelope is applied   to all channels</li> <li>Lazy evaluation is preserved - computation occurs only when needed</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n    \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n    This method applies a symmetric fade-in and fade-out envelope to the signal\n    using a Tukey (tapered cosine) window. The fade duration is the same for\n    both the beginning and end of the signal.\n\n    Args:\n        fade_ms: Fade duration in milliseconds for each end of the signal.\n            The total fade duration is 2 * fade_ms. Default is 50 ms.\n            Must be positive and less than half the signal duration.\n\n    Returns:\n        New ChannelFrame containing the faded signal\n\n    Raises:\n        ValueError: If fade_ms is negative or too long for the signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n        &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n        &gt;&gt;&gt; # Apply very short fade (almost no effect)\n        &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n    Notes:\n        - Uses SciPy's Tukey window for smooth fade transitions\n        - Fade is applied symmetrically to both ends of the signal\n        - The Tukey window alpha parameter is computed automatically\n          based on the fade duration and signal length\n        - For multi-channel signals, the same fade envelope is applied\n          to all channels\n        - Lazy evaluation is preserved - computation occurs only when needed\n    \"\"\"\n    logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n    result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/#wandas.frames.mixins.ChannelTransformMixin","title":"<code>ChannelTransformMixin</code>","text":"<p>Mixin providing methods related to frequency transformations.</p> <p>This mixin provides operations related to frequency analysis and transformations such as FFT, STFT, and Welch method.</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>class ChannelTransformMixin:\n    \"\"\"Mixin providing methods related to frequency transformations.\n\n    This mixin provides operations related to frequency analysis and\n    transformations such as FFT, STFT, and Welch method.\n    \"\"\"\n\n    def fft(\n        self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate Fast Fourier Transform (FFT).\n\n        Args:\n            n_fft: Number of FFT points. Default is the next power of 2 of the data\n                length.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectralFrame containing FFT results\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import FFT, create_operation\n\n        params = {\"n_fft\": n_fft, \"window\": window}\n        operation_name = \"fft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"FFT\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        if n_fft is None:\n            is_even = spectrum_data.shape[-1] % 2 == 0\n            _n_fft = (\n                spectrum_data.shape[-1] * 2 - 2\n                if is_even\n                else spectrum_data.shape[-1] * 2 - 1\n            )\n        else:\n            _n_fft = n_fft\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=_n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def welch(\n        self: T_Transform,\n        n_fft: int | None = None,\n        hop_length: int | None = None,\n        win_length: int = 2048,\n        window: str = \"hann\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate power spectral density using Welch's method.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing power spectral density\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import Welch, create_operation\n\n        params = dict(\n            n_fft=n_fft or win_length,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            average=average,\n        )\n        operation_name = \"welch\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Welch\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"welch\", \"params\": params},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def noct_spectrum(\n        self: T_Transform,\n        fmin: float = 25,\n        fmax: float = 20000,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; \"NOctFrame\":\n        \"\"\"Calculate N-octave band spectrum.\n\n        Args:\n            fmin: Minimum center frequency (Hz). Default is 25 Hz.\n            fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n            n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n            G: Reference gain (dB). Default is 10 dB.\n            fr: Reference frequency (Hz). Default is 1000 Hz.\n\n        Returns:\n            NOctFrame containing N-octave band spectrum\n        \"\"\"\n        from wandas.processing import NOctSpectrum, create_operation\n\n        from ..noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_spectrum\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSpectrum\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_spectrum\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def stft(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Calculate Short-Time Fourier Transform.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectrogramFrame containing STFT results\n        \"\"\"\n        from wandas.processing import STFT, create_operation\n\n        from ..spectrogram import SpectrogramFrame\n\n        # Set hop length and window length\n        _hop_length = hop_length if hop_length is not None else n_fft // 4\n        _win_length = win_length if win_length is not None else n_fft\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": _hop_length,\n            \"win_length\": _win_length,\n            \"window\": window,\n        }\n        operation_name = \"stft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"STFT\", operation)\n\n        # Apply processing to data\n        spectrogram_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new instance\n        return SpectrogramFrame(\n            data=spectrogram_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=n_fft,\n            hop_length=_hop_length,\n            win_length=_win_length,\n            window=window,\n            label=f\"stft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def coherence(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate magnitude squared coherence.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n        Returns:\n            SpectralFrame containing magnitude squared coherence\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.processing import Coherence, create_operation\n\n        from ..spectral import SpectralFrame\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n        }\n        operation_name = \"coherence\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Coherence\", operation)\n\n        # Apply processing to data\n        coherence_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=coherence_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Coherence of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def csd(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate cross-spectral density matrix.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing cross-spectral density matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import CSD, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"csd\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"CSD\", operation)\n\n        # Apply processing to data\n        csd_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=csd_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def transfer_function(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate transfer function matrix.\n\n        The transfer function represents the signal transfer characteristics between\n        channels in the frequency domain and represents the input-output relationship\n        of the system.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing transfer function matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import TransferFunction, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"transfer_function\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"TransferFunction\", operation)\n\n        # Apply processing to data\n        tf_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=tf_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Transfer function of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n</code></pre> Functions\u00b6 <code></code> <code>fft(n_fft=None, window='hann')</code> \u00b6 <p>Calculate Fast Fourier Transform (FFT).</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is the next power of 2 of the data length.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing FFT results</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def fft(\n    self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate Fast Fourier Transform (FFT).\n\n    Args:\n        n_fft: Number of FFT points. Default is the next power of 2 of the data\n            length.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectralFrame containing FFT results\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import FFT, create_operation\n\n    params = {\"n_fft\": n_fft, \"window\": window}\n    operation_name = \"fft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"FFT\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    if n_fft is None:\n        is_even = spectrum_data.shape[-1] % 2 == 0\n        _n_fft = (\n            spectrum_data.shape[-1] * 2 - 2\n            if is_even\n            else spectrum_data.shape[-1] * 2 - 1\n        )\n    else:\n        _n_fft = n_fft\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=_n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>welch(n_fft=None, hop_length=None, win_length=2048, window='hann', average='mean')</code> \u00b6 <p>Calculate power spectral density using Welch's method.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is 2048.</p> <code>None</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int</code> <p>Window length. Default is n_fft.</p> <code>2048</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing power spectral density</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def welch(\n    self: T_Transform,\n    n_fft: int | None = None,\n    hop_length: int | None = None,\n    win_length: int = 2048,\n    window: str = \"hann\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate power spectral density using Welch's method.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing power spectral density\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import Welch, create_operation\n\n    params = dict(\n        n_fft=n_fft or win_length,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        average=average,\n    )\n    operation_name = \"welch\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Welch\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"welch\", \"params\": params},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>noct_spectrum(fmin=25, fmax=20000, n=3, G=10, fr=1000)</code> \u00b6 <p>Calculate N-octave band spectrum.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>fmin</code> <code>float</code> <p>Minimum center frequency (Hz). Default is 25 Hz.</p> <code>25</code> <code>fmax</code> <code>float</code> <p>Maximum center frequency (Hz). Default is 20000 Hz.</p> <code>20000</code> <code>n</code> <code>int</code> <p>Band division (1: octave, 3: 1/3 octave). Default is 3.</p> <code>3</code> <code>G</code> <code>int</code> <p>Reference gain (dB). Default is 10 dB.</p> <code>10</code> <code>fr</code> <code>int</code> <p>Reference frequency (Hz). Default is 1000 Hz.</p> <code>1000</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NOctFrame</code> <p>NOctFrame containing N-octave band spectrum</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def noct_spectrum(\n    self: T_Transform,\n    fmin: float = 25,\n    fmax: float = 20000,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; \"NOctFrame\":\n    \"\"\"Calculate N-octave band spectrum.\n\n    Args:\n        fmin: Minimum center frequency (Hz). Default is 25 Hz.\n        fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n        n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n        G: Reference gain (dB). Default is 10 dB.\n        fr: Reference frequency (Hz). Default is 1000 Hz.\n\n    Returns:\n        NOctFrame containing N-octave band spectrum\n    \"\"\"\n    from wandas.processing import NOctSpectrum, create_operation\n\n    from ..noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_spectrum\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSpectrum\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_spectrum\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Calculate Short-Time Fourier Transform.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectrogramFrame</code> <p>SpectrogramFrame containing STFT results</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def stft(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Calculate Short-Time Fourier Transform.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectrogramFrame containing STFT results\n    \"\"\"\n    from wandas.processing import STFT, create_operation\n\n    from ..spectrogram import SpectrogramFrame\n\n    # Set hop length and window length\n    _hop_length = hop_length if hop_length is not None else n_fft // 4\n    _win_length = win_length if win_length is not None else n_fft\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": _hop_length,\n        \"win_length\": _win_length,\n        \"window\": window,\n    }\n    operation_name = \"stft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"STFT\", operation)\n\n    # Apply processing to data\n    spectrogram_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new instance\n    return SpectrogramFrame(\n        data=spectrogram_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=n_fft,\n        hop_length=_hop_length,\n        win_length=_win_length,\n        window=window,\n        label=f\"stft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>coherence(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code> \u00b6 <p>Calculate magnitude squared coherence.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing magnitude squared coherence</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def coherence(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate magnitude squared coherence.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n    Returns:\n        SpectralFrame containing magnitude squared coherence\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.processing import Coherence, create_operation\n\n    from ..spectral import SpectralFrame\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n    }\n    operation_name = \"coherence\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Coherence\", operation)\n\n    # Apply processing to data\n    coherence_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=coherence_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Coherence of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>csd(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate cross-spectral density matrix.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing cross-spectral density matrix</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def csd(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate cross-spectral density matrix.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing cross-spectral density matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import CSD, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"csd\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"CSD\", operation)\n\n    # Apply processing to data\n    csd_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=csd_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>transfer_function(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate transfer function matrix.</p> <p>The transfer function represents the signal transfer characteristics between channels in the frequency domain and represents the input-output relationship of the system.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing transfer function matrix</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def transfer_function(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate transfer function matrix.\n\n    The transfer function represents the signal transfer characteristics between\n    channels in the frequency domain and represents the input-output relationship\n    of the system.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing transfer function matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import TransferFunction, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"transfer_function\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"TransferFunction\", operation)\n\n    # Apply processing to data\n    tf_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=tf_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Transfer function of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.mixins.channel_collection_mixin","title":"<code>channel_collection_mixin</code>","text":"<p>ChannelCollectionMixin: Common functionality for adding/removing channels in ChannelFrame</p> Attributes\u00b6 <code>T = TypeVar('T', bound='ChannelCollectionMixin')</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>ChannelCollectionMixin</code> \u00b6 Source code in <code>wandas/frames/mixins/channel_collection_mixin.py</code> <pre><code>class ChannelCollectionMixin:\n    def add_channel(\n        self: T,\n        data: np.ndarray[Any, Any] | da.Array | T,\n        label: str | None = None,\n        align: Literal[\"strict\", \"pad\", \"truncate\"] = \"strict\",\n        suffix_on_dup: str | None = None,\n        inplace: bool = False,\n        **kwargs: Any,\n    ) -&gt; T:\n        \"\"\"\n        Add a channel\n        Args:\n            data: Channel to add (1ch ndarray/dask/ChannelFrame)\n            label: Label for the added channel\n            align: Behavior when lengths don't match\n            suffix_on_dup: Suffix when label is duplicated\n            inplace: True for self-modification\n        Returns:\n            New Frame or self\n        Raises:\n            ValueError, TypeError\n        \"\"\"\n        raise NotImplementedError(\"add_channel() must be implemented in subclasses\")\n\n    def remove_channel(\n        self: T,\n        key: int | str,\n        inplace: bool = False,\n    ) -&gt; T:\n        \"\"\"\n        Remove a channel\n        Args:\n            key: Target to remove (index or label)\n            inplace: True for self-modification\n        Returns:\n            New Frame or self\n        Raises:\n            ValueError, KeyError, IndexError\n        \"\"\"\n        raise NotImplementedError(\"remove_channel() must be implemented in subclasses\")\n</code></pre> Functions\u00b6 <code></code> <code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False, **kwargs)</code> \u00b6 <p>Add a channel Args:     data: Channel to add (1ch ndarray/dask/ChannelFrame)     label: Label for the added channel     align: Behavior when lengths don't match     suffix_on_dup: Suffix when label is duplicated     inplace: True for self-modification Returns:     New Frame or self Raises:     ValueError, TypeError</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_collection_mixin.py</code> <pre><code>def add_channel(\n    self: T,\n    data: np.ndarray[Any, Any] | da.Array | T,\n    label: str | None = None,\n    align: Literal[\"strict\", \"pad\", \"truncate\"] = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n    **kwargs: Any,\n) -&gt; T:\n    \"\"\"\n    Add a channel\n    Args:\n        data: Channel to add (1ch ndarray/dask/ChannelFrame)\n        label: Label for the added channel\n        align: Behavior when lengths don't match\n        suffix_on_dup: Suffix when label is duplicated\n        inplace: True for self-modification\n    Returns:\n        New Frame or self\n    Raises:\n        ValueError, TypeError\n    \"\"\"\n    raise NotImplementedError(\"add_channel() must be implemented in subclasses\")\n</code></pre> <code></code> <code>remove_channel(key, inplace=False)</code> \u00b6 <p>Remove a channel Args:     key: Target to remove (index or label)     inplace: True for self-modification Returns:     New Frame or self Raises:     ValueError, KeyError, IndexError</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_collection_mixin.py</code> <pre><code>def remove_channel(\n    self: T,\n    key: int | str,\n    inplace: bool = False,\n) -&gt; T:\n    \"\"\"\n    Remove a channel\n    Args:\n        key: Target to remove (index or label)\n        inplace: True for self-modification\n    Returns:\n        New Frame or self\n    Raises:\n        ValueError, KeyError, IndexError\n    \"\"\"\n    raise NotImplementedError(\"remove_channel() must be implemented in subclasses\")\n</code></pre>"},{"location":"en/api/#wandas.frames.mixins.channel_processing_mixin","title":"<code>channel_processing_mixin</code>","text":"<p>Module providing mixins related to signal processing.</p> Attributes\u00b6 <code>logger = logging.getLogger(__name__)</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>ChannelProcessingMixin</code> \u00b6 <p>Mixin that provides methods related to signal processing.</p> <p>This mixin provides processing methods applied to audio signals and other time-series data, such as signal processing filters and transformation operations.</p> Source code in <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>class ChannelProcessingMixin:\n    \"\"\"Mixin that provides methods related to signal processing.\n\n    This mixin provides processing methods applied to audio signals and\n    other time-series data, such as signal processing filters and\n    transformation operations.\n    \"\"\"\n\n    def high_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a high-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def low_pass_filter(\n        self: T_Processing, cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a low-pass filter to the signal.\n\n        Args:\n            cutoff: Filter cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n        return cast(T_Processing, result)\n\n    def band_pass_filter(\n        self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n    ) -&gt; T_Processing:\n        \"\"\"Apply a band-pass filter to the signal.\n\n        Args:\n            low_cutoff: Lower cutoff frequency (Hz)\n            high_cutoff: Higher cutoff frequency (Hz)\n            order: Filter order. Default is 4.\n\n        Returns:\n            New ChannelFrame after filter application\n        \"\"\"\n        logger.debug(\n            f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n            f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"bandpass_filter\",\n            low_cutoff=low_cutoff,\n            high_cutoff=high_cutoff,\n            order=order,\n        )\n        return cast(T_Processing, result)\n\n    def normalize(\n        self: T_Processing,\n        norm: float | None = float(\"inf\"),\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Normalize signal levels using librosa.util.normalize.\n\n        This method normalizes the signal amplitude according to the specified norm.\n\n        Args:\n            norm: Norm type. Default is np.inf (maximum absolute value normalization).\n                Supported values:\n                - np.inf: Maximum absolute value normalization\n                - -np.inf: Minimum absolute value normalization\n                - 0: Peak normalization\n                - float: Lp norm\n                - None: No normalization\n            axis: Axis along which to normalize. Default is -1 (time axis).\n                - -1: Normalize along time axis (each channel independently)\n                - None: Global normalization across all axes\n                - int: Normalize along specified axis\n            threshold: Threshold below which values are considered zero.\n                If None, no threshold is applied.\n            fill: Value to fill when the norm is zero.\n                If None, the zero vector remains zero.\n\n        Returns:\n            New ChannelFrame containing the normalized signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n            &gt;&gt;&gt; normalized = signal.normalize()\n            &gt;&gt;&gt; # Global normalization across all channels\n            &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n            &gt;&gt;&gt; # L2 normalization\n            &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n        \"\"\"\n        logger.debug(\n            f\"Setting up normalize: norm={norm}, axis={axis}, \"\n            f\"threshold={threshold}, fill={fill} (lazy)\"\n        )\n        result = self.apply_operation(\n            \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        return cast(T_Processing, result)\n\n    def remove_dc(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Remove DC component (DC offset) from the signal.\n\n        This method removes the DC (direct current) component by subtracting\n        the mean value from each channel. This is equivalent to centering the\n        signal around zero.\n\n        Returns:\n            New ChannelFrame with DC component removed\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; # Create signal with DC offset\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n            &gt;&gt;&gt; # Remove DC offset\n            &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n            &gt;&gt;&gt; # Verify DC removal\n            &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n        Notes:\n            - This operation is performed per channel\n            - Equivalent to applying a high-pass filter with very low cutoff\n            - Useful for removing sensor drift or measurement offset\n        \"\"\"\n        logger.debug(\"Setting up DC removal (lazy)\")\n        result = self.apply_operation(\"remove_dc\")\n        return cast(T_Processing, result)\n\n    def a_weighting(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Apply A-weighting filter to the signal.\n\n        A-weighting adjusts the frequency response to approximate human\n        auditory perception, according to the IEC 61672-1:2013 standard.\n\n        Returns:\n            New ChannelFrame containing the A-weighted signal\n        \"\"\"\n        result = self.apply_operation(\"a_weighting\")\n        return cast(T_Processing, result)\n\n    def abs(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Compute the absolute value of the signal.\n\n        Returns:\n            New ChannelFrame containing the absolute values\n        \"\"\"\n        result = self.apply_operation(\"abs\")\n        return cast(T_Processing, result)\n\n    def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n        \"\"\"Compute the power of the signal.\n\n        Args:\n            exponent: Exponent to raise the signal to. Default is 2.0.\n\n        Returns:\n            New ChannelFrame containing the powered signal\n        \"\"\"\n        result = self.apply_operation(\"power\", exponent=exponent)\n        return cast(T_Processing, result)\n\n    def _reduce_channels(self: T_Processing, op: str) -&gt; T_Processing:\n        \"\"\"Helper to reduce all channels with the given operation ('sum' or 'mean').\"\"\"\n        if op == \"sum\":\n            reduced_data = self._data.sum(axis=0, keepdims=True)\n            label = \"sum\"\n        elif op == \"mean\":\n            reduced_data = self._data.mean(axis=0, keepdims=True)\n            label = \"mean\"\n        else:\n            raise ValueError(f\"Unsupported reduction operation: {op}\")\n\n        units = [ch.unit for ch in self._channel_metadata]\n        if all(u == units[0] for u in units):\n            reduced_unit = units[0]\n        else:\n            reduced_unit = \"\"\n\n        reduced_extra = {\"source_extras\": [ch.extra for ch in self._channel_metadata]}\n        new_channel_metadata = [\n            ChannelMetadata(\n                label=label,\n                unit=reduced_unit,\n                extra=reduced_extra,\n            )\n        ]\n        new_history = (\n            self.operation_history.copy() if hasattr(self, \"operation_history\") else []\n        )\n        new_history.append({\"operation\": op})\n        new_metadata = self.metadata.copy() if hasattr(self, \"metadata\") else {}\n        result = self._create_new_instance(\n            data=reduced_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=new_channel_metadata,\n        )\n        return result\n\n    def sum(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Sum all channels.\n\n        Returns:\n            A new ChannelFrame with summed signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n\n    def mean(self: T_Processing) -&gt; T_Processing:\n        \"\"\"Average all channels.\n\n        Returns:\n            A new ChannelFrame with averaged signal.\n        \"\"\"\n        return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n\n    def trim(\n        self: T_Processing,\n        start: float = 0,\n        end: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Trim the signal to the specified time range.\n\n        Args:\n            start: Start time (seconds)\n            end: End time (seconds)\n\n        Returns:\n            New ChannelFrame containing the trimmed signal\n\n        Raises:\n            ValueError: If end time is earlier than start time\n        \"\"\"\n        if end is None:\n            end = self.duration\n        if start &gt; end:\n            raise ValueError(\"start must be less than end\")\n        result = self.apply_operation(\"trim\", start=start, end=end)\n        return cast(T_Processing, result)\n\n    def fix_length(\n        self: T_Processing,\n        length: int | None = None,\n        duration: float | None = None,\n    ) -&gt; T_Processing:\n        \"\"\"Adjust the signal to the specified length.\n\n        Args:\n            duration: Signal length in seconds\n            length: Signal length in samples\n\n        Returns:\n            New ChannelFrame containing the adjusted signal\n        \"\"\"\n\n        result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n        return cast(T_Processing, result)\n\n    def rms_trend(\n        self: T_Processing,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; T_Processing:\n        \"\"\"Compute the RMS trend of the signal.\n\n        This method calculates the root mean square value over a sliding window.\n\n        Args:\n            frame_length: Size of the sliding window in samples. Default is 2048.\n            hop_length: Hop length between windows in samples. Default is 512.\n            dB: Whether to return RMS values in decibels. Default is False.\n            Aw: Whether to apply A-weighting. Default is False.\n\n        Returns:\n            New ChannelFrame containing the RMS trend\n        \"\"\"\n        # Access _channel_metadata to retrieve reference values\n        frame = cast(ProcessingFrameProtocol, self)\n\n        # Ensure _channel_metadata exists before referencing\n        ref_values = []\n        if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n            ref_values = [ch.ref for ch in frame._channel_metadata]\n\n        result = self.apply_operation(\n            \"rms_trend\",\n            frame_length=frame_length,\n            hop_length=hop_length,\n            ref=ref_values,\n            dB=dB,\n            Aw=Aw,\n        )\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def channel_difference(\n        self: T_Processing, other_channel: int | str = 0\n    ) -&gt; T_Processing:\n        \"\"\"Compute the difference between channels.\n\n        Args:\n            other_channel: Index or label of the reference channel. Default is 0.\n\n        Returns:\n            New ChannelFrame containing the channel difference\n        \"\"\"\n        # label2index is a method of BaseFrame\n        if isinstance(other_channel, str):\n            if hasattr(self, \"label2index\"):\n                other_channel = self.label2index(other_channel)\n\n        result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n        return cast(T_Processing, result)\n\n    def resampling(\n        self: T_Processing,\n        target_sr: float,\n        **kwargs: Any,\n    ) -&gt; T_Processing:\n        \"\"\"Resample audio data.\n\n        Args:\n            target_sr: Target sampling rate (Hz)\n            **kwargs: Additional resampling parameters\n\n        Returns:\n            Resampled ChannelFrame\n        \"\"\"\n        return cast(\n            T_Processing,\n            self.apply_operation(\n                \"resampling\",\n                target_sr=target_sr,\n                **kwargs,\n            ),\n        )\n\n    def hpss_harmonic(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract harmonic components using HPSS\n         (Harmonic-Percussive Source Separation).\n\n        This method separates the harmonic (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n            n_fft: Size of FFT window.\n            hop_length: Hop length for STFT.\n            win_length: Window length for STFT.\n            window: Window type for STFT.\n            center: If True, center the frames.\n            pad_mode: Padding mode for STFT.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_harmonic\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def hpss_percussive(\n        self: T_Processing,\n        kernel_size: Union[\n            \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n        ] = 31,\n        power: float = 2,\n        margin: Union[\n            \"_FloatLike_co\",\n            tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n            list[\"_FloatLike_co\"],\n        ] = 1,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: \"_WindowSpec\" = \"hann\",\n        center: bool = True,\n        pad_mode: \"_PadModeSTFT\" = \"constant\",\n    ) -&gt; T_Processing:\n        \"\"\"\n        Extract percussive components using HPSS\n        (Harmonic-Percussive Source Separation).\n\n        This method separates the percussive (tonal) components from the signal.\n\n        Args:\n            kernel_size: Median filter size for HPSS.\n            power: Exponent for the Weiner filter used in HPSS.\n            margin: Margin size for the separation.\n\n        Returns:\n            A new ChannelFrame containing the harmonic components.\n        \"\"\"\n        result = self.apply_operation(\n            \"hpss_percussive\",\n            kernel_size=kernel_size,\n            power=power,\n            margin=margin,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n        )\n        return cast(T_Processing, result)\n\n    def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n        \"\"\"\n        Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of non-stationary signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            New ChannelFrame containing time-varying loudness values in sones.\n            Each channel is processed independently.\n            The output sampling rate is adjusted based on the loudness\n            calculation time resolution (typically ~500 Hz for 2ms steps).\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate loudness for a signal:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n        Notes:\n            - The output contains time-varying loudness values in sones\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - The time resolution is approximately 2ms (determined by the algorithm)\n            - For multi-channel signals, loudness is calculated per channel\n            - The output sampling rate is updated to reflect the time resolution\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 2ms analysis step. This differs slightly from the MoSQITo\n            library, which uses the center time of each step. For example:\n\n            - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n            - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n            The difference is very small (~1ms) and does not affect the loudness\n            values themselves. This design choice ensures consistency with\n            wandas's time axis convention across all frame types.\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n        # Sampling rate update is handled by the Operation class\n        return cast(T_Processing, result)\n\n    def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n        \"\"\"\n        Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n        This method computes the loudness of stationary (steady) signals according to\n        the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n        calculated in sones, where a doubling of sones corresponds to a doubling\n        of perceived loudness.\n\n        This method is suitable for analyzing steady sounds such as fan noise,\n        constant machinery sounds, or other stationary signals.\n\n        Args:\n            field_type: Type of sound field. Options:\n                - 'free': Free field (sound from a specific direction)\n                - 'diffuse': Diffuse field (sound from all directions)\n                Default is 'free'.\n\n        Returns:\n            Loudness values in sones, one per channel. Shape: (n_channels,)\n\n        Raises:\n            ValueError: If field_type is not 'free' or 'diffuse'\n\n        Examples:\n            Calculate steady-state loudness for a fan noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n            &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n            Compare free field and diffuse field:\n            &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n            &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n            &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n            &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n        Notes:\n            - Returns a 1D array with one loudness value per channel\n            - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n            - For multi-channel signals, loudness is calculated independently\n              per channel\n            - This method is designed for stationary signals (constant sounds)\n            - For time-varying signals, use loudness_zwtv() instead\n            - Similar to the rms property, returns NDArrayReal for consistency\n\n        References:\n            ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n            Part 1: Zwicker method\"\n        \"\"\"\n        # Treat self as a ProcessingFrameProtocol so mypy understands\n        # where sampling_rate and data come from.\n        from wandas.processing.psychoacoustic import LoudnessZwst\n        from wandas.utils.types import NDArrayReal\n\n        # Create operation instance\n        operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n        # Get data (triggers computation if lazy)\n        data = self.data\n\n        # Ensure data is 2D (n_channels, n_samples)\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        # Process the array using the public API and materialize to NumPy\n        result = operation.process_array(data).compute()\n\n        # Squeeze to get 1D array (n_channels,)\n        loudness_values: NDArrayReal = result.squeeze()\n\n        # Ensure it's 1D even for single channel\n        if loudness_values.ndim == 0:\n            loudness_values = loudness_values.reshape(1)\n\n        return loudness_values\n\n    def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n        \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n        Roughness is a psychoacoustic metric that quantifies the perceived\n        harshness or roughness of a sound, measured in asper. This method\n        implements the Daniel &amp; Weber (1997) standard calculation.\n\n        The calculation follows the standard formula:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            New ChannelFrame containing time-varying roughness values in asper.\n            The output sampling rate depends on the overlap parameter.\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Calculate roughness for a motor noise:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n            &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n            &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n            Analyze roughness statistics:\n            &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n            &gt;&gt;&gt; max_roughness = roughness.data.max()\n            &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n            &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n            Compare before and after modification:\n            &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n            &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n            &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n            &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n        Notes:\n            - Returns a ChannelFrame with time-varying roughness values\n            - Typical roughness values: 0-2 asper for most sounds\n            - Higher values indicate rougher, harsher sounds\n            - For multi-channel signals, roughness is calculated independently\n              per channel\n            - This is the standard-compliant total roughness (R)\n            - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n            **Time axis convention:**\n            The time axis in the returned frame represents the start time of\n            each 200ms analysis window. This differs from the MoSQITo library,\n            which uses the center time of each window. For example:\n\n            - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n            - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n            The difference is constant (half the window duration = 100ms) and\n            does not affect the roughness values themselves. This design choice\n            ensures consistency with wandas's time axis convention across all\n            frame types.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n        logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n        result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n        return cast(T_Processing, result)\n\n    def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n        \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n        This method returns detailed roughness analysis data organized by\n        Bark frequency bands over time, allowing for frequency-specific\n        roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n        The relationship between total roughness and specific roughness:\n        R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n        Args:\n            overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n                - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n                - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n                Default is 0.5.\n\n        Returns:\n            RoughnessFrame containing:\n                - data: Specific roughness by Bark band, shape (47, n_time)\n                        for mono or (n_channels, 47, n_time) for multi-channel\n                - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n                - time: Time axis for each analysis frame\n                - overlap: Overlap coefficient used\n                - plot(): Method for Bark-Time heatmap visualization\n\n        Raises:\n            ValueError: If overlap is not in the range [0.0, 1.0]\n\n        Examples:\n            Analyze frequency-specific roughness:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n            &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Plot Bark-Time heatmap\n            &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Find dominant Bark band\n            &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n            &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n            &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Extract specific Bark band time series\n            &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n            &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Verify standard formula\n            &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n            &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n        Notes:\n            - Returns a RoughnessFrame (not ChannelFrame)\n            - Contains 47 Bark bands from 0.5 to 23.5 Bark\n            - Each Bark band corresponds to a critical band of hearing\n            - Useful for identifying which frequencies contribute most to roughness\n            - The specific roughness can be integrated to obtain total roughness\n            - For simple time-series analysis, use roughness_dw() instead\n\n            **Time axis convention:**\n            The time axis represents the start time of each 200ms analysis\n            window, consistent with roughness_dw() and other wandas methods.\n\n        References:\n            Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n            Implementation of an optimized model.\" Acustica, 83, 113-123.\n        \"\"\"\n\n        params = {\"overlap\": overlap}\n        operation_name = \"roughness_dw_spec\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance via factory\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing lazily to self._data (Dask)\n        r_spec_dask = operation.process(self._data)\n\n        # Get metadata updates (sampling rate, bark_axis)\n        metadata_updates = operation.get_metadata_updates()\n\n        # Build metadata and history\n        new_metadata = {**self.metadata, **params}\n        new_history = [\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ]\n\n        # Extract bark_axis with proper type handling\n        bark_axis_value = metadata_updates.get(\"bark_axis\")\n        if bark_axis_value is None:\n            raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n        # Create RoughnessFrame. operation.get_metadata_updates() should provide\n        # sampling_rate and bark_axis\n        roughness_frame = RoughnessFrame(\n            data=r_spec_dask,\n            sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n            bark_axis=bark_axis_value,\n            overlap=overlap,\n            label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=cast(\"BaseFrame[NDArrayReal]\", self),\n        )\n\n        logger.debug(\n            \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n            operation_name,\n            r_spec_dask.shape,\n            roughness_frame.sampling_rate,\n        )\n\n        return roughness_frame\n\n    def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n        \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n        This method applies a symmetric fade-in and fade-out envelope to the signal\n        using a Tukey (tapered cosine) window. The fade duration is the same for\n        both the beginning and end of the signal.\n\n        Args:\n            fade_ms: Fade duration in milliseconds for each end of the signal.\n                The total fade duration is 2 * fade_ms. Default is 50 ms.\n                Must be positive and less than half the signal duration.\n\n        Returns:\n            New ChannelFrame containing the faded signal\n\n        Raises:\n            ValueError: If fade_ms is negative or too long for the signal\n\n        Examples:\n            &gt;&gt;&gt; import wandas as wd\n            &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n            &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n            &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n            &gt;&gt;&gt; # Apply very short fade (almost no effect)\n            &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n        Notes:\n            - Uses SciPy's Tukey window for smooth fade transitions\n            - Fade is applied symmetrically to both ends of the signal\n            - The Tukey window alpha parameter is computed automatically\n              based on the fade duration and signal length\n            - For multi-channel signals, the same fade envelope is applied\n              to all channels\n            - Lazy evaluation is preserved - computation occurs only when needed\n        \"\"\"\n        logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n        result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n        return cast(T_Processing, result)\n</code></pre> Functions\u00b6 <code></code> <code>high_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a high-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def high_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a high-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>low_pass_filter(cutoff, order=4)</code> \u00b6 <p>Apply a low-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def low_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a low-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>band_pass_filter(low_cutoff, high_cutoff, order=4)</code> \u00b6 <p>Apply a band-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>low_cutoff</code> <code>float</code> <p>Lower cutoff frequency (Hz)</p> \u5fc5\u9808 <code>high_cutoff</code> <code>float</code> <p>Higher cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def band_pass_filter(\n    self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a band-pass filter to the signal.\n\n    Args:\n        low_cutoff: Lower cutoff frequency (Hz)\n        high_cutoff: Higher cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n        f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"bandpass_filter\",\n        low_cutoff=low_cutoff,\n        high_cutoff=high_cutoff,\n        order=order,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>normalize(norm=float('inf'), axis=-1, threshold=None, fill=None)</code> \u00b6 <p>Normalize signal levels using librosa.util.normalize.</p> <p>This method normalizes the signal amplitude according to the specified norm.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>norm</code> <code>float | None</code> <p>Norm type. Default is np.inf (maximum absolute value normalization). Supported values: - np.inf: Maximum absolute value normalization - -np.inf: Minimum absolute value normalization - 0: Peak normalization - float: Lp norm - None: No normalization</p> <code>float('inf')</code> <code>axis</code> <code>int | None</code> <p>Axis along which to normalize. Default is -1 (time axis). - -1: Normalize along time axis (each channel independently) - None: Global normalization across all axes - int: Normalize along specified axis</p> <code>-1</code> <code>threshold</code> <code>float | None</code> <p>Threshold below which values are considered zero. If None, no threshold is applied.</p> <code>None</code> <code>fill</code> <code>bool | None</code> <p>Value to fill when the norm is zero. If None, the zero vector remains zero.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the normalized signal</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n&gt;&gt;&gt; normalized = signal.normalize()\n&gt;&gt;&gt; # Global normalization across all channels\n&gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n&gt;&gt;&gt; # L2 normalization\n&gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def normalize(\n    self: T_Processing,\n    norm: float | None = float(\"inf\"),\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n) -&gt; T_Processing:\n    \"\"\"Normalize signal levels using librosa.util.normalize.\n\n    This method normalizes the signal amplitude according to the specified norm.\n\n    Args:\n        norm: Norm type. Default is np.inf (maximum absolute value normalization).\n            Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Peak normalization\n            - float: Lp norm\n            - None: No normalization\n        axis: Axis along which to normalize. Default is -1 (time axis).\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold: Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill: Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n    Returns:\n        New ChannelFrame containing the normalized signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n        &gt;&gt;&gt; normalized = signal.normalize()\n        &gt;&gt;&gt; # Global normalization across all channels\n        &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n        &gt;&gt;&gt; # L2 normalization\n        &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n    \"\"\"\n    logger.debug(\n        f\"Setting up normalize: norm={norm}, axis={axis}, \"\n        f\"threshold={threshold}, fill={fill} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>remove_dc()</code> \u00b6 <p>Remove DC component (DC offset) from the signal.</p> <p>This method removes the DC (direct current) component by subtracting the mean value from each channel. This is equivalent to centering the signal around zero.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame with DC component removed</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create signal with DC offset\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n&gt;&gt;&gt; # Remove DC offset\n&gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n&gt;&gt;&gt; # Verify DC removal\n&gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n</code></pre> Notes <ul> <li>This operation is performed per channel</li> <li>Equivalent to applying a high-pass filter with very low cutoff</li> <li>Useful for removing sensor drift or measurement offset</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def remove_dc(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This method removes the DC (direct current) component by subtracting\n    the mean value from each channel. This is equivalent to centering the\n    signal around zero.\n\n    Returns:\n        New ChannelFrame with DC component removed\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # Create signal with DC offset\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n        &gt;&gt;&gt; # Remove DC offset\n        &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n        &gt;&gt;&gt; # Verify DC removal\n        &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n    Notes:\n        - This operation is performed per channel\n        - Equivalent to applying a high-pass filter with very low cutoff\n        - Useful for removing sensor drift or measurement offset\n    \"\"\"\n    logger.debug(\"Setting up DC removal (lazy)\")\n    result = self.apply_operation(\"remove_dc\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>a_weighting()</code> \u00b6 <p>Apply A-weighting filter to the signal.</p> <p>A-weighting adjusts the frequency response to approximate human auditory perception, according to the IEC 61672-1:2013 standard.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the A-weighted signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def a_weighting(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Apply A-weighting filter to the signal.\n\n    A-weighting adjusts the frequency response to approximate human\n    auditory perception, according to the IEC 61672-1:2013 standard.\n\n    Returns:\n        New ChannelFrame containing the A-weighted signal\n    \"\"\"\n    result = self.apply_operation(\"a_weighting\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>abs()</code> \u00b6 <p>Compute the absolute value of the signal.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the absolute values</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def abs(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Compute the absolute value of the signal.\n\n    Returns:\n        New ChannelFrame containing the absolute values\n    \"\"\"\n    result = self.apply_operation(\"abs\")\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>power(exponent=2.0)</code> \u00b6 <p>Compute the power of the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>exponent</code> <code>float</code> <p>Exponent to raise the signal to. Default is 2.0.</p> <code>2.0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the powered signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n    \"\"\"Compute the power of the signal.\n\n    Args:\n        exponent: Exponent to raise the signal to. Default is 2.0.\n\n    Returns:\n        New ChannelFrame containing the powered signal\n    \"\"\"\n    result = self.apply_operation(\"power\", exponent=exponent)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>sum()</code> \u00b6 <p>Sum all channels.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame with summed signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def sum(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Sum all channels.\n\n    Returns:\n        A new ChannelFrame with summed signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n</code></pre> <code></code> <code>mean()</code> \u00b6 <p>Average all channels.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame with averaged signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def mean(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Average all channels.\n\n    Returns:\n        A new ChannelFrame with averaged signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n</code></pre> <code></code> <code>trim(start=0, end=None)</code> \u00b6 <p>Trim the signal to the specified time range.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>start</code> <code>float</code> <p>Start time (seconds)</p> <code>0</code> <code>end</code> <code>float | None</code> <p>End time (seconds)</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the trimmed signal</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If end time is earlier than start time</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def trim(\n    self: T_Processing,\n    start: float = 0,\n    end: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Trim the signal to the specified time range.\n\n    Args:\n        start: Start time (seconds)\n        end: End time (seconds)\n\n    Returns:\n        New ChannelFrame containing the trimmed signal\n\n    Raises:\n        ValueError: If end time is earlier than start time\n    \"\"\"\n    if end is None:\n        end = self.duration\n    if start &gt; end:\n        raise ValueError(\"start must be less than end\")\n    result = self.apply_operation(\"trim\", start=start, end=end)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>fix_length(length=None, duration=None)</code> \u00b6 <p>Adjust the signal to the specified length.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>duration</code> <code>float | None</code> <p>Signal length in seconds</p> <code>None</code> <code>length</code> <code>int | None</code> <p>Signal length in samples</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the adjusted signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fix_length(\n    self: T_Processing,\n    length: int | None = None,\n    duration: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Adjust the signal to the specified length.\n\n    Args:\n        duration: Signal length in seconds\n        length: Signal length in samples\n\n    Returns:\n        New ChannelFrame containing the adjusted signal\n    \"\"\"\n\n    result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>rms_trend(frame_length=2048, hop_length=512, dB=False, Aw=False)</code> \u00b6 <p>Compute the RMS trend of the signal.</p> <p>This method calculates the root mean square value over a sliding window.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame_length</code> <code>int</code> <p>Size of the sliding window in samples. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int</code> <p>Hop length between windows in samples. Default is 512.</p> <code>512</code> <code>dB</code> <code>bool</code> <p>Whether to return RMS values in decibels. Default is False.</p> <code>False</code> <code>Aw</code> <code>bool</code> <p>Whether to apply A-weighting. Default is False.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the RMS trend</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def rms_trend(\n    self: T_Processing,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; T_Processing:\n    \"\"\"Compute the RMS trend of the signal.\n\n    This method calculates the root mean square value over a sliding window.\n\n    Args:\n        frame_length: Size of the sliding window in samples. Default is 2048.\n        hop_length: Hop length between windows in samples. Default is 512.\n        dB: Whether to return RMS values in decibels. Default is False.\n        Aw: Whether to apply A-weighting. Default is False.\n\n    Returns:\n        New ChannelFrame containing the RMS trend\n    \"\"\"\n    # Access _channel_metadata to retrieve reference values\n    frame = cast(ProcessingFrameProtocol, self)\n\n    # Ensure _channel_metadata exists before referencing\n    ref_values = []\n    if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n        ref_values = [ch.ref for ch in frame._channel_metadata]\n\n    result = self.apply_operation(\n        \"rms_trend\",\n        frame_length=frame_length,\n        hop_length=hop_length,\n        ref=ref_values,\n        dB=dB,\n        Aw=Aw,\n    )\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>channel_difference(other_channel=0)</code> \u00b6 <p>Compute the difference between channels.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>other_channel</code> <code>int | str</code> <p>Index or label of the reference channel. Default is 0.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the channel difference</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def channel_difference(\n    self: T_Processing, other_channel: int | str = 0\n) -&gt; T_Processing:\n    \"\"\"Compute the difference between channels.\n\n    Args:\n        other_channel: Index or label of the reference channel. Default is 0.\n\n    Returns:\n        New ChannelFrame containing the channel difference\n    \"\"\"\n    # label2index is a method of BaseFrame\n    if isinstance(other_channel, str):\n        if hasattr(self, \"label2index\"):\n            other_channel = self.label2index(other_channel)\n\n    result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>resampling(target_sr, **kwargs)</code> \u00b6 <p>Resample audio data.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>target_sr</code> <code>float</code> <p>Target sampling rate (Hz)</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional resampling parameters</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>Resampled ChannelFrame</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def resampling(\n    self: T_Processing,\n    target_sr: float,\n    **kwargs: Any,\n) -&gt; T_Processing:\n    \"\"\"Resample audio data.\n\n    Args:\n        target_sr: Target sampling rate (Hz)\n        **kwargs: Additional resampling parameters\n\n    Returns:\n        Resampled ChannelFrame\n    \"\"\"\n    return cast(\n        T_Processing,\n        self.apply_operation(\n            \"resampling\",\n            target_sr=target_sr,\n            **kwargs,\n        ),\n    )\n</code></pre> <code></code> <code>hpss_harmonic(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract harmonic components using HPSS  (Harmonic-Percussive Source Separation).</p> <p>This method separates the harmonic (tonal) components from the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <code>n_fft</code> <code>int</code> <p>Size of FFT window.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Hop length for STFT.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length for STFT.</p> <code>None</code> <code>window</code> <code>_WindowSpec</code> <p>Window type for STFT.</p> <code>'hann'</code> <code>center</code> <code>bool</code> <p>If True, center the frames.</p> <code>True</code> <code>pad_mode</code> <code>_PadModeSTFT</code> <p>Padding mode for STFT.</p> <code>'constant'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_harmonic(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract harmonic components using HPSS\n     (Harmonic-Percussive Source Separation).\n\n    This method separates the harmonic (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n        n_fft: Size of FFT window.\n        hop_length: Hop length for STFT.\n        win_length: Window length for STFT.\n        window: Window type for STFT.\n        center: If True, center the frames.\n        pad_mode: Padding mode for STFT.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_harmonic\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>hpss_percussive(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code> \u00b6 <p>Extract percussive components using HPSS (Harmonic-Percussive Source Separation).</p> <p>This method separates the percussive (tonal) components from the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_percussive(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract percussive components using HPSS\n    (Harmonic-Percussive Source Separation).\n\n    This method separates the percussive (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_percussive\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwtv(field_type='free')</code> \u00b6 <p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing time-varying loudness values in sones.</p> <code>T_Processing</code> <p>Each channel is processed independently.</p> <code>T_Processing</code> <p>The output sampling rate is adjusted based on the loudness</p> <code>T_Processing</code> <p>calculation time resolution (typically ~500 Hz for 2ms steps).</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>\u4f8b\uff1a</p> <p>Calculate loudness for a signal:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre> Notes <ul> <li>The output contains time-varying loudness values in sones</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>The time resolution is approximately 2ms (determined by the algorithm)</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The output sampling rate is updated to reflect the time resolution</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 2ms analysis step. This differs slightly from the MoSQITo library, which uses the center time of each step. For example:</p> <ul> <li>wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)</li> <li>MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)</li> </ul> <p>The difference is very small (~1ms) and does not affect the loudness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        New ChannelFrame containing time-varying loudness values in sones.\n        Each channel is processed independently.\n        The output sampling rate is adjusted based on the loudness\n        calculation time resolution (typically ~500 Hz for 2ms steps).\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate loudness for a signal:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n    Notes:\n        - The output contains time-varying loudness values in sones\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - The time resolution is approximately 2ms (determined by the algorithm)\n        - For multi-channel signals, loudness is calculated per channel\n        - The output sampling rate is updated to reflect the time resolution\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 2ms analysis step. This differs slightly from the MoSQITo\n        library, which uses the center time of each step. For example:\n\n        - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n        - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n        The difference is very small (~1ms) and does not affect the loudness\n        values themselves. This design choice ensures consistency with\n        wandas's time axis convention across all frame types.\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>loudness_zwst(field_type='free')</code> \u00b6 <p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>This method is suitable for analyzing steady sounds such as fan noise, constant machinery sounds, or other stationary signals.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Loudness values in sones, one per channel. Shape: (n_channels,)</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>\u4f8b\uff1a</p> <p>Calculate steady-state loudness for a fan noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n&gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre> Notes <ul> <li>Returns a 1D array with one loudness value per channel</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>For multi-channel signals, loudness is calculated independently   per channel</li> <li>This method is designed for stationary signals (constant sounds)</li> <li>For time-varying signals, use loudness_zwtv() instead</li> <li>Similar to the rms property, returns NDArrayReal for consistency</li> </ul> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    This method is suitable for analyzing steady sounds such as fan noise,\n    constant machinery sounds, or other stationary signals.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        Loudness values in sones, one per channel. Shape: (n_channels,)\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate steady-state loudness for a fan noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n        &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n    Notes:\n        - Returns a 1D array with one loudness value per channel\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - For multi-channel signals, loudness is calculated independently\n          per channel\n        - This method is designed for stationary signals (constant sounds)\n        - For time-varying signals, use loudness_zwtv() instead\n        - Similar to the rms property, returns NDArrayReal for consistency\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    # Treat self as a ProcessingFrameProtocol so mypy understands\n    # where sampling_rate and data come from.\n    from wandas.processing.psychoacoustic import LoudnessZwst\n    from wandas.utils.types import NDArrayReal\n\n    # Create operation instance\n    operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n    # Get data (triggers computation if lazy)\n    data = self.data\n\n    # Ensure data is 2D (n_channels, n_samples)\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    # Process the array using the public API and materialize to NumPy\n    result = operation.process_array(data).compute()\n\n    # Squeeze to get 1D array (n_channels,)\n    loudness_values: NDArrayReal = result.squeeze()\n\n    # Ensure it's 1D even for single channel\n    if loudness_values.ndim == 0:\n        loudness_values = loudness_values.reshape(1)\n\n    return loudness_values\n</code></pre> <code></code> <code>roughness_dw(overlap=0.5)</code> \u00b6 <p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound, measured in asper. This method implements the Daniel &amp; Weber (1997) standard calculation.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing time-varying roughness values in asper.</p> <code>T_Processing</code> <p>The output sampling rate depends on the overlap parameter.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>\u4f8b\uff1a</p> <p>Calculate roughness for a motor noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n&gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n&gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n</code></pre> <p>Analyze roughness statistics:</p> <pre><code>&gt;&gt;&gt; mean_roughness = roughness.data.mean()\n&gt;&gt;&gt; max_roughness = roughness.data.max()\n&gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n&gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n</code></pre> <p>Compare before and after modification:</p> <pre><code>&gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n&gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n&gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n&gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n</code></pre> Notes <ul> <li>Returns a ChannelFrame with time-varying roughness values</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher values indicate rougher, harsher sounds</li> <li>For multi-channel signals, roughness is calculated independently   per channel</li> <li>This is the standard-compliant total roughness (R)</li> <li>For detailed Bark-band analysis, use roughness_dw_spec() instead</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 200ms analysis window. This differs from the MoSQITo library, which uses the center time of each window. For example:</p> <ul> <li>wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)</li> <li>MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)</li> </ul> <p>The difference is constant (half the window duration = 100ms) and does not affect the roughness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n    \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound, measured in asper. This method\n    implements the Daniel &amp; Weber (1997) standard calculation.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        New ChannelFrame containing time-varying roughness values in asper.\n        The output sampling rate depends on the overlap parameter.\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Calculate roughness for a motor noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n        &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n        &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n        Analyze roughness statistics:\n        &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n        &gt;&gt;&gt; max_roughness = roughness.data.max()\n        &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n        &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n        Compare before and after modification:\n        &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n        &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n        &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n        &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n    Notes:\n        - Returns a ChannelFrame with time-varying roughness values\n        - Typical roughness values: 0-2 asper for most sounds\n        - Higher values indicate rougher, harsher sounds\n        - For multi-channel signals, roughness is calculated independently\n          per channel\n        - This is the standard-compliant total roughness (R)\n        - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 200ms analysis window. This differs from the MoSQITo library,\n        which uses the center time of each window. For example:\n\n        - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n        - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n        The difference is constant (half the window duration = 100ms) and\n        does not affect the roughness values themselves. This design choice\n        ensures consistency with wandas's time axis convention across all\n        frame types.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n    logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n    result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n    return cast(T_Processing, result)\n</code></pre> <code></code> <code>roughness_dw_spec(overlap=0.5)</code> \u00b6 <p>Calculate specific roughness with Bark-band frequency information.</p> <p>This method returns detailed roughness analysis data organized by Bark frequency bands over time, allowing for frequency-specific roughness analysis. It uses the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>RoughnessFrame</code> <p>RoughnessFrame containing: - data: Specific roughness by Bark band, shape (47, n_time)         for mono or (n_channels, 47, n_time) for multi-channel - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5) - time: Time axis for each analysis frame - overlap: Overlap coefficient used - plot(): Method for Bark-Time heatmap visualization</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>\u4f8b\uff1a</p> <p>Analyze frequency-specific roughness:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n&gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot Bark-Time heatmap\n&gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find dominant Bark band\n&gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n&gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n&gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Extract specific Bark band time series\n&gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n&gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify standard formula\n&gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n&gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n</code></pre> Notes <ul> <li>Returns a RoughnessFrame (not ChannelFrame)</li> <li>Contains 47 Bark bands from 0.5 to 23.5 Bark</li> <li>Each Bark band corresponds to a critical band of hearing</li> <li>Useful for identifying which frequencies contribute most to roughness</li> <li>The specific roughness can be integrated to obtain total roughness</li> <li>For simple time-series analysis, use roughness_dw() instead</li> </ul> <p>Time axis convention: The time axis represents the start time of each 200ms analysis window, consistent with roughness_dw() and other wandas methods.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n    \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n    This method returns detailed roughness analysis data organized by\n    Bark frequency bands over time, allowing for frequency-specific\n    roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n    The relationship between total roughness and specific roughness:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        RoughnessFrame containing:\n            - data: Specific roughness by Bark band, shape (47, n_time)\n                    for mono or (n_channels, 47, n_time) for multi-channel\n            - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n            - time: Time axis for each analysis frame\n            - overlap: Overlap coefficient used\n            - plot(): Method for Bark-Time heatmap visualization\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Analyze frequency-specific roughness:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot Bark-Time heatmap\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Find dominant Bark band\n        &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n        &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n        &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Extract specific Bark band time series\n        &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n        &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verify standard formula\n        &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n        &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n    Notes:\n        - Returns a RoughnessFrame (not ChannelFrame)\n        - Contains 47 Bark bands from 0.5 to 23.5 Bark\n        - Each Bark band corresponds to a critical band of hearing\n        - Useful for identifying which frequencies contribute most to roughness\n        - The specific roughness can be integrated to obtain total roughness\n        - For simple time-series analysis, use roughness_dw() instead\n\n        **Time axis convention:**\n        The time axis represents the start time of each 200ms analysis\n        window, consistent with roughness_dw() and other wandas methods.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n\n    params = {\"overlap\": overlap}\n    operation_name = \"roughness_dw_spec\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance via factory\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n\n    # Apply processing lazily to self._data (Dask)\n    r_spec_dask = operation.process(self._data)\n\n    # Get metadata updates (sampling rate, bark_axis)\n    metadata_updates = operation.get_metadata_updates()\n\n    # Build metadata and history\n    new_metadata = {**self.metadata, **params}\n    new_history = [\n        *self.operation_history,\n        {\"operation\": operation_name, \"params\": params},\n    ]\n\n    # Extract bark_axis with proper type handling\n    bark_axis_value = metadata_updates.get(\"bark_axis\")\n    if bark_axis_value is None:\n        raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n    # Create RoughnessFrame. operation.get_metadata_updates() should provide\n    # sampling_rate and bark_axis\n    roughness_frame = RoughnessFrame(\n        data=r_spec_dask,\n        sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n        bark_axis=bark_axis_value,\n        overlap=overlap,\n        label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=cast(\"BaseFrame[NDArrayReal]\", self),\n    )\n\n    logger.debug(\n        \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n        operation_name,\n        r_spec_dask.shape,\n        roughness_frame.sampling_rate,\n    )\n\n    return roughness_frame\n</code></pre> <code></code> <code>fade(fade_ms=50)</code> \u00b6 <p>Apply symmetric fade-in and fade-out to the signal using Tukey window.</p> <p>This method applies a symmetric fade-in and fade-out envelope to the signal using a Tukey (tapered cosine) window. The fade duration is the same for both the beginning and end of the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>fade_ms</code> <code>float</code> <p>Fade duration in milliseconds for each end of the signal. The total fade duration is 2 * fade_ms. Default is 50 ms. Must be positive and less than half the signal duration.</p> <code>50</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the faded signal</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If fade_ms is negative or too long for the signal</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n&gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n&gt;&gt;&gt; # Apply very short fade (almost no effect)\n&gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n</code></pre> Notes <ul> <li>Uses SciPy's Tukey window for smooth fade transitions</li> <li>Fade is applied symmetrically to both ends of the signal</li> <li>The Tukey window alpha parameter is computed automatically   based on the fade duration and signal length</li> <li>For multi-channel signals, the same fade envelope is applied   to all channels</li> <li>Lazy evaluation is preserved - computation occurs only when needed</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n    \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n    This method applies a symmetric fade-in and fade-out envelope to the signal\n    using a Tukey (tapered cosine) window. The fade duration is the same for\n    both the beginning and end of the signal.\n\n    Args:\n        fade_ms: Fade duration in milliseconds for each end of the signal.\n            The total fade duration is 2 * fade_ms. Default is 50 ms.\n            Must be positive and less than half the signal duration.\n\n    Returns:\n        New ChannelFrame containing the faded signal\n\n    Raises:\n        ValueError: If fade_ms is negative or too long for the signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n        &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n        &gt;&gt;&gt; # Apply very short fade (almost no effect)\n        &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n    Notes:\n        - Uses SciPy's Tukey window for smooth fade transitions\n        - Fade is applied symmetrically to both ends of the signal\n        - The Tukey window alpha parameter is computed automatically\n          based on the fade duration and signal length\n        - For multi-channel signals, the same fade envelope is applied\n          to all channels\n        - Lazy evaluation is preserved - computation occurs only when needed\n    \"\"\"\n    logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n    result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n    return cast(T_Processing, result)\n</code></pre> Functions\u00b6"},{"location":"en/api/#wandas.frames.mixins.channel_transform_mixin","title":"<code>channel_transform_mixin</code>","text":"<p>Module providing mixins related to frequency transformations and transform operations.</p> Attributes\u00b6 <code>logger = logging.getLogger(__name__)</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>ChannelTransformMixin</code> \u00b6 <p>Mixin providing methods related to frequency transformations.</p> <p>This mixin provides operations related to frequency analysis and transformations such as FFT, STFT, and Welch method.</p> Source code in <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>class ChannelTransformMixin:\n    \"\"\"Mixin providing methods related to frequency transformations.\n\n    This mixin provides operations related to frequency analysis and\n    transformations such as FFT, STFT, and Welch method.\n    \"\"\"\n\n    def fft(\n        self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate Fast Fourier Transform (FFT).\n\n        Args:\n            n_fft: Number of FFT points. Default is the next power of 2 of the data\n                length.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectralFrame containing FFT results\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import FFT, create_operation\n\n        params = {\"n_fft\": n_fft, \"window\": window}\n        operation_name = \"fft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"FFT\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        if n_fft is None:\n            is_even = spectrum_data.shape[-1] % 2 == 0\n            _n_fft = (\n                spectrum_data.shape[-1] * 2 - 2\n                if is_even\n                else spectrum_data.shape[-1] * 2 - 1\n            )\n        else:\n            _n_fft = n_fft\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=_n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def welch(\n        self: T_Transform,\n        n_fft: int | None = None,\n        hop_length: int | None = None,\n        win_length: int = 2048,\n        window: str = \"hann\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate power spectral density using Welch's method.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing power spectral density\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import Welch, create_operation\n\n        params = dict(\n            n_fft=n_fft or win_length,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            average=average,\n        )\n        operation_name = \"welch\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Welch\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return SpectralFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Spectrum of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": \"welch\", \"params\": params},\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def noct_spectrum(\n        self: T_Transform,\n        fmin: float = 25,\n        fmax: float = 20000,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; \"NOctFrame\":\n        \"\"\"Calculate N-octave band spectrum.\n\n        Args:\n            fmin: Minimum center frequency (Hz). Default is 25 Hz.\n            fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n            n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n            G: Reference gain (dB). Default is 10 dB.\n            fr: Reference frequency (Hz). Default is 1000 Hz.\n\n        Returns:\n            NOctFrame containing N-octave band spectrum\n        \"\"\"\n        from wandas.processing import NOctSpectrum, create_operation\n\n        from ..noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_spectrum\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSpectrum\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_spectrum\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def stft(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Calculate Short-Time Fourier Transform.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n\n        Returns:\n            SpectrogramFrame containing STFT results\n        \"\"\"\n        from wandas.processing import STFT, create_operation\n\n        from ..spectrogram import SpectrogramFrame\n\n        # Set hop length and window length\n        _hop_length = hop_length if hop_length is not None else n_fft // 4\n        _win_length = win_length if win_length is not None else n_fft\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": _hop_length,\n            \"win_length\": _win_length,\n            \"window\": window,\n        }\n        operation_name = \"stft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"STFT\", operation)\n\n        # Apply processing to data\n        spectrogram_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new instance\n        return SpectrogramFrame(\n            data=spectrogram_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=n_fft,\n            hop_length=_hop_length,\n            win_length=_win_length,\n            window=window,\n            label=f\"stft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=base_self,\n        )\n\n    def coherence(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate magnitude squared coherence.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n        Returns:\n            SpectralFrame containing magnitude squared coherence\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.processing import Coherence, create_operation\n\n        from ..spectral import SpectralFrame\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n        }\n        operation_name = \"coherence\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"Coherence\", operation)\n\n        # Apply processing to data\n        coherence_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=coherence_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Coherence of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def csd(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate cross-spectral density matrix.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing cross-spectral density matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import CSD, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"csd\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"CSD\", operation)\n\n        # Apply processing to data\n        csd_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=csd_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n\n    def transfer_function(\n        self: T_Transform,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ) -&gt; \"SpectralFrame\":\n        \"\"\"Calculate transfer function matrix.\n\n        The transfer function represents the signal transfer characteristics between\n        channels in the frequency domain and represents the input-output relationship\n        of the system.\n\n        Args:\n            n_fft: Number of FFT points. Default is 2048.\n            hop_length: Number of samples between frames.\n                Default is n_fft//4.\n            win_length: Window length. Default is n_fft.\n            window: Window type. Default is \"hann\".\n            detrend: Detrend method. Options: \"constant\", \"linear\", None.\n            scaling: Scaling method. Options: \"spectrum\", \"density\".\n            average: Method for averaging segments. Default is \"mean\".\n\n        Returns:\n            SpectralFrame containing transfer function matrix\n        \"\"\"\n        from wandas.core.metadata import ChannelMetadata\n        from wandas.frames.spectral import SpectralFrame\n        from wandas.processing import TransferFunction, create_operation\n\n        params = {\n            \"n_fft\": n_fft,\n            \"hop_length\": hop_length,\n            \"win_length\": win_length,\n            \"window\": window,\n            \"detrend\": detrend,\n            \"scaling\": scaling,\n            \"average\": average,\n        }\n        operation_name = \"transfer_function\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"TransferFunction\", operation)\n\n        # Apply processing to data\n        tf_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Cast self as BaseFrame type\n        base_self = cast(BaseFrame[Any], self)\n\n        # Create new channel metadata\n        channel_metadata = []\n        for in_ch in self._channel_metadata:\n            for out_ch in self._channel_metadata:\n                meta = ChannelMetadata()\n                meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n                meta.unit = \"\"\n                meta.ref = 1\n                meta[\"metadata\"] = dict(\n                    in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n                )\n                channel_metadata.append(meta)\n\n        # Create new instance\n        return SpectralFrame(\n            data=tf_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=operation.n_fft,\n            window=operation.window,\n            label=f\"Transfer function of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\"operation\": operation_name, \"params\": params},\n            ],\n            channel_metadata=channel_metadata,\n            previous=base_self,\n        )\n</code></pre> Functions\u00b6 <code></code> <code>fft(n_fft=None, window='hann')</code> \u00b6 <p>Calculate Fast Fourier Transform (FFT).</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is the next power of 2 of the data length.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing FFT results</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def fft(\n    self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate Fast Fourier Transform (FFT).\n\n    Args:\n        n_fft: Number of FFT points. Default is the next power of 2 of the data\n            length.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectralFrame containing FFT results\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import FFT, create_operation\n\n    params = {\"n_fft\": n_fft, \"window\": window}\n    operation_name = \"fft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"FFT\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    if n_fft is None:\n        is_even = spectrum_data.shape[-1] % 2 == 0\n        _n_fft = (\n            spectrum_data.shape[-1] * 2 - 2\n            if is_even\n            else spectrum_data.shape[-1] * 2 - 1\n        )\n    else:\n        _n_fft = n_fft\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=_n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>welch(n_fft=None, hop_length=None, win_length=2048, window='hann', average='mean')</code> \u00b6 <p>Calculate power spectral density using Welch's method.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is 2048.</p> <code>None</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int</code> <p>Window length. Default is n_fft.</p> <code>2048</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing power spectral density</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def welch(\n    self: T_Transform,\n    n_fft: int | None = None,\n    hop_length: int | None = None,\n    win_length: int = 2048,\n    window: str = \"hann\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate power spectral density using Welch's method.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing power spectral density\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import Welch, create_operation\n\n    params = dict(\n        n_fft=n_fft or win_length,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        average=average,\n    )\n    operation_name = \"welch\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Welch\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"welch\", \"params\": params},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>noct_spectrum(fmin=25, fmax=20000, n=3, G=10, fr=1000)</code> \u00b6 <p>Calculate N-octave band spectrum.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>fmin</code> <code>float</code> <p>Minimum center frequency (Hz). Default is 25 Hz.</p> <code>25</code> <code>fmax</code> <code>float</code> <p>Maximum center frequency (Hz). Default is 20000 Hz.</p> <code>20000</code> <code>n</code> <code>int</code> <p>Band division (1: octave, 3: 1/3 octave). Default is 3.</p> <code>3</code> <code>G</code> <code>int</code> <p>Reference gain (dB). Default is 10 dB.</p> <code>10</code> <code>fr</code> <code>int</code> <p>Reference frequency (Hz). Default is 1000 Hz.</p> <code>1000</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NOctFrame</code> <p>NOctFrame containing N-octave band spectrum</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def noct_spectrum(\n    self: T_Transform,\n    fmin: float = 25,\n    fmax: float = 20000,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; \"NOctFrame\":\n    \"\"\"Calculate N-octave band spectrum.\n\n    Args:\n        fmin: Minimum center frequency (Hz). Default is 25 Hz.\n        fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n        n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n        G: Reference gain (dB). Default is 10 dB.\n        fr: Reference frequency (Hz). Default is 1000 Hz.\n\n    Returns:\n        NOctFrame containing N-octave band spectrum\n    \"\"\"\n    from wandas.processing import NOctSpectrum, create_operation\n\n    from ..noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_spectrum\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSpectrum\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_spectrum\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Calculate Short-Time Fourier Transform.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectrogramFrame</code> <p>SpectrogramFrame containing STFT results</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def stft(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Calculate Short-Time Fourier Transform.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectrogramFrame containing STFT results\n    \"\"\"\n    from wandas.processing import STFT, create_operation\n\n    from ..spectrogram import SpectrogramFrame\n\n    # Set hop length and window length\n    _hop_length = hop_length if hop_length is not None else n_fft // 4\n    _win_length = win_length if win_length is not None else n_fft\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": _hop_length,\n        \"win_length\": _win_length,\n        \"window\": window,\n    }\n    operation_name = \"stft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"STFT\", operation)\n\n    # Apply processing to data\n    spectrogram_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new instance\n    return SpectrogramFrame(\n        data=spectrogram_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=n_fft,\n        hop_length=_hop_length,\n        win_length=_win_length,\n        window=window,\n        label=f\"stft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>coherence(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code> \u00b6 <p>Calculate magnitude squared coherence.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing magnitude squared coherence</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def coherence(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate magnitude squared coherence.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n    Returns:\n        SpectralFrame containing magnitude squared coherence\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.processing import Coherence, create_operation\n\n    from ..spectral import SpectralFrame\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n    }\n    operation_name = \"coherence\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Coherence\", operation)\n\n    # Apply processing to data\n    coherence_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=coherence_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Coherence of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>csd(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate cross-spectral density matrix.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing cross-spectral density matrix</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def csd(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate cross-spectral density matrix.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing cross-spectral density matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import CSD, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"csd\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"CSD\", operation)\n\n    # Apply processing to data\n    csd_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=csd_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre> <code></code> <code>transfer_function(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Calculate transfer function matrix.</p> <p>The transfer function represents the signal transfer characteristics between channels in the frequency domain and represents the input-output relationship of the system.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing transfer function matrix</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def transfer_function(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate transfer function matrix.\n\n    The transfer function represents the signal transfer characteristics between\n    channels in the frequency domain and represents the input-output relationship\n    of the system.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing transfer function matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import TransferFunction, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"transfer_function\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"TransferFunction\", operation)\n\n    # Apply processing to data\n    tf_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=tf_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Transfer function of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.mixins.protocols","title":"<code>protocols</code>","text":"<p>Common protocol definition module.</p> <p>This module contains common protocols used by mixin classes.</p> Attributes\u00b6 <code>logger = logging.getLogger(__name__)</code> <code>module-attribute</code> \u00b6 <code></code> <code>T_Base = TypeVar('T_Base', bound='BaseFrameProtocol')</code> <code>module-attribute</code> \u00b6 <code></code> <code>T_Processing = TypeVar('T_Processing', bound=ProcessingFrameProtocol)</code> <code>module-attribute</code> \u00b6 <code></code> <code>T_Transform = TypeVar('T_Transform', bound=TransformFrameProtocol)</code> <code>module-attribute</code> \u00b6 <code></code> <code>__all__ = ['BaseFrameProtocol', 'ProcessingFrameProtocol', 'TransformFrameProtocol', 'T_Processing']</code> <code>module-attribute</code> \u00b6 Classes\u00b6 <code></code> <code>BaseFrameProtocol</code> \u00b6 <p>               Bases: <code>Protocol</code></p> <p>Protocol that defines basic frame operations.</p> <p>Defines the basic methods and properties provided by all frame classes.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>@runtime_checkable\nclass BaseFrameProtocol(Protocol):\n    \"\"\"Protocol that defines basic frame operations.\n\n    Defines the basic methods and properties provided by all frame classes.\n    \"\"\"\n\n    _data: DaArray\n    sampling_rate: float\n    _channel_metadata: list[ChannelMetadata]\n    metadata: dict[str, Any]\n    operation_history: list[dict[str, Any]]\n    label: str\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Returns the duration in seconds.\"\"\"\n        ...\n\n    @property\n    def data(self) -&gt; NDArrayReal:\n        \"\"\"Returns the computed data as a NumPy array.\n\n        Implementations should materialize any lazy computation (e.g. Dask)\n        and return a concrete NumPy array.\n        \"\"\"\n        ...\n\n    def label2index(self, label: str) -&gt; int:\n        \"\"\"\n        Get the index from a channel label.\n        \"\"\"\n        ...\n\n    def apply_operation(\n        self, operation_name: str, **params: Any\n    ) -&gt; \"BaseFrameProtocol\":\n        \"\"\"Apply a named operation.\n\n        Args:\n            operation_name: Name of the operation to apply\n            **params: Parameters to pass to the operation\n\n        Returns:\n            A new frame instance with the operation applied\n        \"\"\"\n        ...\n\n    def _create_new_instance(self: T_Base, data: DaArray, **kwargs: Any) -&gt; T_Base:\n        \"\"\"Create a new instance of the frame with updated data and metadata.\n        Args:\n            data: The new data for the frame\n            metadata: The new metadata for the frame\n            operation_history: The new operation history for the frame\n            channel_metadata: The new channel metadata for the frame\n        Returns:\n            A new instance of the frame with the updated data and metadata\n        \"\"\"\n        ...\n</code></pre> Attributes\u00b6 <code></code> <code>sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>metadata</code> <code>instance-attribute</code> \u00b6 <code></code> <code>operation_history</code> <code>instance-attribute</code> \u00b6 <code></code> <code>label</code> <code>instance-attribute</code> \u00b6 <code></code> <code>duration</code> <code>property</code> \u00b6 <p>Returns the duration in seconds.</p> <code></code> <code>data</code> <code>property</code> \u00b6 <p>Returns the computed data as a NumPy array.</p> <p>Implementations should materialize any lazy computation (e.g. Dask) and return a concrete NumPy array.</p> Functions\u00b6 <code></code> <code>label2index(label)</code> \u00b6 <p>Get the index from a channel label.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/protocols.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n    \"\"\"\n    ...\n</code></pre> <code></code> <code>apply_operation(operation_name, **params)</code> \u00b6 <p>Apply a named operation.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>operation_name</code> <code>str</code> <p>Name of the operation to apply</p> \u5fc5\u9808 <code>**params</code> <code>Any</code> <p>Parameters to pass to the operation</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>BaseFrameProtocol</code> <p>A new frame instance with the operation applied</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/protocols.py</code> <pre><code>def apply_operation(\n    self, operation_name: str, **params: Any\n) -&gt; \"BaseFrameProtocol\":\n    \"\"\"Apply a named operation.\n\n    Args:\n        operation_name: Name of the operation to apply\n        **params: Parameters to pass to the operation\n\n    Returns:\n        A new frame instance with the operation applied\n    \"\"\"\n    ...\n</code></pre> <code></code> <code>ProcessingFrameProtocol</code> \u00b6 <p>               Bases: <code>BaseFrameProtocol</code>, <code>Protocol</code></p> <p>Protocol that defines operations related to signal processing.</p> <p>Defines methods that provide frame operations related to signal processing.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>@runtime_checkable\nclass ProcessingFrameProtocol(BaseFrameProtocol, Protocol):\n    \"\"\"Protocol that defines operations related to signal processing.\n\n    Defines methods that provide frame operations related to signal processing.\n    \"\"\"\n\n    pass\n</code></pre> <code></code> <code>TransformFrameProtocol</code> \u00b6 <p>               Bases: <code>BaseFrameProtocol</code>, <code>Protocol</code></p> <p>Protocol related to transform operations.</p> <p>Defines methods that provide operations such as frequency analysis and spectral transformation.</p> Source code in <code>wandas/frames/mixins/protocols.py</code> <pre><code>@runtime_checkable\nclass TransformFrameProtocol(BaseFrameProtocol, Protocol):\n    \"\"\"Protocol related to transform operations.\n\n    Defines methods that provide operations such as frequency analysis and\n    spectral transformation.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"en/api/#wandas.frames.noct.NOctFrame--notes","title":"Notes","text":"<ul> <li>Binary operations (addition, multiplication, etc.) are not currently   supported for N-octave band data.</li> <li>The actual frequency bands are determined by the parameters n, G, and fr   according to IEC 61260-1:2014 standard for fractional octave band filters.</li> <li>The class follows acoustic standards for band definitions and analysis,   making it suitable for noise measurements and sound level analysis.</li> <li>A-weighting is available for better correlation with human hearing   perception, following IEC 61672-1:2013.</li> </ul> Source code in <code>wandas/frames/noct.py</code> <pre><code>class NOctFrame(BaseFrame[NDArrayReal]):\n    \"\"\"\n    Class for handling N-octave band analysis data.\n\n    This class represents frequency data analyzed in fractional octave bands,\n    typically used in acoustic and vibration analysis. It handles real-valued\n    data representing energy or power in each frequency band, following standard\n    acoustical band definitions.\n\n    Parameters\n    ----------\n    data : DaArray\n        The N-octave band data. Must be a dask array with shape:\n        - (channels, frequency_bins) for multi-channel data\n        - (frequency_bins,) for single-channel data, which will be\n          reshaped to (1, frequency_bins)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    fmin : float, default=0\n        Lower frequency bound in Hz.\n    fmax : float, default=0\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number according to IEC 61260-1:2014.\n    fr : int, default=1000\n        Reference frequency in Hz, typically 1000 Hz for acoustic analysis.\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    freqs : NDArrayReal\n        The center frequencies of each band in Hz, calculated according to\n        the standard fractional octave band definitions.\n    dB : NDArrayReal\n        The spectrum in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrum in decibels, applying frequency weighting\n        for better correlation with perceived loudness.\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int\n        Number of bands per octave.\n    G : int\n        Reference band number.\n    fr : int\n        Reference frequency in Hz.\n\n    Examples\n    --------\n    Create an N-octave band spectrum from a time-domain signal:\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrum = signal.noct_spectrum(fmin=20, fmax=20000, n=3)\n\n    Plot the N-octave band spectrum:\n    &gt;&gt;&gt; spectrum.plot()\n\n    Plot with A-weighting applied:\n    &gt;&gt;&gt; spectrum.plot(Aw=True)\n\n    Notes\n    -----\n    - Binary operations (addition, multiplication, etc.) are not currently\n      supported for N-octave band data.\n    - The actual frequency bands are determined by the parameters n, G, and fr\n      according to IEC 61260-1:2014 standard for fractional octave band filters.\n    - The class follows acoustic standards for band definitions and analysis,\n      making it suitable for noise measurements and sound level analysis.\n    - A-weighting is available for better correlation with human hearing\n      perception, following IEC 61672-1:2013.\n    \"\"\"\n\n    fmin: float\n    fmax: float\n    n: int\n    G: int\n    fr: int\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        fmin: float = 0,\n        fmax: float = 0,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a NOctFrame instance.\n\n        Sets up N-octave band analysis parameters and prepares the frame for\n        storing band-filtered data. Data shape is validated to ensure compatibility\n        with N-octave band analysis.\n\n        See class docstring for parameter descriptions.\n        \"\"\"\n        self.n = n\n        self.G = G\n        self.fr = fr\n        self.fmin = fmin\n        self.fmax = fmax\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrum in decibels relative to each channel's reference value.\n\n        The reference value for each channel is specified in its metadata.\n        A minimum value of -120 dB is enforced to avoid numerical issues.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrum in decibels. Shape matches the input data shape:\n            (channels, frequency_bins).\n        \"\"\"\n        # Collect dB reference values from _channel_metadata\n        ref = np.array([ch.ref for ch in self._channel_metadata])\n        # Convert to dB\n        # Use either the maximum value or 1e-12 to avoid division by zero\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(self.data / ref[..., np.newaxis], 1e-12)\n        )\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrum in decibels.\n\n        A-weighting applies a frequency-dependent weighting filter that approximates\n        the human ear's response to different frequencies. This is particularly useful\n        for analyzing noise and acoustic measurements as it provides a better\n        correlation with perceived loudness.\n\n        The weighting is applied according to IEC 61672-1:2013 standard.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrum in decibels. Shape matches the input data shape:\n            (channels, frequency_bins).\n        \"\"\"\n        # Collect dB reference values from _channel_metadata\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels in the N-octave band data.\n        \"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the center frequencies of each band in Hz.\n\n        These frequencies are calculated based on the N-octave band parameters\n        (n, G, fr) and the frequency bounds (fmin, fmax) according to\n        IEC 61260-1:2014 standard for fractional octave band filters.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of center frequencies for each frequency band.\n\n        Raises\n        ------\n        ValueError\n            If the center frequencies cannot be calculated or the result\n            is not a numpy array.\n        \"\"\"\n        _, freqs = _center_freq(\n            fmax=self.fmax,\n            fmin=self.fmin,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if isinstance(freqs, np.ndarray):\n            return freqs\n        else:\n            raise ValueError(\"freqs is not numpy array.\")\n\n    def _binary_op(\n        self: S,\n        other: S | int | float | NDArrayReal | DaArray,\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; S:\n        \"\"\"\n        Binary operations are not currently supported for N-octave band data.\n\n        Parameters\n        ----------\n        other : Union[S, int, float, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation.\n        symbol : str\n            String representation of the operation (e.g., '+', '-', '*', '/').\n\n        Raises\n        ------\n        NotImplementedError\n            Always raises this error as operations are not implemented\n            for N-octave band data.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Operation {symbol} is not implemented for NOctFrame.\"\n        )\n        return self\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Apply operations using lazy evaluation.\n        \"\"\"\n        # Apply operations using lazy evaluation\n        raise NotImplementedError(\n            f\"Operation {operation_name} is not implemented for NOctFrame.\"\n        )\n        return self\n\n    def plot(\n        self,\n        plot_type: str = \"noct\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the N-octave band data using various visualization strategies.\n\n        Supports standard plotting configurations for acoustic analysis,\n        including decibel scales and A-weighting.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"noct\"\n            Type of plot to create. The default \"noct\" type creates a step plot\n            suitable for displaying N-octave band data.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses a default title with band specification.\n        overlay : bool, default=False\n            Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel : str, optional\n            Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n        ylabel : str, optional\n            Label for the y-axis. If None, uses default based on data type.\n        alpha : float, default=1.0\n            Transparency level for the plot lines (0.0 to 1.0).\n        xlim : tuple[float, float], optional\n            Limits for the x-axis as (min, max) tuple.\n        ylim : tuple[float, float], optional\n            Limits for the y-axis as (min, max) tuple.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the data.\n        **kwargs : dict\n            Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; noct = spectrum.noct(n=3)\n        &gt;&gt;&gt; # Basic 1/3-octave plot\n        &gt;&gt;&gt; noct.plot()\n        &gt;&gt;&gt; # Overlay with A-weighting\n        &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get additional initialization arguments for NOctFrame.\n\n        This internal method provides the additional initialization arguments\n        required by NOctFrame beyond those required by BaseFrame. These include\n        the N-octave band analysis parameters that define the frequency bands.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments specific to NOctFrame:\n            - n: Number of bands per octave\n            - G: Reference band number\n            - fr: Reference frequency\n            - fmin: Lower frequency bound\n            - fmax: Upper frequency bound\n        \"\"\"\n        return {\n            \"n\": self.n,\n            \"G\": self.G,\n            \"fr\": self.fr,\n            \"fmin\": self.fmin,\n            \"fmax\": self.fmax,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"Get frequency index for DataFrame.\"\"\"\n        return pd.Index(self.freqs, name=\"frequency\")\n</code></pre> Attributes\u00b6 <code></code> <code>n = n</code> <code>instance-attribute</code> \u00b6 <code></code> <code>G = G</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fr = fr</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmin = fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax = fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>dB</code> <code>property</code> \u00b6 <p>Get the spectrum in decibels relative to each channel's reference value.</p> <p>The reference value for each channel is specified in its metadata. A minimum value of -120 dB is enforced to avoid numerical issues.</p> <code></code> <code>dBA</code> <code>property</code> \u00b6 <p>Get the A-weighted spectrum in decibels.</p> <p>A-weighting applies a frequency-dependent weighting filter that approximates the human ear's response to different frequencies. This is particularly useful for analyzing noise and acoustic measurements as it provides a better correlation with perceived loudness.</p> <p>The weighting is applied according to IEC 61672-1:2013 standard.</p> <code></code> <code>freqs</code> <code>property</code> \u00b6 <p>Get the center frequencies of each band in Hz.</p> <p>These frequencies are calculated based on the N-octave band parameters (n, G, fr) and the frequency bounds (fmin, fmax) according to IEC 61260-1:2014 standard for fractional octave band filters.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, fmin=0, fmax=0, n=3, G=10, fr=1000, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 <p>Initialize a NOctFrame instance.</p> <p>Sets up N-octave band analysis parameters and prepares the frame for storing band-filtered data. Data shape is validated to ensure compatibility with N-octave band analysis.</p> <p>See class docstring for parameter descriptions.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/noct.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    fmin: float = 0,\n    fmax: float = 0,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a NOctFrame instance.\n\n    Sets up N-octave band analysis parameters and prepares the frame for\n    storing band-filtered data. Data shape is validated to ensure compatibility\n    with N-octave band analysis.\n\n    See class docstring for parameter descriptions.\n    \"\"\"\n    self.n = n\n    self.G = G\n    self.fr = fr\n    self.fmin = fmin\n    self.fmax = fmax\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>plot(plot_type='noct', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, Aw=False, **kwargs)</code> \u00b6 <p>Plot the N-octave band data using various visualization strategies.</p> <p>Supports standard plotting configurations for acoustic analysis, including decibel scales and A-weighting.</p>"},{"location":"en/api/#wandas.frames.noct.NOctFrame.plot--examples","title":"Examples","text":"<p>noct = spectrum.noct(n=3)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/noct.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"noct\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the N-octave band data using various visualization strategies.\n\n    Supports standard plotting configurations for acoustic analysis,\n    including decibel scales and A-weighting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"noct\"\n        Type of plot to create. The default \"noct\" type creates a step plot\n        suitable for displaying N-octave band data.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses a default title with band specification.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; noct = spectrum.noct(n=3)\n    &gt;&gt;&gt; # Basic 1/3-octave plot\n    &gt;&gt;&gt; noct.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/#wandas.frames.roughness.RoughnessFrame--references","title":"References","text":"<p>.. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:        Implementation of an optimized model\". Acta Acustica united with        Acustica, 83(1), 113-123.</p> Source code in <code>wandas/frames/roughness.py</code> <pre><code>class RoughnessFrame(BaseFrame[NDArrayReal]):\n    \"\"\"\n    Frame for detailed roughness analysis with Bark-band information.\n\n    This frame contains specific roughness (R_spec) data organized by\n    Bark frequency bands over time, calculated using the Daniel &amp; Weber (1997)\n    method.\n\n    The relationship between total roughness and specific roughness follows:\n    R = 0.25 * sum(R_spec, axis=bark_bands)\n\n    Parameters\n    ----------\n    data : da.Array\n        Specific roughness data with shape:\n        - (n_bark_bands, n_time) for mono signals\n        - (n_channels, n_bark_bands, n_time) for multi-channel signals\n        where n_bark_bands is always 47.\n    sampling_rate : float\n        Sampling rate of the roughness time series in Hz.\n        For overlap=0.5, this is approximately 10 Hz (100ms hop).\n        For overlap=0.0, this is approximately 5 Hz (200ms hop).\n    bark_axis : NDArrayReal\n        Bark frequency axis with 47 values from 0.5 to 23.5 Bark.\n    overlap : float\n        Overlap coefficient used in the calculation (0.0 to 1.0).\n    label : str, optional\n        Frame label. Defaults to \"roughness_spec\".\n    metadata : dict, optional\n        Additional metadata.\n    operation_history : list[dict], optional\n        History of operations applied to this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel.\n    previous : BaseFrame, optional\n        Reference to the previous frame in the processing chain.\n\n    Attributes\n    ----------\n    bark_axis : NDArrayReal\n        Frequency axis in Bark scale.\n    n_bark_bands : int\n        Number of Bark bands (always 47).\n    n_time_points : int\n        Number of time points.\n    time : NDArrayReal\n        Time axis based on sampling rate.\n    overlap : float\n        Overlap coefficient used (0.0 to 1.0).\n\n    Examples\n    --------\n    Create a roughness frame from a signal:\n\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Plot Bark-Time heatmap\n    &gt;&gt;&gt; roughness_spec.plot()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Find dominant Bark band\n    &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n    &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n    &gt;&gt;&gt; print(f\"Dominant frequency: {dominant_bark:.1f} Bark\")\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Extract specific Bark band\n    &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n    &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n\n    Notes\n    -----\n    The Daniel &amp; Weber (1997) roughness model calculates specific roughness\n    for 47 critical bands (Bark scale) over time, then integrates them to\n    produce the total roughness:\n\n    .. math::\n        R = 0.25 \\\\sum_{i=1}^{47} R'_i\n\n    where R'_i is the specific roughness in the i-th Bark band.\n\n    References\n    ----------\n    .. [1] Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n           Implementation of an optimized model\". Acta Acustica united with\n           Acustica, 83(1), 113-123.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: da.Array,\n        sampling_rate: float,\n        bark_axis: NDArrayReal,\n        overlap: float,\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a RoughnessFrame.\"\"\"\n        # Validate dimensions\n        if data.ndim not in (2, 3):\n            raise ValueError(\n                f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n            )\n\n        # Validate Bark bands\n        if data.shape[-2] != 47:\n            raise ValueError(\n                f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n                f\"(data shape: {data.shape})\"\n            )\n\n        if len(bark_axis) != 47:\n            raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n        # Validate overlap\n        if not 0.0 &lt;= overlap &lt;= 1.0:\n            raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n        # Store Bark-specific attributes\n        self._bark_axis = bark_axis\n        self._overlap = overlap\n\n        # Initialize base frame\n        metadata = metadata or {}\n        metadata[\"overlap\"] = overlap\n\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label or \"roughness_spec\",\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def data(self) -&gt; NDArrayReal:\n        \"\"\"\n        Returns the computed data without squeezing.\n\n        For RoughnessFrame, even mono signals have 2D shape (47, n_time)\n        so we don't squeeze the channel dimension.\n\n        Returns\n        -------\n        NDArrayReal\n            Computed data array.\n        \"\"\"\n        return self.compute()\n\n    @property\n    def bark_axis(self) -&gt; NDArrayReal:\n        \"\"\"\n        Bark frequency axis.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of 47 Bark values from 0.5 to 23.5 Bark.\n        \"\"\"\n        return self._bark_axis\n\n    @property\n    def n_bark_bands(self) -&gt; int:\n        \"\"\"\n        Number of Bark bands.\n\n        Returns\n        -------\n        int\n            Always 47 for the Daniel &amp; Weber model.\n        \"\"\"\n        return 47\n\n    @property\n    def n_time_points(self) -&gt; int:\n        \"\"\"\n        Number of time points in the roughness time series.\n\n        Returns\n        -------\n        int\n            Number of time frames in the analysis.\n        \"\"\"\n        return int(self._data.shape[-1])\n\n    @property\n    def time(self) -&gt; NDArrayReal:\n        \"\"\"\n        Time axis based on sampling rate.\n\n        Returns\n        -------\n        NDArrayReal\n            Time values in seconds for each frame.\n        \"\"\"\n        return np.arange(self.n_time_points) / self.sampling_rate\n\n    @property\n    def overlap(self) -&gt; float:\n        \"\"\"\n        Overlap coefficient used in the calculation.\n\n        Returns\n        -------\n        float\n            Overlap value between 0.0 and 1.0.\n        \"\"\"\n        return self._overlap\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Return the number of channels.\n\n        Returns\n        -------\n        int\n            Number of channels. For 2D data (mono), returns 1.\n        \"\"\"\n        if self._data.ndim == 2:\n            return 1\n        return int(self._data.shape[0])\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Provide additional initialization arguments for RoughnessFrame.\n\n        Returns\n        -------\n        dict\n            Dictionary containing bark_axis and overlap\n        \"\"\"\n        return {\n            \"bark_axis\": self._bark_axis,\n            \"overlap\": self._overlap,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"DataFrame index is not supported for RoughnessFrame.\"\"\"\n        raise NotImplementedError(\n            \"DataFrame index is not supported for RoughnessFrame.\"\n        )\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n        RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n        which cannot be directly converted to a 2D DataFrame.\n\n        Raises\n        ------\n        NotImplementedError\n            Always raised as DataFrame conversion is not supported.\n        \"\"\"\n        raise NotImplementedError(\n            \"DataFrame conversion is not supported for RoughnessFrame.\"\n        )\n\n    def _binary_op(\n        self,\n        other: Union[\"RoughnessFrame\", int, float, NDArrayReal, da.Array],\n        op: \"Callable[[da.Array, Any], da.Array]\",\n        symbol: str,\n    ) -&gt; \"RoughnessFrame\":\n        \"\"\"\n        Common implementation for binary operations.\n\n        Parameters\n        ----------\n        other : RoughnessFrame, int, float, NDArrayReal, or da.Array\n            Right operand for the operation.\n        op : Callable\n            Function to execute the operation.\n        symbol : str\n            Symbolic representation of the operation.\n\n        Returns\n        -------\n        RoughnessFrame\n            A new RoughnessFrame with the operation result.\n\n        Raises\n        ------\n        ValueError\n            If sampling rates don't match or shapes are incompatible.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle metadata and operation_history\n        metadata = self.metadata.copy() if self.metadata else {}\n        operation_history = (\n            self.operation_history.copy() if self.operation_history else []\n        )\n\n        # Check if other is a RoughnessFrame\n        if isinstance(other, RoughnessFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    f\"Sampling rates do not match: {self.sampling_rate} vs \"\n                    f\"{other.sampling_rate}\"\n                )\n\n            if self._data.shape != other._data.shape:\n                raise ValueError(\n                    f\"Shape mismatch: {self._data.shape} vs {other._data.shape}\"\n                )\n\n            # Apply operation\n            result_data = op(self._data, other._data)\n\n            # Update operation history\n            operation_history.append(\n                {\"name\": f\"binary_op_{symbol}\", \"params\": {\"other\": \"RoughnessFrame\"}}\n            )\n\n        else:\n            # Scalar or array operation\n            if isinstance(other, np.ndarray):\n                other = da.from_array(other, chunks=self._data.chunks)\n\n            result_data = op(self._data, other)\n\n            operation_history.append(\n                {\"name\": f\"binary_op_{symbol}\", \"params\": {\"other\": str(type(other))}}\n            )\n\n        # Create new instance\n        return RoughnessFrame(\n            data=result_data,\n            sampling_rate=self.sampling_rate,\n            bark_axis=self._bark_axis,\n            overlap=self._overlap,\n            label=self.label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def _apply_operation_impl(\n        self, operation_name: str, **params: Any\n    ) -&gt; \"RoughnessFrame\":\n        \"\"\"\n        Implementation of operation application.\n\n        Note: RoughnessFrame is typically a terminal node in processing chains.\n        Most operations are not directly applicable to spectral roughness data.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Operation parameters.\n\n        Returns\n        -------\n        RoughnessFrame\n            A new RoughnessFrame with the operation applied.\n\n        Raises\n        ------\n        NotImplementedError\n            As most operations are not applicable to roughness spectrograms.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Operation '{operation_name}' is not supported for RoughnessFrame. \"\n            \"RoughnessFrame is typically a terminal node in the processing chain.\"\n        )\n\n    def plot(\n        self,\n        plot_type: str = \"heatmap\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        cmap: str = \"viridis\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        xlabel: str = \"Time [s]\",\n        ylabel: str = \"Frequency [Bark]\",\n        colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n        **kwargs: Any,\n    ) -&gt; \"Axes\":\n        \"\"\"\n        Plot Bark-Time-Roughness heatmap.\n\n        For multi-channel signals, the mean across channels is plotted.\n\n        Parameters\n        ----------\n        ax : Axes, optional\n            Matplotlib axes to plot on. If None, a new figure is created.\n        title : str, optional\n            Plot title. If None, a default title is used.\n        cmap : str, default=\"viridis\"\n            Colormap name for the heatmap.\n        vmin, vmax : float, optional\n            Color scale limits. If None, automatic scaling is used.\n        xlabel : str, default=\"Time [s]\"\n            Label for the x-axis.\n        ylabel : str, default=\"Frequency [Bark]\"\n            Label for the y-axis.\n        colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n            Label for the colorbar.\n        **kwargs : Any\n            Additional keyword arguments passed to pcolormesh.\n\n        Returns\n        -------\n        Axes\n            The matplotlib axes object containing the plot.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 6))\n\n        # Select data to plot (first channel for mono, mean for multi-channel)\n        # self._data is Dask array, self.data is computed NumPy array\n        computed_data = self.compute()\n\n        if computed_data.ndim == 2:\n            # Mono: (47, n_time)\n            data_to_plot = computed_data\n        else:\n            # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n            data_to_plot = computed_data.mean(axis=0)\n\n        # Create heatmap\n        im = ax.pcolormesh(\n            self.time,\n            self.bark_axis,\n            data_to_plot,\n            shading=\"auto\",\n            cmap=cmap,\n            vmin=vmin,\n            vmax=vmax,\n            **kwargs,\n        )\n\n        # Labels and title\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        if title is None:\n            title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n        ax.set_title(title)\n\n        # Colorbar\n        plt.colorbar(im, ax=ax, label=colorbar_label)\n\n        return ax\n</code></pre> Attributes\u00b6 <code></code> <code>data</code> <code>property</code> \u00b6 <p>Returns the computed data without squeezing.</p> <p>For RoughnessFrame, even mono signals have 2D shape (47, n_time) so we don't squeeze the channel dimension.</p> <code></code> <code>bark_axis</code> <code>property</code> \u00b6 <p>Bark frequency axis.</p> <code></code> <code>n_bark_bands</code> <code>property</code> \u00b6 <p>Number of Bark bands.</p> <code></code> <code>n_time_points</code> <code>property</code> \u00b6 <p>Number of time points in the roughness time series.</p> <code></code> <code>time</code> <code>property</code> \u00b6 <p>Time axis based on sampling rate.</p> <code></code> <code>overlap</code> <code>property</code> \u00b6 <p>Overlap coefficient used in the calculation.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, bark_axis, overlap, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 <p>Initialize a RoughnessFrame.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/roughness.py</code> <pre><code>def __init__(\n    self,\n    data: da.Array,\n    sampling_rate: float,\n    bark_axis: NDArrayReal,\n    overlap: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a RoughnessFrame.\"\"\"\n    # Validate dimensions\n    if data.ndim not in (2, 3):\n        raise ValueError(\n            f\"Data must be 2D or 3D (mono or multi-channel), got {data.ndim}D\"\n        )\n\n    # Validate Bark bands\n    if data.shape[-2] != 47:\n        raise ValueError(\n            f\"Expected 47 Bark bands, got {data.shape[-2]} \"\n            f\"(data shape: {data.shape})\"\n        )\n\n    if len(bark_axis) != 47:\n        raise ValueError(f\"bark_axis must have 47 elements, got {len(bark_axis)}\")\n\n    # Validate overlap\n    if not 0.0 &lt;= overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {overlap}\")\n\n    # Store Bark-specific attributes\n    self._bark_axis = bark_axis\n    self._overlap = overlap\n\n    # Initialize base frame\n    metadata = metadata or {}\n    metadata[\"overlap\"] = overlap\n\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label or \"roughness_spec\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>to_dataframe()</code> \u00b6 <p>DataFrame conversion is not supported for RoughnessFrame.</p> <p>RoughnessFrame contains 3D data (channels, bark_bands, time_frames) which cannot be directly converted to a 2D DataFrame.</p> <code></code> <code>plot(plot_type='heatmap', ax=None, title=None, cmap='viridis', vmin=None, vmax=None, xlabel='Time [s]', ylabel='Frequency [Bark]', colorbar_label='Specific Roughness [Asper/Bark]', **kwargs)</code> \u00b6 <p>Plot Bark-Time-Roughness heatmap.</p> <p>For multi-channel signals, the mean across channels is plotted.</p>"},{"location":"en/api/#wandas.frames.roughness.RoughnessFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/roughness.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for RoughnessFrame.\n\n    RoughnessFrame contains 3D data (channels, bark_bands, time_frames)\n    which cannot be directly converted to a 2D DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for RoughnessFrame.\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.roughness.RoughnessFrame.plot--examples","title":"Examples","text":"<p>import wandas as wd signal = wd.read_wav(\"motor.wav\") roughness_spec = signal.roughness_dw_spec(overlap=0.5) roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/roughness.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"heatmap\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"viridis\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlabel: str = \"Time [s]\",\n    ylabel: str = \"Frequency [Bark]\",\n    colorbar_label: str = \"Specific Roughness [Asper/Bark]\",\n    **kwargs: Any,\n) -&gt; \"Axes\":\n    \"\"\"\n    Plot Bark-Time-Roughness heatmap.\n\n    For multi-channel signals, the mean across channels is plotted.\n\n    Parameters\n    ----------\n    ax : Axes, optional\n        Matplotlib axes to plot on. If None, a new figure is created.\n    title : str, optional\n        Plot title. If None, a default title is used.\n    cmap : str, default=\"viridis\"\n        Colormap name for the heatmap.\n    vmin, vmax : float, optional\n        Color scale limits. If None, automatic scaling is used.\n    xlabel : str, default=\"Time [s]\"\n        Label for the x-axis.\n    ylabel : str, default=\"Frequency [Bark]\"\n        Label for the y-axis.\n    colorbar_label : str, default=\"Specific Roughness [Asper/Bark]\"\n        Label for the colorbar.\n    **kwargs : Any\n        Additional keyword arguments passed to pcolormesh.\n\n    Returns\n    -------\n    Axes\n        The matplotlib axes object containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n    &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n    &gt;&gt;&gt; roughness_spec.plot(cmap=\"hot\", title=\"Motor Roughness Analysis\")\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=(10, 6))\n\n    # Select data to plot (first channel for mono, mean for multi-channel)\n    # self._data is Dask array, self.data is computed NumPy array\n    computed_data = self.compute()\n\n    if computed_data.ndim == 2:\n        # Mono: (47, n_time)\n        data_to_plot = computed_data\n    else:\n        # Multi-channel: (n_channels, 47, n_time) -&gt; average to (47, n_time)\n        data_to_plot = computed_data.mean(axis=0)\n\n    # Create heatmap\n    im = ax.pcolormesh(\n        self.time,\n        self.bark_axis,\n        data_to_plot,\n        shading=\"auto\",\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n        **kwargs,\n    )\n\n    # Labels and title\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    if title is None:\n        title = f\"Roughness Spectrogram (overlap={self._overlap})\"\n    ax.set_title(title)\n\n    # Colorbar\n    plt.colorbar(im, ax=ax, label=colorbar_label)\n\n    return ax\n</code></pre>"},{"location":"en/api/#wandas.frames.spectral.SpectralFrame--notes","title":"Notes","text":"<ul> <li>All operations are performed lazily using dask arrays for efficient memory usage.</li> <li>Binary operations (+, -, *, /) can be performed between SpectralFrames or with   scalar values.</li> <li>The class maintains the processing history and metadata through all operations.</li> </ul> Source code in <code>wandas/frames/spectral.py</code> <pre><code>class SpectralFrame(BaseFrame[NDArrayComplex]):\n    \"\"\"\n    Class for handling frequency-domain signal data.\n\n    This class represents spectral data, providing methods for spectral analysis,\n    manipulation, and visualization. It handles complex-valued frequency domain data\n    obtained through operations like FFT.\n\n    Parameters\n    ----------\n    data : DaArray\n        The spectral data. Must be a dask array with shape:\n        - (channels, frequency_bins) for multi-channel data\n        - (frequency_bins,) for single-channel data, which will be\n          reshaped to (1, frequency_bins)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    n_fft : int\n        The FFT size used to generate this spectral data.\n    window : str, default=\"hann\"\n        The window function used in the FFT.\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    magnitude : NDArrayReal\n        The magnitude spectrum of the data.\n    phase : NDArrayReal\n        The phase spectrum in radians.\n    unwrapped_phase : NDArrayReal\n        The unwrapped phase spectrum in radians.\n    power : NDArrayReal\n        The power spectrum (magnitude squared).\n    dB : NDArrayReal\n        The spectrum in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrum in decibels.\n    freqs : NDArrayReal\n        The frequency axis values in Hz.\n\n    Examples\n    --------\n    Create a SpectralFrame from FFT:\n    &gt;&gt;&gt; signal = ChannelFrame.from_numpy(data, sampling_rate=44100)\n    &gt;&gt;&gt; spectrum = signal.fft(n_fft=2048)\n\n    Plot the magnitude spectrum:\n    &gt;&gt;&gt; spectrum.plot()\n\n    Perform binary operations:\n    &gt;&gt;&gt; scaled = spectrum * 2.0\n    &gt;&gt;&gt; summed = spectrum1 + spectrum2  # Must have matching sampling rates\n\n    Convert back to time domain:\n    &gt;&gt;&gt; time_signal = spectrum.ifft()\n\n    Notes\n    -----\n    - All operations are performed lazily using dask arrays for efficient memory usage.\n    - Binary operations (+, -, *, /) can be performed between SpectralFrames or with\n      scalar values.\n    - The class maintains the processing history and metadata through all operations.\n    \"\"\"\n\n    n_fft: int\n    window: str\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        n_fft: int,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: BaseFrame[Any] | None = None,\n    ) -&gt; None:\n        if data.ndim == 1:\n            data = data.reshape(1, -1)\n        elif data.ndim &gt; 2:\n            raise ValueError(\n                f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n            )\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def magnitude(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the magnitude spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The absolute values of the complex spectrum.\n        \"\"\"\n        return np.abs(self.data)\n\n    @property\n    def phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the phase spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The phase angles of the complex spectrum in radians.\n        \"\"\"\n        return np.angle(self.data)\n\n    @property\n    def unwrapped_phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the unwrapped phase spectrum.\n\n        The unwrapped phase removes discontinuities of 2\u03c0 radians, providing\n        continuous phase values across frequency bins.\n\n        Returns\n        -------\n        NDArrayReal\n            The unwrapped phase angles of the complex spectrum in radians.\n        \"\"\"\n        return np.unwrap(np.angle(self.data))\n\n    @property\n    def power(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the power spectrum.\n\n        Returns\n        -------\n        NDArrayReal\n            The squared magnitude spectrum.\n        \"\"\"\n        return self.magnitude**2\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrum in decibels.\n\n        The reference values are taken from channel metadata. If no reference\n        is specified, uses 1.0.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrum in dB relative to channel references.\n        \"\"\"\n        mag: NDArrayReal = self.magnitude\n        ref_values: NDArrayReal = np.array([ch.ref for ch in self._channel_metadata])\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(mag / ref_values[:, np.newaxis], 1e-12)\n        )\n\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrum in decibels.\n\n        Applies A-weighting filter to the spectrum for better correlation with\n        perceived loudness.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrum in dB.\n        \"\"\"\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels.\n        \"\"\"\n        return int(self._data.shape[-2])\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the frequency axis values in Hz.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of frequency values corresponding to each frequency bin.\n        \"\"\"\n        return np.fft.rfftfreq(self.n_fft, 1.0 / self.sampling_rate)\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Implementation of operation application for spectral data.\n\n        This internal method handles the application of various operations to\n        spectral data, maintaining lazy evaluation through dask.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters for the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n\n        # Apply processing to data\n        processed_data = operation.process(self._data)\n\n        # Update metadata\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n        return self._create_new_instance(\n            data=processed_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n        )\n\n    def _binary_op(\n        self,\n        other: (\n            SpectralFrame\n            | int\n            | float\n            | complex\n            | NDArrayComplex\n            | NDArrayReal\n            | DaArray\n        ),\n        op: Callable[[DaArray, Any], DaArray],\n        symbol: str,\n    ) -&gt; SpectralFrame:\n        \"\"\"\n        Common implementation for binary operations.\n\n        This method handles binary operations between SpectralFrames and various types\n        of operands, maintaining lazy evaluation through dask arrays.\n\n        Parameters\n        ----------\n        other : Union[SpectralFrame, int, float, complex,\n                        NDArrayComplex, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation (e.g., lambda a, b: a + b)\n        symbol : str\n            String representation of the operation (e.g., '+')\n\n        Returns\n        -------\n        SpectralFrame\n            A new SpectralFrame containing the result of the operation.\n\n        Raises\n        ------\n        ValueError\n            If attempting to operate with a SpectralFrame\n            with a different sampling rate.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        # Handle potentially None metadata and operation_history\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        # Check if other is a ChannelFrame - improved type checking\n        if isinstance(other, SpectralFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"Sampling rates do not match. Cannot perform operation.\"\n                )\n\n            # Directly operate on dask arrays (maintaining lazy execution)\n            result_data = op(self._data, other._data)\n\n            # Combine channel metadata\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return SpectralFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n\n        # Operation with scalar, NumPy array, or other types\n        else:\n            # Apply operation directly to dask array (maintaining lazy execution)\n            result_data = op(self._data, other)\n\n            # String representation of operand for display\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, complex):\n                other_str = f\"complex({other.real}, {other.imag})\"\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):  # Check for dask.array.Array\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            # Update channel metadata\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return SpectralFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n            )\n\n    def plot(\n        self,\n        plot_type: str = \"frequency\",\n        ax: Axes | None = None,\n        title: str | None = None,\n        overlay: bool = False,\n        xlabel: str | None = None,\n        ylabel: str | None = None,\n        alpha: float = 1.0,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"\n        Plot the spectral data using various visualization strategies.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"frequency\"\n            Type of plot to create. Options include:\n            - \"frequency\": Standard frequency plot\n            - \"matrix\": Matrix plot for comparing channels\n            - Other types as defined by available plot strategies\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses the frame label.\n        overlay : bool, default=False\n            Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel : str, optional\n            Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n        ylabel : str, optional\n            Label for the y-axis. If None, uses default based on data type.\n        alpha : float, default=1.0\n            Transparency level for the plot lines (0.0 to 1.0).\n        xlim : tuple[float, float], optional\n            Limits for the x-axis as (min, max) tuple.\n        ylim : tuple[float, float], optional\n            Limits for the y-axis as (min, max) tuple.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the data.\n        **kwargs : dict\n            Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; spectrum = cf.fft()\n        &gt;&gt;&gt; # Basic frequency plot\n        &gt;&gt;&gt; spectrum.plot()\n        &gt;&gt;&gt; # Overlay with A-weighting\n        &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"overlay\": overlay,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlabel is not None:\n            plot_kwargs[\"xlabel\"] = xlabel\n        if ylabel is not None:\n            plot_kwargs[\"ylabel\"] = ylabel\n        if alpha != 1.0:\n            plot_kwargs[\"alpha\"] = alpha\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def ifft(self) -&gt; ChannelFrame:\n        \"\"\"\n        Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n        This method transforms the frequency-domain data back to the time domain using\n        the inverse FFT operation. The window function used in the forward FFT is\n        taken into account to ensure proper reconstruction.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the time-domain signal.\n        \"\"\"\n        from ..processing import IFFT, create_operation\n        from .channel import ChannelFrame\n\n        params = {\"n_fft\": self.n_fft, \"window\": self.window}\n        operation_name = \"ifft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"IFFT\", operation)\n        # Apply processing to data\n        time_series = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        # Create new instance\n        return ChannelFrame(\n            data=time_series,\n            sampling_rate=self.sampling_rate,\n            label=f\"ifft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Provide additional initialization arguments required for SpectralFrame.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments for SpectralFrame.\n        \"\"\"\n        return {\n            \"n_fft\": self.n_fft,\n            \"window\": self.window,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; pd.Index[Any]:\n        \"\"\"Get frequency index for DataFrame.\"\"\"\n        return pd.Index(self.freqs, name=\"frequency\")\n\n    def noct_synthesis(\n        self,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ) -&gt; NOctFrame:\n        \"\"\"\n        Synthesize N-octave band spectrum.\n\n        This method combines frequency components into N-octave bands according to\n        standard acoustical band definitions. This is commonly used in noise and\n        vibration analysis.\n\n        Parameters\n        ----------\n        fmin : float\n            Lower frequency bound in Hz.\n        fmax : float\n            Upper frequency bound in Hz.\n        n : int, default=3\n            Number of bands per octave (e.g., 3 for third-octave bands).\n        G : int, default=10\n            Reference band number.\n        fr : int, default=1000\n            Reference frequency in Hz.\n\n        Returns\n        -------\n        NOctFrame\n            A new NOctFrame containing the N-octave band spectrum.\n\n        Raises\n        ------\n        ValueError\n            If the sampling rate is not 48000 Hz, which is required for this operation.\n        \"\"\"\n        if self.sampling_rate != 48000:\n            raise ValueError(\n                \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n            )\n        from ..processing import NOctSynthesis\n        from .noct import NOctFrame\n\n        params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n        operation_name = \"noct_synthesis\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from ..processing import create_operation\n\n        # Create operation instance\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"NOctSynthesis\", operation)\n        # Apply processing to data\n        spectrum_data = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n        )\n\n        return NOctFrame(\n            data=spectrum_data,\n            sampling_rate=self.sampling_rate,\n            fmin=fmin,\n            fmax=fmax,\n            n=n,\n            G=G,\n            fr=fr,\n            label=f\"1/{n}Oct of {self.label}\",\n            metadata={**self.metadata, **params},\n            operation_history=[\n                *self.operation_history,\n                {\n                    \"operation\": \"noct_synthesis\",\n                    \"params\": params,\n                },\n            ],\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def plot_matrix(\n        self,\n        plot_type: str = \"matrix\",\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"\n        Plot channel relationships in matrix format.\n\n        This method creates a matrix plot showing relationships between channels,\n        such as coherence, transfer functions, or cross-spectral density.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"matrix\"\n            Type of matrix plot to create.\n        **kwargs : dict\n            Additional plot parameters:\n            - vmin, vmax: Color scale limits\n            - cmap: Colormap name\n            - title: Plot title\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot.\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # Get plot strategy\n        plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n        # Execute plot\n        _ax = plot_strategy.plot(self, **kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the SpectralFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - FFT size\n        - Frequency range\n        - Number of frequency bins\n        - Frequency resolution (\u0394F)\n        - Channel labels\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; spectrum = cf.fft()\n        &gt;&gt;&gt; spectrum.info()\n        SpectralFrame Information:\n          Channels: 2\n          Sampling rate: 44100 Hz\n          FFT size: 2048\n          Frequency range: 0.0 - 22050.0 Hz\n          Frequency bins: 1025\n          Frequency resolution (\u0394F): 21.5 Hz\n          Channel labels: ['ch0', 'ch1']\n          Operations Applied: 1\n        \"\"\"\n        # Calculate frequency resolution (\u0394F)\n        delta_f = self.sampling_rate / self.n_fft\n\n        print(\"SpectralFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  FFT size: {self.n_fft}\")\n        print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n        print(f\"  Frequency bins: {len(self.freqs)}\")\n        print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n</code></pre> Attributes\u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>magnitude</code> <code>property</code> \u00b6 <p>Get the magnitude spectrum.</p> <code></code> <code>phase</code> <code>property</code> \u00b6 <p>Get the phase spectrum.</p> <code></code> <code>unwrapped_phase</code> <code>property</code> \u00b6 <p>Get the unwrapped phase spectrum.</p> <p>The unwrapped phase removes discontinuities of 2\u03c0 radians, providing continuous phase values across frequency bins.</p> <code></code> <code>power</code> <code>property</code> \u00b6 <p>Get the power spectrum.</p> <code></code> <code>dB</code> <code>property</code> \u00b6 <p>Get the spectrum in decibels.</p> <p>The reference values are taken from channel metadata. If no reference is specified, uses 1.0.</p> <code></code> <code>dBA</code> <code>property</code> \u00b6 <p>Get the A-weighted spectrum in decibels.</p> <p>Applies A-weighting filter to the spectrum for better correlation with perceived loudness.</p> <code></code> <code>freqs</code> <code>property</code> \u00b6 <p>Get the frequency axis values in Hz.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, n_fft, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: BaseFrame[Any] | None = None,\n) -&gt; None:\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>plot(plot_type='frequency', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, Aw=False, **kwargs)</code> \u00b6 <p>Plot the spectral data using various visualization strategies.</p> <code></code> <code>ifft()</code> \u00b6 <p>Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.</p> <p>This method transforms the frequency-domain data back to the time domain using the inverse FFT operation. The window function used in the forward FFT is taken into account to ensure proper reconstruction.</p> <code></code> <code>noct_synthesis(fmin, fmax, n=3, G=10, fr=1000)</code> \u00b6 <p>Synthesize N-octave band spectrum.</p> <p>This method combines frequency components into N-octave bands according to standard acoustical band definitions. This is commonly used in noise and vibration analysis.</p> <code></code> <code>plot_matrix(plot_type='matrix', **kwargs)</code> \u00b6 <p>Plot channel relationships in matrix format.</p> <p>This method creates a matrix plot showing relationships between channels, such as coherence, transfer functions, or cross-spectral density.</p> <code></code> <code>info()</code> \u00b6 <p>Display comprehensive information about the SpectralFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - FFT size - Frequency range - Number of frequency bins - Frequency resolution (\u0394F) - Channel labels</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p>"},{"location":"en/api/#wandas.frames.spectral.SpectralFrame.plot--examples","title":"Examples","text":"<p>spectrum = cf.fft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"frequency\",\n    ax: Axes | None = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot the spectral data using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"frequency\"\n        Type of plot to create. Options include:\n        - \"frequency\": Standard frequency plot\n        - \"matrix\": Matrix plot for comparing channels\n        - Other types as defined by available plot strategies\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; # Basic frequency plot\n    &gt;&gt;&gt; spectrum.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/#wandas.frames.spectral.SpectralFrame.ifft--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the time-domain signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def ifft(self) -&gt; ChannelFrame:\n    \"\"\"\n    Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n    This method transforms the frequency-domain data back to the time domain using\n    the inverse FFT operation. The window function used in the forward FFT is\n    taken into account to ensure proper reconstruction.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the time-domain signal.\n    \"\"\"\n    from ..processing import IFFT, create_operation\n    from .channel import ChannelFrame\n\n    params = {\"n_fft\": self.n_fft, \"window\": self.window}\n    operation_name = \"ifft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"IFFT\", operation)\n    # Apply processing to data\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Create new instance\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"ifft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.spectral.SpectralFrame.noct_synthesis--raises","title":"Raises","text":"<p>ValueError     If the sampling rate is not 48000 Hz, which is required for this operation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def noct_synthesis(\n    self,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; NOctFrame:\n    \"\"\"\n    Synthesize N-octave band spectrum.\n\n    This method combines frequency components into N-octave bands according to\n    standard acoustical band definitions. This is commonly used in noise and\n    vibration analysis.\n\n    Parameters\n    ----------\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number.\n    fr : int, default=1000\n        Reference frequency in Hz.\n\n    Returns\n    -------\n    NOctFrame\n        A new NOctFrame containing the N-octave band spectrum.\n\n    Raises\n    ------\n    ValueError\n        If the sampling rate is not 48000 Hz, which is required for this operation.\n    \"\"\"\n    if self.sampling_rate != 48000:\n        raise ValueError(\n            \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n        )\n    from ..processing import NOctSynthesis\n    from .noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_synthesis\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n    from ..processing import create_operation\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSynthesis\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_synthesis\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.spectral.SpectralFrame.plot_matrix--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def plot_matrix(\n    self,\n    plot_type: str = \"matrix\",\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot channel relationships in matrix format.\n\n    This method creates a matrix plot showing relationships between channels,\n    such as coherence, transfer functions, or cross-spectral density.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"matrix\"\n        Type of matrix plot to create.\n    **kwargs : dict\n        Additional plot parameters:\n        - vmin, vmax: Color scale limits\n        - cmap: Colormap name\n        - title: Plot title\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, **kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/#wandas.frames.spectral.SpectralFrame.info--examples","title":"Examples","text":"<p>spectrum = cf.fft() spectrum.info() SpectralFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectralFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; spectrum.info()\n    SpectralFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F)\n    delta_f = self.sampling_rate / self.n_fft\n\n    print(\"SpectralFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {len(self.freqs)}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame--examples","title":"Examples","text":"<p>Create a spectrogram from a time-domain signal:</p> <p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512)</p> <p>Extract a specific time frame:</p> <p>frame_at_1s = spectrogram.get_frame_at(int(1.0 * sampling_rate / hop_length))</p> <p>Convert back to time domain:</p> <p>reconstructed = spectrogram.to_channel_frame()</p> <p>Plot the spectrogram:</p> <p>spectrogram.plot()</p> Source code in <code>wandas/frames/spectrogram.py</code> <pre><code>class SpectrogramFrame(BaseFrame[NDArrayComplex]):\n    \"\"\"\n    Class for handling time-frequency domain data (spectrograms).\n\n    This class represents spectrogram data obtained through\n    Short-Time Fourier Transform (STFT)\n    or similar time-frequency analysis methods. It provides methods for visualization,\n    manipulation, and conversion back to time domain.\n\n    Parameters\n    ----------\n    data : DaArray\n        The spectrogram data. Must be a dask array with shape:\n        - (channels, frequency_bins, time_frames) for multi-channel data\n        - (frequency_bins, time_frames) for single-channel data, which will be\n          reshaped to (1, frequency_bins, time_frames)\n    sampling_rate : float\n        The sampling rate of the original time-domain signal in Hz.\n    n_fft : int\n        The FFT size used to generate this spectrogram.\n    hop_length : int\n        Number of samples between successive frames.\n    win_length : int, optional\n        The window length in samples. If None, defaults to n_fft.\n    window : str, default=\"hann\"\n        The window function to use (e.g., \"hann\", \"hamming\", \"blackman\").\n    label : str, optional\n        A label for the frame.\n    metadata : dict, optional\n        Additional metadata for the frame.\n    operation_history : list[dict], optional\n        History of operations performed on this frame.\n    channel_metadata : list[ChannelMetadata], optional\n        Metadata for each channel in the frame.\n    previous : BaseFrame, optional\n        The frame that this frame was derived from.\n\n    Attributes\n    ----------\n    magnitude : NDArrayReal\n        The magnitude spectrogram.\n    phase : NDArrayReal\n        The phase spectrogram in radians.\n    power : NDArrayReal\n        The power spectrogram.\n    dB : NDArrayReal\n        The spectrogram in decibels relative to channel reference values.\n    dBA : NDArrayReal\n        The A-weighted spectrogram in decibels.\n    n_frames : int\n        Number of time frames.\n    n_freq_bins : int\n        Number of frequency bins.\n    freqs : NDArrayReal\n        The frequency axis values in Hz.\n    times : NDArrayReal\n        The time axis values in seconds.\n\n    Examples\n    --------\n    Create a spectrogram from a time-domain signal:\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n\n    Extract a specific time frame:\n    &gt;&gt;&gt; frame_at_1s = spectrogram.get_frame_at(int(1.0 * sampling_rate / hop_length))\n\n    Convert back to time domain:\n    &gt;&gt;&gt; reconstructed = spectrogram.to_channel_frame()\n\n    Plot the spectrogram:\n    &gt;&gt;&gt; spectrogram.plot()\n    \"\"\"\n\n    n_fft: int\n    hop_length: int\n    win_length: int\n    window: str\n\n    def __init__(\n        self,\n        data: DaArray,\n        sampling_rate: float,\n        n_fft: int,\n        hop_length: int,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; None:\n        if data.ndim == 2:\n            data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n        elif data.ndim != 3:\n            raise ValueError(\n                f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n            )\n        if not data.shape[-2] == n_fft // 2 + 1:\n            raise ValueError(\n                f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n            )\n\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.win_length = win_length if win_length is not None else n_fft\n        self.window = window\n        super().__init__(\n            data=data,\n            sampling_rate=sampling_rate,\n            label=label,\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n\n    @property\n    def magnitude(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the magnitude spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The absolute values of the complex spectrogram.\n        \"\"\"\n        return np.abs(self.data)\n\n    @property\n    def phase(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the phase spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The phase angles of the complex spectrogram in radians.\n        \"\"\"\n        return np.angle(self.data)\n\n    @property\n    def power(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the power spectrogram.\n\n        Returns\n        -------\n        NDArrayReal\n            The squared magnitude of the complex spectrogram.\n        \"\"\"\n        return np.abs(self.data) ** 2\n\n    @property\n    def dB(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the spectrogram in decibels relative to each channel's reference value.\n\n        The reference value for each channel is specified in its metadata.\n        A minimum value of -120 dB is enforced to avoid numerical issues.\n\n        Returns\n        -------\n        NDArrayReal\n            The spectrogram in decibels.\n        \"\"\"\n        # dB\u898f\u5b9a\u5024\u3092_channel_metadata\u304b\u3089\u53ce\u96c6\n        ref = np.array([ch.ref for ch in self._channel_metadata])\n        # dB\u5909\u63db\n        # 0\u9664\u7b97\u3092\u907f\u3051\u308b\u305f\u3081\u306b\u3001\u6700\u5927\u5024\u30681e-12\u306e\u3044\u305a\u308c\u304b\u3092\u4f7f\u7528\n        level: NDArrayReal = 20 * np.log10(\n            np.maximum(self.magnitude / ref[..., np.newaxis, np.newaxis], 1e-12)\n        )\n        return level\n\n    @property\n    def dBA(self) -&gt; NDArrayReal:  # noqa: N802\n        \"\"\"\n        Get the A-weighted spectrogram in decibels.\n\n        A-weighting applies a frequency-dependent weighting filter that approximates\n        the human ear's response. This is particularly useful for analyzing noise\n        and acoustic measurements.\n\n        Returns\n        -------\n        NDArrayReal\n            The A-weighted spectrogram in decibels.\n        \"\"\"\n        weighted: NDArrayReal = librosa.A_weighting(frequencies=self.freqs, min_db=None)\n        return self.dB + weighted[:, np.newaxis]  # \u5468\u6ce2\u6570\u8ef8\u306b\u6cbf\u3063\u3066\u30d6\u30ed\u30fc\u30c9\u30ad\u30e3\u30b9\u30c8\n\n    @property\n    def _n_channels(self) -&gt; int:\n        \"\"\"\n        Get the number of channels in the data.\n\n        Returns\n        -------\n        int\n            The number of channels.\n        \"\"\"\n        return int(self._data.shape[-3])\n\n    @property\n    def n_frames(self) -&gt; int:\n        \"\"\"\n        Get the number of time frames.\n\n        Returns\n        -------\n        int\n            The number of time frames in the spectrogram.\n        \"\"\"\n        return self.shape[-1]\n\n    @property\n    def n_freq_bins(self) -&gt; int:\n        \"\"\"\n        Get the number of frequency bins.\n\n        Returns\n        -------\n        int\n            The number of frequency bins (n_fft // 2 + 1).\n        \"\"\"\n        return self.shape[-2]\n\n    @property\n    def freqs(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the frequency axis values in Hz.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of frequency values corresponding to each frequency bin.\n        \"\"\"\n        return np.fft.rfftfreq(self.n_fft, 1.0 / self.sampling_rate)\n\n    @property\n    def times(self) -&gt; NDArrayReal:\n        \"\"\"\n        Get the time axis values in seconds.\n\n        Returns\n        -------\n        NDArrayReal\n            Array of time values corresponding to each time frame.\n        \"\"\"\n        return np.arange(self.n_frames) * self.hop_length / self.sampling_rate\n\n    def _apply_operation_impl(self: S, operation_name: str, **params: Any) -&gt; S:\n        \"\"\"\n        Implementation of operation application for spectrogram data.\n\n        This internal method handles the application of various operations to\n        spectrogram data, maintaining lazy evaluation through dask.\n\n        Parameters\n        ----------\n        operation_name : str\n            Name of the operation to apply.\n        **params : Any\n            Parameters for the operation.\n\n        Returns\n        -------\n        S\n            A new instance with the operation applied.\n        \"\"\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n        from wandas.processing import create_operation\n\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        processed_data = operation.process(self._data)\n\n        operation_metadata = {\"operation\": operation_name, \"params\": params}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[operation_name] = params\n\n        logger.debug(\n            f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n        )\n        return self._create_new_instance(\n            data=processed_data,\n            metadata=new_metadata,\n            operation_history=new_history,\n        )\n\n    def _binary_op(\n        self,\n        other: Union[\n            \"SpectrogramFrame\",\n            int,\n            float,\n            complex,\n            NDArrayComplex,\n            NDArrayReal,\n            \"DaArray\",\n        ],\n        op: Callable[[\"DaArray\", Any], \"DaArray\"],\n        symbol: str,\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"\n        Common implementation for binary operations.\n\n        This method handles binary operations between\n        SpectrogramFrames and various types\n        of operands, maintaining lazy evaluation through dask arrays.\n\n        Parameters\n        ----------\n        other : Union[SpectrogramFrame, int, float, complex,\n            NDArrayComplex, NDArrayReal, DaArray]\n            The right operand of the operation.\n        op : callable\n            Function to execute the operation (e.g., lambda a, b: a + b)\n        symbol : str\n            String representation of the operation (e.g., '+')\n\n        Returns\n        -------\n        SpectrogramFrame\n            A new SpectrogramFrame containing the result of the operation.\n\n        Raises\n        ------\n        ValueError\n            If attempting to operate with a SpectrogramFrame\n            with a different sampling rate.\n        \"\"\"\n        logger.debug(f\"Setting up {symbol} operation (lazy)\")\n\n        metadata = {}\n        if self.metadata is not None:\n            metadata = self.metadata.copy()\n\n        operation_history = []\n        if self.operation_history is not None:\n            operation_history = self.operation_history.copy()\n\n        if isinstance(other, SpectrogramFrame):\n            if self.sampling_rate != other.sampling_rate:\n                raise ValueError(\n                    \"\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8\u304c\u4e00\u81f4\u3057\u3066\u3044\u307e\u305b\u3093\u3002\u6f14\u7b97\u3067\u304d\u307e\u305b\u3093\u3002\"\n                )\n\n            result_data = op(self._data, other._data)\n\n            merged_channel_metadata = []\n            for self_ch, other_ch in zip(\n                self._channel_metadata, other._channel_metadata\n            ):\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch['label']} {symbol} {other_ch['label']})\"\n                merged_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other.label})\n\n            return SpectrogramFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                hop_length=self.hop_length,\n                win_length=self.win_length,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other.label})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=merged_channel_metadata,\n                previous=self,\n            )\n        else:\n            result_data = op(self._data, other)\n\n            if isinstance(other, int | float):\n                other_str = str(other)\n            elif isinstance(other, complex):\n                other_str = f\"complex({other.real}, {other.imag})\"\n            elif isinstance(other, np.ndarray):\n                other_str = f\"ndarray{other.shape}\"\n            elif hasattr(other, \"shape\"):\n                other_str = f\"dask.array{other.shape}\"\n            else:\n                other_str = str(type(other).__name__)\n\n            updated_channel_metadata: list[ChannelMetadata] = []\n            for self_ch in self._channel_metadata:\n                ch = self_ch.model_copy(deep=True)\n                ch[\"label\"] = f\"({self_ch.label} {symbol} {other_str})\"\n                updated_channel_metadata.append(ch)\n\n            operation_history.append({\"operation\": symbol, \"with\": other_str})\n\n            return SpectrogramFrame(\n                data=result_data,\n                sampling_rate=self.sampling_rate,\n                n_fft=self.n_fft,\n                hop_length=self.hop_length,\n                win_length=self.win_length,\n                window=self.window,\n                label=f\"({self.label} {symbol} {other_str})\",\n                metadata=metadata,\n                operation_history=operation_history,\n                channel_metadata=updated_channel_metadata,\n            )\n\n    def plot(\n        self,\n        plot_type: str = \"spectrogram\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        cmap: str = \"jet\",\n        vmin: float | None = None,\n        vmax: float | None = None,\n        fmin: float = 0,\n        fmax: float | None = None,\n        xlim: tuple[float, float] | None = None,\n        ylim: tuple[float, float] | None = None,\n        Aw: bool = False,  # noqa: N803\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the spectrogram using various visualization strategies.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"spectrogram\"\n            Type of plot to create.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        title : str, optional\n            Title for the plot. If None, uses the frame label.\n        cmap : str, default=\"jet\"\n            Colormap name for the spectrogram visualization.\n        vmin : float, optional\n            Minimum value for colormap scaling (dB). Auto-calculated if None.\n        vmax : float, optional\n            Maximum value for colormap scaling (dB). Auto-calculated if None.\n        fmin : float, default=0\n            Minimum frequency to display (Hz).\n        fmax : float, optional\n            Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n        xlim : tuple[float, float], optional\n            Time axis limits as (start_time, end_time) in seconds.\n        ylim : tuple[float, float], optional\n            Frequency axis limits as (min_freq, max_freq) in Hz.\n        Aw : bool, default=False\n            Whether to apply A-weighting to the spectrogram.\n        **kwargs : dict\n            Additional keyword arguments passed to librosa.display.specshow().\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot, or an iterator of axes\n            for multi-plot outputs.\n\n        Examples\n        --------\n        &gt;&gt;&gt; stft = cf.stft()\n        &gt;&gt;&gt; # Basic spectrogram\n        &gt;&gt;&gt; stft.plot()\n        &gt;&gt;&gt; # Custom color scale and frequency range\n        &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n        &gt;&gt;&gt; # A-weighted spectrogram\n        &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n        \"\"\"\n        from wandas.visualization.plotting import create_operation\n\n        logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n        # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n        plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n        # Build kwargs for plot strategy\n        plot_kwargs = {\n            \"title\": title,\n            \"cmap\": cmap,\n            \"vmin\": vmin,\n            \"vmax\": vmax,\n            \"fmin\": fmin,\n            \"fmax\": fmax,\n            \"Aw\": Aw,\n            **kwargs,\n        }\n        if xlim is not None:\n            plot_kwargs[\"xlim\"] = xlim\n        if ylim is not None:\n            plot_kwargs[\"ylim\"] = ylim\n\n        # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n        _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n        logger.debug(\"Plot rendering complete\")\n\n        return _ax\n\n    def plot_Aw(  # noqa: N802\n        self,\n        plot_type: str = \"spectrogram\",\n        ax: Optional[\"Axes\"] = None,\n        **kwargs: Any,\n    ) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n        \"\"\"\n        Plot the A-weighted spectrogram.\n\n        A convenience method that calls plot() with Aw=True, applying A-weighting\n        to the spectrogram before plotting.\n\n        Parameters\n        ----------\n        plot_type : str, default=\"spectrogram\"\n            Type of plot to create.\n        ax : matplotlib.axes.Axes, optional\n            Axes to plot on. If None, creates new axes.\n        **kwargs : dict\n            Additional keyword arguments passed to plot().\n            Accepts all parameters from plot() except Aw (which is set to True).\n\n        Returns\n        -------\n        Union[Axes, Iterator[Axes]]\n            The matplotlib axes containing the plot.\n\n        Examples\n        --------\n        &gt;&gt;&gt; stft = cf.stft()\n        &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n        &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n        \"\"\"\n        return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n\n    def abs(self) -&gt; \"SpectrogramFrame\":\n        \"\"\"\n        Compute the absolute value (magnitude) of the complex spectrogram.\n\n        This method calculates the magnitude of each complex value in the\n        spectrogram, converting the complex-valued data to real-valued magnitude data.\n        The result is stored in a new SpectrogramFrame with complex dtype to maintain\n        compatibility with other spectrogram operations.\n\n        Returns\n        -------\n        SpectrogramFrame\n            A new SpectrogramFrame containing the magnitude values as complex numbers\n            (with zero imaginary parts).\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n        &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n        &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n        \"\"\"\n        logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n        # Compute the absolute value using dask for lazy evaluation\n        magnitude_data = da.absolute(self._data)\n\n        # Update operation history\n        operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n        new_history = self.operation_history.copy()\n        new_history.append(operation_metadata)\n        new_metadata = {**self.metadata}\n        new_metadata[\"abs\"] = {}\n\n        logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n        return SpectrogramFrame(\n            data=magnitude_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=self.n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=self.window,\n            label=f\"abs({self.label})\",\n            metadata=new_metadata,\n            operation_history=new_history,\n            channel_metadata=self._channel_metadata,\n            previous=self,\n        )\n\n    def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n        \"\"\"\n        Extract spectral data at a specific time frame.\n\n        Parameters\n        ----------\n        time_idx : int\n            Index of the time frame to extract.\n\n        Returns\n        -------\n        SpectralFrame\n            A new SpectralFrame containing the spectral data at the specified time.\n\n        Raises\n        ------\n        IndexError\n            If time_idx is out of range.\n        \"\"\"\n        from wandas.frames.spectral import SpectralFrame\n\n        if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n            raise IndexError(\n                f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n            )\n\n        frame_data = self._data[..., time_idx]\n\n        return SpectralFrame(\n            data=frame_data,\n            sampling_rate=self.sampling_rate,\n            n_fft=self.n_fft,\n            window=self.window,\n            label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def to_channel_frame(self) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Convert the spectrogram back to time domain using inverse STFT.\n\n        This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n        reconstruct the time-domain signal from the spectrogram.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the reconstructed time-domain signal.\n\n        See Also\n        --------\n        istft : Alias for this method with more intuitive naming.\n        \"\"\"\n        from wandas.frames.channel import ChannelFrame\n        from wandas.processing import ISTFT, create_operation\n\n        params = {\n            \"n_fft\": self.n_fft,\n            \"hop_length\": self.hop_length,\n            \"win_length\": self.win_length,\n            \"window\": self.window,\n        }\n        operation_name = \"istft\"\n        logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n        # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n        operation = create_operation(operation_name, self.sampling_rate, **params)\n        operation = cast(\"ISTFT\", operation)\n        # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n        time_series = operation.process(self._data)\n\n        logger.debug(\n            f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n        )\n\n        # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n        return ChannelFrame(\n            data=time_series,\n            sampling_rate=self.sampling_rate,\n            label=f\"istft({self.label})\",\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=self._channel_metadata,\n        )\n\n    def istft(self) -&gt; \"ChannelFrame\":\n        \"\"\"\n        Convert the spectrogram back to time domain using inverse STFT.\n\n        This is an alias for `to_channel_frame()` with a more intuitive name.\n        It performs an inverse Short-Time Fourier Transform (ISTFT) to\n        reconstruct the time-domain signal from the spectrogram.\n\n        Returns\n        -------\n        ChannelFrame\n            A new ChannelFrame containing the reconstructed time-domain signal.\n\n        See Also\n        --------\n        to_channel_frame : The underlying implementation.\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; reconstructed = spectrogram.istft()\n        \"\"\"\n        return self.to_channel_frame()\n\n    def _get_additional_init_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get additional initialization arguments for SpectrogramFrame.\n\n        This internal method provides the additional initialization arguments\n        required by SpectrogramFrame beyond those required by BaseFrame.\n\n        Returns\n        -------\n        dict[str, Any]\n            Additional initialization arguments.\n        \"\"\"\n        return {\n            \"n_fft\": self.n_fft,\n            \"hop_length\": self.hop_length,\n            \"win_length\": self.win_length,\n            \"window\": self.window,\n        }\n\n    def _get_dataframe_columns(self) -&gt; list[str]:\n        \"\"\"Get channel labels as DataFrame columns.\"\"\"\n        return [ch.label for ch in self._channel_metadata]\n\n    def _get_dataframe_index(self) -&gt; \"pd.Index[Any]\":\n        \"\"\"DataFrame index is not supported for SpectrogramFrame.\"\"\"\n        raise NotImplementedError(\n            \"DataFrame index is not supported for SpectrogramFrame.\"\n        )\n\n    def to_dataframe(self) -&gt; \"pd.DataFrame\":\n        \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n        SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n        which cannot be directly converted to a 2D DataFrame. Consider using\n        get_frame_at() to extract a specific time frame as a SpectralFrame,\n        then convert that to a DataFrame.\n\n        Raises\n        ------\n        NotImplementedError\n            Always raised as DataFrame conversion is not supported.\n        \"\"\"\n        raise NotImplementedError(\n            \"DataFrame conversion is not supported for SpectrogramFrame. \"\n            \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n            \"then convert that to a DataFrame.\"\n        )\n\n    def info(self) -&gt; None:\n        \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n        This method prints a summary of the frame's properties including:\n        - Number of channels\n        - Sampling rate\n        - FFT size\n        - Hop length\n        - Window length\n        - Window function\n        - Frequency range\n        - Number of frequency bins\n        - Frequency resolution (\u0394F)\n        - Number of time frames\n        - Time resolution (\u0394T)\n        - Total duration\n        - Channel labels\n        - Number of operations applied\n\n        This is a convenience method to view all key properties at once,\n        similar to pandas DataFrame.info().\n\n        Examples\n        --------\n        &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n        &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n        &gt;&gt;&gt; spectrogram.info()\n        SpectrogramFrame Information:\n          Channels: 2\n          Sampling rate: 44100 Hz\n          FFT size: 2048\n          Hop length: 512 samples\n          Window length: 2048 samples\n          Window: hann\n          Frequency range: 0.0 - 22050.0 Hz\n          Frequency bins: 1025\n          Frequency resolution (\u0394F): 21.5 Hz\n          Time frames: 100\n          Time resolution (\u0394T): 11.6 ms\n          Total duration: 1.16 s\n          Channel labels: ['ch0', 'ch1']\n          Operations Applied: 1\n        \"\"\"\n        # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n        delta_f = self.sampling_rate / self.n_fft\n        delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n        total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n        print(\"SpectrogramFrame Information:\")\n        print(f\"  Channels: {self.n_channels}\")\n        print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n        print(f\"  FFT size: {self.n_fft}\")\n        print(f\"  Hop length: {self.hop_length} samples\")\n        print(f\"  Window length: {self.win_length} samples\")\n        print(f\"  Window: {self.window}\")\n        print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n        print(f\"  Frequency bins: {self.n_freq_bins}\")\n        print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n        print(f\"  Time frames: {self.n_frames}\")\n        print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n        print(f\"  Total duration: {total_duration:.2f} s\")\n        print(f\"  Channel labels: {self.labels}\")\n        self._print_operation_history()\n\n    @classmethod\n    def from_numpy(\n        cls,\n        data: NDArrayComplex,\n        sampling_rate: float,\n        n_fft: int,\n        hop_length: int,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        label: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        operation_history: list[dict[str, Any]] | None = None,\n        channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n        previous: Optional[\"BaseFrame[Any]\"] = None,\n    ) -&gt; \"SpectrogramFrame\":\n        \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n        Args:\n            data: NumPy array containing spectrogram data.\n                Shape should be (n_channels, n_freq_bins, n_time_frames) or\n                (n_freq_bins, n_time_frames) for single channel.\n            sampling_rate: The sampling rate in Hz.\n            n_fft: The FFT size used to generate this spectrogram.\n            hop_length: Number of samples between successive frames.\n            win_length: The window length in samples. If None, defaults to n_fft.\n            window: The window function used (e.g., \"hann\", \"hamming\").\n            label: A label for the frame.\n            metadata: Optional metadata dictionary.\n            operation_history: History of operations applied to the frame.\n            channel_metadata: Metadata for each channel.\n            previous: Reference to the previous frame in the processing chain.\n\n        Returns:\n            A new SpectrogramFrame containing the NumPy data.\n        \"\"\"\n\n        # Convert NumPy array to dask array\n        dask_data = da.from_array(data)\n        sf = cls(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            n_fft=n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            label=label or \"numpy_spectrogram\",\n            metadata=metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata,\n            previous=previous,\n        )\n        return sf\n</code></pre> Attributes\u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = win_length if win_length is not None else n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>magnitude</code> <code>property</code> \u00b6 <p>Get the magnitude spectrogram.</p> <code></code> <code>phase</code> <code>property</code> \u00b6 <p>Get the phase spectrogram.</p> <code></code> <code>power</code> <code>property</code> \u00b6 <p>Get the power spectrogram.</p> <code></code> <code>dB</code> <code>property</code> \u00b6 <p>Get the spectrogram in decibels relative to each channel's reference value.</p> <p>The reference value for each channel is specified in its metadata. A minimum value of -120 dB is enforced to avoid numerical issues.</p> <code></code> <code>dBA</code> <code>property</code> \u00b6 <p>Get the A-weighted spectrogram in decibels.</p> <p>A-weighting applies a frequency-dependent weighting filter that approximates the human ear's response. This is particularly useful for analyzing noise and acoustic measurements.</p> <code></code> <code>n_frames</code> <code>property</code> \u00b6 <p>Get the number of time frames.</p> <code></code> <code>n_freq_bins</code> <code>property</code> \u00b6 <p>Get the number of frequency bins.</p> <code></code> <code>freqs</code> <code>property</code> \u00b6 <p>Get the frequency axis values in Hz.</p> <code></code> <code>times</code> <code>property</code> \u00b6 <p>Get the time axis values in seconds.</p> Functions\u00b6 <code></code> <code>__init__(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    if data.ndim == 2:\n        data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n    elif data.ndim != 3:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n        )\n    if not data.shape[-2] == n_fft // 2 + 1:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n        )\n\n    self.n_fft = n_fft\n    self.hop_length = hop_length\n    self.win_length = win_length if win_length is not None else n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre> <code></code> <code>plot(plot_type='spectrogram', ax=None, title=None, cmap='jet', vmin=None, vmax=None, fmin=0, fmax=None, xlim=None, ylim=None, Aw=False, **kwargs)</code> \u00b6 <p>Plot the spectrogram using various visualization strategies.</p> <code></code> <code>plot_Aw(plot_type='spectrogram', ax=None, **kwargs)</code> \u00b6 <p>Plot the A-weighted spectrogram.</p> <p>A convenience method that calls plot() with Aw=True, applying A-weighting to the spectrogram before plotting.</p> <code></code> <code>abs()</code> \u00b6 <p>Compute the absolute value (magnitude) of the complex spectrogram.</p> <p>This method calculates the magnitude of each complex value in the spectrogram, converting the complex-valued data to real-valued magnitude data. The result is stored in a new SpectrogramFrame with complex dtype to maintain compatibility with other spectrogram operations.</p> <code></code> <code>get_frame_at(time_idx)</code> \u00b6 <p>Extract spectral data at a specific time frame.</p> <code></code> <code>to_channel_frame()</code> \u00b6 <p>Convert the spectrogram back to time domain using inverse STFT.</p> <p>This method performs an inverse Short-Time Fourier Transform (ISTFT) to reconstruct the time-domain signal from the spectrogram.</p> <code></code> <code>istft()</code> \u00b6 <p>Convert the spectrogram back to time domain using inverse STFT.</p> <p>This is an alias for <code>to_channel_frame()</code> with a more intuitive name. It performs an inverse Short-Time Fourier Transform (ISTFT) to reconstruct the time-domain signal from the spectrogram.</p> <code></code> <code>to_dataframe()</code> \u00b6 <p>DataFrame conversion is not supported for SpectrogramFrame.</p> <p>SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames) which cannot be directly converted to a 2D DataFrame. Consider using get_frame_at() to extract a specific time frame as a SpectralFrame, then convert that to a DataFrame.</p> <code></code> <code>info()</code> \u00b6 <p>Display comprehensive information about the SpectrogramFrame.</p> <p>This method prints a summary of the frame's properties including: - Number of channels - Sampling rate - FFT size - Hop length - Window length - Window function - Frequency range - Number of frequency bins - Frequency resolution (\u0394F) - Number of time frames - Time resolution (\u0394T) - Total duration - Channel labels - Number of operations applied</p> <p>This is a convenience method to view all key properties at once, similar to pandas DataFrame.info().</p> <code></code> <code>from_numpy(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code> <code>classmethod</code> \u00b6 <p>Create a SpectrogramFrame from a NumPy array.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>NDArrayComplex</code> <p>NumPy array containing spectrogram data. Shape should be (n_channels, n_freq_bins, n_time_frames) or (n_freq_bins, n_time_frames) for single channel.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> \u5fc5\u9808 <code>n_fft</code> <code>int</code> <p>The FFT size used to generate this spectrogram.</p> \u5fc5\u9808 <code>hop_length</code> <code>int</code> <p>Number of samples between successive frames.</p> \u5fc5\u9808 <code>win_length</code> <code>int | None</code> <p>The window length in samples. If None, defaults to n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>The window function used (e.g., \"hann\", \"hamming\").</p> <code>'hann'</code> <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectrogramFrame</code> <p>A new SpectrogramFrame containing the NumPy data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayComplex,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing spectrogram data.\n            Shape should be (n_channels, n_freq_bins, n_time_frames) or\n            (n_freq_bins, n_time_frames) for single channel.\n        sampling_rate: The sampling rate in Hz.\n        n_fft: The FFT size used to generate this spectrogram.\n        hop_length: Number of samples between successive frames.\n        win_length: The window length in samples. If None, defaults to n_fft.\n        window: The window function used (e.g., \"hann\", \"hamming\").\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Returns:\n        A new SpectrogramFrame containing the NumPy data.\n    \"\"\"\n\n    # Convert NumPy array to dask array\n    dask_data = da.from_array(data)\n    sf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        label=label or \"numpy_spectrogram\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n    return sf\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.plot--examples","title":"Examples","text":"<p>stft = cf.stft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    fmin: float = 0,\n    fmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the spectrogram using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    cmap : str, default=\"jet\"\n        Colormap name for the spectrogram visualization.\n    vmin : float, optional\n        Minimum value for colormap scaling (dB). Auto-calculated if None.\n    vmax : float, optional\n        Maximum value for colormap scaling (dB). Auto-calculated if None.\n    fmin : float, default=0\n        Minimum frequency to display (Hz).\n    fmax : float, optional\n        Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n    xlim : tuple[float, float], optional\n        Time axis limits as (start_time, end_time) in seconds.\n    ylim : tuple[float, float], optional\n        Frequency axis limits as (min_freq, max_freq) in Hz.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the spectrogram.\n    **kwargs : dict\n        Additional keyword arguments passed to librosa.display.specshow().\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # Basic spectrogram\n    &gt;&gt;&gt; stft.plot()\n    &gt;&gt;&gt; # Custom color scale and frequency range\n    &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n    &gt;&gt;&gt; # A-weighted spectrogram\n    &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n    plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--examples","title":"Examples","text":"<p>stft = cf.stft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def plot_Aw(  # noqa: N802\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the A-weighted spectrogram.\n\n    A convenience method that calls plot() with Aw=True, applying A-weighting\n    to the spectrogram before plotting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    **kwargs : dict\n        Additional keyword arguments passed to plot().\n        Accepts all parameters from plot() except Aw (which is set to True).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n    &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n    \"\"\"\n    return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.abs--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) magnitude_spectrogram = spectrogram.abs()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def abs(self) -&gt; \"SpectrogramFrame\":\n    \"\"\"\n    Compute the absolute value (magnitude) of the complex spectrogram.\n\n    This method calculates the magnitude of each complex value in the\n    spectrogram, converting the complex-valued data to real-valued magnitude data.\n    The result is stored in a new SpectrogramFrame with complex dtype to maintain\n    compatibility with other spectrogram operations.\n\n    Returns\n    -------\n    SpectrogramFrame\n        A new SpectrogramFrame containing the magnitude values as complex numbers\n        (with zero imaginary parts).\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n    &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n    &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n    \"\"\"\n    logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n    # Compute the absolute value using dask for lazy evaluation\n    magnitude_data = da.absolute(self._data)\n\n    # Update operation history\n    operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n    new_history = self.operation_history.copy()\n    new_history.append(operation_metadata)\n    new_metadata = {**self.metadata}\n    new_metadata[\"abs\"] = {}\n\n    logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n    return SpectrogramFrame(\n        data=magnitude_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=self.window,\n        label=f\"abs({self.label})\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--raises","title":"Raises","text":"<p>IndexError     If time_idx is out of range.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n    \"\"\"\n    Extract spectral data at a specific time frame.\n\n    Parameters\n    ----------\n    time_idx : int\n        Index of the time frame to extract.\n\n    Returns\n    -------\n    SpectralFrame\n        A new SpectralFrame containing the spectral data at the specified time.\n\n    Raises\n    ------\n    IndexError\n        If time_idx is out of range.\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n\n    if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n        raise IndexError(\n            f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n        )\n\n    frame_data = self._data[..., time_idx]\n\n    return SpectralFrame(\n        data=frame_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        window=self.window,\n        label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame--see-also","title":"See Also","text":"<p>istft : Alias for this method with more intuitive naming.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def to_channel_frame(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    istft : Alias for this method with more intuitive naming.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n    from wandas.processing import ISTFT, create_operation\n\n    params = {\n        \"n_fft\": self.n_fft,\n        \"hop_length\": self.hop_length,\n        \"win_length\": self.win_length,\n        \"window\": self.window,\n    }\n    operation_name = \"istft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"ISTFT\", operation)\n    # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n    )\n\n    # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"istft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.istft--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) reconstructed = spectrogram.istft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def istft(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This is an alias for `to_channel_frame()` with a more intuitive name.\n    It performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    to_channel_frame : The underlying implementation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; reconstructed = spectrogram.istft()\n    \"\"\"\n    return self.to_channel_frame()\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n    SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n    which cannot be directly converted to a 2D DataFrame. Consider using\n    get_frame_at() to extract a specific time frame as a SpectralFrame,\n    then convert that to a DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for SpectrogramFrame. \"\n        \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n        \"then convert that to a DataFrame.\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.frames.spectrogram.SpectrogramFrame.info--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) spectrogram.info() SpectrogramFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Hop length: 512 samples   Window length: 2048 samples   Window: hann   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Time frames: 100   Time resolution (\u0394T): 11.6 ms   Total duration: 1.16 s   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Hop length\n    - Window length\n    - Window function\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Number of time frames\n    - Time resolution (\u0394T)\n    - Total duration\n    - Channel labels\n    - Number of operations applied\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; spectrogram.info()\n    SpectrogramFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Hop length: 512 samples\n      Window length: 2048 samples\n      Window: hann\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Time frames: 100\n      Time resolution (\u0394T): 11.6 ms\n      Total duration: 1.16 s\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n    delta_f = self.sampling_rate / self.n_fft\n    delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n    total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n    print(\"SpectrogramFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Hop length: {self.hop_length} samples\")\n    print(f\"  Window length: {self.win_length} samples\")\n    print(f\"  Window: {self.window}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {self.n_freq_bins}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Time frames: {self.n_frames}\")\n    print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n    print(f\"  Total duration: {total_duration:.2f} s\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/#processing-module","title":"Processing Module","text":"<p>The processing module provides various processing functions for audio data.</p>"},{"location":"en/api/#wandas.processing.AudioOperation.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) pure : bool, default=True     Whether the operation is pure (deterministic with no side effects).     When True, Dask can cache results for identical inputs.     Set to False only if the operation has side effects or is non-deterministic. **params : Any     Operation-specific parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n    \"\"\"\n    Initialize AudioOperation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    pure : bool, default=True\n        Whether the operation is pure (deterministic with no side effects).\n        When True, Dask can cache results for identical inputs.\n        Set to False only if the operation has side effects or is non-deterministic.\n    **params : Any\n        Operation-specific parameters\n    \"\"\"\n    self.sampling_rate = sampling_rate\n    self.pure = pure\n    self.params = params\n\n    # Validate parameters during initialization\n    self.validate_params()\n\n    # Create processor function (lazy initialization possible)\n    self._setup_processor()\n\n    logger.debug(\n        f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.AudioOperation.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters (raises exception if invalid)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/#wandas.processing.AudioOperation.get_metadata_updates--notes","title":"Notes","text":"<p>This method is called by the framework after processing to update the frame metadata. Subclasses should override this method if they need to update metadata (e.g., changing sampling rate).</p> <p>Design principle: Operations should use parameters provided at initialization (via init). All necessary information should be available as instance variables.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    This method allows operations to specify how metadata should be\n    updated after processing. By default, no metadata is updated.\n\n    Returns\n    -------\n    dict\n        Dictionary of metadata updates. Can include:\n        - 'sampling_rate': New sampling rate (float)\n        - Other metadata keys as needed\n\n    Examples\n    --------\n    Return empty dict for operations that don't change metadata:\n\n    &gt;&gt;&gt; return {}\n\n    Return new sampling rate for operations that resample:\n\n    &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n    Notes\n    -----\n    This method is called by the framework after processing to update\n    the frame metadata. Subclasses should override this method if they\n    need to update metadata (e.g., changing sampling rate).\n\n    Design principle: Operations should use parameters provided at\n    initialization (via __init__). All necessary information should be\n    available as instance variables.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"en/api/#wandas.processing.AudioOperation.get_display_name--notes","title":"Notes","text":"<p>Subclasses can override this method to provide operation-specific display names that include parameter information, making labels more informative.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_display_name(self) -&gt; str | None:\n    \"\"\"\n    Get display name for the operation for use in channel labels.\n\n    This method allows operations to customize how they appear in\n    channel labels. By default, returns None, which means the\n    operation name will be used.\n\n    Returns\n    -------\n    str or None\n        Display name for the operation. If None, the operation name\n        (from the `name` class variable) is used.\n\n    Examples\n    --------\n    Default behavior (returns None, uses operation name):\n\n    &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n    ...     name = \"normalize\"\n    &gt;&gt;&gt; op = NormalizeOp(44100)\n    &gt;&gt;&gt; op.get_display_name()  # Returns None\n    &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n    Custom display name:\n\n    &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n    ...     name = \"lowpass_filter\"\n    ...\n    ...     def __init__(self, sr, cutoff):\n    ...         self.cutoff = cutoff\n    ...         super().__init__(sr, cutoff=cutoff)\n    ...\n    ...     def get_display_name(self):\n    ...         return f\"lpf_{self.cutoff}Hz\"\n    &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n    &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n    &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n    Notes\n    -----\n    Subclasses can override this method to provide operation-specific\n    display names that include parameter information, making labels\n    more informative.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"en/api/#wandas.processing.AudioOperation.process_array--returns","title":"Returns","text":"<p>dask.delayed.Delayed     A Delayed object representing the computation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def process_array(self, x: InputArrayType) -&gt; Any:\n    \"\"\"\n    Processing function wrapped with @dask.delayed.\n\n    This method returns a Delayed object that can be computed later.\n    The operation name is used in the Dask task graph for better visualization.\n\n    Parameters\n    ----------\n    x : InputArrayType\n        Input array to process.\n\n    Returns\n    -------\n    dask.delayed.Delayed\n        A Delayed object representing the computation.\n    \"\"\"\n    logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n    # Create wrapper with operation name and wrap it with dask.delayed\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    return delayed_func(x)\n</code></pre>"},{"location":"en/api/#wandas.processing.AudioOperation.calculate_output_shape--notes","title":"Notes","text":"<p>The default implementation creates a minimal test array and processes it to determine output shape. For performance-critical code, subclasses should override this method with a direct calculation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    This method can be overridden by subclasses for efficiency.\n    If not overridden, it will execute _process_array on a small test array\n    to determine the output shape.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n\n    Notes\n    -----\n    The default implementation creates a minimal test array and processes it\n    to determine output shape. For performance-critical code, subclasses should\n    override this method with a direct calculation.\n    \"\"\"\n    # Try to infer shape by executing _process_array on test data\n    import numpy as np\n\n    try:\n        # Create minimal test array with input shape\n        if len(input_shape) == 0:\n            return input_shape\n\n        # Create test input with correct dtype\n        # Try complex first, fall back to float if needed\n        test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n        # Process test input\n        test_output: Any = self._process_array(test_input)\n\n        # Return the shape of the output\n        if isinstance(test_output, np.ndarray):\n            return tuple(int(s) for s in test_output.shape)\n        return input_shape\n    except Exception as e:\n        logger.warning(\n            f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n            \"Please implement calculate_output_shape method.\"\n        )\n        raise NotImplementedError(\n            f\"Subclass {self.__class__.__name__} must implement \"\n            f\"calculate_output_shape or ensure _process_array can be \"\n            f\"called with test data.\"\n        ) from e\n</code></pre>"},{"location":"en/api/#wandas.processing.AudioOperation.process","title":"<code>process(data)</code>","text":"<p>Execute operation and return result data shape is (channels, samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    \"\"\"\n    Execute operation and return result\n    data shape is (channels, samples)\n    \"\"\"\n    # Add task as delayed processing with custom name for visualization\n    logger.debug(\"Adding delayed operation to computation graph\")\n\n    # Create a wrapper function with the operation name\n    # This allows Dask to use the operation name in the task graph\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    delayed_result = delayed_func(data)\n\n    # Convert delayed result to dask array and return\n    output_shape = self.calculate_output_shape(data.shape)\n    return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"en/api/#wandas.processing.AddWithSNR.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other : DaArray     Noise signal to add (channel-frame format) snr : float     Signal-to-noise ratio (dB)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n    \"\"\"\n    Initialize addition operation considering SNR\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other : DaArray\n        Noise signal to add (channel-frame format)\n    snr : float\n        Signal-to-noise ratio (dB)\n    \"\"\"\n    super().__init__(sampling_rate, other=other, snr=snr)\n\n    self.other = other\n    self.snr = snr\n    logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n</code></pre>"},{"location":"en/api/#wandas.processing.AddWithSNR.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.AddWithSNR.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"+SNR\"\n</code></pre>"},{"location":"en/api/#wandas.processing.HpssHarmonic.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Harmonic\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"en/api/#wandas.processing.HpssHarmonic.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.HpssHarmonic.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Hrm\"\n</code></pre>"},{"location":"en/api/#wandas.processing.HpssPercussive.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Percussive\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"en/api/#wandas.processing.HpssPercussive.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.HpssPercussive.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Prc\"\n</code></pre>"},{"location":"en/api/#wandas.processing.AWeighting.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize A-weighting filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"en/api/#wandas.processing.AWeighting.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.AWeighting.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Aw\"\n</code></pre>"},{"location":"en/api/#wandas.processing.HighPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize high-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"en/api/#wandas.processing.HighPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.processing.HighPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.HighPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"hpf\"\n</code></pre>"},{"location":"en/api/#wandas.processing.LowPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize low-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"en/api/#wandas.processing.LowPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.processing.LowPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.LowPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"lpf\"\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwst.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize steady-state loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwst.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwst.get_metadata_updates--notes","title":"Notes","text":"<p>Unlike time-varying loudness, steady-state loudness produces a single value, not a time series, so the sampling rate concept doesn't apply.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    For steady-state loudness, the output is a single value per channel,\n    so no sampling rate update is needed (output is scalar, not time-series).\n\n    Returns\n    -------\n    dict\n        Empty dictionary (no metadata updates needed)\n\n    Notes\n    -----\n    Unlike time-varying loudness, steady-state loudness produces a single\n    value, not a time series, so the sampling rate concept doesn't apply.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwst.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape: (channels, 1) - one loudness value per channel</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The steady-state loudness calculation produces a single loudness value\n    per channel.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape: (channels, 1) - one loudness value per channel\n    \"\"\"\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    return (n_channels, 1)\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwtv.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize Loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwtv.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwtv.get_metadata_updates--notes","title":"Notes","text":"<p>All necessary parameters are provided at initialization. The output sampling rate is always 500 Hz regardless of input.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on MoSQITo's time resolution.\n\n    The Zwicker method uses approximately 2ms time steps,\n    which corresponds to 500 Hz sampling rate, independent of\n    the input sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    All necessary parameters are provided at initialization.\n    The output sampling rate is always 500 Hz regardless of input.\n    \"\"\"\n    return {\"sampling_rate\": 500.0}\n</code></pre>"},{"location":"en/api/#wandas.processing.LoudnessZwtv.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape. For loudness, we return a placeholder shape     since the actual length is determined by the algorithm.     The shape will be (channels, time_samples) where time_samples     depends on the input length and algorithm parameters.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The loudness calculation produces a time-varying output where the time\n    resolution depends on the algorithm's internal processing. The exact\n    output length is determined dynamically by the loudness_zwtv function.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape. For loudness, we return a placeholder shape\n        since the actual length is determined by the algorithm.\n        The shape will be (channels, time_samples) where time_samples\n        depends on the input length and algorithm parameters.\n    \"\"\"\n    # Return a placeholder shape - the actual shape will be determined\n    # after processing since loudness_zwtv determines the time resolution\n    # For now, we estimate based on typical behavior (approx 2ms time steps)\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    # Rough estimate: one loudness value per 2ms (0.002s)\n    estimated_time_samples = int(input_shape[-1] / (self.sampling_rate * 0.002))\n    return (n_channels, estimated_time_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.CSD.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize cross-spectral density estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"CSD\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.CSD.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.CSD.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"CSD\"\n</code></pre>"},{"location":"en/api/#wandas.processing.FFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not a positive integer</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize FFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is None (determined by input size)\n    window : str, optional\n        Window function type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not a positive integer\n    \"\"\"\n    # Validate n_fft parameter\n    if n_fft is not None and n_fft &lt;= 0:\n        raise ValueError(\n            f\"Invalid FFT size\\n\"\n            f\"  Got: {n_fft}\\n\"\n            f\"  Expected: Positive integer &gt; 0\\n\"\n            f\"FFT size must be a positive integer.\\n\"\n            f\"Common values: 512, 1024, 2048, 4096,\\n\"\n            f\"8192 (powers of 2 are most efficient)\"\n        )\n\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"en/api/#wandas.processing.FFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n    Parameters\n    ----------\n    input_shape : tuple\n        \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n    Returns\n    -------\n    tuple\n        \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.FFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"FFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.IFFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : Optional[int], optional     IFFT size, default is None (determined based on input size) window : str, optional     Window function type, default is 'hann'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize IFFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : Optional[int], optional\n        IFFT size, default is None (determined based on input size)\n    window : str, optional\n        Window function type, default is 'hann'\n    \"\"\"\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"en/api/#wandas.processing.IFFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, freqs)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, samples)\n    \"\"\"\n    n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.IFFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iFFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.ISTFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    length: int | None = None,\n):\n    \"\"\"\n    Initialize ISTFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n    length : int, optional\n        Length of output signal. Default is None (determined from input)\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"ISTFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.length = length\n\n    # Instantiate ShortTimeFFT for ISTFT calculation\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",  # Consistent scaling with STFT\n    )\n\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        length=length,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.ISTFT.calculate_output_shape--references","title":"References","text":"<ul> <li>SciPy ShortTimeFFT.istft:   https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html</li> <li>SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after ISTFT operation.\n\n    Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n    output length based on the input spectrogram dimensions and output range\n    parameters (k0, k1).\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input spectrogram shape (channels, n_freqs, n_frames)\n        where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n    Returns\n    -------\n    tuple\n        Output shape (channels, output_samples) where output_samples is the\n        reconstructed signal length determined by the output range [k0, k1).\n\n    Notes\n    -----\n    The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n    When k1 is None (default), the maximum reconstructible signal length is\n    computed as:\n\n    .. math::\n\n        q_{max} = n_{frames} + p_{min}\n\n        k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n    The output length is then:\n\n    .. math::\n\n        output\\\\_samples = k_1 - k_0\n\n    where k0 defaults to 0 and k1 defaults to k_max.\n\n    Parameters that affect the calculation:\n    - n_frames: number of time frames in the STFT\n    - p_min: minimum frame index (ShortTimeFFT property)\n    - hop: hop length (samples between frames)\n    - m_num: window length\n    - m_num_mid: window midpoint position\n    - self.length: optional length override (if set, limits output)\n\n    References\n    ----------\n    - SciPy ShortTimeFFT.istft:\n      https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n    - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    \"\"\"\n    n_channels = input_shape[0]\n    n_frames = input_shape[-1]  # time_frames\n\n    # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n    # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    q_max = n_frames + self.SFT.p_min\n    k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n    # Default parameters: k0=0, k1=None (which becomes k_max)\n    # The output length is k1 - k0 = k_max - 0 = k_max\n    k0 = 0\n    k1 = k_max\n\n    # If self.length is specified, it acts as an override to limit the output\n    if self.length is not None:\n        k1 = min(self.length, k1)\n\n    output_samples = k1 - k0\n\n    return (n_channels, output_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.ISTFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iSTFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.STFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n):\n    \"\"\"\n    Initialize STFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"STFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",\n    )\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.STFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    n_samples = input_shape[-1]\n    n_f = len(self.SFT.f)\n    n_t = len(self.SFT.t(n_samples))\n    return (input_shape[0], n_f, n_t)\n</code></pre>"},{"location":"en/api/#wandas.processing.STFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"STFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.Coherence.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize coherence estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Coherence\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.Coherence.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.Coherence.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Coh\"\n</code></pre>"},{"location":"en/api/#wandas.processing.NOctSpectrum.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize N-octave spectrum\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"en/api/#wandas.processing.NOctSpectrum.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"en/api/#wandas.processing.NOctSpectrum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Oct\"\n</code></pre>"},{"location":"en/api/#wandas.processing.NOctSynthesis.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize octave synthesis\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"en/api/#wandas.processing.NOctSynthesis.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"en/api/#wandas.processing.NOctSynthesis.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Octs\"\n</code></pre>"},{"location":"en/api/#wandas.processing.TransferFunction.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize transfer function estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Transfer function\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.TransferFunction.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.TransferFunction.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"H\"\n</code></pre>"},{"location":"en/api/#wandas.processing.Welch.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft, win_length, or hop_length are invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    average: str = \"mean\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize Welch operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str, optional\n        Window function type, default is 'hann'\n    average : str, optional\n        Averaging method, default is 'mean'\n    detrend : str, optional\n        Detrend method, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft, win_length, or hop_length are invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Welch method\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n    self.average = average\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        average=average,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.Welch.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.Welch.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"PS\"\n</code></pre>"},{"location":"en/api/#wandas.processing.ABS.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize absolute value operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"en/api/#wandas.processing.ABS.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"abs\"\n</code></pre>"},{"location":"en/api/#wandas.processing.ABS.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"en/api/#wandas.processing.ChannelDifference.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other_channel : int     Channel to calculate difference with, default is 0</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, other_channel: int = 0):\n    \"\"\"\n    Initialize channel difference calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other_channel : int\n        Channel to calculate difference with, default is 0\n    \"\"\"\n    self.other_channel = other_channel\n    super().__init__(sampling_rate, other_channel=other_channel)\n</code></pre>"},{"location":"en/api/#wandas.processing.ChannelDifference.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"diff\"\n</code></pre>"},{"location":"en/api/#wandas.processing.ChannelDifference.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    result = data - data[self.other_channel]\n    return result\n</code></pre>"},{"location":"en/api/#wandas.processing.Mean.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"mean\"\n</code></pre>"},{"location":"en/api/#wandas.processing.Mean.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"en/api/#wandas.processing.Power.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) exponent : float     Power exponent</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, exponent: float):\n    \"\"\"\n    Initialize power operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    exponent : float\n        Power exponent\n    \"\"\"\n    super().__init__(sampling_rate)\n    self.exp = exponent\n</code></pre>"},{"location":"en/api/#wandas.processing.Power.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"pow\"\n</code></pre>"},{"location":"en/api/#wandas.processing.Power.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"en/api/#wandas.processing.Sum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"sum\"\n</code></pre>"},{"location":"en/api/#wandas.processing.Sum.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"en/api/#wandas.processing.ReSampling.__init__--raises","title":"Raises","text":"<p>ValueError     If sampling_rate or target_sr is not positive</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(self, sampling_rate: float, target_sr: float):\n    \"\"\"\n    Initialize resampling operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    target_sampling_rate : float\n        Target sampling rate (Hz)\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate or target_sr is not positive\n    \"\"\"\n    validate_sampling_rate(sampling_rate, \"source sampling rate\")\n    validate_sampling_rate(target_sr, \"target sampling rate\")\n    super().__init__(sampling_rate, target_sr=target_sr)\n    self.target_sr = target_sr\n</code></pre>"},{"location":"en/api/#wandas.processing.ReSampling.get_metadata_updates--notes","title":"Notes","text":"<p>Resampling always produces output at target_sr, regardless of input sampling rate. All necessary parameters are provided at initialization.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate to target sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    Resampling always produces output at target_sr, regardless of input\n    sampling rate. All necessary parameters are provided at initialization.\n    \"\"\"\n    return {\"sampling_rate\": self.target_sr}\n</code></pre>"},{"location":"en/api/#wandas.processing.ReSampling.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after resampling\n    ratio = float(self.target_sr) / float(self.sampling_rate)\n    n_samples = int(np.ceil(input_shape[-1] * ratio))\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.ReSampling.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"rs\"\n</code></pre>"},{"location":"en/api/#wandas.processing.RmsTrend.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) frame_length : int     Frame length, default is 2048 hop_length : int     Hop length, default is 512 ref : Union[list[float], float]     Reference value(s) for dB calculation dB : bool     Whether to convert to decibels Aw : bool     Whether to apply A-weighting before RMS calculation</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    ref: list[float] | float = 1.0,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; None:\n    \"\"\"\n    Initialize RMS calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    frame_length : int\n        Frame length, default is 2048\n    hop_length : int\n        Hop length, default is 512\n    ref : Union[list[float], float]\n        Reference value(s) for dB calculation\n    dB : bool\n        Whether to convert to decibels\n    Aw : bool\n        Whether to apply A-weighting before RMS calculation\n    \"\"\"\n    self.frame_length = frame_length\n    self.hop_length = hop_length\n    self.dB = dB\n    self.Aw = Aw\n    self.ref = np.array(ref if isinstance(ref, list) else [ref])\n    super().__init__(\n        sampling_rate,\n        frame_length=frame_length,\n        hop_length=hop_length,\n        dB=dB,\n        Aw=Aw,\n        ref=self.ref,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.RmsTrend.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is determined by downsampling the input by hop_length. All necessary parameters are provided at initialization.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on hop length.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate based on hop length\n\n    Notes\n    -----\n    The output sampling rate is determined by downsampling the input\n    by hop_length. All necessary parameters are provided at initialization.\n    \"\"\"\n    new_sr = self.sampling_rate / self.hop_length\n    return {\"sampling_rate\": new_sr}\n</code></pre>"},{"location":"en/api/#wandas.processing.RmsTrend.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, frames)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, frames)\n    \"\"\"\n    n_frames = librosa.feature.rms(\n        y=np.ones((1, input_shape[-1])),\n        frame_length=self.frame_length,\n        hop_length=self.hop_length,\n    ).shape[-1]\n    return (*input_shape[:-1], n_frames)\n</code></pre>"},{"location":"en/api/#wandas.processing.RmsTrend.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"RMS\"\n</code></pre>"},{"location":"en/api/#wandas.processing.Trim.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) start : float     Start time for trimming (seconds) end : float     End time for trimming (seconds)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    start: float,\n    end: float,\n):\n    \"\"\"\n    Initialize trimming operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    start : float\n        Start time for trimming (seconds)\n    end : float\n        End time for trimming (seconds)\n    \"\"\"\n    super().__init__(sampling_rate, start=start, end=end)\n    self.start = start\n    self.end = end\n    self.start_sample = int(start * sampling_rate)\n    self.end_sample = int(end * sampling_rate)\n    logger.debug(\n        f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.Trim.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after trimming\n    # Exclude parts where there is no signal\n    end_sample = min(self.end_sample, input_shape[-1])\n    n_samples = end_sample - self.start_sample\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.Trim.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"trim\"\n</code></pre>"},{"location":"en/api/#wandas.processing.create_operation","title":"<code>create_operation(name, sampling_rate, **params)</code>","text":"<p>Create operation instance from name and parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def create_operation(\n    name: str, sampling_rate: float, **params: Any\n) -&gt; AudioOperation[Any, Any]:\n    \"\"\"Create operation instance from name and parameters\"\"\"\n    operation_class = get_operation(name)\n    return operation_class(sampling_rate, **params)\n</code></pre>"},{"location":"en/api/#wandas.processing.get_operation","title":"<code>get_operation(name)</code>","text":"<p>Get operation class by name</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_operation(name: str) -&gt; type[AudioOperation[Any, Any]]:\n    \"\"\"Get operation class by name\"\"\"\n    if name not in _OPERATION_REGISTRY:\n        raise ValueError(f\"Unknown operation type: {name}\")\n    return _OPERATION_REGISTRY[name]\n</code></pre>"},{"location":"en/api/#wandas.processing.register_operation","title":"<code>register_operation(operation_class)</code>","text":"<p>Register a new operation type</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def register_operation(operation_class: type) -&gt; None:\n    \"\"\"Register a new operation type\"\"\"\n\n    if not issubclass(operation_class, AudioOperation):\n        raise TypeError(\"Strategy class must inherit from AudioOperation.\")\n    if inspect.isabstract(operation_class):\n        raise TypeError(\"Cannot register abstract AudioOperation class.\")\n\n    _OPERATION_REGISTRY[operation_class.name] = operation_class\n</code></pre>"},{"location":"en/api/#wandas.processing.base.AudioOperation","title":"<code>AudioOperation</code>","text":"<p>               Bases: <code>Generic[InputArrayType, OutputArrayType]</code></p> <p>Abstract base class for audio processing operations.</p> Source code in <code>wandas/processing/base.py</code> <pre><code>class AudioOperation(Generic[InputArrayType, OutputArrayType]):\n    \"\"\"Abstract base class for audio processing operations.\"\"\"\n\n    # Class variable: operation name\n    name: ClassVar[str]\n\n    def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n        \"\"\"\n        Initialize AudioOperation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        pure : bool, default=True\n            Whether the operation is pure (deterministic with no side effects).\n            When True, Dask can cache results for identical inputs.\n            Set to False only if the operation has side effects or is non-deterministic.\n        **params : Any\n            Operation-specific parameters\n        \"\"\"\n        self.sampling_rate = sampling_rate\n        self.pure = pure\n        self.params = params\n\n        # Validate parameters during initialization\n        self.validate_params()\n\n        # Create processor function (lazy initialization possible)\n        self._setup_processor()\n\n        logger.debug(\n            f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n        pass\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up processor function (implemented by subclasses)\"\"\"\n        pass\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Get metadata updates to apply after processing.\n\n        This method allows operations to specify how metadata should be\n        updated after processing. By default, no metadata is updated.\n\n        Returns\n        -------\n        dict\n            Dictionary of metadata updates. Can include:\n            - 'sampling_rate': New sampling rate (float)\n            - Other metadata keys as needed\n\n        Examples\n        --------\n        Return empty dict for operations that don't change metadata:\n\n        &gt;&gt;&gt; return {}\n\n        Return new sampling rate for operations that resample:\n\n        &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n        Notes\n        -----\n        This method is called by the framework after processing to update\n        the frame metadata. Subclasses should override this method if they\n        need to update metadata (e.g., changing sampling rate).\n\n        Design principle: Operations should use parameters provided at\n        initialization (via __init__). All necessary information should be\n        available as instance variables.\n        \"\"\"\n        return {}\n\n    def get_display_name(self) -&gt; str | None:\n        \"\"\"\n        Get display name for the operation for use in channel labels.\n\n        This method allows operations to customize how they appear in\n        channel labels. By default, returns None, which means the\n        operation name will be used.\n\n        Returns\n        -------\n        str or None\n            Display name for the operation. If None, the operation name\n            (from the `name` class variable) is used.\n\n        Examples\n        --------\n        Default behavior (returns None, uses operation name):\n\n        &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n        ...     name = \"normalize\"\n        &gt;&gt;&gt; op = NormalizeOp(44100)\n        &gt;&gt;&gt; op.get_display_name()  # Returns None\n        &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n        Custom display name:\n\n        &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n        ...     name = \"lowpass_filter\"\n        ...\n        ...     def __init__(self, sr, cutoff):\n        ...         self.cutoff = cutoff\n        ...         super().__init__(sr, cutoff=cutoff)\n        ...\n        ...     def get_display_name(self):\n        ...         return f\"lpf_{self.cutoff}Hz\"\n        &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n        &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n        &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n        Notes\n        -----\n        Subclasses can override this method to provide operation-specific\n        display names that include parameter information, making labels\n        more informative.\n        \"\"\"\n        return None\n\n    def _process_array(self, x: InputArrayType) -&gt; OutputArrayType:\n        \"\"\"Processing function (implemented by subclasses)\"\"\"\n        # Default is no-op function\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n\n    def _create_named_wrapper(self) -&gt; Any:\n        \"\"\"\n        Create a named wrapper function for better Dask graph visualization.\n\n        Returns\n        -------\n        callable\n            A wrapper function with the operation name set as __name__.\n        \"\"\"\n\n        def operation_wrapper(x: InputArrayType) -&gt; OutputArrayType:\n            return self._process_array(x)\n\n        # Set the function name to the operation name for better visualization\n        operation_wrapper.__name__ = self.name\n        return operation_wrapper\n\n    def process_array(self, x: InputArrayType) -&gt; Any:\n        \"\"\"\n        Processing function wrapped with @dask.delayed.\n\n        This method returns a Delayed object that can be computed later.\n        The operation name is used in the Dask task graph for better visualization.\n\n        Parameters\n        ----------\n        x : InputArrayType\n            Input array to process.\n\n        Returns\n        -------\n        dask.delayed.Delayed\n            A Delayed object representing the computation.\n        \"\"\"\n        logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n        # Create wrapper with operation name and wrap it with dask.delayed\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        return delayed_func(x)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation.\n\n        This method can be overridden by subclasses for efficiency.\n        If not overridden, it will execute _process_array on a small test array\n        to determine the output shape.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n\n        Notes\n        -----\n        The default implementation creates a minimal test array and processes it\n        to determine output shape. For performance-critical code, subclasses should\n        override this method with a direct calculation.\n        \"\"\"\n        # Try to infer shape by executing _process_array on test data\n        import numpy as np\n\n        try:\n            # Create minimal test array with input shape\n            if len(input_shape) == 0:\n                return input_shape\n\n            # Create test input with correct dtype\n            # Try complex first, fall back to float if needed\n            test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n            # Process test input\n            test_output: Any = self._process_array(test_input)\n\n            # Return the shape of the output\n            if isinstance(test_output, np.ndarray):\n                return tuple(int(s) for s in test_output.shape)\n            return input_shape\n        except Exception as e:\n            logger.warning(\n                f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n                \"Please implement calculate_output_shape method.\"\n            )\n            raise NotImplementedError(\n                f\"Subclass {self.__class__.__name__} must implement \"\n                f\"calculate_output_shape or ensure _process_array can be \"\n                f\"called with test data.\"\n            ) from e\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        \"\"\"\n        Execute operation and return result\n        data shape is (channels, samples)\n        \"\"\"\n        # Add task as delayed processing with custom name for visualization\n        logger.debug(\"Adding delayed operation to computation graph\")\n\n        # Create a wrapper function with the operation name\n        # This allows Dask to use the operation name in the task graph\n        wrapper = self._create_named_wrapper()\n        delayed_func = delayed(wrapper, pure=self.pure)\n        delayed_result = delayed_func(data)\n\n        # Convert delayed result to dask array and return\n        output_shape = self.calculate_output_shape(data.shape)\n        return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre> Attributes\u00b6 <code></code> <code>name</code> <code>class-attribute</code> \u00b6 <code></code> <code>sampling_rate = sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>pure = pure</code> <code>instance-attribute</code> \u00b6 <code></code> <code>params = params</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, *, pure=True, **params)</code> \u00b6 <p>Initialize AudioOperation.</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters (raises exception if invalid)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n    pass\n</code></pre> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Get metadata updates to apply after processing.</p> <p>This method allows operations to specify how metadata should be updated after processing. By default, no metadata is updated.</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> <p>This method allows operations to customize how they appear in channel labels. By default, returns None, which means the operation name will be used.</p> <code></code> <code>process_array(x)</code> \u00b6 <p>Processing function wrapped with @dask.delayed.</p> <p>This method returns a Delayed object that can be computed later. The operation name is used in the Dask task graph for better visualization.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <p>This method can be overridden by subclasses for efficiency. If not overridden, it will execute _process_array on a small test array to determine the output shape.</p> <code></code> <code>process(data)</code> \u00b6 <p>Execute operation and return result data shape is (channels, samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    \"\"\"\n    Execute operation and return result\n    data shape is (channels, samples)\n    \"\"\"\n    # Add task as delayed processing with custom name for visualization\n    logger.debug(\"Adding delayed operation to computation graph\")\n\n    # Create a wrapper function with the operation name\n    # This allows Dask to use the operation name in the task graph\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    delayed_result = delayed_func(data)\n\n    # Convert delayed result to dask array and return\n    output_shape = self.calculate_output_shape(data.shape)\n    return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"en/api/#wandas.processing.base.AudioOperation.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) pure : bool, default=True     Whether the operation is pure (deterministic with no side effects).     When True, Dask can cache results for identical inputs.     Set to False only if the operation has side effects or is non-deterministic. **params : Any     Operation-specific parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n    \"\"\"\n    Initialize AudioOperation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    pure : bool, default=True\n        Whether the operation is pure (deterministic with no side effects).\n        When True, Dask can cache results for identical inputs.\n        Set to False only if the operation has side effects or is non-deterministic.\n    **params : Any\n        Operation-specific parameters\n    \"\"\"\n    self.sampling_rate = sampling_rate\n    self.pure = pure\n    self.params = params\n\n    # Validate parameters during initialization\n    self.validate_params()\n\n    # Create processor function (lazy initialization possible)\n    self._setup_processor()\n\n    logger.debug(\n        f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.base.AudioOperation.get_metadata_updates--notes","title":"Notes","text":"<p>This method is called by the framework after processing to update the frame metadata. Subclasses should override this method if they need to update metadata (e.g., changing sampling rate).</p> <p>Design principle: Operations should use parameters provided at initialization (via init). All necessary information should be available as instance variables.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    This method allows operations to specify how metadata should be\n    updated after processing. By default, no metadata is updated.\n\n    Returns\n    -------\n    dict\n        Dictionary of metadata updates. Can include:\n        - 'sampling_rate': New sampling rate (float)\n        - Other metadata keys as needed\n\n    Examples\n    --------\n    Return empty dict for operations that don't change metadata:\n\n    &gt;&gt;&gt; return {}\n\n    Return new sampling rate for operations that resample:\n\n    &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n    Notes\n    -----\n    This method is called by the framework after processing to update\n    the frame metadata. Subclasses should override this method if they\n    need to update metadata (e.g., changing sampling rate).\n\n    Design principle: Operations should use parameters provided at\n    initialization (via __init__). All necessary information should be\n    available as instance variables.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"en/api/#wandas.processing.base.AudioOperation.get_display_name--notes","title":"Notes","text":"<p>Subclasses can override this method to provide operation-specific display names that include parameter information, making labels more informative.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_display_name(self) -&gt; str | None:\n    \"\"\"\n    Get display name for the operation for use in channel labels.\n\n    This method allows operations to customize how they appear in\n    channel labels. By default, returns None, which means the\n    operation name will be used.\n\n    Returns\n    -------\n    str or None\n        Display name for the operation. If None, the operation name\n        (from the `name` class variable) is used.\n\n    Examples\n    --------\n    Default behavior (returns None, uses operation name):\n\n    &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n    ...     name = \"normalize\"\n    &gt;&gt;&gt; op = NormalizeOp(44100)\n    &gt;&gt;&gt; op.get_display_name()  # Returns None\n    &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n    Custom display name:\n\n    &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n    ...     name = \"lowpass_filter\"\n    ...\n    ...     def __init__(self, sr, cutoff):\n    ...         self.cutoff = cutoff\n    ...         super().__init__(sr, cutoff=cutoff)\n    ...\n    ...     def get_display_name(self):\n    ...         return f\"lpf_{self.cutoff}Hz\"\n    &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n    &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n    &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n    Notes\n    -----\n    Subclasses can override this method to provide operation-specific\n    display names that include parameter information, making labels\n    more informative.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"en/api/#wandas.processing.base.AudioOperation.process_array--returns","title":"Returns","text":"<p>dask.delayed.Delayed     A Delayed object representing the computation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def process_array(self, x: InputArrayType) -&gt; Any:\n    \"\"\"\n    Processing function wrapped with @dask.delayed.\n\n    This method returns a Delayed object that can be computed later.\n    The operation name is used in the Dask task graph for better visualization.\n\n    Parameters\n    ----------\n    x : InputArrayType\n        Input array to process.\n\n    Returns\n    -------\n    dask.delayed.Delayed\n        A Delayed object representing the computation.\n    \"\"\"\n    logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n    # Create wrapper with operation name and wrap it with dask.delayed\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    return delayed_func(x)\n</code></pre>"},{"location":"en/api/#wandas.processing.base.AudioOperation.calculate_output_shape--notes","title":"Notes","text":"<p>The default implementation creates a minimal test array and processes it to determine output shape. For performance-critical code, subclasses should override this method with a direct calculation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    This method can be overridden by subclasses for efficiency.\n    If not overridden, it will execute _process_array on a small test array\n    to determine the output shape.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n\n    Notes\n    -----\n    The default implementation creates a minimal test array and processes it\n    to determine output shape. For performance-critical code, subclasses should\n    override this method with a direct calculation.\n    \"\"\"\n    # Try to infer shape by executing _process_array on test data\n    import numpy as np\n\n    try:\n        # Create minimal test array with input shape\n        if len(input_shape) == 0:\n            return input_shape\n\n        # Create test input with correct dtype\n        # Try complex first, fall back to float if needed\n        test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n        # Process test input\n        test_output: Any = self._process_array(test_input)\n\n        # Return the shape of the output\n        if isinstance(test_output, np.ndarray):\n            return tuple(int(s) for s in test_output.shape)\n        return input_shape\n    except Exception as e:\n        logger.warning(\n            f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n            \"Please implement calculate_output_shape method.\"\n        )\n        raise NotImplementedError(\n            f\"Subclass {self.__class__.__name__} must implement \"\n            f\"calculate_output_shape or ensure _process_array can be \"\n            f\"called with test data.\"\n        ) from e\n</code></pre>"},{"location":"en/api/#wandas.processing.base.register_operation","title":"<code>register_operation(operation_class)</code>","text":"<p>Register a new operation type</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def register_operation(operation_class: type) -&gt; None:\n    \"\"\"Register a new operation type\"\"\"\n\n    if not issubclass(operation_class, AudioOperation):\n        raise TypeError(\"Strategy class must inherit from AudioOperation.\")\n    if inspect.isabstract(operation_class):\n        raise TypeError(\"Cannot register abstract AudioOperation class.\")\n\n    _OPERATION_REGISTRY[operation_class.name] = operation_class\n</code></pre>"},{"location":"en/api/#wandas.processing.base.get_operation","title":"<code>get_operation(name)</code>","text":"<p>Get operation class by name</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_operation(name: str) -&gt; type[AudioOperation[Any, Any]]:\n    \"\"\"Get operation class by name\"\"\"\n    if name not in _OPERATION_REGISTRY:\n        raise ValueError(f\"Unknown operation type: {name}\")\n    return _OPERATION_REGISTRY[name]\n</code></pre>"},{"location":"en/api/#wandas.processing.base.create_operation","title":"<code>create_operation(name, sampling_rate, **params)</code>","text":"<p>Create operation instance from name and parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def create_operation(\n    name: str, sampling_rate: float, **params: Any\n) -&gt; AudioOperation[Any, Any]:\n    \"\"\"Create operation instance from name and parameters\"\"\"\n    operation_class = get_operation(name)\n    return operation_class(sampling_rate, **params)\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.HpssHarmonic","title":"<code>HpssHarmonic</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Harmonic operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssHarmonic(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Harmonic operation\"\"\"\n\n    name = \"hpss_harmonic\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Harmonic\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Hrm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Harmonic\"\"\"\n        logger.debug(f\"Applying HPSS Harmonic to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.harmonic(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Harmonic applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'hpss_harmonic'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>kwargs = kwargs</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, **kwargs)</code> \u00b6 <p>Initialize HPSS Harmonic</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Hrm\"\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.HpssHarmonic.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Harmonic\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.HpssPercussive","title":"<code>HpssPercussive</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>HPSS Percussive operation</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class HpssPercussive(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"HPSS Percussive operation\"\"\"\n\n    name = \"hpss_percussive\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        **kwargs: Any,\n    ):\n        \"\"\"\n        Initialize HPSS Percussive\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        self.kwargs = kwargs\n        super().__init__(sampling_rate, **kwargs)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Prc\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for HPSS Percussive\"\"\"\n        logger.debug(f\"Applying HPSS Percussive to array with shape: {x.shape}\")\n        result: NDArrayReal = effects.percussive(x, **self.kwargs)\n        logger.debug(\n            f\"HPSS Percussive applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'hpss_percussive'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>kwargs = kwargs</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, **kwargs)</code> \u00b6 <p>Initialize HPSS Percussive</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Prc\"\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.HpssPercussive.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Percussive\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.Normalize","title":"<code>Normalize</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Signal normalization operation using librosa.util.normalize</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class Normalize(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Signal normalization operation using librosa.util.normalize\"\"\"\n\n    name = \"normalize\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        norm: float | None = np.inf,\n        axis: int | None = -1,\n        threshold: float | None = None,\n        fill: bool | None = None,\n    ):\n        \"\"\"\n        Initialize normalization operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        norm : float or np.inf, default=np.inf\n            Norm type. Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n            - float: Lp norm\n            - None: No normalization\n        axis : int or None, default=-1\n            Axis along which to normalize.\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold : float or None, optional\n            Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill : bool or None, optional\n            Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n        Raises\n        ------\n        ValueError\n            If norm parameter is invalid or threshold is negative\n        \"\"\"\n        # Validate norm parameter\n        if norm is not None and not isinstance(norm, int | float):\n            raise ValueError(\n                f\"Invalid normalization method\\n\"\n                f\"  Got: {type(norm).__name__} ({norm})\\n\"\n                f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n                f\"Norm parameter must be a numeric value or None.\\n\"\n                f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n                f\"1 (L1 norm), 0 (pseudo L0)\"\n            )\n\n        # Validate that norm is non-negative (except for -np.inf which is valid)\n        if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n            raise ValueError(\n                f\"Invalid normalization method\\n\"\n                f\"  Got: {norm}\\n\"\n                f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n                f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n                f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n                f\"1 (L1 norm), 0 (pseudo L0)\"\n            )\n\n        # Validate threshold\n        if threshold is not None and threshold &lt; 0:\n            raise ValueError(\n                f\"Invalid threshold for normalization\\n\"\n                f\"  Got: {threshold}\\n\"\n                f\"  Expected: Non-negative value or None\\n\"\n                f\"Threshold must be non-negative.\\n\"\n                f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n            )\n\n        super().__init__(\n            sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n        )\n        self.norm = norm\n        self.axis = axis\n        self.threshold = threshold\n        self.fill = fill\n        logger.debug(\n            f\"Initialized Normalize operation with norm={norm}, \"\n            f\"axis={axis}, threshold={threshold}, fill={fill}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"norm\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform normalization processing\"\"\"\n        logger.debug(\n            f\"Applying normalization to array with shape: {x.shape}, \"\n            f\"norm={self.norm}, axis={self.axis}\"\n        )\n\n        # Apply librosa.util.normalize\n        result: NDArrayReal = librosa_util.normalize(\n            x, norm=self.norm, axis=self.axis, threshold=self.threshold, fill=self.fill\n        )\n\n        logger.debug(\n            f\"Normalization applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'normalize'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>norm = norm</code> <code>instance-attribute</code> \u00b6 <code></code> <code>axis = axis</code> <code>instance-attribute</code> \u00b6 <code></code> <code>threshold = threshold</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fill = fill</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, norm=np.inf, axis=-1, threshold=None, fill=None)</code> \u00b6 <p>Initialize normalization operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"norm\"\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.Normalize.__init__--raises","title":"Raises","text":"<p>ValueError     If norm parameter is invalid or threshold is negative</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    norm: float | None = np.inf,\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n):\n    \"\"\"\n    Initialize normalization operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    norm : float or np.inf, default=np.inf\n        Norm type. Supported values:\n        - np.inf: Maximum absolute value normalization\n        - -np.inf: Minimum absolute value normalization\n        - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n        - float: Lp norm\n        - None: No normalization\n    axis : int or None, default=-1\n        Axis along which to normalize.\n        - -1: Normalize along time axis (each channel independently)\n        - None: Global normalization across all axes\n        - int: Normalize along specified axis\n    threshold : float or None, optional\n        Threshold below which values are considered zero.\n        If None, no threshold is applied.\n    fill : bool or None, optional\n        Value to fill when the norm is zero.\n        If None, the zero vector remains zero.\n\n    Raises\n    ------\n    ValueError\n        If norm parameter is invalid or threshold is negative\n    \"\"\"\n    # Validate norm parameter\n    if norm is not None and not isinstance(norm, int | float):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {type(norm).__name__} ({norm})\\n\"\n            f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be a numeric value or None.\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate that norm is non-negative (except for -np.inf which is valid)\n    if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {norm}\\n\"\n            f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate threshold\n    if threshold is not None and threshold &lt; 0:\n        raise ValueError(\n            f\"Invalid threshold for normalization\\n\"\n            f\"  Got: {threshold}\\n\"\n            f\"  Expected: Non-negative value or None\\n\"\n            f\"Threshold must be non-negative.\\n\"\n            f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n        )\n\n    super().__init__(\n        sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    self.norm = norm\n    self.axis = axis\n    self.threshold = threshold\n    self.fill = fill\n    logger.debug(\n        f\"Initialized Normalize operation with norm={norm}, \"\n        f\"axis={axis}, threshold={threshold}, fill={fill}\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.Normalize.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.RemoveDC","title":"<code>RemoveDC</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Remove DC component (DC offset) from the signal.</p> <p>This operation removes the DC component by subtracting the mean value from each channel, centering the signal around zero.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class RemoveDC(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This operation removes the DC component by subtracting the mean value\n    from each channel, centering the signal around zero.\n    \"\"\"\n\n    name = \"remove_dc\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"Initialize DC removal operation.\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n        logger.debug(\"Initialized RemoveDC operation\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"Calculate output data shape after operation.\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"dcRM\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform DC removal processing.\n\n        Parameters\n        ----------\n        x : NDArrayReal\n            Input signal array (channels, samples)\n\n        Returns\n        -------\n        NDArrayReal\n            Signal with DC component removed\n        \"\"\"\n        logger.debug(f\"Removing DC component from array with shape: {x.shape}\")\n\n        # Subtract mean along time axis (axis=1 for channel data)\n        mean_values = x.mean(axis=-1, keepdims=True)\n        result: NDArrayReal = x - mean_values\n\n        logger.debug(f\"DC removal applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'remove_dc'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate)</code> \u00b6 <p>Initialize DC removal operation.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation.</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"dcRM\"\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.RemoveDC.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"Initialize DC removal operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n    logger.debug(\"Initialized RemoveDC operation\")\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.RemoveDC.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"Calculate output data shape after operation.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.AddWithSNR","title":"<code>AddWithSNR</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Addition operation considering SNR</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class AddWithSNR(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Addition operation considering SNR\"\"\"\n\n    name = \"add_with_snr\"\n\n    def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n        \"\"\"\n        Initialize addition operation considering SNR\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other : DaArray\n            Noise signal to add (channel-frame format)\n        snr : float\n            Signal-to-noise ratio (dB)\n        \"\"\"\n        super().__init__(sampling_rate, other=other, snr=snr)\n\n        self.other = other\n        self.snr = snr\n        logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape (same as input)\n        \"\"\"\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"+SNR\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Perform addition processing considering SNR\"\"\"\n        logger.debug(f\"Applying SNR-based addition with shape: {x.shape}\")\n        other: NDArrayReal = self.other.compute()\n\n        # Use multi-channel versions of calculate_rms and calculate_desired_noise_rms\n        clean_rms = util.calculate_rms(x)\n        other_rms = util.calculate_rms(other)\n\n        # Adjust noise gain based on specified SNR (apply per channel)\n        desired_noise_rms = util.calculate_desired_noise_rms(clean_rms, self.snr)\n\n        # Apply gain per channel using broadcasting\n        gain = desired_noise_rms / other_rms\n        # Add adjusted noise to signal\n        result: NDArrayReal = x + other * gain\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'add_with_snr'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>other = other</code> <code>instance-attribute</code> \u00b6 <code></code> <code>snr = snr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, other, snr=1.0)</code> \u00b6 <p>Initialize addition operation considering SNR</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"+SNR\"\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.AddWithSNR.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other : DaArray     Noise signal to add (channel-frame format) snr : float     Signal-to-noise ratio (dB)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n    \"\"\"\n    Initialize addition operation considering SNR\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other : DaArray\n        Noise signal to add (channel-frame format)\n    snr : float\n        Signal-to-noise ratio (dB)\n    \"\"\"\n    super().__init__(sampling_rate, other=other, snr=snr)\n\n    self.other = other\n    self.snr = snr\n    logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.AddWithSNR.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/#wandas.processing.effects.Fade","title":"<code>Fade</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Fade operation using a Tukey (tapered cosine) window.</p> <p>This operation applies symmetric fade-in and fade-out with the same duration. The Tukey window alpha parameter is computed from the fade duration so that the tapered portion equals the requested fade length at each end.</p> Source code in <code>wandas/processing/effects.py</code> <pre><code>class Fade(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Fade operation using a Tukey (tapered cosine) window.\n\n    This operation applies symmetric fade-in and fade-out with the same\n    duration. The Tukey window alpha parameter is computed from the fade\n    duration so that the tapered portion equals the requested fade length\n    at each end.\n    \"\"\"\n\n    name = \"fade\"\n\n    def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n        self.fade_ms = float(fade_ms)\n        # Precompute fade length in samples at construction time\n        self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n        super().__init__(sampling_rate, fade_ms=fade_ms)\n\n    def validate_params(self) -&gt; None:\n        if self.fade_ms &lt; 0:\n            raise ValueError(\"fade_ms must be non-negative\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"fade\"\n\n    @staticmethod\n    def calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n        \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n        The alpha parameter determines what fraction of the window is tapered.\n        For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n        that each side's taper has exactly fade_len samples.\n\n        Parameters\n        ----------\n        fade_len : int\n            Desired fade length in samples for each end (in and out).\n        n_samples : int\n            Total number of samples in the signal.\n\n        Returns\n        -------\n        float\n            Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n        Examples\n        --------\n        &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n        0.2\n        &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n        1.0\n        \"\"\"\n        alpha = float(2 * fade_len) / float(n_samples)\n        return min(1.0, alpha)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        logger.debug(f\"Applying Tukey Fade to array with shape: {x.shape}\")\n\n        arr = x\n        if arr.ndim == 1:\n            arr = arr.reshape(1, -1)\n\n        n_samples = int(arr.shape[-1])\n\n        # If no fade requested, return input\n        if self.fade_len &lt;= 0:\n            return arr\n\n        if 2 * self.fade_len &gt;= n_samples:\n            raise ValueError(\n                \"Fade length too long: 2*fade_ms must be less than signal length\"\n            )\n\n        # Calculate Tukey window alpha parameter\n        alpha = self.calculate_tukey_alpha(self.fade_len, n_samples)\n\n        # Create tukey window (numpy) and apply\n        env = sp_windows.tukey(n_samples, alpha=alpha)\n\n        result: NDArrayReal = arr * env[None, :]\n        logger.debug(\"Tukey fade applied\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'fade'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fade_ms = float(fade_ms)</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, fade_ms=50)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n    self.fade_ms = float(fade_ms)\n    # Precompute fade length in samples at construction time\n    self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n    super().__init__(sampling_rate, fade_ms=fade_ms)\n</code></pre> <code></code> <code>validate_params()</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def validate_params(self) -&gt; None:\n    if self.fade_ms &lt; 0:\n        raise ValueError(\"fade_ms must be non-negative\")\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fade\"\n</code></pre> <code></code> <code>calculate_tukey_alpha(fade_len, n_samples)</code> <code>staticmethod</code> \u00b6 <p>Calculate Tukey window alpha parameter from fade length.</p> <p>The alpha parameter determines what fraction of the window is tapered. For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures that each side's taper has exactly fade_len samples.</p>"},{"location":"en/api/#wandas.processing.effects.Fade.calculate_tukey_alpha--examples","title":"Examples","text":"<p>Fade.calculate_tukey_alpha(fade_len=20, n_samples=200) 0.2 Fade.calculate_tukey_alpha(fade_len=100, n_samples=100) 1.0</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>@staticmethod\ndef calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n    \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n    The alpha parameter determines what fraction of the window is tapered.\n    For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n    that each side's taper has exactly fade_len samples.\n\n    Parameters\n    ----------\n    fade_len : int\n        Desired fade length in samples for each end (in and out).\n    n_samples : int\n        Total number of samples in the signal.\n\n    Returns\n    -------\n    float\n        Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n    Examples\n    --------\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n    0.2\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n    1.0\n    \"\"\"\n    alpha = float(2 * fade_len) / float(n_samples)\n    return min(1.0, alpha)\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.HighPassFilter","title":"<code>HighPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>High-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class HighPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"High-pass filter operation\"\"\"\n\n    name = \"highpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize high-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up high-pass filter processor\"\"\"\n        # Calculate filter coefficients (once) - safely retrieve from instance variables\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"high\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Highpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"hpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying highpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'highpass_filter'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>a</code> <code>instance-attribute</code> \u00b6 <code></code> <code>b</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cutoff = cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>order = order</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, cutoff, order=4)</code> \u00b6 <p>Initialize high-pass filter</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"hpf\"\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.HighPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize high-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.LowPassFilter","title":"<code>LowPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Low-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class LowPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Low-pass filter operation\"\"\"\n\n    name = \"lowpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n        \"\"\"\n        Initialize low-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        cutoff : float\n            Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            (sampling_rate / 2).\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n        \"\"\"\n        self.cutoff = cutoff\n        self.order = order\n        super().__init__(sampling_rate, cutoff=cutoff, order=order)\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Solutions:\\n\"\n                f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n                f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n                f\"    using resample()\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up low-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        normal_cutoff = self.cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(self.order, normal_cutoff, btype=\"low\")  # type: ignore [unused-ignore]\n        logger.debug(f\"Lowpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"lpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying lowpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'lowpass_filter'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>a</code> <code>instance-attribute</code> \u00b6 <code></code> <code>b</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cutoff = cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>order = order</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, cutoff, order=4)</code> \u00b6 <p>Initialize low-pass filter</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"lpf\"\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.LowPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize low-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.BandPassFilter","title":"<code>BandPassFilter</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Band-pass filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class BandPassFilter(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Band-pass filter operation\"\"\"\n\n    name = \"bandpass_filter\"\n    a: NDArrayReal\n    b: NDArrayReal\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        low_cutoff: float,\n        high_cutoff: float,\n        order: int = 4,\n    ):\n        \"\"\"\n        Initialize band-pass filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        low_cutoff : float\n            Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n        high_cutoff : float\n            Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n            and greater than low_cutoff.\n        order : int, optional\n            Filter order, default is 4\n\n        Raises\n        ------\n        ValueError\n            If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n            or if low_cutoff &gt;= high_cutoff\n        \"\"\"\n        self.low_cutoff = low_cutoff\n        self.high_cutoff = high_cutoff\n        self.order = order\n        super().__init__(\n            sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n        )\n\n    def validate_params(self) -&gt; None:\n        \"\"\"Validate parameters\"\"\"\n        nyquist = self.sampling_rate / 2\n        if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Lower cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.low_cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Use a lower cutoff frequency below {nyquist} Hz\"\n            )\n        if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n            raise ValueError(\n                f\"Higher cutoff frequency out of valid range\\n\"\n                f\"  Got: {self.high_cutoff} Hz\\n\"\n                f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n                f\"The Nyquist frequency is half the sampling rate\\n\"\n                f\"  ({self.sampling_rate} Hz).\\n\"\n                f\"Filters cannot work above this limit due to aliasing.\\n\"\n                f\"Use a cutoff frequency below {nyquist} Hz\"\n            )\n        if self.low_cutoff &gt;= self.high_cutoff:\n            raise ValueError(\n                f\"Invalid bandpass filter cutoff frequencies\\n\"\n                f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n                f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n                f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n                f\"A bandpass filter passes frequencies between low and high\\n\"\n                f\"  cutoffs.\\n\"\n                f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n                f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n            )\n\n    def _setup_processor(self) -&gt; None:\n        \"\"\"Set up band-pass filter processor\"\"\"\n        nyquist = 0.5 * self.sampling_rate\n        low_normal_cutoff = self.low_cutoff / nyquist\n        high_normal_cutoff = self.high_cutoff / nyquist\n\n        # Precompute and save filter coefficients\n        self.b, self.a = signal.butter(\n            self.order, [low_normal_cutoff, high_normal_cutoff], btype=\"band\"\n        )  # type: ignore [unused-ignore]\n        logger.debug(f\"Bandpass filter coefficients calculated: b={self.b}, a={self.a}\")\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"bpf\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Filter processing wrapped with @dask.delayed\"\"\"\n        logger.debug(f\"Applying bandpass filter to array with shape: {x.shape}\")\n        result: NDArrayReal = signal.filtfilt(self.b, self.a, x, axis=1)\n        logger.debug(f\"Filter applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'bandpass_filter'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>a</code> <code>instance-attribute</code> \u00b6 <code></code> <code>b</code> <code>instance-attribute</code> \u00b6 <code></code> <code>low_cutoff = low_cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>high_cutoff = high_cutoff</code> <code>instance-attribute</code> \u00b6 <code></code> <code>order = order</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, low_cutoff, high_cutoff, order=4)</code> \u00b6 <p>Initialize band-pass filter</p> <code></code> <code>validate_params()</code> \u00b6 <p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Lower cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.low_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a lower cutoff frequency below {nyquist} Hz\"\n        )\n    if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Higher cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.high_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a cutoff frequency below {nyquist} Hz\"\n        )\n    if self.low_cutoff &gt;= self.high_cutoff:\n        raise ValueError(\n            f\"Invalid bandpass filter cutoff frequencies\\n\"\n            f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n            f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n            f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n            f\"A bandpass filter passes frequencies between low and high\\n\"\n            f\"  cutoffs.\\n\"\n            f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n            f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n        )\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"bpf\"\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.BandPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),     or if low_cutoff &gt;= high_cutoff</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    low_cutoff: float,\n    high_cutoff: float,\n    order: int = 4,\n):\n    \"\"\"\n    Initialize band-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    low_cutoff : float\n        Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n    high_cutoff : float\n        Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        and greater than low_cutoff.\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n        or if low_cutoff &gt;= high_cutoff\n    \"\"\"\n    self.low_cutoff = low_cutoff\n    self.high_cutoff = high_cutoff\n    self.order = order\n    super().__init__(\n        sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.AWeighting","title":"<code>AWeighting</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>A-weighting filter operation</p> Source code in <code>wandas/processing/filters.py</code> <pre><code>class AWeighting(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"A-weighting filter operation\"\"\"\n\n    name = \"a_weighting\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize A-weighting filter\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        return input_shape\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Aw\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for A-weighting filter\"\"\"\n        logger.debug(f\"Applying A-weighting to array with shape: {x.shape}\")\n        result = A_weight(x, self.sampling_rate)\n\n        # Handle case where A_weight returns a tuple\n        if isinstance(result, tuple):\n            # Use the first element of the tuple\n            result = result[0]\n\n        logger.debug(\n            f\"A-weighting applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'a_weighting'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate)</code> \u00b6 <p>Initialize A-weighting filter</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Aw\"\n</code></pre>"},{"location":"en/api/#wandas.processing.filters.AWeighting.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize A-weighting filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwtv.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize Loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwtv.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwtv.get_metadata_updates--notes","title":"Notes","text":"<p>All necessary parameters are provided at initialization. The output sampling rate is always 500 Hz regardless of input.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on MoSQITo's time resolution.\n\n    The Zwicker method uses approximately 2ms time steps,\n    which corresponds to 500 Hz sampling rate, independent of\n    the input sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    All necessary parameters are provided at initialization.\n    The output sampling rate is always 500 Hz regardless of input.\n    \"\"\"\n    return {\"sampling_rate\": 500.0}\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwtv.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape. For loudness, we return a placeholder shape     since the actual length is determined by the algorithm.     The shape will be (channels, time_samples) where time_samples     depends on the input length and algorithm parameters.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The loudness calculation produces a time-varying output where the time\n    resolution depends on the algorithm's internal processing. The exact\n    output length is determined dynamically by the loudness_zwtv function.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape. For loudness, we return a placeholder shape\n        since the actual length is determined by the algorithm.\n        The shape will be (channels, time_samples) where time_samples\n        depends on the input length and algorithm parameters.\n    \"\"\"\n    # Return a placeholder shape - the actual shape will be determined\n    # after processing since loudness_zwtv determines the time resolution\n    # For now, we estimate based on typical behavior (approx 2ms time steps)\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    # Rough estimate: one loudness value per 2ms (0.002s)\n    estimated_time_samples = int(input_shape[-1] / (self.sampling_rate * 0.002))\n    return (n_channels, estimated_time_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwst.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) field_type : str, default=\"free\"     Type of sound field ('free' or 'diffuse')</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, field_type: str = \"free\"):\n    \"\"\"\n    Initialize steady-state loudness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n    \"\"\"\n    self.field_type = field_type\n    super().__init__(sampling_rate, field_type=field_type)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwst.validate_params--raises","title":"Raises","text":"<p>ValueError     If field_type is not 'free' or 'diffuse'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If field_type is not 'free' or 'diffuse'\n    \"\"\"\n    if self.field_type not in (\"free\", \"diffuse\"):\n        raise ValueError(\n            f\"field_type must be 'free' or 'diffuse', got '{self.field_type}'\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwst.get_metadata_updates--notes","title":"Notes","text":"<p>Unlike time-varying loudness, steady-state loudness produces a single value, not a time series, so the sampling rate concept doesn't apply.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    For steady-state loudness, the output is a single value per channel,\n    so no sampling rate update is needed (output is scalar, not time-series).\n\n    Returns\n    -------\n    dict\n        Empty dictionary (no metadata updates needed)\n\n    Notes\n    -----\n    Unlike time-varying loudness, steady-state loudness produces a single\n    value, not a time series, so the sampling rate concept doesn't apply.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.LoudnessZwst.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape: (channels, 1) - one loudness value per channel</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The steady-state loudness calculation produces a single loudness value\n    per channel.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape: (channels, 1) - one loudness value per channel\n    \"\"\"\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    return (n_channels, 1)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.RoughnessDw.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) overlap : float, default=0.5     Overlapping coefficient (0.0 to 1.0)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n    \"\"\"\n    Initialize Roughness calculation operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    overlap : float, default=0.5\n        Overlapping coefficient (0.0 to 1.0)\n    \"\"\"\n    self.overlap = overlap\n    super().__init__(sampling_rate, overlap=overlap)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.RoughnessDw.validate_params--raises","title":"Raises","text":"<p>ValueError     If overlap is not in [0.0, 1.0]</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"\n    Validate parameters.\n\n    Raises\n    ------\n    ValueError\n        If overlap is not in [0.0, 1.0]\n    \"\"\"\n    if not 0.0 &lt;= self.overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.RoughnessDw.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is approximately 1 / (0.2 * (1 - overlap)) Hz.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on overlap and window size.\n\n    The Daniel &amp; Weber method uses 200ms windows. The output\n    sampling rate depends on the overlap:\n    - overlap=0.0: hop=200ms \u2192 fs=5 Hz\n    - overlap=0.5: hop=100ms \u2192 fs=10 Hz\n    - overlap=0.75: hop=50ms \u2192 fs=20 Hz\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    The output sampling rate is approximately 1 / (0.2 * (1 - overlap)) Hz.\n    \"\"\"\n    window_duration = 0.2  # 200ms window\n    hop_duration = window_duration * (1 - self.overlap)\n    output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n    return {\"sampling_rate\": output_sampling_rate}\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.RoughnessDw.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, time_samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    The roughness calculation produces a time-varying output where the\n    number of time points depends on the signal length and overlap.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, time_samples)\n    \"\"\"\n    n_channels = input_shape[0] if len(input_shape) &gt; 1 else 1\n    n_samples = input_shape[-1]\n\n    # Estimate output length based on window size and overlap\n    window_samples = int(0.2 * self.sampling_rate)  # 200ms\n    hop_samples = int(window_samples * (1 - self.overlap))\n\n    if hop_samples &gt; 0:\n        estimated_time_samples = max(\n            1, (n_samples - window_samples) // hop_samples + 1\n        )\n    else:\n        estimated_time_samples = 1\n\n    return (n_channels, estimated_time_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.psychoacoustic.RoughnessDwSpec","title":"<code>RoughnessDwSpec</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Specific roughness (R_spec) operation.</p> <p>Computes per-Bark-band specific roughness over time using MoSQITo's <code>roughness_dw</code> implementation. Output is band-by-time.</p> <p>The bark_axis is retrieved dynamically from MoSQITo during initialization to ensure consistency with MoSQITo's implementation. Results are cached based on sampling_rate and overlap to avoid redundant computations.</p> Source code in <code>wandas/processing/psychoacoustic.py</code> <pre><code>class RoughnessDwSpec(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Specific roughness (R_spec) operation.\n\n    Computes per-Bark-band specific roughness over time using MoSQITo's\n    `roughness_dw` implementation. Output is band-by-time.\n\n    The bark_axis is retrieved dynamically from MoSQITo during initialization\n    to ensure consistency with MoSQITo's implementation. Results are cached\n    based on sampling_rate and overlap to avoid redundant computations.\n    \"\"\"\n\n    name = \"roughness_dw_spec\"\n    # Class-level cache: {(sampling_rate, overlap): bark_axis}\n    _bark_axis_cache: dict[tuple[float, float], NDArrayReal] = {}\n\n    def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n        self.overlap = overlap\n        self.validate_params()\n        # Check cache first to avoid redundant MoSQITo calls\n        cache_key = (sampling_rate, overlap)\n        if cache_key in RoughnessDwSpec._bark_axis_cache:\n            logger.debug(\n                f\"Using cached bark_axis for sampling_rate={sampling_rate}, \"\n                f\"overlap={overlap}\"\n            )\n            self._bark_axis: NDArrayReal = RoughnessDwSpec._bark_axis_cache[cache_key]\n        else:\n            # Retrieve bark_axis dynamically from MoSQITo to ensure consistency\n            # Use a minimal reference signal to get the bark_axis structure\n            logger.debug(\n                f\"Computing bark_axis from MoSQITo for sampling_rate={sampling_rate}, \"\n                f\"overlap={overlap}\"\n            )\n            reference_signal = np.zeros(\n                int(sampling_rate * 0.2)\n            )  # 200ms minimal signal\n            try:\n                _, _, bark_axis_from_mosqito, _ = roughness_dw_mosqito(\n                    reference_signal, sampling_rate, overlap=overlap\n                )\n            except Exception as e:\n                logger.error(\n                    f\"Failed to retrieve bark_axis from MoSQITo's roughness_dw: {e}\"\n                )\n                raise RuntimeError(\n                    \"Could not initialize RoughnessDwSpec: error retrieving bark_axis \"\n                    \"from MoSQITo.\"\n                ) from e\n            if bark_axis_from_mosqito is None or (\n                hasattr(bark_axis_from_mosqito, \"__len__\")\n                and len(bark_axis_from_mosqito) == 0\n            ):\n                logger.error(\n                    \"MoSQITo's roughness_dw returned an empty or None bark_axis.\"\n                )\n                raise RuntimeError(\n                    \"Could not initialize RoughnessDwSpec: MoSQITo's roughness_dw \"\n                    \"returned an empty or None bark_axis.\"\n                )\n            self._bark_axis = bark_axis_from_mosqito\n            # Cache the result for future use\n            RoughnessDwSpec._bark_axis_cache[cache_key] = bark_axis_from_mosqito\n        super().__init__(sampling_rate, overlap=overlap)\n\n    @property\n    def bark_axis(self) -&gt; NDArrayReal:\n        return self._bark_axis\n\n    def validate_params(self) -&gt; None:\n        if not 0.0 &lt;= self.overlap &lt;= 1.0:\n            raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        window_duration = 0.2\n        hop_duration = window_duration * (1 - self.overlap)\n        output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n\n        return {\"sampling_rate\": output_sampling_rate, \"bark_axis\": self._bark_axis}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        n_bark_bands = len(self._bark_axis)\n        if len(input_shape) == 1:\n            n_samples = input_shape[0]\n            n_channels = 1\n        else:\n            n_channels, n_samples = input_shape[:2]\n\n        window_samples = int(0.2 * self.sampling_rate)\n        hop_samples = int(window_samples * (1 - self.overlap))\n\n        if hop_samples &gt; 0:\n            estimated_time_samples = max(\n                1, (n_samples - window_samples) // hop_samples + 1\n            )\n        else:\n            estimated_time_samples = 1\n\n        if n_channels == 1:\n            return (n_bark_bands, estimated_time_samples)\n        return (n_channels, n_bark_bands, estimated_time_samples)\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        logger.debug(\n            \"Calculating specific roughness for signal with shape: %s, overlap: %s\",\n            x.shape,\n            self.overlap,\n        )\n\n        # Ensure (n_channels, n_samples)\n        if x.ndim == 1:\n            x_proc: NDArrayReal = x.reshape(1, -1)\n        else:\n            x_proc = x\n\n        n_channels = x_proc.shape[0]\n        r_spec_list: list[NDArrayReal] = []\n\n        for ch in range(n_channels):\n            channel_data = np.asarray(x_proc[ch]).ravel()\n\n            # Call MoSQITo's roughness_dw (module-level import)\n            _, r_spec, bark_axis, _ = roughness_dw_mosqito(\n                channel_data, self.sampling_rate, overlap=self.overlap\n            )\n\n            r_spec_list.append(r_spec)\n            if self._bark_axis is None:\n                self._bark_axis = bark_axis\n\n            logger.debug(\n                \"Channel %d: calculated specific roughness shape=%s\",\n                ch,\n                r_spec.shape,\n            )\n\n        if n_channels == 1:\n            result: NDArrayReal = r_spec_list[0]\n            return result\n        return np.stack(r_spec_list, axis=0)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'roughness_dw_spec'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>overlap = overlap</code> <code>instance-attribute</code> \u00b6 <code></code> <code>bark_axis</code> <code>property</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, overlap=0.5)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def __init__(self, sampling_rate: float, overlap: float = 0.5) -&gt; None:\n    self.overlap = overlap\n    self.validate_params()\n    # Check cache first to avoid redundant MoSQITo calls\n    cache_key = (sampling_rate, overlap)\n    if cache_key in RoughnessDwSpec._bark_axis_cache:\n        logger.debug(\n            f\"Using cached bark_axis for sampling_rate={sampling_rate}, \"\n            f\"overlap={overlap}\"\n        )\n        self._bark_axis: NDArrayReal = RoughnessDwSpec._bark_axis_cache[cache_key]\n    else:\n        # Retrieve bark_axis dynamically from MoSQITo to ensure consistency\n        # Use a minimal reference signal to get the bark_axis structure\n        logger.debug(\n            f\"Computing bark_axis from MoSQITo for sampling_rate={sampling_rate}, \"\n            f\"overlap={overlap}\"\n        )\n        reference_signal = np.zeros(\n            int(sampling_rate * 0.2)\n        )  # 200ms minimal signal\n        try:\n            _, _, bark_axis_from_mosqito, _ = roughness_dw_mosqito(\n                reference_signal, sampling_rate, overlap=overlap\n            )\n        except Exception as e:\n            logger.error(\n                f\"Failed to retrieve bark_axis from MoSQITo's roughness_dw: {e}\"\n            )\n            raise RuntimeError(\n                \"Could not initialize RoughnessDwSpec: error retrieving bark_axis \"\n                \"from MoSQITo.\"\n            ) from e\n        if bark_axis_from_mosqito is None or (\n            hasattr(bark_axis_from_mosqito, \"__len__\")\n            and len(bark_axis_from_mosqito) == 0\n        ):\n            logger.error(\n                \"MoSQITo's roughness_dw returned an empty or None bark_axis.\"\n            )\n            raise RuntimeError(\n                \"Could not initialize RoughnessDwSpec: MoSQITo's roughness_dw \"\n                \"returned an empty or None bark_axis.\"\n            )\n        self._bark_axis = bark_axis_from_mosqito\n        # Cache the result for future use\n        RoughnessDwSpec._bark_axis_cache[cache_key] = bark_axis_from_mosqito\n    super().__init__(sampling_rate, overlap=overlap)\n</code></pre> <code></code> <code>validate_params()</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def validate_params(self) -&gt; None:\n    if not 0.0 &lt;= self.overlap &lt;= 1.0:\n        raise ValueError(f\"overlap must be in [0.0, 1.0], got {self.overlap}\")\n</code></pre> <code></code> <code>get_metadata_updates()</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    window_duration = 0.2\n    hop_duration = window_duration * (1 - self.overlap)\n    output_sampling_rate = 1.0 / hop_duration if hop_duration &gt; 0 else 5.0\n\n    return {\"sampling_rate\": output_sampling_rate, \"bark_axis\": self._bark_axis}\n</code></pre> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/psychoacoustic.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    n_bark_bands = len(self._bark_axis)\n    if len(input_shape) == 1:\n        n_samples = input_shape[0]\n        n_channels = 1\n    else:\n        n_channels, n_samples = input_shape[:2]\n\n    window_samples = int(0.2 * self.sampling_rate)\n    hop_samples = int(window_samples * (1 - self.overlap))\n\n    if hop_samples &gt; 0:\n        estimated_time_samples = max(\n            1, (n_samples - window_samples) // hop_samples + 1\n        )\n    else:\n        estimated_time_samples = 1\n\n    if n_channels == 1:\n        return (n_bark_bands, estimated_time_samples)\n    return (n_channels, n_bark_bands, estimated_time_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.FFT","title":"<code>FFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>FFT (Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class FFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"FFT (Fast Fourier Transform) operation\"\"\"\n\n    name = \"fft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize FFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is None (determined by input size)\n        window : str, optional\n            Window function type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not a positive integer\n        \"\"\"\n        # Validate n_fft parameter\n        if n_fft is not None and n_fft &lt;= 0:\n            raise ValueError(\n                f\"Invalid FFT size\\n\"\n                f\"  Got: {n_fft}\\n\"\n                f\"  Expected: Positive integer &gt; 0\\n\"\n                f\"FFT size must be a positive integer.\\n\"\n                f\"Common values: 512, 1024, 2048, 4096,\\n\"\n                f\"8192 (powers of 2 are most efficient)\"\n            )\n\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n        Parameters\n        ----------\n        input_shape : tuple\n            \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n        Returns\n        -------\n        tuple\n            \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"FFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"FFT\u64cd\u4f5c\u306e\u30d7\u30ed\u30bb\u30c3\u30b5\u95a2\u6570\u3092\u4f5c\u6210\"\"\"\n        from scipy.signal import get_window\n\n        if self.n_fft is not None and x.shape[-1] &gt; self.n_fft:\n            # If n_fft is specified and input length exceeds it, truncate\n            x = x[..., : self.n_fft]\n\n        win = get_window(self.window, x.shape[-1])\n        x = x * win\n        result: NDArrayComplex = np.fft.rfft(x, n=self.n_fft, axis=-1)\n        result[..., 1:-1] *= 2.0\n        # \u7a93\u95a2\u6570\u88dc\u6b63\n        scaling_factor = np.sum(win)\n        result = result / scaling_factor\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'fft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=None, window='hann')</code> \u00b6 <p>Initialize FFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>\u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"FFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.FFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not a positive integer</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize FFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is None (determined by input size)\n    window : str, optional\n        Window function type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not a positive integer\n    \"\"\"\n    # Validate n_fft parameter\n    if n_fft is not None and n_fft &lt;= 0:\n        raise ValueError(\n            f\"Invalid FFT size\\n\"\n            f\"  Got: {n_fft}\\n\"\n            f\"  Expected: Positive integer &gt; 0\\n\"\n            f\"FFT size must be a positive integer.\\n\"\n            f\"Common values: 512, 1024, 2048, 4096,\\n\"\n            f\"8192 (powers of 2 are most efficient)\"\n        )\n\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.FFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n    Parameters\n    ----------\n    input_shape : tuple\n        \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n    Returns\n    -------\n    tuple\n        \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.IFFT","title":"<code>IFFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>IFFT (Inverse Fast Fourier Transform) operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class IFFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"IFFT (Inverse Fast Fourier Transform) operation\"\"\"\n\n    name = \"ifft\"\n    n_fft: int | None\n    window: str\n\n    def __init__(\n        self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n    ):\n        \"\"\"\n        Initialize IFFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : Optional[int], optional\n            IFFT size, default is None (determined based on input size)\n        window : str, optional\n            Window function type, default is 'hann'\n        \"\"\"\n        self.n_fft = n_fft\n        self.window = window\n        super().__init__(sampling_rate, n_fft=n_fft, window=window)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, freqs)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, samples)\n        \"\"\"\n        n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iFFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"Create processor function for IFFT operation\"\"\"\n        logger.debug(f\"Applying IFFT to array with shape: {x.shape}\")\n\n        # Restore frequency component scaling (remove the 2.0 multiplier applied in FFT)\n        _x = x.copy()\n        _x[..., 1:-1] /= 2.0\n\n        # Execute IFFT\n        result: NDArrayReal = np.fft.irfft(_x, n=self.n_fft, axis=-1)\n\n        # Window function correction (inverse of FFT operation)\n        from scipy.signal import get_window\n\n        win = get_window(self.window, result.shape[-1])\n\n        # Correct the FFT window function scaling\n        scaling_factor = np.sum(win) / result.shape[-1]\n        result = result / scaling_factor\n\n        logger.debug(f\"IFFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'ifft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=None, window='hann')</code> \u00b6 <p>Initialize IFFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iFFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.IFFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : Optional[int], optional     IFFT size, default is None (determined based on input size) window : str, optional     Window function type, default is 'hann'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize IFFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : Optional[int], optional\n        IFFT size, default is None (determined based on input size)\n    window : str, optional\n        Window function type, default is 'hann'\n    \"\"\"\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.IFFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, freqs)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, samples)\n    \"\"\"\n    n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.STFT","title":"<code>STFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class STFT(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Short-Time Fourier Transform operation\"\"\"\n\n    name = \"stft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ):\n        \"\"\"\n        Initialize STFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"STFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",\n        )\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        n_samples = input_shape[-1]\n        n_f = len(self.SFT.f)\n        n_t = len(self.SFT.t(n_samples))\n        return (input_shape[0], n_f, n_t)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"STFT\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Apply SciPy STFT processing to multiple channels at once\"\"\"\n        logger.debug(f\"Applying SciPy STFT to array with shape: {x.shape}\")\n\n        # Convert 1D input to 2D\n        if x.ndim == 1:\n            x = x.reshape(1, -1)\n\n        # Apply STFT to all channels at once\n        result: NDArrayComplex = self.SFT.stft(x)\n        result[..., 1:-1, :] *= 2.0\n        logger.debug(f\"SciPy STFT applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'stft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Initialize STFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"STFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.STFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n):\n    \"\"\"\n    Initialize STFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"STFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",\n    )\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.STFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    n_samples = input_shape[-1]\n    n_f = len(self.SFT.f)\n    n_t = len(self.SFT.t(n_samples))\n    return (input_shape[0], n_f, n_t)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.ISTFT","title":"<code>ISTFT</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayComplex, NDArrayReal]</code></p> <p>Inverse Short-Time Fourier Transform operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class ISTFT(AudioOperation[NDArrayComplex, NDArrayReal]):\n    \"\"\"Inverse Short-Time Fourier Transform operation\"\"\"\n\n    name = \"istft\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        length: int | None = None,\n    ):\n        \"\"\"\n        Initialize ISTFT operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window type, default is 'hann'\n        length : int, optional\n            Length of output signal. Default is None (determined from input)\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"ISTFT\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.length = length\n\n        # Instantiate ShortTimeFFT for ISTFT calculation\n        self.SFT = ShortTimeFFT(\n            win=get_window(window, self.win_length),\n            hop=self.hop_length,\n            fs=sampling_rate,\n            mfft=self.n_fft,\n            scale_to=\"magnitude\",  # Consistent scaling with STFT\n        )\n\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            length=length,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after ISTFT operation.\n\n        Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n        output length based on the input spectrogram dimensions and output range\n        parameters (k0, k1).\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input spectrogram shape (channels, n_freqs, n_frames)\n            where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n        Returns\n        -------\n        tuple\n            Output shape (channels, output_samples) where output_samples is the\n            reconstructed signal length determined by the output range [k0, k1).\n\n        Notes\n        -----\n        The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n        When k1 is None (default), the maximum reconstructible signal length is\n        computed as:\n\n        .. math::\n\n            q_{max} = n_{frames} + p_{min}\n\n            k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n        The output length is then:\n\n        .. math::\n\n            output\\\\_samples = k_1 - k_0\n\n        where k0 defaults to 0 and k1 defaults to k_max.\n\n        Parameters that affect the calculation:\n        - n_frames: number of time frames in the STFT\n        - p_min: minimum frame index (ShortTimeFFT property)\n        - hop: hop length (samples between frames)\n        - m_num: window length\n        - m_num_mid: window midpoint position\n        - self.length: optional length override (if set, limits output)\n\n        References\n        ----------\n        - SciPy ShortTimeFFT.istft:\n          https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n        - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        \"\"\"\n        n_channels = input_shape[0]\n        n_frames = input_shape[-1]  # time_frames\n\n        # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n        # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n        q_max = n_frames + self.SFT.p_min\n        k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n        # Default parameters: k0=0, k1=None (which becomes k_max)\n        # The output length is k1 - k0 = k_max - 0 = k_max\n        k0 = 0\n        k1 = k_max\n\n        # If self.length is specified, it acts as an override to limit the output\n        if self.length is not None:\n            k1 = min(self.length, k1)\n\n        output_samples = k1 - k0\n\n        return (n_channels, output_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"iSTFT\"\n\n    def _process_array(self, x: NDArrayComplex) -&gt; NDArrayReal:\n        \"\"\"\n        Apply SciPy ISTFT processing to multiple channels at once using ShortTimeFFT\"\"\"\n        logger.debug(\n            f\"Applying SciPy ISTFT (ShortTimeFFT) to array with shape: {x.shape}\"\n        )\n\n        # Convert 2D input to 3D (assume single channel)\n        if x.ndim == 2:\n            x = x.reshape(1, *x.shape)\n\n        # Adjust scaling back if STFT applied factor of 2\n        _x = np.copy(x)\n        _x[..., 1:-1, :] /= 2.0\n\n        # Apply ISTFT using the ShortTimeFFT instance\n        result: NDArrayReal = self.SFT.istft(_x)\n\n        # Trim to desired length if specified\n        if self.length is not None:\n            result = result[..., : self.length]\n\n        logger.debug(\n            f\"ShortTimeFFT applied, returning result with shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'istft'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>length = length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>SFT = ShortTimeFFT(win=(get_window(window, self.win_length)), hop=(self.hop_length), fs=sampling_rate, mfft=(self.n_fft), scale_to='magnitude')</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', length=None)</code> \u00b6 <p>Initialize ISTFT operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after ISTFT operation.</p> <p>Uses the SciPy ShortTimeFFT calculation formula to compute the expected output length based on the input spectrogram dimensions and output range parameters (k0, k1).</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iSTFT\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.ISTFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    length: int | None = None,\n):\n    \"\"\"\n    Initialize ISTFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n    length : int, optional\n        Length of output signal. Default is None (determined from input)\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"ISTFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.length = length\n\n    # Instantiate ShortTimeFFT for ISTFT calculation\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",  # Consistent scaling with STFT\n    )\n\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        length=length,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.ISTFT.calculate_output_shape--references","title":"References","text":"<ul> <li>SciPy ShortTimeFFT.istft:   https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html</li> <li>SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after ISTFT operation.\n\n    Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n    output length based on the input spectrogram dimensions and output range\n    parameters (k0, k1).\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input spectrogram shape (channels, n_freqs, n_frames)\n        where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n    Returns\n    -------\n    tuple\n        Output shape (channels, output_samples) where output_samples is the\n        reconstructed signal length determined by the output range [k0, k1).\n\n    Notes\n    -----\n    The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n    When k1 is None (default), the maximum reconstructible signal length is\n    computed as:\n\n    .. math::\n\n        q_{max} = n_{frames} + p_{min}\n\n        k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n    The output length is then:\n\n    .. math::\n\n        output\\\\_samples = k_1 - k_0\n\n    where k0 defaults to 0 and k1 defaults to k_max.\n\n    Parameters that affect the calculation:\n    - n_frames: number of time frames in the STFT\n    - p_min: minimum frame index (ShortTimeFFT property)\n    - hop: hop length (samples between frames)\n    - m_num: window length\n    - m_num_mid: window midpoint position\n    - self.length: optional length override (if set, limits output)\n\n    References\n    ----------\n    - SciPy ShortTimeFFT.istft:\n      https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n    - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    \"\"\"\n    n_channels = input_shape[0]\n    n_frames = input_shape[-1]  # time_frames\n\n    # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n    # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    q_max = n_frames + self.SFT.p_min\n    k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n    # Default parameters: k0=0, k1=None (which becomes k_max)\n    # The output length is k1 - k0 = k_max - 0 = k_max\n    k0 = 0\n    k1 = k_max\n\n    # If self.length is specified, it acts as an override to limit the output\n    if self.length is not None:\n        k1 = min(self.length, k1)\n\n    output_samples = k1 - k0\n\n    return (n_channels, output_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.Welch","title":"<code>Welch</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Welch</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Welch(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Welch\"\"\"\n\n    name = \"welch\"\n    n_fft: int\n    window: str\n    hop_length: int | None\n    win_length: int | None\n    average: str\n    detrend: str\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        average: str = \"mean\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize Welch operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int, optional\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str, optional\n            Window function type, default is 'hann'\n        average : str, optional\n            Averaging method, default is 'mean'\n        detrend : str, optional\n            Detrend method, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft, win_length, or hop_length are invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Welch method\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.noverlap = (\n            self.win_length - self.hop_length if hop_length is not None else None\n        )\n        self.window = window\n        self.average = average\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            win_length=self.win_length,\n            hop_length=self.hop_length,\n            window=window,\n            average=average,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, freqs)\n        \"\"\"\n        n_freqs = self.n_fft // 2 + 1\n        return (*input_shape[:-1], n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"PS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for Welch operation\"\"\"\n        from scipy import signal as ss\n\n        _, result = ss.welch(\n            x,\n            nperseg=self.win_length,\n            noverlap=self.noverlap,\n            nfft=self.n_fft,\n            window=self.window,\n            average=self.average,\n            detrend=self.detrend,\n            scaling=\"spectrum\",\n        )\n\n        if not isinstance(x, np.ndarray):\n            # Trigger computation for Dask array\n            raise ValueError(\n                \"Welch operation requires a Dask array, but received a non-ndarray.\"\n            )\n        return np.array(result)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'welch'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>noverlap = self.win_length - self.hop_length if hop_length is not None else None</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>average = average</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', average='mean', detrend='constant')</code> \u00b6 <p>Initialize Welch operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"PS\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.Welch.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft, win_length, or hop_length are invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    average: str = \"mean\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize Welch operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str, optional\n        Window function type, default is 'hann'\n    average : str, optional\n        Averaging method, default is 'mean'\n    detrend : str, optional\n        Detrend method, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft, win_length, or hop_length are invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Welch method\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n    self.average = average\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        average=average,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.Welch.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.NOctSpectrum","title":"<code>NOctSpectrum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>N-octave spectrum operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSpectrum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"N-octave spectrum operation\"\"\"\n\n    name = \"noct_spectrum\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize N-octave spectrum\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Oct\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave spectrum\"\"\"\n        logger.debug(f\"Applying NoctSpectrum to array with shape: {x.shape}\")\n        spec, _ = noct_spectrum(\n            sig=x.T,\n            fs=self.sampling_rate,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        if spec.ndim == 1:\n            # Add channel dimension for 1D\n            spec = np.expand_dims(spec, axis=0)\n        else:\n            spec = spec.T\n        logger.debug(f\"NoctSpectrum applied, returning result with shape: {spec.shape}\")\n        return np.array(spec)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'noct_spectrum'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmin = fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax = fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n = n</code> <code>instance-attribute</code> \u00b6 <code></code> <code>G = G</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fr = fr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code> \u00b6 <p>Initialize N-octave spectrum</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Oct\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.NOctSpectrum.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize N-octave spectrum\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.NOctSynthesis","title":"<code>NOctSynthesis</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Octave synthesis operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class NOctSynthesis(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Octave synthesis operation\"\"\"\n\n    name = \"noct_synthesis\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        fmin: float,\n        fmax: float,\n        n: int = 3,\n        G: int = 10,  # noqa: N803\n        fr: int = 1000,\n    ):\n        \"\"\"\n        Initialize octave synthesis\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        fmin : float\n            Minimum frequency (Hz)\n        fmax : float\n            Maximum frequency (Hz)\n        n : int, optional\n            Number of octave divisions, default is 3\n        G : int, optional\n            Reference level, default is 10\n        fr : int, optional\n            Reference frequency, default is 1000\n        \"\"\"\n        super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n        self.fmin = fmin\n        self.fmax = fmax\n        self.n = n\n        self.G = G\n        self.fr = fr\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate output shape for octave spectrum\n        _, fpref = _center_freq(\n            fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n        )\n        return (input_shape[0], fpref.shape[0])\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Octs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for octave synthesis\"\"\"\n        logger.debug(f\"Applying NoctSynthesis to array with shape: {x.shape}\")\n        # Calculate n from shape[-1]\n        n = x.shape[-1]  # Calculate n from shape[-1]\n        if n % 2 == 0:\n            n = n * 2 - 1\n        else:\n            n = (n - 1) * 2\n        freqs = np.fft.rfftfreq(n, d=1 / self.sampling_rate)\n        result, _ = noct_synthesis(\n            spectrum=np.abs(x).T,\n            freqs=freqs,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            n=self.n,\n            G=self.G,\n            fr=self.fr,\n        )\n        result = result.T\n        logger.debug(\n            f\"NoctSynthesis applied, returning result with shape: {result.shape}\"\n        )\n        return np.array(result)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'noct_synthesis'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmin = fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax = fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n = n</code> <code>instance-attribute</code> \u00b6 <code></code> <code>G = G</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fr = fr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, fmin, fmax, n=3, G=10, fr=1000)</code> \u00b6 <p>Initialize octave synthesis</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Octs\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.NOctSynthesis.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize octave synthesis\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.Coherence","title":"<code>Coherence</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Coherence estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class Coherence(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Coherence estimation operation\"\"\"\n\n    name = \"coherence\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n    ):\n        \"\"\"\n        Initialize coherence estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Coherence\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"Coh\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Processor function for coherence estimation operation\"\"\"\n        logger.debug(f\"Applying coherence estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        _, coh = ss.coherence(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayReal = coh.transpose(1, 0, 2).reshape(-1, coh.shape[-1])\n\n        logger.debug(f\"Coherence estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'coherence'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code> \u00b6 <p>Initialize coherence estimation operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Coh\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.Coherence.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize coherence estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Coherence\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.Coherence.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.CSD","title":"<code>CSD</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Cross-spectral density estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class CSD(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Cross-spectral density estimation operation\"\"\"\n\n    name = \"csd\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize cross-spectral density estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"CSD\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"CSD\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for cross-spectral density estimation operation\"\"\"\n        logger.debug(f\"Applying CSD estimation to array with shape: {x.shape}\")\n        from scipy import signal as ss\n\n        # Calculate all combinations using scipy's csd function\n        _, csd_result = ss.csd(\n            x=x[:, np.newaxis],\n            y=x[np.newaxis, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n        )\n\n        # Reshape result to (n_channels * n_channels, n_freqs)\n        result: NDArrayComplex = csd_result.transpose(1, 0, 2).reshape(\n            -1, csd_result.shape[-1]\n        )\n\n        logger.debug(f\"CSD estimation applied, result shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'csd'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 <code></code> <code>scaling = scaling</code> <code>instance-attribute</code> \u00b6 <code></code> <code>average = average</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Initialize cross-spectral density estimation operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"CSD\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.CSD.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize cross-spectral density estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"CSD\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.CSD.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.TransferFunction","title":"<code>TransferFunction</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayComplex]</code></p> <p>Transfer function estimation operation</p> Source code in <code>wandas/processing/spectral.py</code> <pre><code>class TransferFunction(AudioOperation[NDArrayReal, NDArrayComplex]):\n    \"\"\"Transfer function estimation operation\"\"\"\n\n    name = \"transfer_function\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n        detrend: str = \"constant\",\n        scaling: str = \"spectrum\",\n        average: str = \"mean\",\n    ):\n        \"\"\"\n        Initialize transfer function estimation operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        n_fft : int\n            FFT size, default is 2048\n        hop_length : int, optional\n            Number of samples between frames. Default is win_length // 4\n        win_length : int, optional\n            Window length. Default is n_fft\n        window : str\n            Window function, default is 'hann'\n        detrend : str\n            Type of detrend, default is 'constant'\n        scaling : str\n            Type of scaling, default is 'spectrum'\n        average : str\n            Method of averaging, default is 'mean'\n\n        Raises\n        ------\n        ValueError\n            If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n        \"\"\"\n        # Validate and compute parameters\n        actual_win_length, actual_hop_length = _validate_spectral_params(\n            n_fft, win_length, hop_length, \"Transfer function\"\n        )\n\n        self.n_fft = n_fft\n        self.win_length = actual_win_length\n        self.hop_length = actual_hop_length\n        self.window = window\n        self.detrend = detrend\n        self.scaling = scaling\n        self.average = average\n        super().__init__(\n            sampling_rate,\n            n_fft=n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            window=window,\n            detrend=detrend,\n            scaling=scaling,\n            average=average,\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels * channels, freqs)\n        \"\"\"\n        n_channels = input_shape[0]\n        n_freqs = self.n_fft // 2 + 1\n        return (n_channels * n_channels, n_freqs)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"H\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayComplex:\n        \"\"\"Processor function for transfer function estimation operation\"\"\"\n        logger.debug(\n            f\"Applying transfer function estimation to array with shape: {x.shape}\"\n        )\n        from scipy import signal as ss\n\n        # Calculate cross-spectral density between all channels\n        f, p_yx = ss.csd(\n            x=x[:, np.newaxis, :],\n            y=x[np.newaxis, :, :],\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_yx shape: (num_channels, num_channels, num_frequencies)\n\n        # Calculate power spectral density for each channel\n        f, p_xx = ss.welch(\n            x=x,\n            fs=self.sampling_rate,\n            nperseg=self.win_length,\n            noverlap=self.win_length - self.hop_length,\n            nfft=self.n_fft,\n            window=self.window,\n            detrend=self.detrend,\n            scaling=self.scaling,\n            average=self.average,\n            axis=-1,\n        )\n        # p_xx shape: (num_channels, num_frequencies)\n\n        # Calculate transfer function H(f) = P_yx / P_xx\n        h_f = p_yx / p_xx[np.newaxis, :, :]\n        result: NDArrayComplex = h_f.transpose(1, 0, 2).reshape(-1, h_f.shape[-1])\n\n        logger.debug(\n            f\"Transfer function estimation applied, result shape: {result.shape}\"\n        )\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'transfer_function'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>n_fft = n_fft</code> <code>instance-attribute</code> \u00b6 <code></code> <code>win_length = actual_win_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = actual_hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>window = window</code> <code>instance-attribute</code> \u00b6 <code></code> <code>detrend = detrend</code> <code>instance-attribute</code> \u00b6 <code></code> <code>scaling = scaling</code> <code>instance-attribute</code> \u00b6 <code></code> <code>average = average</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code> \u00b6 <p>Initialize transfer function estimation operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"H\"\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.TransferFunction.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize transfer function estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Transfer function\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.spectral.TransferFunction.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.ABS","title":"<code>ABS</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Absolute value operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ABS(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Absolute value operation\"\"\"\n\n    name = \"abs\"\n\n    def __init__(self, sampling_rate: float):\n        \"\"\"\n        Initialize absolute value operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        \"\"\"\n        super().__init__(sampling_rate)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"abs\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'abs'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate)</code> \u00b6 <p>Initialize absolute value operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"abs\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.ABS.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize absolute value operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.Power","title":"<code>Power</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Power operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Power(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Power operation\"\"\"\n\n    name = \"power\"\n\n    def __init__(self, sampling_rate: float, exponent: float):\n        \"\"\"\n        Initialize power operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        exponent : float\n            Power exponent\n        \"\"\"\n        super().__init__(sampling_rate)\n        self.exp = exponent\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"pow\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'power'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>exp = exponent</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, exponent)</code> \u00b6 <p>Initialize power operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"pow\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.Power.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) exponent : float     Power exponent</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, exponent: float):\n    \"\"\"\n    Initialize power operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    exponent : float\n        Power exponent\n    \"\"\"\n    super().__init__(sampling_rate)\n    self.exp = exponent\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.Sum","title":"<code>Sum</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Sum calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Sum(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Sum calculation\"\"\"\n\n    name = \"sum\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"sum\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.sum(axis=0, keepdims=True)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'sum'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"sum\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.Mean","title":"<code>Mean</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Mean calculation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class Mean(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Mean calculation\"\"\"\n\n    name = \"mean\"\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"mean\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # Use Dask's aggregate function directly without map_blocks\n        return data.mean(axis=0, keepdims=True)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'mean'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"mean\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.ChannelDifference","title":"<code>ChannelDifference</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Channel difference calculation operation</p> Source code in <code>wandas/processing/stats.py</code> <pre><code>class ChannelDifference(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Channel difference calculation operation\"\"\"\n\n    name = \"channel_difference\"\n    other_channel: int\n\n    def __init__(self, sampling_rate: float, other_channel: int = 0):\n        \"\"\"\n        Initialize channel difference calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        other_channel : int\n            Channel to calculate difference with, default is 0\n        \"\"\"\n        self.other_channel = other_channel\n        super().__init__(sampling_rate, other_channel=other_channel)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"diff\"\n\n    def process(self, data: DaArray) -&gt; DaArray:\n        # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n        result = data - data[self.other_channel]\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'channel_difference'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>other_channel = other_channel</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, other_channel=0)</code> \u00b6 <p>Initialize channel difference calculation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"diff\"\n</code></pre> <code></code> <code>process(data)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    result = data - data[self.other_channel]\n    return result\n</code></pre>"},{"location":"en/api/#wandas.processing.stats.ChannelDifference.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other_channel : int     Channel to calculate difference with, default is 0</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, other_channel: int = 0):\n    \"\"\"\n    Initialize channel difference calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other_channel : int\n        Channel to calculate difference with, default is 0\n    \"\"\"\n    self.other_channel = other_channel\n    super().__init__(sampling_rate, other_channel=other_channel)\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.ReSampling","title":"<code>ReSampling</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Resampling operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class ReSampling(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Resampling operation\"\"\"\n\n    name = \"resampling\"\n\n    def __init__(self, sampling_rate: float, target_sr: float):\n        \"\"\"\n        Initialize resampling operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        target_sampling_rate : float\n            Target sampling rate (Hz)\n\n        Raises\n        ------\n        ValueError\n            If sampling_rate or target_sr is not positive\n        \"\"\"\n        validate_sampling_rate(sampling_rate, \"source sampling rate\")\n        validate_sampling_rate(target_sr, \"target sampling rate\")\n        super().__init__(sampling_rate, target_sr=target_sr)\n        self.target_sr = target_sr\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate to target sampling rate.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate\n\n        Notes\n        -----\n        Resampling always produces output at target_sr, regardless of input\n        sampling rate. All necessary parameters are provided at initialization.\n        \"\"\"\n        return {\"sampling_rate\": self.target_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after resampling\n        ratio = float(self.target_sr) / float(self.sampling_rate)\n        n_samples = int(np.ceil(input_shape[-1] * ratio))\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"rs\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for resampling operation\"\"\"\n        logger.debug(f\"Applying resampling to array with shape: {x.shape}\")\n        result: NDArrayReal = librosa.resample(\n            x, orig_sr=self.sampling_rate, target_sr=self.target_sr\n        )\n        logger.debug(f\"Resampling applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'resampling'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>target_sr = target_sr</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, target_sr)</code> \u00b6 <p>Initialize resampling operation</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Update sampling rate to target sampling rate.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"rs\"\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.ReSampling.__init__--raises","title":"Raises","text":"<p>ValueError     If sampling_rate or target_sr is not positive</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(self, sampling_rate: float, target_sr: float):\n    \"\"\"\n    Initialize resampling operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    target_sampling_rate : float\n        Target sampling rate (Hz)\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate or target_sr is not positive\n    \"\"\"\n    validate_sampling_rate(sampling_rate, \"source sampling rate\")\n    validate_sampling_rate(target_sr, \"target sampling rate\")\n    super().__init__(sampling_rate, target_sr=target_sr)\n    self.target_sr = target_sr\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.ReSampling.get_metadata_updates--notes","title":"Notes","text":"<p>Resampling always produces output at target_sr, regardless of input sampling rate. All necessary parameters are provided at initialization.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate to target sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    Resampling always produces output at target_sr, regardless of input\n    sampling rate. All necessary parameters are provided at initialization.\n    \"\"\"\n    return {\"sampling_rate\": self.target_sr}\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.ReSampling.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after resampling\n    ratio = float(self.target_sr) / float(self.sampling_rate)\n    n_samples = int(np.ceil(input_shape[-1] * ratio))\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.Trim","title":"<code>Trim</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>Trimming operation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class Trim(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"Trimming operation\"\"\"\n\n    name = \"trim\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        start: float,\n        end: float,\n    ):\n        \"\"\"\n        Initialize trimming operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        start : float\n            Start time for trimming (seconds)\n        end : float\n            End time for trimming (seconds)\n        \"\"\"\n        super().__init__(sampling_rate, start=start, end=end)\n        self.start = start\n        self.end = end\n        self.start_sample = int(start * sampling_rate)\n        self.end_sample = int(end * sampling_rate)\n        logger.debug(\n            f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n        )\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        # Calculate length after trimming\n        # Exclude parts where there is no signal\n        end_sample = min(self.end_sample, input_shape[-1])\n        n_samples = end_sample - self.start_sample\n        return (*input_shape[:-1], n_samples)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"trim\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for trimming operation\"\"\"\n        logger.debug(f\"Applying trim to array with shape: {x.shape}\")\n        # Apply trimming\n        result = x[..., self.start_sample : self.end_sample]\n        logger.debug(f\"Trim applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'trim'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>start = start</code> <code>instance-attribute</code> \u00b6 <code></code> <code>end = end</code> <code>instance-attribute</code> \u00b6 <code></code> <code>start_sample = int(start * sampling_rate)</code> <code>instance-attribute</code> \u00b6 <code></code> <code>end_sample = int(end * sampling_rate)</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, start, end)</code> \u00b6 <p>Initialize trimming operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"trim\"\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.Trim.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) start : float     Start time for trimming (seconds) end : float     End time for trimming (seconds)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    start: float,\n    end: float,\n):\n    \"\"\"\n    Initialize trimming operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    start : float\n        Start time for trimming (seconds)\n    end : float\n        End time for trimming (seconds)\n    \"\"\"\n    super().__init__(sampling_rate, start=start, end=end)\n    self.start = start\n    self.end = end\n    self.start_sample = int(start * sampling_rate)\n    self.end_sample = int(end * sampling_rate)\n    logger.debug(\n        f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.Trim.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after trimming\n    # Exclude parts where there is no signal\n    end_sample = min(self.end_sample, input_shape[-1])\n    n_samples = end_sample - self.start_sample\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.FixLength","title":"<code>FixLength</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>\u4fe1\u53f7\u306e\u9577\u3055\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u8abf\u6574\u3059\u308b\u64cd\u4f5c</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class FixLength(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"\u4fe1\u53f7\u306e\u9577\u3055\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u8abf\u6574\u3059\u308b\u64cd\u4f5c\"\"\"\n\n    name = \"fix_length\"\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        length: int | None = None,\n        duration: float | None = None,\n    ):\n        \"\"\"\n        Initialize fix length operation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        length : Optional[int]\n            Target length for fixing\n        duration : Optional[float]\n            Target length for fixing\n        \"\"\"\n        if length is None:\n            if duration is None:\n                raise ValueError(\"Either length or duration must be provided.\")\n            else:\n                length = int(duration * sampling_rate)\n        self.target_length = length\n\n        super().__init__(sampling_rate, target_length=self.target_length)\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape\n\n        Returns\n        -------\n        tuple\n            Output data shape\n        \"\"\"\n        return (*input_shape[:-1], self.target_length)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"fix\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for padding operation\"\"\"\n        logger.debug(f\"Applying padding to array with shape: {x.shape}\")\n        # Apply padding\n        pad_width = self.target_length - x.shape[-1]\n        if pad_width &gt; 0:\n            result = np.pad(x, ((0, 0), (0, pad_width)), mode=\"constant\")\n        else:\n            result = x[..., : self.target_length]\n        logger.debug(f\"Padding applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'fix_length'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>target_length = length</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, length=None, duration=None)</code> \u00b6 <p>Initialize fix length operation</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fix\"\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.FixLength.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) length : Optional[int]     Target length for fixing duration : Optional[float]     Target length for fixing</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    length: int | None = None,\n    duration: float | None = None,\n):\n    \"\"\"\n    Initialize fix length operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    length : Optional[int]\n        Target length for fixing\n    duration : Optional[float]\n        Target length for fixing\n    \"\"\"\n    if length is None:\n        if duration is None:\n            raise ValueError(\"Either length or duration must be provided.\")\n        else:\n            length = int(duration * sampling_rate)\n    self.target_length = length\n\n    super().__init__(sampling_rate, target_length=self.target_length)\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.FixLength.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    return (*input_shape[:-1], self.target_length)\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.RmsTrend","title":"<code>RmsTrend</code>","text":"<p>               Bases: <code>AudioOperation[NDArrayReal, NDArrayReal]</code></p> <p>RMS calculation</p> Source code in <code>wandas/processing/temporal.py</code> <pre><code>class RmsTrend(AudioOperation[NDArrayReal, NDArrayReal]):\n    \"\"\"RMS calculation\"\"\"\n\n    name = \"rms_trend\"\n    frame_length: int\n    hop_length: int\n    Aw: bool\n\n    def __init__(\n        self,\n        sampling_rate: float,\n        frame_length: int = 2048,\n        hop_length: int = 512,\n        ref: list[float] | float = 1.0,\n        dB: bool = False,  # noqa: N803\n        Aw: bool = False,  # noqa: N803\n    ) -&gt; None:\n        \"\"\"\n        Initialize RMS calculation\n\n        Parameters\n        ----------\n        sampling_rate : float\n            Sampling rate (Hz)\n        frame_length : int\n            Frame length, default is 2048\n        hop_length : int\n            Hop length, default is 512\n        ref : Union[list[float], float]\n            Reference value(s) for dB calculation\n        dB : bool\n            Whether to convert to decibels\n        Aw : bool\n            Whether to apply A-weighting before RMS calculation\n        \"\"\"\n        self.frame_length = frame_length\n        self.hop_length = hop_length\n        self.dB = dB\n        self.Aw = Aw\n        self.ref = np.array(ref if isinstance(ref, list) else [ref])\n        super().__init__(\n            sampling_rate,\n            frame_length=frame_length,\n            hop_length=hop_length,\n            dB=dB,\n            Aw=Aw,\n            ref=self.ref,\n        )\n\n    def get_metadata_updates(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Update sampling rate based on hop length.\n\n        Returns\n        -------\n        dict\n            Metadata updates with new sampling rate based on hop length\n\n        Notes\n        -----\n        The output sampling rate is determined by downsampling the input\n        by hop_length. All necessary parameters are provided at initialization.\n        \"\"\"\n        new_sr = self.sampling_rate / self.hop_length\n        return {\"sampling_rate\": new_sr}\n\n    def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n        \"\"\"\n        Calculate output data shape after operation\n\n        Parameters\n        ----------\n        input_shape : tuple\n            Input data shape (channels, samples)\n\n        Returns\n        -------\n        tuple\n            Output data shape (channels, frames)\n        \"\"\"\n        n_frames = librosa.feature.rms(\n            y=np.ones((1, input_shape[-1])),\n            frame_length=self.frame_length,\n            hop_length=self.hop_length,\n        ).shape[-1]\n        return (*input_shape[:-1], n_frames)\n\n    def get_display_name(self) -&gt; str:\n        \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n        return \"RMS\"\n\n    def _process_array(self, x: NDArrayReal) -&gt; NDArrayReal:\n        \"\"\"Create processor function for RMS calculation\"\"\"\n        logger.debug(f\"Applying RMS to array with shape: {x.shape}\")\n\n        if self.Aw:\n            # Apply A-weighting\n            _x = A_weight(x, self.sampling_rate)\n            if isinstance(_x, np.ndarray):\n                # A_weight\u304c\u30bf\u30d7\u30eb\u3092\u8fd4\u3059\u5834\u5408\u3001\u6700\u521d\u306e\u8981\u7d20\u3092\u4f7f\u7528\n                x = _x\n            elif isinstance(_x, tuple):\n                # Use the first element if A_weight returns a tuple\n                x = _x[0]\n            else:\n                raise ValueError(\"A_weighting returned an unexpected type.\")\n\n        # Calculate RMS\n        result: NDArrayReal = librosa.feature.rms(\n            y=x, frame_length=self.frame_length, hop_length=self.hop_length\n        )[..., 0, :]\n\n        if self.dB:\n            # Convert to dB\n            result = 20 * np.log10(\n                np.maximum(result / self.ref[..., np.newaxis], 1e-12)\n            )\n        #\n        logger.debug(f\"RMS applied, returning result with shape: {result.shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'rms_trend'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>frame_length = frame_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>hop_length = hop_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>dB = dB</code> <code>instance-attribute</code> \u00b6 <code></code> <code>Aw = Aw</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ref = np.array(ref if isinstance(ref, list) else [ref])</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(sampling_rate, frame_length=2048, hop_length=512, ref=1.0, dB=False, Aw=False)</code> \u00b6 <p>Initialize RMS calculation</p> <code></code> <code>get_metadata_updates()</code> \u00b6 <p>Update sampling rate based on hop length.</p> <code></code> <code>calculate_output_shape(input_shape)</code> \u00b6 <p>Calculate output data shape after operation</p> <code></code> <code>get_display_name()</code> \u00b6 <p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"RMS\"\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.RmsTrend.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) frame_length : int     Frame length, default is 2048 hop_length : int     Hop length, default is 512 ref : Union[list[float], float]     Reference value(s) for dB calculation dB : bool     Whether to convert to decibels Aw : bool     Whether to apply A-weighting before RMS calculation</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    ref: list[float] | float = 1.0,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; None:\n    \"\"\"\n    Initialize RMS calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    frame_length : int\n        Frame length, default is 2048\n    hop_length : int\n        Hop length, default is 512\n    ref : Union[list[float], float]\n        Reference value(s) for dB calculation\n    dB : bool\n        Whether to convert to decibels\n    Aw : bool\n        Whether to apply A-weighting before RMS calculation\n    \"\"\"\n    self.frame_length = frame_length\n    self.hop_length = hop_length\n    self.dB = dB\n    self.Aw = Aw\n    self.ref = np.array(ref if isinstance(ref, list) else [ref])\n    super().__init__(\n        sampling_rate,\n        frame_length=frame_length,\n        hop_length=hop_length,\n        dB=dB,\n        Aw=Aw,\n        ref=self.ref,\n    )\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.RmsTrend.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is determined by downsampling the input by hop_length. All necessary parameters are provided at initialization.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on hop length.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate based on hop length\n\n    Notes\n    -----\n    The output sampling rate is determined by downsampling the input\n    by hop_length. All necessary parameters are provided at initialization.\n    \"\"\"\n    new_sr = self.sampling_rate / self.hop_length\n    return {\"sampling_rate\": new_sr}\n</code></pre>"},{"location":"en/api/#wandas.processing.temporal.RmsTrend.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, frames)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, frames)\n    \"\"\"\n    n_frames = librosa.feature.rms(\n        y=np.ones((1, input_shape[-1])),\n        frame_length=self.frame_length,\n        hop_length=self.hop_length,\n    ).shape[-1]\n    return (*input_shape[:-1], n_frames)\n</code></pre>"},{"location":"en/api/#io-module","title":"IO Module","text":"<p>The IO module provides file reading and writing functions.</p>"},{"location":"en/api/#wandas.io.read_wav--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the audio data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wav_io.py</code> <pre><code>def read_wav(filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Read a WAV file and create a ChannelFrame object.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file or URL to the WAV file.\n    labels : list of str, optional\n        Labels for each channel.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the audio data.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304cURL\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\n    if filename.startswith(\"http://\") or filename.startswith(\"https://\"):\n        # URL\u306e\u5834\u5408\u3001requests\u3092\u4f7f\u7528\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n        response = requests.get(filename)\n        file_obj = io.BytesIO(response.content)\n        file_label = os.path.basename(filename)\n        # \u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u306f\u4f7f\u7528\u305b\u305a\u306b\u8aad\u307f\u8fbc\u3080\n        sampling_rate, data = wavfile.read(file_obj)\n    else:\n        # \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u5834\u5408\n        file_label = os.path.basename(filename)\n        # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\uff08\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4f7f\u7528\uff09\n        sampling_rate, data = wavfile.read(filename, mmap=True)\n\n    # \u30c7\u30fc\u30bf\u3092(num_channels, num_samples)\u5f62\u72b6\u306eNumPy\u914d\u5217\u306b\u5909\u63db\n    if data.ndim == 1:\n        # \u30e2\u30ce\u30e9\u30eb\uff1a(samples,) -&gt; (1, samples)\n        data = np.expand_dims(data, axis=0)\n    else:\n        # \u30b9\u30c6\u30ec\u30aa\uff1a(samples, channels) -&gt; (channels, samples)\n        data = data.T\n\n    # NumPy\u914d\u5217\u304b\u3089ChannelFrame\u3092\u4f5c\u6210\n    channel_frame = ChannelFrame.from_numpy(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=file_label,\n        ch_labels=labels,\n    )\n\n    return channel_frame\n</code></pre>"},{"location":"en/api/#wandas.io.write_wav--raises","title":"Raises","text":"<p>ValueError     If target is not a ChannelFrame object.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wav_io.py</code> <pre><code>def write_wav(filename: str, target: \"ChannelFrame\", format: str | None = None) -&gt; None:\n    \"\"\"\n    Write a ChannelFrame object to a WAV file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file.\n    target : ChannelFrame\n        ChannelFrame object containing the data to write.\n    format : str, optional\n        File format. If None, determined from file extension.\n\n    Raises\n    ------\n    ValueError\n        If target is not a ChannelFrame object.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    if not isinstance(target, ChannelFrame):\n        raise ValueError(\"target must be a ChannelFrame object.\")\n\n    logger.debug(f\"Saving audio data to file: {filename} (will compute now)\")\n    data = target.compute()\n    data = data.T\n    if data.shape[1] == 1:\n        data = data.squeeze(axis=1)\n    if data.dtype == float and max([np.abs(data.max()), np.abs(data.min())]) &lt; 1:\n        sf.write(\n            str(filename),\n            data,\n            int(target.sampling_rate),\n            subtype=\"FLOAT\",\n            format=format,\n        )\n    else:\n        sf.write(str(filename), data, int(target.sampling_rate), format=format)\n    logger.debug(f\"Save complete: {filename}\")\n</code></pre>"},{"location":"en/api/#wandas.io.load","title":"<code>load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"en/api/#wandas.io.save","title":"<code>save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> \u5fc5\u9808 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"en/api/#wandas.io.readers.FileReader","title":"<code>FileReader</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for audio file readers.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class FileReader(ABC):\n    \"\"\"Base class for audio file readers.\"\"\"\n\n    # Class attribute for supported file extensions\n    supported_extensions: list[str] = []\n\n    @classmethod\n    @abstractmethod\n    def get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the audio file.\n\n        Args:\n            path: Path to the file.\n            **kwargs: Additional parameters specific to the file reader.\n\n        Returns:\n            Dictionary containing file information including:\n            - samplerate: Sampling rate in Hz\n            - channels: Number of channels\n            - frames: Total number of frames\n            - format: File format\n            - duration: Duration in seconds\n        \"\"\"\n        pass\n\n    @classmethod\n    @abstractmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read audio data from the file.\n\n        Args:\n            path: Path to the file.\n            channels: List of channel indices to read.\n            start_idx: Starting frame index.\n            frames: Number of frames to read.\n            **kwargs: Additional parameters specific to the file reader.\n\n        Returns:\n            Array of shape (channels, frames) containing the audio data.\n        \"\"\"\n        pass\n\n    @classmethod\n    def can_read(cls, path: str | Path) -&gt; bool:\n        \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n        ext = Path(path).suffix.lower()\n        return ext in cls.supported_extensions\n</code></pre> Attributes\u00b6 <code></code> <code>supported_extensions = []</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_file_info(path, **kwargs)</code> <code>abstractmethod</code> <code>classmethod</code> \u00b6 <p>Get basic information about the audio file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the file.</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>dict[str, Any]</code> <p>Dictionary containing file information including:</p> <code>dict[str, Any]</code> <ul> <li>samplerate: Sampling rate in Hz</li> </ul> <code>dict[str, Any]</code> <ul> <li>channels: Number of channels</li> </ul> <code>dict[str, Any]</code> <ul> <li>frames: Total number of frames</li> </ul> <code>dict[str, Any]</code> <ul> <li>format: File format</li> </ul> <code>dict[str, Any]</code> <ul> <li>duration: Duration in seconds</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\n\n    Args:\n        path: Path to the file.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Dictionary containing file information including:\n        - samplerate: Sampling rate in Hz\n        - channels: Number of channels\n        - frames: Total number of frames\n        - format: File format\n        - duration: Duration in seconds\n    \"\"\"\n    pass\n</code></pre> <code></code> <code>get_data(path, channels, start_idx, frames, **kwargs)</code> <code>abstractmethod</code> <code>classmethod</code> \u00b6 <p>Read audio data from the file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the file.</p> \u5fc5\u9808 <code>channels</code> <code>list[int]</code> <p>List of channel indices to read.</p> \u5fc5\u9808 <code>start_idx</code> <code>int</code> <p>Starting frame index.</p> \u5fc5\u9808 <code>frames</code> <code>int</code> <p>Number of frames to read.</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ArrayLike</code> <p>Array of shape (channels, frames) containing the audio data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\n\n    Args:\n        path: Path to the file.\n        channels: List of channel indices to read.\n        start_idx: Starting frame index.\n        frames: Number of frames to read.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Array of shape (channels, frames) containing the audio data.\n    \"\"\"\n    pass\n</code></pre> <code></code> <code>can_read(path)</code> <code>classmethod</code> \u00b6 <p>Check if this reader can handle the file based on extension.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef can_read(cls, path: str | Path) -&gt; bool:\n    \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n    ext = Path(path).suffix.lower()\n    return ext in cls.supported_extensions\n</code></pre>"},{"location":"en/api/#wandas.io.readers.SoundFileReader","title":"<code>SoundFileReader</code>","text":"<p>               Bases: <code>FileReader</code></p> <p>Audio file reader using SoundFile library.</p> Source code in <code>wandas/io/readers.py</code> <pre><code>class SoundFileReader(FileReader):\n    \"\"\"Audio file reader using SoundFile library.\"\"\"\n\n    # SoundFile supported formats\n    supported_extensions = [\".wav\", \".flac\", \".ogg\", \".aiff\", \".aif\", \".snd\"]\n\n    @classmethod\n    def get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Get basic information about the audio file.\"\"\"\n        info = sf.info(str(path))\n        return {\n            \"samplerate\": info.samplerate,\n            \"channels\": info.channels,\n            \"frames\": info.frames,\n            \"format\": info.format,\n            \"subtype\": info.subtype,\n            \"duration\": info.frames / info.samplerate,\n        }\n\n    @classmethod\n    def get_data(\n        cls,\n        path: str | Path,\n        channels: list[int],\n        start_idx: int,\n        frames: int,\n        **kwargs: Any,\n    ) -&gt; ArrayLike:\n        \"\"\"Read audio data from the file.\"\"\"\n        logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n        with sf.SoundFile(str(path)) as f:\n            if start_idx &gt; 0:\n                f.seek(start_idx)\n            data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n            # Select requested channels\n            if len(channels) &lt; f.channels:\n                data = data[:, channels]\n\n            # Transpose to get (channels, samples) format\n            result: ArrayLike = data.T\n            if not isinstance(result, np.ndarray):\n                raise ValueError(\"Unexpected data type after reading file\")\n\n        _shape = result.shape\n        logger.debug(f\"File read complete, returning data with shape {_shape}\")\n        return result\n</code></pre> Attributes\u00b6 <code></code> <code>supported_extensions = ['.wav', '.flac', '.ogg', '.aiff', '.aif', '.snd']</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>get_file_info(path, **kwargs)</code> <code>classmethod</code> \u00b6 <p>Get basic information about the audio file.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\"\"\"\n    info = sf.info(str(path))\n    return {\n        \"samplerate\": info.samplerate,\n        \"channels\": info.channels,\n        \"frames\": info.frames,\n        \"format\": info.format,\n        \"subtype\": info.subtype,\n        \"duration\": info.frames / info.samplerate,\n    }\n</code></pre> <code></code> <code>get_data(path, channels, start_idx, frames, **kwargs)</code> <code>classmethod</code> \u00b6 <p>Read audio data from the file.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\"\"\"\n    logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n    with sf.SoundFile(str(path)) as f:\n        if start_idx &gt; 0:\n            f.seek(start_idx)\n        data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n        # Select requested channels\n        if len(channels) &lt; f.channels:\n            data = data[:, channels]\n\n        # Transpose to get (channels, samples) format\n        result: ArrayLike = data.T\n        if not isinstance(result, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"File read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"en/api/#wandas.io.readers.CSVFileReader.get_file_info--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVFileInfoParams for supported parameter types.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(\n    cls,\n    path: str | Path,\n    **kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header. Set to None if no header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing file information including:\n        - samplerate: Estimated sampling rate in Hz\n        - channels: Number of data channels (excluding time column)\n        - frames: Total number of frames\n        - format: \"CSV\"\n        - duration: Duration in seconds (or None if cannot be calculated)\n        - ch_labels: List of channel labels\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVFileInfoParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n\n    # Read first few lines to determine structure\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Estimate sampling rate from first column (assuming it's time)\n    try:\n        # Get time column as Series\n        if isinstance(time_column, str):\n            time_series = df[time_column]\n        else:\n            time_series = df.iloc[:, time_column]\n        time_values = np.array(time_series.values)\n        if len(time_values) &gt; 1:\n            # Use round() instead of int() to handle floating-point precision issues\n            estimated_sr = round(1 / np.mean(np.diff(time_values)))\n        else:\n            estimated_sr = 0  # Cannot determine from single row\n    except Exception:\n        estimated_sr = 0  # Default if can't calculate\n\n    frames = df.shape[0]\n    duration = frames / estimated_sr if estimated_sr &gt; 0 else None\n\n    # Return file info\n    return {\n        \"samplerate\": estimated_sr,\n        \"channels\": df.shape[1] - 1,  # Assuming first column is time\n        \"frames\": frames,\n        \"format\": \"CSV\",\n        \"duration\": duration,\n        \"ch_labels\": df.columns[1:].tolist(),  # Assuming first column is time\n    }\n</code></pre>"},{"location":"en/api/#wandas.io.readers.CSVFileReader.get_data--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVGetDataParams for supported parameter types.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read data from the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    channels : list[int]\n        List of channel indices to read.\n    start_idx : int\n        Starting frame index.\n    frames : int\n        Number of frames to read.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    ArrayLike\n        Array of shape (channels, frames) containing the data.\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVGetDataParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n\n    logger.debug(f\"Reading CSV data from {path} starting at {start_idx}\")\n\n    # Read the CSV file\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Remove time column\n    df = df.drop(\n        columns=[time_column]\n        if isinstance(time_column, str)\n        else df.columns[time_column]\n    )\n\n    # Select requested channels - adjust indices to account for time column removal\n    if channels:\n        try:\n            data_df = df.iloc[:, channels]\n        except IndexError:\n            raise ValueError(f\"Requested channels {channels} out of range\")\n    else:\n        data_df = df\n\n    # Handle start_idx and frames for partial reading\n    end_idx = start_idx + frames if frames &gt; 0 else None\n    data_df = data_df.iloc[start_idx:end_idx]\n\n    # Convert to numpy array and transpose to (channels, samples) format\n    result = data_df.values.T\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"CSV read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"en/api/#wandas.io.readers.get_file_reader","title":"<code>get_file_reader(path)</code>","text":"<p>Get an appropriate file reader for the given path.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>def get_file_reader(path: str | Path) -&gt; FileReader:\n    \"\"\"Get an appropriate file reader for the given path.\"\"\"\n    path_str = str(path)\n    ext = Path(path).suffix.lower()\n\n    # Try each reader in order\n    for reader in _file_readers:\n        if ext in reader.__class__.supported_extensions:\n            logger.debug(f\"Using {reader.__class__.__name__} for {path_str}\")\n            return reader\n\n    # If no reader found, raise error\n    raise ValueError(f\"No suitable file reader found for {path_str}\")\n</code></pre>"},{"location":"en/api/#wandas.io.readers.register_file_reader","title":"<code>register_file_reader(reader_class)</code>","text":"<p>Register a new file reader.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>def register_file_reader(reader_class: type) -&gt; None:\n    \"\"\"Register a new file reader.\"\"\"\n    reader = reader_class()\n    _file_readers.append(reader)\n    logger.debug(f\"Registered new file reader: {reader_class.__name__}\")\n</code></pre>"},{"location":"en/api/#wandas.io.wav_io.read_wav--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the audio data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wav_io.py</code> <pre><code>def read_wav(filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Read a WAV file and create a ChannelFrame object.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file or URL to the WAV file.\n    labels : list of str, optional\n        Labels for each channel.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the audio data.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304cURL\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\n    if filename.startswith(\"http://\") or filename.startswith(\"https://\"):\n        # URL\u306e\u5834\u5408\u3001requests\u3092\u4f7f\u7528\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n        response = requests.get(filename)\n        file_obj = io.BytesIO(response.content)\n        file_label = os.path.basename(filename)\n        # \u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u306f\u4f7f\u7528\u305b\u305a\u306b\u8aad\u307f\u8fbc\u3080\n        sampling_rate, data = wavfile.read(file_obj)\n    else:\n        # \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u5834\u5408\n        file_label = os.path.basename(filename)\n        # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\uff08\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4f7f\u7528\uff09\n        sampling_rate, data = wavfile.read(filename, mmap=True)\n\n    # \u30c7\u30fc\u30bf\u3092(num_channels, num_samples)\u5f62\u72b6\u306eNumPy\u914d\u5217\u306b\u5909\u63db\n    if data.ndim == 1:\n        # \u30e2\u30ce\u30e9\u30eb\uff1a(samples,) -&gt; (1, samples)\n        data = np.expand_dims(data, axis=0)\n    else:\n        # \u30b9\u30c6\u30ec\u30aa\uff1a(samples, channels) -&gt; (channels, samples)\n        data = data.T\n\n    # NumPy\u914d\u5217\u304b\u3089ChannelFrame\u3092\u4f5c\u6210\n    channel_frame = ChannelFrame.from_numpy(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=file_label,\n        ch_labels=labels,\n    )\n\n    return channel_frame\n</code></pre>"},{"location":"en/api/#wandas.io.wav_io.write_wav--raises","title":"Raises","text":"<p>ValueError     If target is not a ChannelFrame object.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wav_io.py</code> <pre><code>def write_wav(filename: str, target: \"ChannelFrame\", format: str | None = None) -&gt; None:\n    \"\"\"\n    Write a ChannelFrame object to a WAV file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file.\n    target : ChannelFrame\n        ChannelFrame object containing the data to write.\n    format : str, optional\n        File format. If None, determined from file extension.\n\n    Raises\n    ------\n    ValueError\n        If target is not a ChannelFrame object.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    if not isinstance(target, ChannelFrame):\n        raise ValueError(\"target must be a ChannelFrame object.\")\n\n    logger.debug(f\"Saving audio data to file: {filename} (will compute now)\")\n    data = target.compute()\n    data = data.T\n    if data.shape[1] == 1:\n        data = data.squeeze(axis=1)\n    if data.dtype == float and max([np.abs(data.max()), np.abs(data.min())]) &lt; 1:\n        sf.write(\n            str(filename),\n            data,\n            int(target.sampling_rate),\n            subtype=\"FLOAT\",\n            format=format,\n        )\n    else:\n        sf.write(str(filename), data, int(target.sampling_rate), format=format)\n    logger.debug(f\"Save complete: {filename}\")\n</code></pre>"},{"location":"en/api/#wandas.io.wdf_io.save","title":"<code>save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> \u5fc5\u9808 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"en/api/#wandas.io.wdf_io.load","title":"<code>load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"en/api/#utilities-module","title":"Utilities Module","text":"<p>The utilities module provides auxiliary functions.</p>"},{"location":"en/api/#wandas.utils.accepted_kwargs","title":"<code>accepted_kwargs(func)</code>","text":"<p>Get the set of explicit keyword arguments accepted by a function and whether it accepts **kwargs.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>func</code> <code>Callable[..., Any]</code> <p>The function to inspect.</p> \u5fc5\u9808 <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>set[str]</code> <p>A tuple containing:</p> <code>bool</code> <ul> <li>set[str]: Set of explicit keyword argument names accepted by func.</li> </ul> <code>tuple[set[str], bool]</code> <ul> <li>bool: Whether the function accepts variable keyword arguments (**kwargs).</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/introspection.py</code> <pre><code>def accepted_kwargs(func: Callable[..., Any]) -&gt; tuple[set[str], bool]:\n    \"\"\"\n    Get the set of explicit keyword arguments accepted by\n    a function and whether it accepts **kwargs.\n\n    Args:\n        func: The function to inspect.\n\n    Returns:\n        A tuple containing:\n        - set[str]: Set of explicit keyword argument names accepted by func.\n        - bool: Whether the function accepts variable keyword arguments (**kwargs).\n    \"\"\"\n    # \u30e2\u30c3\u30af\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n    if hasattr(func, \"__module__\") and func.__module__ == \"unittest.mock\":\n        return set(), True\n    try:\n        params = signature(func).parameters.values()\n\n        # \u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u5f15\u6570\u3092\u53ce\u96c6\n        explicit_kwargs = {\n            p.name\n            for p in params\n            if p.kind in (Parameter.POSITIONAL_OR_KEYWORD, Parameter.KEYWORD_ONLY)\n        }\n\n        # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\n        has_var_kwargs = any(p.kind is Parameter.VAR_KEYWORD for p in params)\n\n        return explicit_kwargs, has_var_kwargs\n    except (ValueError, TypeError):\n        # \u30b7\u30b0\u30cd\u30c1\u30e3\u3092\u53d6\u5f97\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n        return set(), True\n</code></pre>"},{"location":"en/api/#wandas.utils.filter_kwargs","title":"<code>filter_kwargs(func, kwargs, *, strict_mode=False)</code>","text":"<p>Filter keyword arguments to only those accepted by the function.</p> <p>This function examines the signature of <code>func</code> and returns a dictionary containing only the key-value pairs from <code>kwargs</code> that are valid keyword arguments for <code>func</code>.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>func</code> <code>Callable[..., Any]</code> <p>The function to filter keyword arguments for.</p> \u5fc5\u9808 <code>kwargs</code> <code>Mapping[str, Any]</code> <p>The keyword arguments to filter.</p> \u5fc5\u9808 <code>strict_mode</code> <code>bool</code> <p>If True, only explicitly defined parameters are passed even when the function accepts kwargs. If False (default), all parameters are passed to functions that accept kwargs, but a warning is issued for parameters not explicitly defined.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>dict[str, Any]</code> <p>A dictionary containing only the key-value pairs that are valid for <code>func</code>.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/introspection.py</code> <pre><code>def filter_kwargs(\n    func: Callable[..., Any],\n    kwargs: Mapping[str, Any],\n    *,\n    strict_mode: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Filter keyword arguments to only those accepted by the function.\n\n    This function examines the signature of `func` and returns a dictionary\n    containing only the key-value pairs from `kwargs` that are valid keyword\n    arguments for `func`.\n\n    Args:\n        func: The function to filter keyword arguments for.\n        kwargs: The keyword arguments to filter.\n        strict_mode: If True, only explicitly defined parameters are passed even when\n            the function accepts **kwargs. If False (default), all parameters are\n            passed to functions that accept **kwargs, but a warning is issued for\n            parameters not explicitly defined.\n\n    Returns:\n        A dictionary containing only the key-value pairs that are valid for `func`.\n    \"\"\"\n    explicit_params, accepts_var_kwargs = accepted_kwargs(func)\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u306a\u3044\u5834\u5408\u3001\u307e\u305f\u306f strict_mode \u304c True \u306e\u5834\u5408\u306f\u3001\n    # \u660e\u793a\u7684\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n    if not accepts_var_kwargs or strict_mode:\n        filtered = {k: v for k, v in kwargs.items() if k in explicit_params}\n        return filtered\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u5834\u5408\uff08strict_mode\u304cFalse\u306e\u5834\u5408\uff09\u306f\u5168\u30ad\u30fc\u3092\u8a31\u53ef\n    # \u305f\u3060\u3057\u3001\u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u306a\u3044\u30ad\u30fc\u306b\u306f\u8b66\u544a\u3092\u51fa\u3059\n    unknown = set(kwargs) - explicit_params\n    if unknown:\n        warnings.warn(\n            f\"Implicit kwargs for {func.__name__}: {unknown}\",\n            UserWarning,\n            stacklevel=2,\n        )\n    return dict(kwargs)\n</code></pre>"},{"location":"en/api/#wandas.utils.validate_sampling_rate--examples","title":"Examples","text":"<p>validate_sampling_rate(44100)  # No error validate_sampling_rate(0)  # Raises ValueError validate_sampling_rate(-100)  # Raises ValueError</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def validate_sampling_rate(\n    sampling_rate: float, param_name: str = \"sampling_rate\"\n) -&gt; None:\n    \"\"\"\n    Validate that sampling rate is positive.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz to validate.\n    param_name : str, default=\"sampling_rate\"\n        Name of the parameter being validated (for error messages).\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate is not positive (i.e., &lt;= 0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; validate_sampling_rate(44100)  # No error\n    &gt;&gt;&gt; validate_sampling_rate(0)  # Raises ValueError\n    &gt;&gt;&gt; validate_sampling_rate(-100)  # Raises ValueError\n    \"\"\"\n    if sampling_rate &lt;= 0:\n        raise ValueError(\n            f\"Invalid {param_name}\\n\"\n            f\"  Got: {sampling_rate} Hz\\n\"\n            f\"  Expected: Positive value &gt; 0\\n\"\n            f\"Sampling rate represents samples per second and must be positive.\\n\"\n            f\"Common values: 8000, 16000, 22050, 44100, 48000 Hz\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.LazyFrame","title":"<code>LazyFrame</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[F]</code></p> <p>A class that encapsulates a frame and its loading state.</p> <p>\u5c5e\u6027\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>file_path</code> <code>Path</code> <p>File path associated with the frame</p> <code>frame</code> <code>F | None</code> <p>Loaded frame object (None if not loaded)</p> <code>is_loaded</code> <code>bool</code> <p>Flag indicating if the frame is loaded</p> <code>load_attempted</code> <code>bool</code> <p>Flag indicating if loading was attempted (for error detection)</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>@dataclass\nclass LazyFrame(Generic[F]):\n    \"\"\"\n    A class that encapsulates a frame and its loading state.\n\n    Attributes:\n        file_path: File path associated with the frame\n        frame: Loaded frame object (None if not loaded)\n        is_loaded: Flag indicating if the frame is loaded\n        load_attempted: Flag indicating if loading was attempted (for error detection)\n    \"\"\"\n\n    file_path: Path\n    frame: F | None = None\n    is_loaded: bool = False\n    load_attempted: bool = False\n\n    def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n        \"\"\"\n        Ensures the frame is loaded, loading it if necessary.\n\n        Args:\n            loader: Function to load a frame from a file path\n\n        Returns:\n            The loaded frame, or None if loading failed\n        \"\"\"\n        # Return the current frame if already loaded\n        if self.is_loaded:\n            return self.frame\n\n        # Attempt to load if not loaded yet\n        try:\n            self.load_attempted = True\n            self.frame = loader(self.file_path)\n            self.is_loaded = True\n            return self.frame\n        except Exception as e:\n            logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n            self.is_loaded = True  # Loading was attempted\n            self.frame = None\n            return None\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the frame state.\n        \"\"\"\n        self.frame = None\n        self.is_loaded = False\n        self.load_attempted = False\n</code></pre> Attributes\u00b6 <code></code> <code>file_path</code> <code>instance-attribute</code> \u00b6 <code></code> <code>frame = None</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>is_loaded = False</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 <code></code> <code>load_attempted = False</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(file_path, frame=None, is_loaded=False, load_attempted=False)</code> \u00b6 <code></code> <code>ensure_loaded(loader)</code> \u00b6 <p>Ensures the frame is loaded, loading it if necessary.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>loader</code> <code>Callable[[Path], F | None]</code> <p>Function to load a frame from a file path</p> \u5fc5\u9808 <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>F | None</code> <p>The loaded frame, or None if loading failed</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n    \"\"\"\n    Ensures the frame is loaded, loading it if necessary.\n\n    Args:\n        loader: Function to load a frame from a file path\n\n    Returns:\n        The loaded frame, or None if loading failed\n    \"\"\"\n    # Return the current frame if already loaded\n    if self.is_loaded:\n        return self.frame\n\n    # Attempt to load if not loaded yet\n    try:\n        self.load_attempted = True\n        self.frame = loader(self.file_path)\n        self.is_loaded = True\n        return self.frame\n    except Exception as e:\n        logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n        self.is_loaded = True  # Loading was attempted\n        self.frame = None\n        return None\n</code></pre> <code></code> <code>reset()</code> \u00b6 <p>Reset the frame state.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the frame state.\n    \"\"\"\n    self.frame = None\n    self.is_loaded = False\n    self.load_attempted = False\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.FrameDataset","title":"<code>FrameDataset</code>","text":"<p>               Bases: <code>Generic[F]</code>, <code>ABC</code></p> <p>Abstract base dataset class for processing files in a folder. Includes lazy loading capability to efficiently handle large datasets. Subclasses handle specific frame types (ChannelFrame, SpectrogramFrame, etc.).</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class FrameDataset(Generic[F], ABC):\n    \"\"\"\n    Abstract base dataset class for processing files in a folder.\n    Includes lazy loading capability to efficiently handle large datasets.\n    Subclasses handle specific frame types (ChannelFrame, SpectrogramFrame, etc.).\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], F | None] | None = None,\n    ):\n        self.folder_path = Path(folder_path)\n        if source_dataset is None and not self.folder_path.exists():\n            raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n        self.sampling_rate = sampling_rate\n        self.signal_length = signal_length\n        self.file_extensions = file_extensions or [\".wav\"]\n        self._recursive = recursive\n        self._lazy_loading = lazy_loading\n\n        # Changed to a list of LazyFrame\n        self._lazy_frames: list[LazyFrame[F]] = []\n\n        self._source_dataset = source_dataset\n        self._transform = transform\n\n        if self._source_dataset:\n            self._initialize_from_source()\n        else:\n            self._initialize_from_folder()\n\n    def _initialize_from_source(self) -&gt; None:\n        \"\"\"Initialize from a source dataset.\"\"\"\n        if self._source_dataset is None:\n            return\n\n        # Copy file paths from source\n        file_paths = self._source_dataset._get_file_paths()\n        self._lazy_frames = [LazyFrame(file_path) for file_path in file_paths]\n\n        # Inherit other properties\n        self.sampling_rate = self.sampling_rate or self._source_dataset.sampling_rate\n        self.signal_length = self.signal_length or self._source_dataset.signal_length\n        self.file_extensions = (\n            self.file_extensions or self._source_dataset.file_extensions\n        )\n        self._recursive = self._source_dataset._recursive\n        self.folder_path = self._source_dataset.folder_path\n\n    def _initialize_from_folder(self) -&gt; None:\n        \"\"\"Initialize from a folder.\"\"\"\n        self._discover_files()\n        if not self._lazy_loading:\n            self._load_all_files()\n\n    def _discover_files(self) -&gt; None:\n        \"\"\"Discover files in the folder and store them in a list of LazyFrame.\"\"\"\n        file_paths = []\n        for ext in self.file_extensions:\n            pattern = f\"**/*{ext}\" if self._recursive else f\"*{ext}\"\n            file_paths.extend(\n                sorted(p for p in self.folder_path.glob(pattern) if p.is_file())\n            )\n\n        # Remove duplicates and sort\n        file_paths = sorted(list(set(file_paths)))\n\n        # Create a list of LazyFrame\n        self._lazy_frames = [LazyFrame(file_path) for file_path in file_paths]\n\n    def _load_all_files(self) -&gt; None:\n        \"\"\"Load all files.\"\"\"\n        for i in tqdm(range(len(self._lazy_frames)), desc=\"Loading/transforming\"):\n            try:\n                self._ensure_loaded(i)\n            except Exception as e:\n                filepath = self._lazy_frames[i].file_path\n                logger.warning(\n                    f\"Failed to load/transform index {i} ({filepath}): {str(e)}\"\n                )\n        self._lazy_loading = False\n\n    @abstractmethod\n    def _load_file(self, file_path: Path) -&gt; F | None:\n        \"\"\"Abstract method to load a frame from a file.\"\"\"\n        pass\n\n    def _load_from_source(self, index: int) -&gt; F | None:\n        \"\"\"Load a frame from the source dataset and transform it if necessary.\"\"\"\n        if self._source_dataset is None or self._transform is None:\n            return None\n\n        source_frame = self._source_dataset._ensure_loaded(index)\n        if source_frame is None:\n            return None\n\n        try:\n            return self._transform(source_frame)\n        except Exception as e:\n            logger.warning(f\"Failed to transform index {index}: {str(e)}\")\n            return None\n\n    def _ensure_loaded(self, index: int) -&gt; F | None:\n        \"\"\"Ensure the frame at the given index is loaded.\"\"\"\n        if not (0 &lt;= index &lt; len(self._lazy_frames)):\n            raise IndexError(\n                f\"Index {index} is out of range (0-{len(self._lazy_frames) - 1})\"\n            )\n\n        lazy_frame = self._lazy_frames[index]\n\n        # Return if already loaded\n        if lazy_frame.is_loaded:\n            return lazy_frame.frame\n\n        try:\n            # Convert from source dataset\n            if self._transform and self._source_dataset:\n                lazy_frame.load_attempted = True\n                frame = self._load_from_source(index)\n                lazy_frame.frame = frame\n                lazy_frame.is_loaded = True\n                return frame\n            # Load directly from file\n            else:\n                return lazy_frame.ensure_loaded(self._load_file)\n        except Exception as e:\n            f_path = lazy_frame.file_path\n            logger.error(\n                f\"Failed to load or initialize index {index} ({f_path}): {str(e)}\"\n            )\n            lazy_frame.frame = None\n            lazy_frame.is_loaded = True\n            lazy_frame.load_attempted = True\n            return None\n\n    def _get_file_paths(self) -&gt; list[Path]:\n        \"\"\"Get a list of file paths.\"\"\"\n        return [lazy_frame.file_path for lazy_frame in self._lazy_frames]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of files in the dataset.\"\"\"\n        return len(self._lazy_frames)\n\n    def get_by_label(self, label: str) -&gt; F | None:\n        \"\"\"\n        Get a frame by its label (filename).\n\n        Parameters\n        ----------\n        label : str\n            The filename (label) to search for (e.g., 'sample_1.wav').\n\n        Returns\n        -------\n        Optional[F]\n            The frame if found, otherwise None.\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n        &gt;&gt;&gt; if frame:\n        ...     print(frame.label)\n        \"\"\"\n        # Keep for backward compatibility: return the first match but emit\n        # a DeprecationWarning recommending `get_all_by_label`.\n        all_matches = self.get_all_by_label(label)\n        if len(all_matches) &gt; 0:\n            warnings.warn(\n                \"get_by_label() returns the first matching frame and is deprecated; \"\n                \"use get_all_by_label() to obtain all matches.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return all_matches[0]\n        return None\n\n    def get_all_by_label(self, label: str) -&gt; list[F]:\n        \"\"\"\n        Get all frames matching the given label (filename).\n\n        Parameters\n        ----------\n        label : str\n            The filename (label) to search for (e.g., 'sample_1.wav').\n\n        Returns\n        -------\n        list[F]\n            A list of frames matching the label.\n            If none are found, returns an empty list.\n\n        Notes\n        -----\n        - Search is performed against the filename portion only (i.e. Path.name).\n        - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n        \"\"\"\n        matches: list[F] = []\n        for i, lazy_frame in enumerate(self._lazy_frames):\n            if lazy_frame.file_path.name == label:\n                loaded = self._ensure_loaded(i)\n                if loaded is not None:\n                    matches.append(loaded)\n        return matches\n\n    @overload\n    def __getitem__(self, key: int) -&gt; F | None: ...\n\n    @overload\n    def __getitem__(self, key: str) -&gt; list[F]: ...\n\n    def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n        \"\"\"\n        Get the frame by index (int) or label (str).\n\n        Parameters\n        ----------\n        key : int or str\n            Index (int) or filename/label (str).\n\n        Returns\n        -------\n        Optional[F] or list[F]\n            If `key` is an int, returns the frame or None. If `key` is a str,\n            returns a list of matching frames (may be empty).\n\n        Examples\n        --------\n        &gt;&gt;&gt; frame = dataset[0]  # by index\n        &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n        \"\"\"\n        if isinstance(key, int):\n            return self._ensure_loaded(key)\n        if isinstance(key, str):\n            # pandas-like behaviour: return all matches for the label as a list\n            return self.get_all_by_label(key)\n        raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n\n    @overload\n    def apply(self, func: Callable[[F], F_out | None]) -&gt; \"FrameDataset[F_out]\": ...\n\n    @overload\n    def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\": ...\n\n    def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n        \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n        new_dataset = type(self)(\n            folder_path=str(self.folder_path),\n            lazy_loading=True,\n            source_dataset=self,\n            transform=func,\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            recursive=self._recursive,\n        )\n        return cast(\"FrameDataset[Any]\", new_dataset)\n\n    def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n        \"\"\"Save processed frames to files.\"\"\"\n        raise NotImplementedError(\"The save method is not currently implemented.\")\n\n    def sample(\n        self,\n        n: int | None = None,\n        ratio: float | None = None,\n        seed: int | None = None,\n    ) -&gt; \"FrameDataset[F]\":\n        \"\"\"Get a sample from the dataset.\"\"\"\n        if seed is not None:\n            random.seed(seed)\n\n        total = len(self._lazy_frames)\n        if total == 0:\n            return type(self)(\n                str(self.folder_path),\n                sampling_rate=self.sampling_rate,\n                signal_length=self.signal_length,\n                file_extensions=self.file_extensions,\n                lazy_loading=self._lazy_loading,\n                recursive=self._recursive,\n            )\n\n        # Determine sample size\n        if n is None and ratio is None:\n            n = max(1, min(10, int(total * 0.1)))\n        elif n is None and ratio is not None:\n            n = max(1, int(total * ratio))\n        elif n is not None:\n            n = max(1, n)\n        else:\n            n = 1\n\n        n = min(n, total)\n\n        # Randomly select indices\n        sampled_indices = sorted(random.sample(range(total), n))\n\n        return _SampledFrameDataset(self, sampled_indices)\n\n    def get_metadata(self) -&gt; dict[str, Any]:\n        \"\"\"Get metadata for the dataset.\"\"\"\n        actual_sr: int | float | None = self.sampling_rate\n        frame_type_name = \"Unknown\"\n\n        # Count loaded frames\n        loaded_count = sum(\n            1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n        )\n\n        # Get metadata from the first frame (if possible)\n        first_frame: F | None = None\n        if len(self._lazy_frames) &gt; 0:\n            try:\n                if self._lazy_frames[0].is_loaded:\n                    first_frame = self._lazy_frames[0].frame\n\n                if first_frame:\n                    actual_sr = getattr(\n                        first_frame, \"sampling_rate\", self.sampling_rate\n                    )\n                    frame_type_name = type(first_frame).__name__\n            except Exception as e:\n                logger.warning(\n                    f\"Error accessing the first frame during metadata retrieval: {e}\"\n                )\n\n        return {\n            \"folder_path\": str(self.folder_path),\n            \"file_count\": len(self._lazy_frames),\n            \"loaded_count\": loaded_count,\n            \"target_sampling_rate\": self.sampling_rate,\n            \"actual_sampling_rate\": actual_sr,\n            \"signal_length\": self.signal_length,\n            \"file_extensions\": self.file_extensions,\n            \"lazy_loading\": self._lazy_loading,\n            \"recursive\": self._recursive,\n            \"frame_type\": frame_type_name,\n            \"has_transform\": self._transform is not None,\n            \"is_sampled\": isinstance(self, _SampledFrameDataset),\n        }\n</code></pre> Attributes\u00b6 <code></code> <code>folder_path = Path(folder_path)</code> <code>instance-attribute</code> \u00b6 <code></code> <code>sampling_rate = sampling_rate</code> <code>instance-attribute</code> \u00b6 <code></code> <code>signal_length = signal_length</code> <code>instance-attribute</code> \u00b6 <code></code> <code>file_extensions = file_extensions or ['.wav']</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], F | None] | None = None,\n):\n    self.folder_path = Path(folder_path)\n    if source_dataset is None and not self.folder_path.exists():\n        raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n    self.sampling_rate = sampling_rate\n    self.signal_length = signal_length\n    self.file_extensions = file_extensions or [\".wav\"]\n    self._recursive = recursive\n    self._lazy_loading = lazy_loading\n\n    # Changed to a list of LazyFrame\n    self._lazy_frames: list[LazyFrame[F]] = []\n\n    self._source_dataset = source_dataset\n    self._transform = transform\n\n    if self._source_dataset:\n        self._initialize_from_source()\n    else:\n        self._initialize_from_folder()\n</code></pre> <code></code> <code>__len__()</code> \u00b6 <p>Return the number of files in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of files in the dataset.\"\"\"\n    return len(self._lazy_frames)\n</code></pre> <code></code> <code>get_by_label(label)</code> \u00b6 <p>Get a frame by its label (filename).</p> <code></code> <code>get_all_by_label(label)</code> \u00b6 <p>Get all frames matching the given label (filename).</p> <code></code> <code>__getitem__(key)</code> \u00b6 <pre><code>__getitem__(key: int) -&gt; F | None\n</code></pre><pre><code>__getitem__(key: str) -&gt; list[F]\n</code></pre> <p>Get the frame by index (int) or label (str).</p> <code></code> <code>apply(func)</code> \u00b6 <pre><code>apply(func: Callable[[F], F_out | None]) -&gt; FrameDataset[F_out]\n</code></pre><pre><code>apply(func: Callable[[F], Any | None]) -&gt; FrameDataset[Any]\n</code></pre> <p>Apply a function to the entire dataset to create a new dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n    \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n    new_dataset = type(self)(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=func,\n        sampling_rate=self.sampling_rate,\n        signal_length=self.signal_length,\n        file_extensions=self.file_extensions,\n        recursive=self._recursive,\n    )\n    return cast(\"FrameDataset[Any]\", new_dataset)\n</code></pre> <code></code> <code>save(output_folder, filename_prefix='')</code> \u00b6 <p>Save processed frames to files.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n    \"\"\"Save processed frames to files.\"\"\"\n    raise NotImplementedError(\"The save method is not currently implemented.\")\n</code></pre> <code></code> <code>sample(n=None, ratio=None, seed=None)</code> \u00b6 <p>Get a sample from the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def sample(\n    self,\n    n: int | None = None,\n    ratio: float | None = None,\n    seed: int | None = None,\n) -&gt; \"FrameDataset[F]\":\n    \"\"\"Get a sample from the dataset.\"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    total = len(self._lazy_frames)\n    if total == 0:\n        return type(self)(\n            str(self.folder_path),\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            lazy_loading=self._lazy_loading,\n            recursive=self._recursive,\n        )\n\n    # Determine sample size\n    if n is None and ratio is None:\n        n = max(1, min(10, int(total * 0.1)))\n    elif n is None and ratio is not None:\n        n = max(1, int(total * ratio))\n    elif n is not None:\n        n = max(1, n)\n    else:\n        n = 1\n\n    n = min(n, total)\n\n    # Randomly select indices\n    sampled_indices = sorted(random.sample(range(total), n))\n\n    return _SampledFrameDataset(self, sampled_indices)\n</code></pre> <code></code> <code>get_metadata()</code> \u00b6 <p>Get metadata for the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_metadata(self) -&gt; dict[str, Any]:\n    \"\"\"Get metadata for the dataset.\"\"\"\n    actual_sr: int | float | None = self.sampling_rate\n    frame_type_name = \"Unknown\"\n\n    # Count loaded frames\n    loaded_count = sum(\n        1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n    )\n\n    # Get metadata from the first frame (if possible)\n    first_frame: F | None = None\n    if len(self._lazy_frames) &gt; 0:\n        try:\n            if self._lazy_frames[0].is_loaded:\n                first_frame = self._lazy_frames[0].frame\n\n            if first_frame:\n                actual_sr = getattr(\n                    first_frame, \"sampling_rate\", self.sampling_rate\n                )\n                frame_type_name = type(first_frame).__name__\n        except Exception as e:\n            logger.warning(\n                f\"Error accessing the first frame during metadata retrieval: {e}\"\n            )\n\n    return {\n        \"folder_path\": str(self.folder_path),\n        \"file_count\": len(self._lazy_frames),\n        \"loaded_count\": loaded_count,\n        \"target_sampling_rate\": self.sampling_rate,\n        \"actual_sampling_rate\": actual_sr,\n        \"signal_length\": self.signal_length,\n        \"file_extensions\": self.file_extensions,\n        \"lazy_loading\": self._lazy_loading,\n        \"recursive\": self._recursive,\n        \"frame_type\": frame_type_name,\n        \"has_transform\": self._transform is not None,\n        \"is_sampled\": isinstance(self, _SampledFrameDataset),\n    }\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.FrameDataset.get_by_label--examples","title":"Examples","text":"<p>frame = dataset.get_by_label(\"sample_1.wav\") if frame: ...     print(frame.label)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_by_label(self, label: str) -&gt; F | None:\n    \"\"\"\n    Get a frame by its label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    Optional[F]\n        The frame if found, otherwise None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n    &gt;&gt;&gt; if frame:\n    ...     print(frame.label)\n    \"\"\"\n    # Keep for backward compatibility: return the first match but emit\n    # a DeprecationWarning recommending `get_all_by_label`.\n    all_matches = self.get_all_by_label(label)\n    if len(all_matches) &gt; 0:\n        warnings.warn(\n            \"get_by_label() returns the first matching frame and is deprecated; \"\n            \"use get_all_by_label() to obtain all matches.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return all_matches[0]\n    return None\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--notes","title":"Notes","text":"<ul> <li>Search is performed against the filename portion only (i.e. Path.name).</li> <li>Each matched frame will be loaded (triggering lazy load) via <code>_ensure_loaded</code>.</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_all_by_label(self, label: str) -&gt; list[F]:\n    \"\"\"\n    Get all frames matching the given label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    list[F]\n        A list of frames matching the label.\n        If none are found, returns an empty list.\n\n    Notes\n    -----\n    - Search is performed against the filename portion only (i.e. Path.name).\n    - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n    \"\"\"\n    matches: list[F] = []\n    for i, lazy_frame in enumerate(self._lazy_frames):\n        if lazy_frame.file_path.name == label:\n            loaded = self._ensure_loaded(i)\n            if loaded is not None:\n                matches.append(loaded)\n    return matches\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.FrameDataset.__getitem__--examples","title":"Examples","text":"<p>frame = dataset[0]  # by index frames = dataset[\"sample_1.wav\"]  # list of matches by filename</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n    \"\"\"\n    Get the frame by index (int) or label (str).\n\n    Parameters\n    ----------\n    key : int or str\n        Index (int) or filename/label (str).\n\n    Returns\n    -------\n    Optional[F] or list[F]\n        If `key` is an int, returns the frame or None. If `key` is a str,\n        returns a list of matching frames (may be empty).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset[0]  # by index\n    &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n    \"\"\"\n    if isinstance(key, int):\n        return self._ensure_loaded(key)\n    if isinstance(key, str):\n        # pandas-like behaviour: return all matches for the label as a list\n        return self.get_all_by_label(key)\n    raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.ChannelFrameDataset","title":"<code>ChannelFrameDataset</code>","text":"<p>               Bases: <code>FrameDataset[ChannelFrame]</code></p> <p>Dataset class for handling audio files as ChannelFrames in a folder.</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class ChannelFrameDataset(FrameDataset[ChannelFrame]):\n    \"\"\"\n    Dataset class for handling audio files as ChannelFrames in a folder.\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], ChannelFrame | None] | None = None,\n    ):\n        _file_extensions = file_extensions or [\n            \".wav\",\n            \".mp3\",\n            \".flac\",\n            \".csv\",\n        ]\n\n        super().__init__(\n            folder_path=folder_path,\n            sampling_rate=sampling_rate,\n            signal_length=signal_length,\n            file_extensions=_file_extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n            source_dataset=source_dataset,\n            transform=transform,\n        )\n\n    def _load_file(self, file_path: Path) -&gt; ChannelFrame | None:\n        \"\"\"Load an audio file and return a ChannelFrame.\"\"\"\n        try:\n            frame = ChannelFrame.from_file(file_path)\n            if self.sampling_rate and frame.sampling_rate != self.sampling_rate:\n                logger.info(\n                    f\"Resampling file {file_path.name} ({frame.sampling_rate} Hz) to \"\n                    f\"dataset rate ({self.sampling_rate} Hz).\"\n                )\n                frame = frame.resampling(target_sr=self.sampling_rate)\n            return frame\n        except Exception as e:\n            logger.error(f\"Failed to load or initialize file {file_path}: {str(e)}\")\n            return None\n\n    def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Resample all frames in the dataset.\"\"\"\n\n        def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.resampling(target_sr=target_sr)\n            except Exception as e:\n                logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n                return None\n\n        new_dataset = self.apply(_resample_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Trim all frames in the dataset.\"\"\"\n\n        def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.trim(start=start, end=end)\n            except Exception as e:\n                logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n                return None\n\n        new_dataset = self.apply(_trim_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Normalize all frames in the dataset.\"\"\"\n\n        def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.normalize(**kwargs)\n            except Exception as e:\n                logger.warning(f\"Normalization error ({kwargs}): {e}\")\n                return None\n\n        new_dataset = self.apply(_normalize_func)\n        return cast(ChannelFrameDataset, new_dataset)\n\n    def stft(\n        self,\n        n_fft: int = 2048,\n        hop_length: int | None = None,\n        win_length: int | None = None,\n        window: str = \"hann\",\n    ) -&gt; \"SpectrogramFrameDataset\":\n        \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n        _hop = hop_length or n_fft // 4\n\n        def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n            if frame is None:\n                return None\n            try:\n                return frame.stft(\n                    n_fft=n_fft,\n                    hop_length=_hop,\n                    win_length=win_length,\n                    window=window,\n                )\n            except Exception as e:\n                logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n                return None\n\n        new_dataset = SpectrogramFrameDataset(\n            folder_path=str(self.folder_path),\n            lazy_loading=True,\n            source_dataset=self,\n            transform=_stft_func,\n            sampling_rate=self.sampling_rate,\n        )\n        return new_dataset\n\n    @classmethod\n    def from_folder(\n        cls,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        file_extensions: list[str] | None = None,\n        recursive: bool = False,\n        lazy_loading: bool = True,\n    ) -&gt; \"ChannelFrameDataset\":\n        \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n        extensions = (\n            file_extensions\n            if file_extensions is not None\n            else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n        )\n\n        return cls(\n            folder_path,\n            sampling_rate=sampling_rate,\n            file_extensions=extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n        )\n</code></pre> Functions\u00b6 <code></code> <code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], ChannelFrame | None] | None = None,\n):\n    _file_extensions = file_extensions or [\n        \".wav\",\n        \".mp3\",\n        \".flac\",\n        \".csv\",\n    ]\n\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=_file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre> <code></code> <code>resample(target_sr)</code> \u00b6 <p>Resample all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Resample all frames in the dataset.\"\"\"\n\n    def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.resampling(target_sr=target_sr)\n        except Exception as e:\n            logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n            return None\n\n    new_dataset = self.apply(_resample_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre> <code></code> <code>trim(start, end)</code> \u00b6 <p>Trim all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Trim all frames in the dataset.\"\"\"\n\n    def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.trim(start=start, end=end)\n        except Exception as e:\n            logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n            return None\n\n    new_dataset = self.apply(_trim_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre> <code></code> <code>normalize(**kwargs)</code> \u00b6 <p>Normalize all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Normalize all frames in the dataset.\"\"\"\n\n    def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.normalize(**kwargs)\n        except Exception as e:\n            logger.warning(f\"Normalization error ({kwargs}): {e}\")\n            return None\n\n    new_dataset = self.apply(_normalize_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre> <code></code> <code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code> \u00b6 <p>Apply STFT to all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def stft(\n    self,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrameDataset\":\n    \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n    _hop = hop_length or n_fft // 4\n\n    def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.stft(\n                n_fft=n_fft,\n                hop_length=_hop,\n                win_length=win_length,\n                window=window,\n            )\n        except Exception as e:\n            logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n            return None\n\n    new_dataset = SpectrogramFrameDataset(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=_stft_func,\n        sampling_rate=self.sampling_rate,\n    )\n    return new_dataset\n</code></pre> <code></code> <code>from_folder(folder_path, sampling_rate=None, file_extensions=None, recursive=False, lazy_loading=True)</code> <code>classmethod</code> \u00b6 <p>Class method to create a ChannelFrameDataset from a folder.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>@classmethod\ndef from_folder(\n    cls,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    file_extensions: list[str] | None = None,\n    recursive: bool = False,\n    lazy_loading: bool = True,\n) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n    extensions = (\n        file_extensions\n        if file_extensions is not None\n        else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n    )\n\n    return cls(\n        folder_path,\n        sampling_rate=sampling_rate,\n        file_extensions=extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n    )\n</code></pre>"},{"location":"en/api/#wandas.utils.frame_dataset.SpectrogramFrameDataset","title":"<code>SpectrogramFrameDataset</code>","text":"<p>               Bases: <code>FrameDataset[SpectrogramFrame]</code></p> <p>Dataset class for handling spectrogram data as SpectrogramFrames. Expected to be generated mainly as a result of ChannelFrameDataset.stft().</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>class SpectrogramFrameDataset(FrameDataset[SpectrogramFrame]):\n    \"\"\"\n    Dataset class for handling spectrogram data as SpectrogramFrames.\n    Expected to be generated mainly as a result of ChannelFrameDataset.stft().\n    \"\"\"\n\n    def __init__(\n        self,\n        folder_path: str,\n        sampling_rate: int | None = None,\n        signal_length: int | None = None,\n        file_extensions: list[str] | None = None,\n        lazy_loading: bool = True,\n        recursive: bool = False,\n        source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n        transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n    ):\n        super().__init__(\n            folder_path=folder_path,\n            sampling_rate=sampling_rate,\n            signal_length=signal_length,\n            file_extensions=file_extensions,\n            lazy_loading=lazy_loading,\n            recursive=recursive,\n            source_dataset=source_dataset,\n            transform=transform,\n        )\n\n    def _load_file(self, file_path: Path) -&gt; SpectrogramFrame | None:\n        \"\"\"Direct loading from files is not currently supported.\"\"\"\n        logger.warning(\n            \"No method defined for directly loading SpectrogramFrames. Normally \"\n            \"created from ChannelFrameDataset.stft().\"\n        )\n        raise NotImplementedError(\n            \"No method defined for directly loading SpectrogramFrames\"\n        )\n\n    def plot(self, index: int, **kwargs: Any) -&gt; None:\n        \"\"\"Plot the spectrogram at the specified index.\"\"\"\n        try:\n            frame = self._ensure_loaded(index)\n\n            if frame is None:\n                logger.warning(\n                    f\"Cannot plot index {index} as it failed to load/transform.\"\n                )\n                return\n\n            plot_method = getattr(frame, \"plot\", None)\n            if callable(plot_method):\n                plot_method(**kwargs)\n            else:\n                logger.warning(\n                    f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                    f\"have a plot method implemented.\"\n                )\n        except Exception as e:\n            logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre> Functions\u00b6 <code></code> <code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n):\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre> <code></code> <code>plot(index, **kwargs)</code> \u00b6 <p>Plot the spectrogram at the specified index.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def plot(self, index: int, **kwargs: Any) -&gt; None:\n    \"\"\"Plot the spectrogram at the specified index.\"\"\"\n    try:\n        frame = self._ensure_loaded(index)\n\n        if frame is None:\n            logger.warning(\n                f\"Cannot plot index {index} as it failed to load/transform.\"\n            )\n            return\n\n        plot_method = getattr(frame, \"plot\", None)\n        if callable(plot_method):\n            plot_method(**kwargs)\n        else:\n            logger.warning(\n                f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                f\"have a plot method implemented.\"\n            )\n    except Exception as e:\n        logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre>"},{"location":"en/api/#wandas.utils.generate_sample.generate_sin--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the sine wave(s).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    # \u76f4\u63a5\u3001generate_sin_lazy\u95a2\u6570\u3092\u547c\u3073\u51fa\u3059\n    return generate_sin_lazy(\n        freqs=freqs, sampling_rate=sampling_rate, duration=duration, label=label\n    )\n</code></pre>"},{"location":"en/api/#wandas.utils.generate_sample.generate_sin_lazy--returns","title":"Returns","text":"<p>ChannelFrame     Lazy ChannelFrame object containing the sine wave(s).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin_lazy(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals using lazy computation.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        Lazy ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    label = label or \"Generated Sin\"\n    t = np.linspace(0, duration, int(sampling_rate * duration), endpoint=False)\n\n    _freqs: list[float]\n    if isinstance(freqs, float):\n        _freqs = [freqs]\n    elif isinstance(freqs, list):\n        _freqs = freqs\n    else:\n        raise ValueError(\"freqs must be a float or a list of floats.\")\n\n    channels = []\n    labels = []\n    for idx, freq in enumerate(_freqs):\n        data = np.sin(2 * np.pi * freq * t)\n        labels.append(f\"Channel {idx + 1}\")\n        channels.append(data)\n    return ChannelFrame.from_numpy(\n        data=np.array(channels),\n        label=label,\n        sampling_rate=sampling_rate,\n        ch_labels=labels,\n    )\n</code></pre>"},{"location":"en/api/#wandas.utils.introspection.accepted_kwargs","title":"<code>accepted_kwargs(func)</code>","text":"<p>Get the set of explicit keyword arguments accepted by a function and whether it accepts **kwargs.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>func</code> <code>Callable[..., Any]</code> <p>The function to inspect.</p> \u5fc5\u9808 <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>set[str]</code> <p>A tuple containing:</p> <code>bool</code> <ul> <li>set[str]: Set of explicit keyword argument names accepted by func.</li> </ul> <code>tuple[set[str], bool]</code> <ul> <li>bool: Whether the function accepts variable keyword arguments (**kwargs).</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/introspection.py</code> <pre><code>def accepted_kwargs(func: Callable[..., Any]) -&gt; tuple[set[str], bool]:\n    \"\"\"\n    Get the set of explicit keyword arguments accepted by\n    a function and whether it accepts **kwargs.\n\n    Args:\n        func: The function to inspect.\n\n    Returns:\n        A tuple containing:\n        - set[str]: Set of explicit keyword argument names accepted by func.\n        - bool: Whether the function accepts variable keyword arguments (**kwargs).\n    \"\"\"\n    # \u30e2\u30c3\u30af\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n    if hasattr(func, \"__module__\") and func.__module__ == \"unittest.mock\":\n        return set(), True\n    try:\n        params = signature(func).parameters.values()\n\n        # \u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u5f15\u6570\u3092\u53ce\u96c6\n        explicit_kwargs = {\n            p.name\n            for p in params\n            if p.kind in (Parameter.POSITIONAL_OR_KEYWORD, Parameter.KEYWORD_ONLY)\n        }\n\n        # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\n        has_var_kwargs = any(p.kind is Parameter.VAR_KEYWORD for p in params)\n\n        return explicit_kwargs, has_var_kwargs\n    except (ValueError, TypeError):\n        # \u30b7\u30b0\u30cd\u30c1\u30e3\u3092\u53d6\u5f97\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u7a7a\u30bb\u30c3\u30c8\u3068\u7121\u5236\u9650\u30d5\u30e9\u30b0\u3092\u8fd4\u3059\n        return set(), True\n</code></pre>"},{"location":"en/api/#wandas.utils.introspection.filter_kwargs","title":"<code>filter_kwargs(func, kwargs, *, strict_mode=False)</code>","text":"<p>Filter keyword arguments to only those accepted by the function.</p> <p>This function examines the signature of <code>func</code> and returns a dictionary containing only the key-value pairs from <code>kwargs</code> that are valid keyword arguments for <code>func</code>.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>func</code> <code>Callable[..., Any]</code> <p>The function to filter keyword arguments for.</p> \u5fc5\u9808 <code>kwargs</code> <code>Mapping[str, Any]</code> <p>The keyword arguments to filter.</p> \u5fc5\u9808 <code>strict_mode</code> <code>bool</code> <p>If True, only explicitly defined parameters are passed even when the function accepts kwargs. If False (default), all parameters are passed to functions that accept kwargs, but a warning is issued for parameters not explicitly defined.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>dict[str, Any]</code> <p>A dictionary containing only the key-value pairs that are valid for <code>func</code>.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/introspection.py</code> <pre><code>def filter_kwargs(\n    func: Callable[..., Any],\n    kwargs: Mapping[str, Any],\n    *,\n    strict_mode: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Filter keyword arguments to only those accepted by the function.\n\n    This function examines the signature of `func` and returns a dictionary\n    containing only the key-value pairs from `kwargs` that are valid keyword\n    arguments for `func`.\n\n    Args:\n        func: The function to filter keyword arguments for.\n        kwargs: The keyword arguments to filter.\n        strict_mode: If True, only explicitly defined parameters are passed even when\n            the function accepts **kwargs. If False (default), all parameters are\n            passed to functions that accept **kwargs, but a warning is issued for\n            parameters not explicitly defined.\n\n    Returns:\n        A dictionary containing only the key-value pairs that are valid for `func`.\n    \"\"\"\n    explicit_params, accepts_var_kwargs = accepted_kwargs(func)\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u306a\u3044\u5834\u5408\u3001\u307e\u305f\u306f strict_mode \u304c True \u306e\u5834\u5408\u306f\u3001\n    # \u660e\u793a\u7684\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n    if not accepts_var_kwargs or strict_mode:\n        filtered = {k: v for k, v in kwargs.items() if k in explicit_params}\n        return filtered\n\n    # **kwargs\u3092\u53d7\u3051\u4ed8\u3051\u308b\u5834\u5408\uff08strict_mode\u304cFalse\u306e\u5834\u5408\uff09\u306f\u5168\u30ad\u30fc\u3092\u8a31\u53ef\n    # \u305f\u3060\u3057\u3001\u660e\u793a\u7684\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u306a\u3044\u30ad\u30fc\u306b\u306f\u8b66\u544a\u3092\u51fa\u3059\n    unknown = set(kwargs) - explicit_params\n    if unknown:\n        warnings.warn(\n            f\"Implicit kwargs for {func.__name__}: {unknown}\",\n            UserWarning,\n            stacklevel=2,\n        )\n    return dict(kwargs)\n</code></pre>"},{"location":"en/api/#wandas.utils.util.validate_sampling_rate--examples","title":"Examples","text":"<p>validate_sampling_rate(44100)  # No error validate_sampling_rate(0)  # Raises ValueError validate_sampling_rate(-100)  # Raises ValueError</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def validate_sampling_rate(\n    sampling_rate: float, param_name: str = \"sampling_rate\"\n) -&gt; None:\n    \"\"\"\n    Validate that sampling rate is positive.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz to validate.\n    param_name : str, default=\"sampling_rate\"\n        Name of the parameter being validated (for error messages).\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate is not positive (i.e., &lt;= 0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; validate_sampling_rate(44100)  # No error\n    &gt;&gt;&gt; validate_sampling_rate(0)  # Raises ValueError\n    &gt;&gt;&gt; validate_sampling_rate(-100)  # Raises ValueError\n    \"\"\"\n    if sampling_rate &lt;= 0:\n        raise ValueError(\n            f\"Invalid {param_name}\\n\"\n            f\"  Got: {sampling_rate} Hz\\n\"\n            f\"  Expected: Positive value &gt; 0\\n\"\n            f\"Sampling rate represents samples per second and must be positive.\\n\"\n            f\"Common values: 8000, 16000, 22050, 44100, 48000 Hz\"\n        )\n</code></pre>"},{"location":"en/api/#wandas.utils.util.unit_to_ref--returns","title":"Returns","text":"<p>float     Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).     For other units, returns 1.0.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def unit_to_ref(unit: str) -&gt; float:\n    \"\"\"\n    Convert unit to reference value.\n\n    Parameters\n    ----------\n    unit : str\n        Unit string.\n\n    Returns\n    -------\n    float\n        Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).\n        For other units, returns 1.0.\n    \"\"\"\n    if unit == \"Pa\":\n        return 2e-5\n\n    else:\n        return 1.0\n</code></pre>"},{"location":"en/api/#wandas.utils.util.calculate_rms--returns","title":"Returns","text":"<p>Union[float, NDArray[np.float64]]     RMS value(s). For multi-channel input, returns an array of RMS values,     one per channel. For single-channel input, returns a single RMS value.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def calculate_rms(wave: \"NDArrayReal\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the root mean square of the wave.\n\n    Parameters\n    ----------\n    wave : NDArrayReal\n        Input waveform data. Can be multi-channel (shape: [channels, samples])\n        or single channel (shape: [samples]).\n\n    Returns\n    -------\n    Union[float, NDArray[np.float64]]\n        RMS value(s). For multi-channel input, returns an array of RMS values,\n        one per channel. For single-channel input, returns a single RMS value.\n    \"\"\"\n    # Calculate RMS considering axis (over the last dimension)\n    axis_to_use = -1 if wave.ndim &gt; 1 else None\n    rms_values: NDArrayReal = np.sqrt(\n        np.mean(np.square(wave), axis=axis_to_use, keepdims=True)\n    )\n    return rms_values\n</code></pre>"},{"location":"en/api/#wandas.utils.util.calculate_desired_noise_rms--returns","title":"Returns","text":"<p>\"NDArrayReal\"     Desired noise RMS value(s) to achieve the target SNR.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def calculate_desired_noise_rms(clean_rms: \"NDArrayReal\", snr: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the desired noise RMS based on clean signal RMS and target SNR.\n\n    Parameters\n    ----------\n    clean_rms : \"NDArrayReal\"\n        RMS value(s) of the clean signal.\n        Can be a single value or an array for multi-channel.\n    snr : float\n        Target Signal-to-Noise Ratio in dB.\n\n    Returns\n    -------\n    \"NDArrayReal\"\n        Desired noise RMS value(s) to achieve the target SNR.\n    \"\"\"\n    a = snr / 20\n    noise_rms = clean_rms / (10**a)\n    return noise_rms\n</code></pre>"},{"location":"en/api/#wandas.utils.util.amplitude_to_db--returns","title":"Returns","text":"<p>NDArrayReal     Amplitude data converted to decibels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def amplitude_to_db(amplitude: \"NDArrayReal\", ref: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Convert amplitude to decibel.\n\n    Parameters\n    ----------\n    amplitude : NDArrayReal\n        Input amplitude data.\n    ref : float\n        Reference value for conversion.\n\n    Returns\n    -------\n    NDArrayReal\n        Amplitude data converted to decibels.\n    \"\"\"\n    db: NDArrayReal = librosa.amplitude_to_db(\n        np.abs(amplitude), ref=ref, amin=1e-15, top_db=None\n    )\n    return db\n</code></pre>"},{"location":"en/api/#wandas.utils.util.level_trigger--returns","title":"Returns","text":"<p>list of int     List of sample indices where the signal crosses the level.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def level_trigger(\n    data: \"NDArrayReal\", level: float, offset: int = 0, hold: int = 1\n) -&gt; list[int]:\n    \"\"\"\n    Find points where the signal crosses the specified level from below.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    level : float\n        Threshold level for triggering.\n    offset : int, default=0\n        Offset to add to trigger points.\n    hold : int, default=1\n        Minimum number of samples between successive trigger points.\n\n    Returns\n    -------\n    list of int\n        List of sample indices where the signal crosses the level.\n    \"\"\"\n    trig_point: list[int] = []\n\n    sig_len = len(data)\n    diff = np.diff(np.sign(data - level))\n    level_point = np.where(diff &gt; 0)[0]\n    level_point = level_point[(level_point + hold) &lt; sig_len]\n\n    if len(level_point) == 0:\n        return list()\n\n    last_point = level_point[0]\n    trig_point.append(last_point + offset)\n    for i in level_point:\n        if (last_point + hold) &lt; i:\n            trig_point.append(i + offset)\n            last_point = i\n\n    return trig_point\n</code></pre>"},{"location":"en/api/#wandas.utils.util.cut_sig--returns","title":"Returns","text":"<p>NDArrayReal     Array containing cut segments with shape (n_segments, cut_len).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def cut_sig(\n    data: \"NDArrayReal\",\n    point_list: list[int],\n    cut_len: int,\n    taper_rate: float = 0,\n    dc_cut: bool = False,\n) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Cut segments from signal at specified points.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    point_list : list of int\n        List of starting points for cutting.\n    cut_len : int\n        Length of each segment to cut.\n    taper_rate : float, default=0\n        Taper rate for Tukey window applied to segments.\n        A value of 0 means no tapering, 1 means full tapering.\n    dc_cut : bool, default=False\n        Whether to remove DC component (mean) from segments.\n\n    Returns\n    -------\n    NDArrayReal\n        Array containing cut segments with shape (n_segments, cut_len).\n    \"\"\"\n    length = len(data)\n    point_list_ = [p for p in point_list if p &gt;= 0 and p + cut_len &lt;= length]\n    trial: NDArrayReal = np.zeros((len(point_list_), cut_len))\n\n    for i, v in enumerate(point_list_):\n        trial[i] = data[v : v + cut_len]\n        if dc_cut:\n            trial[i] = trial[i] - trial[i].mean()\n\n    win: NDArrayReal = tukey(cut_len, taper_rate).astype(trial.dtype)[np.newaxis, :]\n    trial = trial * win\n    return trial\n</code></pre>"},{"location":"en/api/#visualization-module","title":"Visualization Module","text":"<p>The visualization module provides data visualization functions.</p>"},{"location":"en/api/#wandas.visualization.plotting.PlotStrategy","title":"<code>PlotStrategy</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TFrame]</code></p> <p>Base class for plotting strategies</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class PlotStrategy(abc.ABC, Generic[TFrame]):\n    \"\"\"Base class for plotting strategies\"\"\"\n\n    name: ClassVar[str]\n\n    @abc.abstractmethod\n    def channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass\n\n    @abc.abstractmethod\n    def plot(\n        self,\n        bf: TFrame,\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Implementation of plotting\"\"\"\n        pass\n</code></pre> Attributes\u00b6 <code></code> <code>name</code> <code>class-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax)</code> <code>abstractmethod</code> \u00b6 <p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> <code>abstractmethod</code> \u00b6 <p>Implementation of plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef plot(\n    self,\n    bf: TFrame,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of plotting\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.WaveformPlotStrategy","title":"<code>WaveformPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['ChannelFrame']</code></p> <p>Strategy for waveform plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class WaveformPlotStrategy(PlotStrategy[\"ChannelFrame\"]):\n    \"\"\"Strategy for waveform plotting\"\"\"\n\n    name = \"waveform\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.plot(x, y, **kwargs)\n        ax.set_ylabel(\"Amplitude\")\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"ChannelFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Waveform plotting\"\"\"\n        kwargs = kwargs or {}\n        ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n        xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(\n            Line2D,\n            kwargs,\n            strict_mode=True,\n        )\n        ax_set = filter_kwargs(\n            Axes.set,\n            kwargs,\n            strict_mode=True,\n        )\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        data = bf.data\n        data = _reshape_to_2d(data)\n        if overlay:\n            if ax is None:\n                fig, ax = plt.subplots(figsize=(10, 4))\n\n            self.channel_plot(\n                bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n            )\n            ax.set(\n                ylabel=ylabel,\n                title=title or bf.label or \"Channel Data\",\n                xlabel=xlabel,\n                **ax_set,\n            )\n            if ax is None:\n                fig.suptitle(title or bf.label or None)\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n                )\n                ax_i.set(\n                    ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                    title=ch_meta.label,\n                    **ax_set,\n                )\n\n            axes_list[-1].set(\n                xlabel=\"Time [s]\",\n            )\n            fig.suptitle(title or bf.label or \"Channel Data\")\n\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'waveform'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.set_ylabel(\"Amplitude\")\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Waveform plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Waveform plotting\"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n    xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(\n        Line2D,\n        kwargs,\n        strict_mode=True,\n    )\n    ax_set = filter_kwargs(\n        Axes.set,\n        kwargs,\n        strict_mode=True,\n    )\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    data = bf.data\n    data = _reshape_to_2d(data)\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(10, 4))\n\n        self.channel_plot(\n            bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n        )\n        ax.set(\n            ylabel=ylabel,\n            title=title or bf.label or \"Channel Data\",\n            xlabel=xlabel,\n            **ax_set,\n        )\n        if ax is None:\n            fig.suptitle(title or bf.label or None)\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n            )\n            ax_i.set(\n                ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                title=ch_meta.label,\n                **ax_set,\n            )\n\n        axes_list[-1].set(\n            xlabel=\"Time [s]\",\n        )\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.FrequencyPlotStrategy","title":"<code>FrequencyPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectralFrame']</code></p> <p>Strategy for frequency domain plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class FrequencyPlotStrategy(PlotStrategy[\"SpectralFrame\"]):\n    \"\"\"Strategy for frequency domain plotting\"\"\"\n\n    name = \"frequency\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.plot(x, y, **kwargs)\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"SpectralFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Frequency domain plotting\"\"\"\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n        if (\n            len(bf.operation_history) &gt; 0\n            and bf.operation_history[-1][\"operation\"] == \"coherence\"\n        ):\n            unit = \"\"\n            data = bf.magnitude\n            ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n        else:\n            if is_aw:\n                unit = \"dBA\"\n                data = bf.dBA\n            else:\n                unit = \"dB\"\n                data = bf.dB\n            ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n        data = _reshape_to_2d(data)\n        xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                _, ax = plt.subplots(figsize=(10, 4))\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,\n                label=bf.labels,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax.set(\n                ylabel=ylabel,\n                xlabel=xlabel,\n                title=title or bf.label or \"Channel Data\",\n                **ax_set,\n            )\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    label=ch_meta.label,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(\n                    ylabel=ylabel,\n                    title=ch_meta.label,\n                    xlabel=xlabel,\n                    **ax_set,\n                )\n            axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n            fig.suptitle(title or bf.label or \"Channel Data\")\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'frequency'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Frequency domain plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Frequency domain plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    data = _reshape_to_2d(data)\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=title or bf.label or \"Channel Data\",\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.NOctPlotStrategy","title":"<code>NOctPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['NOctFrame']</code></p> <p>Strategy for N-octave band analysis plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class NOctPlotStrategy(PlotStrategy[\"NOctFrame\"]):\n    \"\"\"Strategy for N-octave band analysis plotting\"\"\"\n\n    name = \"noct\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        ax.step(x, y, **kwargs)\n        ax.grid(True)\n        if \"label\" in kwargs:\n            ax.legend()\n\n    def plot(\n        self,\n        bf: \"NOctFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"N-octave band analysis plotting\"\"\"\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n\n        if is_aw:\n            unit = \"dBrA\"\n            data = bf.dBA\n        else:\n            unit = \"dBr\"\n            data = bf.dB\n        data = _reshape_to_2d(data)\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n        xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                _, ax = plt.subplots(figsize=(10, 4))\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,\n                label=bf.labels,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n            actual_title = title if title else (bf.label or default_title)\n            ax.set(\n                ylabel=ylabel,\n                xlabel=xlabel,\n                title=actual_title,\n                **ax_set,\n            )\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n            )\n            # Convert axs to list if it is a single Axes object\n            if not isinstance(axs, list | np.ndarray):\n                axs = [axs]\n\n            axes_list = list(axs)\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    label=ch_meta.label,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(\n                    ylabel=ylabel,\n                    title=ch_meta.label,\n                    xlabel=xlabel,\n                    **ax_set,\n                )\n            axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n            fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n            if ax is None:\n                plt.tight_layout()\n                plt.show()\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'noct'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.step(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>N-octave band analysis plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"NOctFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"N-octave band analysis plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n\n    if is_aw:\n        unit = \"dBrA\"\n        data = bf.dBA\n    else:\n        unit = \"dBr\"\n        data = bf.dB\n    data = _reshape_to_2d(data)\n    ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n        actual_title = title if title else (bf.label or default_title)\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=actual_title,\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.SpectrogramPlotStrategy","title":"<code>SpectrogramPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectrogramFrame']</code></p> <p>Strategy for spectrogram plotting</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class SpectrogramPlotStrategy(PlotStrategy[\"SpectrogramFrame\"]):\n    \"\"\"Strategy for spectrogram plotting\"\"\"\n\n    name = \"spectrogram\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass\n\n    def plot(\n        self,\n        bf: \"SpectrogramFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Spectrogram plotting\"\"\"\n        # Explicit overlay mode is not supported for spectrograms\n        if overlay:\n            raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n        # If an Axes is provided, allow drawing into it only for single-channel frames\n        if ax is not None and bf.n_channels &gt; 1:\n            raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n        kwargs = kwargs or {}\n\n        is_aw = kwargs.pop(\"Aw\", False)\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        data = _reshape_spectrogram_data(data)\n        specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n        ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n        cmap = kwargs.pop(\"cmap\", \"jet\")\n        vmin = kwargs.pop(\"vmin\", None)\n        vmax = kwargs.pop(\"vmax\", None)\n\n        if ax is not None:\n            img = display.specshow(\n                data=data[0],\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                cmap=cmap,\n                ax=ax,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax.set(\n                title=title or bf.label or \"Spectrogram\",\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n\n            fig = ax.figure\n            if fig is not None:\n                try:\n                    cbar = fig.colorbar(img, ax=ax)\n                    cbar.set_label(f\"Spectrum level [{unit}]\")\n                except (ValueError, AttributeError) as e:\n                    # Handle case where img doesn't have proper colorbar properties\n                    logger.warning(\n                        f\"Failed to create colorbar for spectrogram: \"\n                        f\"{type(e).__name__}: {e}\"\n                    )\n            return ax\n\n        else:\n            # Create a new figure if ax is None\n            num_channels = bf.n_channels\n            fig, axs = plt.subplots(\n                num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n            )\n            if not isinstance(fig, Figure):\n                raise ValueError(\"fig must be a matplotlib Figure object.\")\n            # Convert axs to array if it is a single Axes object\n            if not isinstance(axs, np.ndarray):\n                axs = np.array([axs])\n\n            for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n                img = display.specshow(\n                    data=channel_data,\n                    sr=bf.sampling_rate,\n                    hop_length=bf.hop_length,\n                    n_fft=bf.n_fft,\n                    win_length=bf.win_length,\n                    x_axis=\"time\",\n                    y_axis=\"linear\",\n                    ax=ax_i,\n                    cmap=cmap,\n                    vmin=vmin,\n                    vmax=vmax,\n                    **specshow_kwargs,\n                )\n                ax_i.set(\n                    title=ch_meta.label,\n                    ylabel=\"Frequency [Hz]\",\n                    xlabel=\"Time [s]\",\n                    **ax_set_kwargs,\n                )\n                try:\n                    cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                    cbar.set_label(f\"Spectrum level [{unit}]\")\n                except (ValueError, AttributeError) as e:\n                    # Handle case where img doesn't have proper colorbar properties\n                    logger.warning(\n                        f\"Failed to create colorbar for spectrogram: \"\n                        f\"{type(e).__name__}: {e}\"\n                    )\n                fig.suptitle(title or \"Spectrogram Data\")\n            plt.tight_layout()\n            plt.show()\n\n            return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'spectrogram'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Spectrogram plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectrogramFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Spectrogram plotting\"\"\"\n    # Explicit overlay mode is not supported for spectrograms\n    if overlay:\n        raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n    # If an Axes is provided, allow drawing into it only for single-channel frames\n    if ax is not None and bf.n_channels &gt; 1:\n        raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n    kwargs = kwargs or {}\n\n    is_aw = kwargs.pop(\"Aw\", False)\n    if is_aw:\n        unit = \"dBA\"\n        data = bf.dBA\n    else:\n        unit = \"dB\"\n        data = bf.dB\n    data = _reshape_spectrogram_data(data)\n    specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n    ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n\n    if ax is not None:\n        img = display.specshow(\n            data=data[0],\n            sr=bf.sampling_rate,\n            hop_length=bf.hop_length,\n            n_fft=bf.n_fft,\n            win_length=bf.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            cmap=cmap,\n            ax=ax,\n            vmin=vmin,\n            vmax=vmax,\n            **specshow_kwargs,\n        )\n        ax.set(\n            title=title or bf.label or \"Spectrogram\",\n            ylabel=\"Frequency [Hz]\",\n            xlabel=\"Time [s]\",\n            **ax_set_kwargs,\n        )\n\n        fig = ax.figure\n        if fig is not None:\n            try:\n                cbar = fig.colorbar(img, ax=ax)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n        return ax\n\n    else:\n        # Create a new figure if ax is None\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n        )\n        if not isinstance(fig, Figure):\n            raise ValueError(\"fig must be a matplotlib Figure object.\")\n        # Convert axs to array if it is a single Axes object\n        if not isinstance(axs, np.ndarray):\n            axs = np.array([axs])\n\n        for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n            img = display.specshow(\n                data=channel_data,\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                ax=ax_i,\n                cmap=cmap,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax_i.set(\n                title=ch_meta.label,\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n            try:\n                cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n            fig.suptitle(title or \"Spectrogram Data\")\n        plt.tight_layout()\n        plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.DescribePlotStrategy","title":"<code>DescribePlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['ChannelFrame']</code></p> <p>Strategy for visualizing ChannelFrame data with describe plot</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class DescribePlotStrategy(PlotStrategy[\"ChannelFrame\"]):\n    \"\"\"Strategy for visualizing ChannelFrame data with describe plot\"\"\"\n\n    name = \"describe\"\n\n    def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n        \"\"\"Implementation of channel plotting\"\"\"\n        pass  # This method is not used for describe plot\n\n    def plot(\n        self,\n        bf: \"ChannelFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n        fmin = kwargs.pop(\"fmin\", 0)\n        fmax = kwargs.pop(\"fmax\", None)\n        cmap = kwargs.pop(\"cmap\", \"jet\")\n        vmin = kwargs.pop(\"vmin\", None)\n        vmax = kwargs.pop(\"vmax\", None)\n        xlim = kwargs.pop(\"xlim\", None)\n        ylim = kwargs.pop(\"ylim\", None)\n        is_aw = kwargs.pop(\"Aw\", False)\n        waveform = kwargs.pop(\"waveform\", {})\n        spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n        gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n        gs.update(wspace=0.2)\n\n        fig = plt.figure(figsize=(12, 6))\n        fig.subplots_adjust(wspace=0.0001)\n\n        # First subplot (Time Plot)\n        ax_1 = fig.add_subplot(gs[0])\n        bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n        ax_1.set(**waveform)\n        ax_1.legend().set_visible(False)\n        ax_1.set(xlabel=\"\", title=\"\")\n\n        # Second subplot (STFT Plot)\n        ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n        stft_ch = bf.stft()\n        if is_aw:\n            unit = \"dBA\"\n            channel_data = stft_ch.dBA\n        else:\n            unit = \"dB\"\n            channel_data = stft_ch.dB\n        if channel_data.ndim == 3:\n            channel_data = channel_data[0]\n        # Get the maximum value of the data and round it to a convenient value\n        if vmax is None:\n            data_max = np.nanmax(channel_data)\n            # Round to a convenient number with increments of 10, 5, or 2\n            for step in [10, 5, 2]:\n                rounded_max = np.ceil(data_max / step) * step\n                if rounded_max &gt;= data_max:\n                    vmax = rounded_max\n                    vmin = vmax - 180\n                    break\n        img = display.specshow(\n            data=channel_data,\n            sr=bf.sampling_rate,\n            hop_length=stft_ch.hop_length,\n            n_fft=stft_ch.n_fft,\n            win_length=stft_ch.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            ax=ax_2,\n            fmin=fmin,\n            fmax=fmax,\n            cmap=cmap,\n            vmin=vmin,\n            vmax=vmax,\n        )\n        ax_2.set(xlim=xlim, ylim=ylim)\n\n        # Third subplot\n        ax_3 = fig.add_subplot(gs[1])\n        ax_3.axis(\"off\")\n\n        # Fourth subplot (Welch Plot)\n        ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n        welch_ch = bf.welch()\n        if is_aw:\n            unit = \"dBA\"\n            data_db = welch_ch.dBA\n        else:\n            unit = \"dB\"\n            data_db = welch_ch.dB\n        ax_4.plot(data_db.T, welch_ch.freqs.T)\n        ax_4.grid(True)\n        ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n        cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n        cbar.set_label(unit)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        return _return_axes_iterator(fig.axes)\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'describe'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, **kwargs)</code> \u00b6 <p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass  # This method is not used for describe plot\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 <p>Implementation of describe method for visualizing ChannelFrame data</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n    fmin = kwargs.pop(\"fmin\", 0)\n    fmax = kwargs.pop(\"fmax\", None)\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n    xlim = kwargs.pop(\"xlim\", None)\n    ylim = kwargs.pop(\"ylim\", None)\n    is_aw = kwargs.pop(\"Aw\", False)\n    waveform = kwargs.pop(\"waveform\", {})\n    spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n    gs.update(wspace=0.2)\n\n    fig = plt.figure(figsize=(12, 6))\n    fig.subplots_adjust(wspace=0.0001)\n\n    # First subplot (Time Plot)\n    ax_1 = fig.add_subplot(gs[0])\n    bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n    ax_1.set(**waveform)\n    ax_1.legend().set_visible(False)\n    ax_1.set(xlabel=\"\", title=\"\")\n\n    # Second subplot (STFT Plot)\n    ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n    stft_ch = bf.stft()\n    if is_aw:\n        unit = \"dBA\"\n        channel_data = stft_ch.dBA\n    else:\n        unit = \"dB\"\n        channel_data = stft_ch.dB\n    if channel_data.ndim == 3:\n        channel_data = channel_data[0]\n    # Get the maximum value of the data and round it to a convenient value\n    if vmax is None:\n        data_max = np.nanmax(channel_data)\n        # Round to a convenient number with increments of 10, 5, or 2\n        for step in [10, 5, 2]:\n            rounded_max = np.ceil(data_max / step) * step\n            if rounded_max &gt;= data_max:\n                vmax = rounded_max\n                vmin = vmax - 180\n                break\n    img = display.specshow(\n        data=channel_data,\n        sr=bf.sampling_rate,\n        hop_length=stft_ch.hop_length,\n        n_fft=stft_ch.n_fft,\n        win_length=stft_ch.win_length,\n        x_axis=\"time\",\n        y_axis=\"linear\",\n        ax=ax_2,\n        fmin=fmin,\n        fmax=fmax,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n    ax_2.set(xlim=xlim, ylim=ylim)\n\n    # Third subplot\n    ax_3 = fig.add_subplot(gs[1])\n    ax_3.axis(\"off\")\n\n    # Fourth subplot (Welch Plot)\n    ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n    welch_ch = bf.welch()\n    if is_aw:\n        unit = \"dBA\"\n        data_db = welch_ch.dBA\n    else:\n        unit = \"dB\"\n        data_db = welch_ch.dB\n    ax_4.plot(data_db.T, welch_ch.freqs.T)\n    ax_4.grid(True)\n    ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n    cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n    cbar.set_label(unit)\n    fig.suptitle(title or bf.label or \"Channel Data\")\n\n    return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.MatrixPlotStrategy","title":"<code>MatrixPlotStrategy</code>","text":"<p>               Bases: <code>PlotStrategy['SpectralFrame']</code></p> <p>Strategy for displaying relationships between channels in matrix format</p> Source code in <code>wandas/visualization/plotting.py</code> <pre><code>class MatrixPlotStrategy(PlotStrategy[\"SpectralFrame\"]):\n    \"\"\"Strategy for displaying relationships between channels in matrix format\"\"\"\n\n    name = \"matrix\"\n\n    def channel_plot(\n        self,\n        x: Any,\n        y: Any,\n        ax: \"Axes\",\n        title: str | None = None,\n        ylabel: str = \"\",\n        xlabel: str = \"Frequency [Hz]\",\n        alpha: float = 0,\n        **kwargs: Any,\n    ) -&gt; None:\n        ax.plot(x, y, **kwargs)\n        ax.grid(True)\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.set_title(title or \"\")\n\n    def plot(\n        self,\n        bf: \"SpectralFrame\",\n        ax: Optional[\"Axes\"] = None,\n        title: str | None = None,\n        overlay: bool = False,\n        **kwargs: Any,\n    ) -&gt; Axes | Iterator[Axes]:\n        kwargs = kwargs or {}\n        is_aw = kwargs.pop(\"Aw\", False)\n        if (\n            len(bf.operation_history) &gt; 0\n            and bf.operation_history[-1][\"operation\"] == \"coherence\"\n        ):\n            unit = \"\"\n            data = bf.magnitude\n            ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n        else:\n            if is_aw:\n                unit = \"dBA\"\n                data = bf.dBA\n            else:\n                unit = \"dB\"\n                data = bf.dB\n            ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n        data = _reshape_to_2d(data)\n\n        xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n        alpha = kwargs.pop(\"alpha\", 1)\n        plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n        ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n        num_channels = bf.n_channels\n        # If an Axes is provided, prefer drawing into it (treat as overlay)\n        if ax is not None:\n            overlay = True\n        if overlay:\n            if ax is None:\n                fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n            else:\n                fig = ax.figure\n            self.channel_plot(\n                bf.freqs,\n                data.T,\n                ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n                title=title or bf.label or \"Spectral Data\",\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax.set(**ax_set)\n            if fig is not None:\n                fig.suptitle(title or bf.label or \"Spectral Data\")\n            if ax.figure != fig:  # Only show if we created the figure\n                plt.tight_layout()\n                plt.show()\n            return ax\n        else:\n            num_rows = int(np.ceil(np.sqrt(num_channels)))\n            fig, axs = plt.subplots(\n                num_rows,\n                num_rows,\n                figsize=(3 * num_rows, 3 * num_rows),\n                sharex=True,\n                sharey=True,\n            )\n            if isinstance(axs, np.ndarray):\n                axes_list = axs.flatten().tolist()\n            elif isinstance(axs, list):\n                import itertools\n\n                axes_list = list(itertools.chain.from_iterable(axs))\n            else:\n                axes_list = [axs]\n            for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n                self.channel_plot(\n                    bf.freqs,\n                    channel_data,\n                    ax_i,\n                    title=ch_meta.label,\n                    ylabel=ylabel,\n                    xlabel=xlabel,\n                    alpha=alpha,\n                    **plot_kwargs,\n                )\n                ax_i.set(**ax_set)\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n            plt.tight_layout()\n            plt.show()\n            return _return_axes_iterator(fig.axes)\n\n        raise NotImplementedError()\n</code></pre> Attributes\u00b6 <code></code> <code>name = 'matrix'</code> <code>class-attribute</code> <code>instance-attribute</code> \u00b6 Functions\u00b6 <code></code> <code>channel_plot(x, y, ax, title=None, ylabel='', xlabel='Frequency [Hz]', alpha=0, **kwargs)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    title: str | None = None,\n    ylabel: str = \"\",\n    xlabel: str = \"Frequency [Hz]\",\n    alpha: float = 0,\n    **kwargs: Any,\n) -&gt; None:\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_title(title or \"\")\n</code></pre> <code></code> <code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code> \u00b6 \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n    data = _reshape_to_2d(data)\n\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    num_channels = bf.n_channels\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n        else:\n            fig = ax.figure\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n            title=title or bf.label or \"Spectral Data\",\n            ylabel=ylabel,\n            xlabel=xlabel,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(**ax_set)\n        if fig is not None:\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n        if ax.figure != fig:  # Only show if we created the figure\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_rows = int(np.ceil(np.sqrt(num_channels)))\n        fig, axs = plt.subplots(\n            num_rows,\n            num_rows,\n            figsize=(3 * num_rows, 3 * num_rows),\n            sharex=True,\n            sharey=True,\n        )\n        if isinstance(axs, np.ndarray):\n            axes_list = axs.flatten().tolist()\n        elif isinstance(axs, list):\n            import itertools\n\n            axes_list = list(itertools.chain.from_iterable(axs))\n        else:\n            axes_list = [axs]\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                title=ch_meta.label,\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(**ax_set)\n        fig.suptitle(title or bf.label or \"Spectral Data\")\n        plt.tight_layout()\n        plt.show()\n        return _return_axes_iterator(fig.axes)\n\n    raise NotImplementedError()\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.register_plot_strategy","title":"<code>register_plot_strategy(strategy_cls)</code>","text":"<p>Register a new plot strategy from a class</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def register_plot_strategy(strategy_cls: type) -&gt; None:\n    \"\"\"Register a new plot strategy from a class\"\"\"\n    if not issubclass(strategy_cls, PlotStrategy):\n        raise TypeError(\"Strategy class must inherit from PlotStrategy.\")\n    if inspect.isabstract(strategy_cls):\n        raise TypeError(\"Cannot register abstract PlotStrategy class.\")\n    _plot_strategies[strategy_cls.name] = strategy_cls\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.get_plot_strategy","title":"<code>get_plot_strategy(name)</code>","text":"<p>Get plot strategy by name</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def get_plot_strategy(name: str) -&gt; type[PlotStrategy[Any]]:\n    \"\"\"Get plot strategy by name\"\"\"\n    if name not in _plot_strategies:\n        raise ValueError(f\"Unknown plot type: {name}\")\n    return _plot_strategies[name]\n</code></pre>"},{"location":"en/api/#wandas.visualization.plotting.create_operation","title":"<code>create_operation(name, **params)</code>","text":"<p>Create operation instance from operation name and parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def create_operation(name: str, **params: Any) -&gt; PlotStrategy[Any]:\n    \"\"\"Create operation instance from operation name and parameters\"\"\"\n    operation_class = get_plot_strategy(name)\n    return operation_class(**params)\n</code></pre>"},{"location":"en/api/#wandas.visualization.types.DescribeParams","title":"<code>DescribeParams</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters for the describe visualization method.</p> <p>This visualization creates a comprehensive view with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>\u5c5e\u6027\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency</p> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots.</p> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots.</p> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>waveform</code> <code>WaveformConfig</code> <p>Additional configuration dict for waveform subplot.</p> <code>spectral</code> <code>SpectralConfig</code> <p>Additional configuration dict for spectral subplot.</p> <code>normalize</code> <code>bool</code> <p>Normalize audio data for playback. Default: True</p> <code>is_close</code> <code>bool</code> <p>Close the figure after displaying. Default: True</p> <p>Deprecated (for backward compatibility):     axis_config: Old configuration format.         Use specific parameters instead.     cbar_config: Old colorbar configuration. Use vmin/vmax instead.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n</code></pre> Source code in <code>wandas/visualization/types.py</code> <pre><code>class DescribeParams(TypedDict, total=False):\n    \"\"\"Parameters for the describe visualization method.\n\n    This visualization creates a comprehensive view with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Attributes:\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency\n        cmap: Colormap for the spectrogram. Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n        Aw: Apply A-weighting to the frequency analysis. Default: False\n        waveform: Additional configuration dict for waveform subplot.\n        spectral: Additional configuration dict for spectral subplot.\n        normalize: Normalize audio data for playback. Default: True\n        is_close: Close the figure after displaying. Default: True\n\n    Deprecated (for backward compatibility):\n        axis_config: Old configuration format.\n            Use specific parameters instead.\n        cbar_config: Old colorbar configuration. Use vmin/vmax instead.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n    \"\"\"\n\n    # Spectrogram parameters\n    fmin: float\n    fmax: float | None\n    cmap: str\n    vmin: float | None\n    vmax: float | None\n\n    # Axis limits\n    xlim: tuple[float, float] | None\n    ylim: tuple[float, float] | None\n\n    # Weighting\n    Aw: bool\n\n    # Subplot configurations\n    waveform: WaveformConfig\n    spectral: SpectralConfig\n\n    # Display options\n    normalize: bool\n    is_close: bool\n\n    # Deprecated (backward compatibility)\n    axis_config: dict[str, Any]\n    cbar_config: dict[str, Any]\n</code></pre> Attributes\u00b6 <code></code> <code>fmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>fmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cmap</code> <code>instance-attribute</code> \u00b6 <code></code> <code>vmin</code> <code>instance-attribute</code> \u00b6 <code></code> <code>vmax</code> <code>instance-attribute</code> \u00b6 <code></code> <code>xlim</code> <code>instance-attribute</code> \u00b6 <code></code> <code>ylim</code> <code>instance-attribute</code> \u00b6 <code></code> <code>Aw</code> <code>instance-attribute</code> \u00b6 <code></code> <code>waveform</code> <code>instance-attribute</code> \u00b6 <code></code> <code>spectral</code> <code>instance-attribute</code> \u00b6 <code></code> <code>normalize</code> <code>instance-attribute</code> \u00b6 <code></code> <code>is_close</code> <code>instance-attribute</code> \u00b6 <code></code> <code>axis_config</code> <code>instance-attribute</code> \u00b6 <code></code> <code>cbar_config</code> <code>instance-attribute</code> \u00b6"},{"location":"en/api/#datasets-module","title":"Datasets Module","text":"<p>The datasets module provides sample data and dataset functions.</p>"},{"location":"en/api/#wandas.datasets.sample_data.load_sample_signal--returns","title":"Returns","text":"<p>NDArrayReal     Signal data as a NumPy array.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/datasets/sample_data.py</code> <pre><code>def load_sample_signal(\n    frequency: float = 5.0, sampling_rate: int = 100, duration: float = 1.0\n) -&gt; NDArrayReal:\n    \"\"\"\n    Generate a sample sine wave signal.\n\n    Parameters\n    ----------\n    frequency : float, default=5.0\n        Frequency of the signal in Hz.\n    sampling_rate : int, default=100\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n\n    Returns\n    -------\n    NDArrayReal\n        Signal data as a NumPy array.\n    \"\"\"\n    num_samples = int(sampling_rate * duration)\n    t = np.arange(num_samples) / sampling_rate\n    signal: NDArrayReal = np.sin(2 * np.pi * frequency * t, dtype=np.float64)\n    return signal\n</code></pre>"},{"location":"en/api/core/","title":"Core Module","text":"<p>The <code>wandas.core</code> module provides the foundation components of the Wandas library.</p>"},{"location":"en/api/core/#baseframe","title":"BaseFrame","text":"<p>BaseFrame is the base class for all Wandas frames. It defines the basic data structure and operations.</p>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n):\n    self._data = data.rechunk(chunks=-1)  # type: ignore [unused-ignore]\n    if self._data.ndim == 1:\n        self._data = self._data.reshape((1, -1))\n    self.sampling_rate = sampling_rate\n    self.label = label or \"unnamed_frame\"\n    self.metadata = metadata or {}\n    self.operation_history = operation_history or []\n    self._previous = previous\n\n    if channel_metadata:\n        # Pydantic handles both ChannelMetadata objects and dicts\n        def _to_channel_metadata(\n            ch: ChannelMetadata | dict[str, Any], index: int\n        ) -&gt; ChannelMetadata:\n            if isinstance(ch, ChannelMetadata):\n                return copy.deepcopy(ch)\n            elif isinstance(ch, dict):\n                try:\n                    return ChannelMetadata(**ch)\n                except ValidationError as e:\n                    raise ValueError(\n                        f\"Invalid channel_metadata at index {index}\\n\"\n                        f\"  Got: {ch}\\n\"\n                        f\"  Validation error: {e}\\n\"\n                        f\"Ensure all dict keys match ChannelMetadata fields \"\n                        f\"(label, unit, ref, extra) and have correct types.\"\n                    ) from e\n            else:\n                raise TypeError(\n                    f\"Invalid type in channel_metadata at index {index}\\n\"\n                    f\"  Got: {type(ch).__name__} ({ch!r})\\n\"\n                    f\"  Expected: ChannelMetadata or dict\\n\"\n                    f\"Use ChannelMetadata objects or dicts with valid fields.\"\n                )\n\n        self._channel_metadata = [\n            _to_channel_metadata(cast(ChannelMetadata | dict[str, Any], ch), i)\n            for i, ch in enumerate(channel_metadata)\n        ]\n    else:\n        self._channel_metadata = [\n            ChannelMetadata(label=f\"ch{i}\", unit=\"\", extra={})\n            for i in range(self._n_channels)\n        ]\n\n    try:\n        # Display information for newer dask versions\n        logger.debug(f\"Dask graph layers: {list(self._data.dask.layers.keys())}\")\n        logger.debug(\n            f\"Dask graph dependencies: {len(self._data.dask.dependencies)}\"\n        )\n    except Exception as e:\n        logger.debug(f\"Dask graph visualization details unavailable: {e}\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.get_channel--examples","title":"Examples","text":"<p>frame.get_channel(0)  # Single channel frame.get_channel([0, 2, 3])  # Multiple channels frame.get_channel((-1, -2))  # Last two channels frame.get_channel(np.array([1, 2]))  # NumPy array of indices</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def get_channel(\n    self: S,\n    channel_idx: int\n    | list[int]\n    | tuple[int, ...]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index.\n\n    Parameters\n    ----------\n    channel_idx : int or sequence of int\n        Single channel index or sequence of channel indices.\n        Supports negative indices (e.g., -1 for the last channel).\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame.get_channel(0)  # Single channel\n    &gt;&gt;&gt; frame.get_channel([0, 2, 3])  # Multiple channels\n    &gt;&gt;&gt; frame.get_channel((-1, -2))  # Last two channels\n    &gt;&gt;&gt; frame.get_channel(np.array([1, 2]))  # NumPy array of indices\n    \"\"\"\n    if isinstance(channel_idx, int):\n        # Convert single channel to a list.\n        channel_idx_list: list[int] = [channel_idx]\n    else:\n        channel_idx_list = list(channel_idx)\n\n    new_data = self._data[channel_idx_list]\n    new_channel_metadata = [self._channel_metadata[i] for i in channel_idx_list]\n    return self._create_new_instance(\n        data=new_data,\n        operation_history=self.operation_history,\n        channel_metadata=new_channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of channels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of channels.\n    \"\"\"\n    return len(self._channel_metadata)\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__iter__","title":"<code>__iter__()</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __iter__(self: S) -&gt; Iterator[S]:\n    for idx in range(len(self)):\n        yield self[idx]\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__getitem__--examples","title":"Examples","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __getitem__(\n    self: S,\n    key: int\n    | str\n    | slice\n    | list[int]\n    | list[str]\n    | tuple[\n        int\n        | str\n        | slice\n        | list[int]\n        | list[str]\n        | npt.NDArray[np.int_]\n        | npt.NDArray[np.bool_],\n        ...,\n    ]\n    | npt.NDArray[np.int_]\n    | npt.NDArray[np.bool_],\n) -&gt; S:\n    \"\"\"\n    Get channel(s) by index, label, or advanced indexing.\n\n    This method supports multiple indexing patterns similar to NumPy and pandas:\n\n    - Single channel by index: `frame[0]`\n    - Single channel by label: `frame[\"ch0\"]`\n    - Slice of channels: `frame[0:3]`\n    - Multiple channels by indices: `frame[[0, 2, 5]]`\n    - Multiple channels by labels: `frame[[\"ch0\", \"ch2\"]]`\n    - NumPy integer array: `frame[np.array([0, 2])]`\n    - Boolean mask: `frame[mask]` where mask is a boolean array\n    - Multidimensional indexing: `frame[0, 100:200]` (channel + time)\n\n    Parameters\n    ----------\n    key : int, str, slice, list, tuple, or ndarray\n        - int: Single channel index (supports negative indexing)\n        - str: Single channel label\n        - slice: Range of channels\n        - list[int]: Multiple channel indices\n        - list[str]: Multiple channel labels\n        - tuple: Multidimensional indexing (channel_key, time_key, ...)\n        - ndarray[int]: NumPy array of channel indices\n        - ndarray[bool]: Boolean mask for channel selection\n\n    Returns\n    -------\n    S\n        New instance containing the selected channel(s).\n\n    Raises\n    ------\n    ValueError\n        If the key length is invalid for the shape or if boolean mask\n        length doesn't match number of channels.\n    IndexError\n        If the channel index is out of range.\n    TypeError\n        If the key type is invalid or list contains mixed types.\n    KeyError\n        If a channel label is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Single channel selection\n    &gt;&gt;&gt; frame[0]  # First channel\n    &gt;&gt;&gt; frame[\"acc_x\"]  # By label\n    &gt;&gt;&gt; frame[-1]  # Last channel\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Multiple channel selection\n    &gt;&gt;&gt; frame[[0, 2, 5]]  # Multiple indices\n    &gt;&gt;&gt; frame[[\"acc_x\", \"acc_z\"]]  # Multiple labels\n    &gt;&gt;&gt; frame[0:3]  # Slice\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # NumPy array indexing\n    &gt;&gt;&gt; frame[np.array([0, 2, 4])]  # Integer array\n    &gt;&gt;&gt; mask = np.array([True, False, True])\n    &gt;&gt;&gt; frame[mask]  # Boolean mask\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Time slicing (multidimensional)\n    &gt;&gt;&gt; frame[0, 100:200]  # Channel 0, samples 100-200\n    &gt;&gt;&gt; frame[[0, 1], ::2]  # Channels 0-1, every 2nd sample\n    \"\"\"\n\n    # Single index (int)\n    if isinstance(key, numbers.Integral):\n        # Ensure we pass a plain Python int to satisfy the type checker\n        return self.get_channel(int(key))\n\n    # Single label (str)\n    if isinstance(key, str):\n        index = self.label2index(key)\n        return self.get_channel(index)\n\n    # Phase 2: NumPy array support (bool mask and int array)\n    if isinstance(key, np.ndarray):\n        if key.dtype == bool or key.dtype == np.bool_:\n            # Boolean mask\n            if len(key) != self.n_channels:\n                raise ValueError(\n                    f\"Boolean mask length {len(key)} does not match \"\n                    f\"number of channels {self.n_channels}\"\n                )\n            indices = np.where(key)[0]\n            return self.get_channel(indices)\n        elif np.issubdtype(key.dtype, np.integer):\n            # Integer array\n            return self.get_channel(key)\n        else:\n            raise TypeError(\n                f\"NumPy array must be of integer or boolean type, got {key.dtype}\"\n            )\n\n    # Phase 1: List support (int or str)\n    if isinstance(key, list):\n        if len(key) == 0:\n            raise ValueError(\"Cannot index with an empty list\")\n\n        # Check if all elements are strings\n        if all(isinstance(k, str) for k in key):\n            # Multiple labels - type narrowing for mypy\n            str_list = cast(list[str], key)\n            indices_from_labels = [self.label2index(label) for label in str_list]\n            return self.get_channel(indices_from_labels)\n\n        # Check if all elements are integers\n        elif all(isinstance(k, int | np.integer) for k in key):\n            # Multiple indices - convert to list[int] for type safety\n            int_list = [int(k) for k in key]\n            return self.get_channel(int_list)\n\n        else:\n            raise TypeError(\n                f\"List must contain all str or all int, got mixed types: \"\n                f\"{[type(k).__name__ for k in key]}\"\n            )\n\n    # Tuple: multidimensional indexing\n    if isinstance(key, tuple):\n        return self._handle_multidim_indexing(key)\n\n    # Slice\n    if isinstance(key, slice):\n        new_data = self._data[key]\n        new_channel_metadata = self._channel_metadata[key]\n        if isinstance(new_channel_metadata, ChannelMetadata):\n            new_channel_metadata = [new_channel_metadata]\n        return self._create_new_instance(\n            data=new_data,\n            operation_history=self.operation_history,\n            channel_metadata=new_channel_metadata,\n        )\n\n    raise TypeError(\n        f\"Invalid key type: {type(key).__name__}. \"\n        f\"Expected int, str, slice, list, tuple, or ndarray.\"\n    )\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.label2index--raises","title":"Raises","text":"<p>KeyError     If the channel label is not found.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def label2index(self, label: str) -&gt; int:\n    \"\"\"\n    Get the index from a channel label.\n\n    Parameters\n    ----------\n    label : str\n        Channel label.\n\n    Returns\n    -------\n    int\n        Corresponding index.\n\n    Raises\n    ------\n    KeyError\n        If the channel label is not found.\n    \"\"\"\n    for idx, ch in enumerate(self._channel_metadata):\n        if ch.label == label:\n            return idx\n    raise KeyError(f\"Channel label '{label}' not found.\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.compute--raises","title":"Raises","text":"<p>ValueError     If the computed result is not a NumPy array.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def compute(self) -&gt; T:\n    \"\"\"\n    Compute and return the data.\n    This method materializes lazily computed data into a concrete NumPy array.\n\n    Returns\n    -------\n    NDArrayReal\n        The computed data.\n\n    Raises\n    ------\n    ValueError\n        If the computed result is not a NumPy array.\n    \"\"\"\n    logger.debug(\n        \"COMPUTING DASK ARRAY - This will trigger file reading and all processing\"\n    )\n    result = self._data.compute()\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(f\"Computed result is not a np.ndarray: {type(result)}\")\n\n    logger.debug(f\"Computation complete, result shape: {result.shape}\")\n    return cast(T, result)\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.plot","title":"<code>plot(plot_type='default', ax=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Plot the data</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>@abstractmethod\ndef plot(\n    self, plot_type: str = \"default\", ax: Axes | None = None, **kwargs: Any\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the data\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.persist","title":"<code>persist()</code>","text":"<p>Persist the data in memory</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def persist(self: S) -&gt; S:\n    \"\"\"Persist the data in memory\"\"\"\n    persisted_data = self._data.persist()\n    return self._create_new_instance(data=persisted_data)\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__array__","title":"<code>__array__(dtype=None)</code>","text":"<p>Implicit conversion to NumPy array</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __array__(self, dtype: npt.DTypeLike = None) -&gt; NDArrayReal:\n    \"\"\"Implicit conversion to NumPy array\"\"\"\n    result = self.compute()\n    if dtype is not None:\n        return result.astype(dtype)\n    return result\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.visualize_graph--see-also","title":"See Also","text":"<p>debug_info : Print detailed debug information about the frame</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def visualize_graph(self, filename: str | None = None) -&gt; IPythonImage | None:\n    \"\"\"\n    Visualize the computation graph and save it to a file.\n\n    This method creates a visual representation of the Dask computation graph.\n    In Jupyter notebooks, it returns an IPython.display.Image object that\n    will be displayed inline. In other environments, it saves the graph to\n    a file and returns None.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Output filename for the graph image. If None, a unique filename\n        is generated using UUID. The file is saved in the current working\n        directory.\n\n    Returns\n    -------\n    IPython.display.Image or None\n        In Jupyter environments: Returns an IPython.display.Image object\n        that can be displayed inline.\n        In other environments: Returns None after saving the graph to file.\n        Returns None if visualization fails.\n\n    Notes\n    -----\n    This method requires graphviz to be installed on your system:\n    - Ubuntu/Debian: `sudo apt-get install graphviz`\n    - macOS: `brew install graphviz`\n    - Windows: Download from https://graphviz.org/download/\n\n    The graph displays operation names (e.g., 'normalize', 'lowpass_filter')\n    making it easier to understand the processing pipeline.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import wandas as wd\n    &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; processed = signal.normalize().low_pass_filter(cutoff=1000)\n    &gt;&gt;&gt; # In Jupyter: displays graph inline\n    &gt;&gt;&gt; processed.visualize_graph()\n    &gt;&gt;&gt; # Save to specific file\n    &gt;&gt;&gt; processed.visualize_graph(\"my_graph.png\")\n\n    See Also\n    --------\n    debug_info : Print detailed debug information about the frame\n    \"\"\"\n    try:\n        filename = filename or f\"graph_{uuid.uuid4().hex[:8]}.png\"\n        return self._data.visualize(filename=filename)\n    except Exception as e:\n        logger.warning(f\"Failed to visualize the graph: {e}\")\n        return None\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__add__","title":"<code>__add__(other)</code>","text":"<p>Addition operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __add__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Addition operator\"\"\"\n    return self._binary_op(other, lambda x, y: x + y, \"+\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Subtraction operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __sub__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Subtraction operator\"\"\"\n    return self._binary_op(other, lambda x, y: x - y, \"-\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiplication operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __mul__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Multiplication operator\"\"\"\n    return self._binary_op(other, lambda x, y: x * y, \"*\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Division operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __truediv__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Division operator\"\"\"\n    return self._binary_op(other, lambda x, y: x / y, \"/\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.__pow__","title":"<code>__pow__(other)</code>","text":"<p>Power operator</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def __pow__(self: S, other: S | int | float | NDArrayReal) -&gt; S:\n    \"\"\"Power operator\"\"\"\n    return self._binary_op(other, lambda x, y: x**y, \"**\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.apply_operation--returns","title":"Returns","text":"<p>S     A new instance with the operation applied.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def apply_operation(self: S, operation_name: str, **params: Any) -&gt; S:\n    \"\"\"\n    Apply a named operation.\n\n    Parameters\n    ----------\n    operation_name : str\n        Name of the operation to apply.\n    **params : Any\n        Parameters to pass to the operation.\n\n    Returns\n    -------\n    S\n        A new instance with the operation applied.\n    \"\"\"\n    # Apply the operation through abstract method\n    return self._apply_operation_impl(operation_name, **params)\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.debug_info","title":"<code>debug_info()</code>","text":"<p>Output detailed debug information</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def debug_info(self) -&gt; None:\n    \"\"\"Output detailed debug information\"\"\"\n    logger.debug(f\"=== {self.__class__.__name__} Debug Info ===\")\n    logger.debug(f\"Label: {self.label}\")\n    logger.debug(f\"Shape: {self.shape}\")\n    logger.debug(f\"Sampling rate: {self.sampling_rate} Hz\")\n    logger.debug(f\"Operation history: {len(self.operation_history)} operations\")\n    self._debug_info_impl()\n    logger.debug(\"=== End Debug Info ===\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.print_operation_history--examples","title":"Examples","text":"<p>cf.print_operation_history() 1: normalize {} 2: low_pass_filter {'cutoff': 1000}</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def print_operation_history(self) -&gt; None:\n    \"\"\"\n    Print the operation history to standard output in a readable format.\n\n    This method writes a human-friendly representation of the\n    `operation_history` list to stdout. Each operation is printed on its\n    own line with an index, the operation name (if available), and the\n    parameters used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf.print_operation_history()\n    1: normalize {}\n    2: low_pass_filter {'cutoff': 1000}\n    \"\"\"\n    if not self.operation_history:\n        print(\"Operation history: &lt;empty&gt;\")\n        return\n\n    print(f\"Operation history ({len(self.operation_history)}):\")\n    for i, record in enumerate(self.operation_history, start=1):\n        # record is expected to be a dict with at least a 'operation' key\n        op_name = record.get(\"operation\") or record.get(\"name\") or \"&lt;unknown&gt;\"\n        # Copy params for display - exclude the 'operation'/'name' keys\n        params = {k: v for k, v in record.items() if k not in (\"operation\", \"name\")}\n        print(f\"{i}: {op_name} {params}\")\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.to_numpy--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") data = cf.to_numpy() print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def to_numpy(self) -&gt; T:\n    \"\"\"Convert the frame data to a NumPy array.\n\n    This method computes the Dask array and returns it as a concrete NumPy array.\n    The returned array has the same shape as the frame's data.\n\n    Returns\n    -------\n    T\n        NumPy array containing the frame data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; data = cf.to_numpy()\n    &gt;&gt;&gt; print(f\"Shape: {data.shape}\")  # (n_channels, n_samples)\n    \"\"\"\n    return self.data\n</code></pre>"},{"location":"en/api/core/#wandas.core.base_frame.BaseFrame.to_dataframe--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") df = cf.to_dataframe() print(df.head())</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/base_frame.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"Convert the frame data to a pandas DataFrame.\n\n    This method provides a common implementation for converting frame data\n    to pandas DataFrame. Subclasses can override this method for custom behavior.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with appropriate index and columns.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; df = cf.to_dataframe()\n    &gt;&gt;&gt; print(df.head())\n    \"\"\"\n    # Get data as numpy array\n    data = self.to_numpy()\n\n    # Get column names from subclass\n    columns = self._get_dataframe_columns()\n\n    # Get index from subclass\n    index = self._get_dataframe_index()\n\n    # Create DataFrame\n    if data.ndim == 1:\n        # Single channel case - reshape to 2D\n        df = pd.DataFrame(data.reshape(-1, 1), columns=columns, index=index)\n    else:\n        # Multi-channel case - transpose to (n_samples, n_channels)\n        df = pd.DataFrame(data.T, columns=columns, index=index)\n\n    return df\n</code></pre>"},{"location":"en/api/core/#channelmetadata","title":"ChannelMetadata","text":"<p>The ChannelMetadata class manages metadata related to audio channels.</p>"},{"location":"en/api/core/#wandas.core.metadata.ChannelMetadata.__init__","title":"<code>__init__(**data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __init__(self, **data: Any):\n    super().__init__(**data)\n    # unit\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u3066ref\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306a\u3089unit_to_ref\u3067\u81ea\u52d5\u8a2d\u5b9a\n    if self.unit and (\"ref\" not in data or data.get(\"ref\", 1.0) == 1.0):\n        self.ref = unit_to_ref(self.unit)\n</code></pre>"},{"location":"en/api/core/#wandas.core.metadata.ChannelMetadata.__setattr__","title":"<code>__setattr__(name, value)</code>","text":"<p>Override setattr to update ref when unit is changed directly</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Override setattr to update ref when unit is changed directly\"\"\"\n    super().__setattr__(name, value)\n    # Only proceed if unit is being set to a non-empty value\n    if name == \"unit\" and value and isinstance(value, str):\n        super().__setattr__(\"ref\", unit_to_ref(value))\n</code></pre>"},{"location":"en/api/core/#wandas.core.metadata.ChannelMetadata.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Provide dictionary-like behavior</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        return self.label\n    elif key == \"unit\":\n        return self.unit\n    elif key == \"ref\":\n        return self.ref\n    else:\n        return self.extra.get(key)\n</code></pre>"},{"location":"en/api/core/#wandas.core.metadata.ChannelMetadata.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Provide dictionary-like behavior</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def __setitem__(self, key: str, value: Any) -&gt; None:\n    \"\"\"Provide dictionary-like behavior\"\"\"\n    if key == \"label\":\n        self.label = value\n    elif key == \"unit\":\n        self.unit = value\n        self.ref = unit_to_ref(value)\n    elif key == \"ref\":\n        self.ref = value\n    else:\n        self.extra[key] = value\n</code></pre>"},{"location":"en/api/core/#wandas.core.metadata.ChannelMetadata.to_json","title":"<code>to_json()</code>","text":"<p>Convert to JSON format</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert to JSON format\"\"\"\n    json_data: str = self.model_dump_json(indent=4)\n    return json_data\n</code></pre>"},{"location":"en/api/core/#wandas.core.metadata.ChannelMetadata.from_json","title":"<code>from_json(json_data)</code>  <code>classmethod</code>","text":"<p>Convert from JSON format</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/core/metadata.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data: str) -&gt; \"ChannelMetadata\":\n    \"\"\"Convert from JSON format\"\"\"\n    root_model: ChannelMetadata = ChannelMetadata.model_validate_json(json_data)\n\n    return root_model\n</code></pre>"},{"location":"en/api/datasets/","title":"Datasets Module","text":"<p>The <code>wandas.datasets</code> module provides sample data that can be used for testing and demonstrations.</p>"},{"location":"en/api/datasets/#sample-data","title":"Sample Data","text":"<p>Provides sample audio data that can be used for testing and demonstrations.</p>"},{"location":"en/api/datasets/#wandas.datasets.sample_data.load_sample_signal--returns","title":"Returns","text":"<p>NDArrayReal     Signal data as a NumPy array.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/datasets/sample_data.py</code> <pre><code>def load_sample_signal(\n    frequency: float = 5.0, sampling_rate: int = 100, duration: float = 1.0\n) -&gt; NDArrayReal:\n    \"\"\"\n    Generate a sample sine wave signal.\n\n    Parameters\n    ----------\n    frequency : float, default=5.0\n        Frequency of the signal in Hz.\n    sampling_rate : int, default=100\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n\n    Returns\n    -------\n    NDArrayReal\n        Signal data as a NumPy array.\n    \"\"\"\n    num_samples = int(sampling_rate * duration)\n    t = np.arange(num_samples) / sampling_rate\n    signal: NDArrayReal = np.sin(2 * np.pi * frequency * t, dtype=np.float64)\n    return signal\n</code></pre>"},{"location":"en/api/frames/","title":"Frames Module","text":"<p>The <code>wandas.frames</code> module provides various data frame classes for manipulating and representing audio data.</p>"},{"location":"en/api/frames/#channelframe","title":"ChannelFrame","text":"<p>ChannelFrame is the basic frame for handling time-domain waveform data.</p>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.time","title":"<code>time</code>  <code>property</code>","text":"<p>Get time array for the signal.</p> <p>The time array represents the start time of each sample, calculated as sample_index / sampling_rate. This provides a uniform, evenly-spaced time axis that is consistent across all frame types in wandas.</p> <p>For frames resulting from windowed analysis operations (e.g., FFT, loudness, roughness), each time point corresponds to the start of the analysis window, not the center. This differs from some libraries (e.g., MoSQITo) which use window center times, but does not affect the calculated values themselves.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Array of time points in seconds, starting from 0.0.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; time = signal.time\n&gt;&gt;&gt; print(f\"Duration: {time[-1]:.3f}s\")\n&gt;&gt;&gt; print(f\"Time step: {time[1] - time[0]:.6f}s\")\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.rms","title":"<code>rms</code>  <code>property</code>","text":"<p>Calculate RMS (Root Mean Square) value for each channel.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Array of RMS values, one per channel.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; rms_values = cf.rms\n&gt;&gt;&gt; print(f\"RMS values: {rms_values}\")\n&gt;&gt;&gt; # Select channels with RMS &gt; threshold\n&gt;&gt;&gt; active_channels = cf[cf.rms &gt; 0.5]\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.__init__","title":"<code>__init__(data, sampling_rate, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a ChannelFrame.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>Array</code> <p>Dask array containing channel data.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate of the data in Hz. Must be a positive value.</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If data has more than 2 dimensions, or if sampling_rate is not positive.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def __init__(\n    self,\n    data: DaskArray,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"Initialize a ChannelFrame.\n\n    Args:\n        data: Dask array containing channel data.\n        Shape should be (n_channels, n_samples).\n        sampling_rate: The sampling rate of the data in Hz.\n            Must be a positive value.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Raises:\n        ValueError: If data has more than 2 dimensions, or if\n            sampling_rate is not positive.\n    \"\"\"\n    # Validate sampling rate\n    validate_sampling_rate(sampling_rate)\n\n    # Validate and reshape data\n    if data.ndim == 1:\n        data = da.reshape(data, (1, -1))\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Invalid data shape for ChannelFrame\\n\"\n            f\"  Got: {data.shape} ({data.ndim}D)\\n\"\n            f\"  Expected: 1D (samples,) or 2D (channels, samples)\\n\"\n            f\"If you have a 1D array, it will be automatically reshaped to\\n\"\n            f\"  (1, n_samples).\\n\"\n            f\"For higher-dimensional data, reshape it before creating\\n\"\n            f\"  ChannelFrame:\\n\"\n            f\"  Example: data.reshape(n_channels, -1)\"\n        )\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.info--examples","title":"Examples","text":"<p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.info() Channels: 2 Sampling rate: 44100 Hz Duration: 1.0 s Samples: 44100 Channel labels: ['ch0', 'ch1']</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the ChannelFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - Duration\n    - Number of samples\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n    &gt;&gt;&gt; cf.info()\n    Channels: 2\n    Sampling rate: 44100 Hz\n    Duration: 1.0 s\n    Samples: 44100\n    Channel labels: ['ch0', 'ch1']\n    \"\"\"\n    print(\"ChannelFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  Duration: {self.duration:.1f} s\")\n    print(f\"  Samples: {self.n_samples}\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.add","title":"<code>add(other, snr=None)</code>","text":"<p>Add another signal or value to the current signal.</p> <p>If SNR is specified, performs addition with consideration for signal-to-noise ratio.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>other</code> <code>ChannelFrame | int | float | NDArrayReal</code> <p>Signal or value to add.</p> \u5fc5\u9808 <code>snr</code> <code>float | None</code> <p>Signal-to-noise ratio (dB). If specified, adjusts the scale of the other signal based on this SNR. self is treated as the signal, and other as the noise.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new channel frame containing the addition result (lazy execution).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def add(\n    self,\n    other: \"ChannelFrame | int | float | NDArrayReal\",\n    snr: float | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add another signal or value to the current signal.\n\n    If SNR is specified, performs addition with consideration for\n    signal-to-noise ratio.\n\n    Args:\n        other: Signal or value to add.\n        snr: Signal-to-noise ratio (dB). If specified, adjusts the scale of the\n            other signal based on this SNR.\n            self is treated as the signal, and other as the noise.\n\n    Returns:\n        A new channel frame containing the addition result (lazy execution).\n    \"\"\"\n    logger.debug(f\"Setting up add operation with SNR={snr} (lazy)\")\n\n    if isinstance(other, ChannelFrame):\n        # Check if sampling rates match\n        if self.sampling_rate != other.sampling_rate:\n            raise ValueError(\n                \"Sampling rates do not match. Cannot perform operation.\"\n            )\n\n    elif isinstance(other, np.ndarray):\n        other = ChannelFrame.from_numpy(\n            other, self.sampling_rate, label=\"array_data\"\n        )\n    elif isinstance(other, int | float):\n        return self + other\n    else:\n        raise TypeError(\n            \"Addition target with SNR must be a ChannelFrame or \"\n            f\"NumPy array: {type(other)}\"\n        )\n\n    # If SNR is specified, adjust the length of the other signal\n    if other.duration != self.duration:\n        other = other.fix_length(length=self.n_samples)\n\n    if snr is None:\n        return self + other\n    return self.apply_operation(\"add_with_snr\", other=other._data, snr=snr)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.plot","title":"<code>plot(plot_type='waveform', ax=None, title=None, overlay=False, xlabel=None, ylabel=None, alpha=1.0, xlim=None, ylim=None, **kwargs)</code>","text":"<p>Plot the frame data.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>plot_type</code> <code>str</code> <p>Type of plot. Default is \"waveform\".</p> <code>'waveform'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot. If None, uses the frame label.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay all channels on a single plot (True) or create separate subplots for each channel (False).</p> <code>False</code> <code>xlabel</code> <code>str | None</code> <p>Label for the x-axis. If None, uses default based on plot type.</p> <code>None</code> <code>ylabel</code> <code>str | None</code> <p>Label for the y-axis. If None, uses default based on plot type.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level for the plot lines (0.0 to 1.0).</p> <code>1.0</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Limits for the x-axis as (min, max) tuple.</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Limits for the y-axis as (min, max) tuple.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional matplotlib Line2D parameters (e.g., color, linewidth, linestyle). These are passed to the underlying matplotlib plot functions.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic plot\n&gt;&gt;&gt; cf.plot()\n&gt;&gt;&gt; # Overlay all channels\n&gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"waveform\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Plot the frame data.\n\n    Args:\n        plot_type: Type of plot. Default is \"waveform\".\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot. If None, uses the frame label.\n        overlay: Whether to overlay all channels on a single plot (True)\n            or create separate subplots for each channel (False).\n        xlabel: Label for the x-axis. If None, uses default based on plot type.\n        ylabel: Label for the y-axis. If None, uses default based on plot type.\n        alpha: Transparency level for the plot lines (0.0 to 1.0).\n        xlim: Limits for the x-axis as (min, max) tuple.\n        ylim: Limits for the y-axis as (min, max) tuple.\n        **kwargs: Additional matplotlib Line2D parameters\n            (e.g., color, linewidth, linestyle).\n            These are passed to the underlying matplotlib plot functions.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic plot\n        &gt;&gt;&gt; cf.plot()\n        &gt;&gt;&gt; # Overlay all channels\n        &gt;&gt;&gt; cf.plot(overlay=True, alpha=0.7)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.plot(title=\"My Signal\", ylabel=\"Voltage [V]\", color=\"red\")\n    \"\"\"\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    from ..visualization.plotting import create_operation\n\n    plot_strategy = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.rms_plot","title":"<code>rms_plot(ax=None, title=None, overlay=True, Aw=False, **kwargs)</code>","text":"<p>Generate an RMS plot.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib axes for plotting.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title for the plot.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay the plot on the existing axis.</p> <code>True</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the plot() method. Accepts the same arguments as plot() including xlabel, ylabel, alpha, xlim, ylim, and matplotlib Line2D parameters.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>Axes | Iterator[Axes]</code> <p>Single Axes object or iterator of Axes objects.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic RMS plot\n&gt;&gt;&gt; cf.rms_plot()\n&gt;&gt;&gt; # With A-weighting\n&gt;&gt;&gt; cf.rms_plot(Aw=True)\n&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def rms_plot(\n    self,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = True,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Generate an RMS plot.\n\n    Args:\n        ax: Optional matplotlib axes for plotting.\n        title: Title for the plot.\n        overlay: Whether to overlay the plot on the existing axis.\n        Aw: Apply A-weighting.\n        **kwargs: Additional arguments passed to the plot() method.\n            Accepts the same arguments as plot() including xlabel, ylabel,\n            alpha, xlim, ylim, and matplotlib Line2D parameters.\n\n    Returns:\n        Single Axes object or iterator of Axes objects.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic RMS plot\n        &gt;&gt;&gt; cf.rms_plot()\n        &gt;&gt;&gt; # With A-weighting\n        &gt;&gt;&gt; cf.rms_plot(Aw=True)\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; cf.rms_plot(ylabel=\"RMS [V]\", alpha=0.8, color=\"blue\")\n    \"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"RMS\")\n    rms_ch: ChannelFrame = self.rms_trend(Aw=Aw, dB=True)\n    return rms_ch.plot(ax=ax, ylabel=ylabel, title=title, overlay=overlay, **kwargs)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.describe","title":"<code>describe(normalize=True, is_close=True, *, fmin=0, fmax=None, cmap='jet', vmin=None, vmax=None, xlim=None, ylim=None, Aw=False, waveform=None, spectral=None, **kwargs)</code>","text":"<p>Display visual and audio representation of the frame.</p> <p>This method creates a comprehensive visualization with three plots: 1. Time-domain waveform (top) 2. Spectrogram (bottom-left) 3. Frequency spectrum via Welch method (bottom-right)</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>normalize</code> <code>bool</code> <p>Whether to normalize the audio data for playback. Default: True</p> <code>True</code> <code>is_close</code> <code>bool</code> <p>Whether to close the figure after displaying. Default: True</p> <code>True</code> <code>fmin</code> <code>float</code> <p>Minimum frequency to display in the spectrogram (Hz). Default: 0</p> <code>0</code> <code>fmax</code> <code>float | None</code> <p>Maximum frequency to display in the spectrogram (Hz). Default: Nyquist frequency (sampling_rate / 2)</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the spectrogram. Default: 'jet'</p> <code>'jet'</code> <code>vmin</code> <code>float | None</code> <p>Minimum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>vmax</code> <code>float | None</code> <p>Maximum value for spectrogram color scale (dB). Auto-calculated if None.</p> <code>None</code> <code>xlim</code> <code>tuple[float, float] | None</code> <p>Time axis limits (seconds) for all time-based plots. Format: (start_time, end_time)</p> <code>None</code> <code>ylim</code> <code>tuple[float, float] | None</code> <p>Frequency axis limits (Hz) for frequency-based plots. Format: (min_freq, max_freq)</p> <code>None</code> <code>Aw</code> <code>bool</code> <p>Apply A-weighting to the frequency analysis. Default: False</p> <code>False</code> <code>waveform</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for waveform subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>spectral</code> <code>dict[str, Any] | None</code> <p>Additional configuration dict for spectral subplot. Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Deprecated parameters for backward compatibility only. - axis_config: Old configuration format (use waveform/spectral instead) - cbar_config: Old colorbar configuration (use vmin/vmax instead)</p> <code>{}</code> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; cf.describe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom frequency range\n&gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom color scale\n&gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # A-weighted analysis\n&gt;&gt;&gt; cf.describe(Aw=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom time range\n&gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom waveform subplot settings\n&gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def describe(\n    self,\n    normalize: bool = True,\n    is_close: bool = True,\n    *,\n    fmin: float = 0,\n    fmax: float | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    waveform: dict[str, Any] | None = None,\n    spectral: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Display visual and audio representation of the frame.\n\n    This method creates a comprehensive visualization with three plots:\n    1. Time-domain waveform (top)\n    2. Spectrogram (bottom-left)\n    3. Frequency spectrum via Welch method (bottom-right)\n\n    Args:\n        normalize: Whether to normalize the audio data for playback.\n            Default: True\n        is_close: Whether to close the figure after displaying.\n            Default: True\n        fmin: Minimum frequency to display in the spectrogram (Hz).\n            Default: 0\n        fmax: Maximum frequency to display in the spectrogram (Hz).\n            Default: Nyquist frequency (sampling_rate / 2)\n        cmap: Colormap for the spectrogram.\n            Default: 'jet'\n        vmin: Minimum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        vmax: Maximum value for spectrogram color scale (dB).\n            Auto-calculated if None.\n        xlim: Time axis limits (seconds) for all time-based plots.\n            Format: (start_time, end_time)\n        ylim: Frequency axis limits (Hz) for frequency-based plots.\n            Format: (min_freq, max_freq)\n        Aw: Apply A-weighting to the frequency analysis.\n            Default: False\n        waveform: Additional configuration dict for waveform subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        spectral: Additional configuration dict for spectral subplot.\n            Can include 'xlabel', 'ylabel', 'xlim', 'ylim'.\n        **kwargs: Deprecated parameters for backward compatibility only.\n            - axis_config: Old configuration format (use waveform/spectral instead)\n            - cbar_config: Old colorbar configuration (use vmin/vmax instead)\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; cf.describe()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom frequency range\n        &gt;&gt;&gt; cf.describe(fmin=100, fmax=5000)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom color scale\n        &gt;&gt;&gt; cf.describe(vmin=-80, vmax=-20, cmap=\"viridis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # A-weighted analysis\n        &gt;&gt;&gt; cf.describe(Aw=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom time range\n        &gt;&gt;&gt; cf.describe(xlim=(0, 5))  # Show first 5 seconds\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom waveform subplot settings\n        &gt;&gt;&gt; cf.describe(waveform={\"ylabel\": \"Custom Label\"})\n    \"\"\"\n    # Prepare kwargs with explicit parameters\n    plot_kwargs: dict[str, Any] = {\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"xlim\": xlim,\n        \"ylim\": ylim,\n        \"Aw\": Aw,\n        \"waveform\": waveform or {},\n        \"spectral\": spectral or {},\n    }\n    # Merge with additional kwargs\n    plot_kwargs.update(kwargs)\n\n    if \"axis_config\" in plot_kwargs:\n        logger.warning(\n            \"axis_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        axis_config = plot_kwargs[\"axis_config\"]\n        if \"time_plot\" in axis_config:\n            plot_kwargs[\"waveform\"] = axis_config[\"time_plot\"]\n        if \"freq_plot\" in axis_config:\n            if \"xlim\" in axis_config[\"freq_plot\"]:\n                vlim = axis_config[\"freq_plot\"][\"xlim\"]\n                plot_kwargs[\"vmin\"] = vlim[0]\n                plot_kwargs[\"vmax\"] = vlim[1]\n            if \"ylim\" in axis_config[\"freq_plot\"]:\n                ylim_config = axis_config[\"freq_plot\"][\"ylim\"]\n                plot_kwargs[\"ylim\"] = ylim_config\n\n    if \"cbar_config\" in plot_kwargs:\n        logger.warning(\n            \"cbar_config is retained for backward compatibility but will \"\n            \"be deprecated in the future.\"\n        )\n        cbar_config = plot_kwargs[\"cbar_config\"]\n        if \"vmin\" in cbar_config:\n            plot_kwargs[\"vmin\"] = cbar_config[\"vmin\"]\n        if \"vmax\" in cbar_config:\n            plot_kwargs[\"vmax\"] = cbar_config[\"vmax\"]\n\n    for ch in self:\n        ax: Axes\n        _ax = ch.plot(\"describe\", title=f\"{ch.label} {ch.labels[0]}\", **plot_kwargs)\n        if isinstance(_ax, Iterator):\n            ax = next(iter(_ax))\n        elif isinstance(_ax, Axes):\n            ax = _ax\n        else:\n            raise TypeError(\n                f\"Unexpected type for plot result: {type(_ax)}. Expected Axes or Iterator[Axes].\"  # noqa: E501\n            )\n        # display\u95a2\u6570\u3068Audio\u30af\u30e9\u30b9\u3092\u4f7f\u7528\n        display(ax.figure)\n        if is_close:\n            plt.close(getattr(ax, \"figure\", None))\n        display(Audio(ch.data, rate=ch.sampling_rate, normalize=normalize))\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.from_numpy","title":"<code>from_numpy(data, sampling_rate, label=None, metadata=None, ch_labels=None, ch_units=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>NDArrayReal</code> <p>NumPy array containing channel data.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>ch_units</code> <code>list[str] | str | None</code> <p>Units for each channel.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the NumPy data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayReal,\n    sampling_rate: float,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    ch_labels: list[str] | None = None,\n    ch_units: list[str] | str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing channel data.\n        sampling_rate: The sampling rate in Hz.\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        ch_labels: Labels for each channel.\n        ch_units: Units for each channel.\n\n    Returns:\n        A new ChannelFrame containing the NumPy data.\n    \"\"\"\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n\n    # Convert NumPy array to dask array\n    dask_data = da_from_array(data)\n    cf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        label=label or \"numpy_data\",\n    )\n    if metadata is not None:\n        cf.metadata = metadata\n    if ch_labels is not None:\n        if len(ch_labels) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel labels does not match the number of channels\"\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    if ch_units is not None:\n        if isinstance(ch_units, str):\n            ch_units = [ch_units] * cf.n_channels\n\n        if len(ch_units) != cf.n_channels:\n            raise ValueError(\n                \"Number of channel units does not match the number of channels\"\n            )\n        for i in range(len(ch_units)):\n            cf._channel_metadata[i].unit = ch_units[i]\n\n    return cf\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.from_ndarray","title":"<code>from_ndarray(array, sampling_rate, labels=None, unit=None, frame_label=None, metadata=None)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from a NumPy array.</p> <p>This method is deprecated. Use from_numpy instead.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>array</code> <code>NDArrayReal</code> <p>Signal data. Each row corresponds to a channel.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>Sampling rate (Hz).</p> \u5fc5\u9808 <code>labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>unit</code> <code>list[str] | str | None</code> <p>Unit of the signal.</p> <code>None</code> <code>frame_label</code> <code>str | None</code> <p>Label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_ndarray(\n    cls,\n    array: NDArrayReal,\n    sampling_rate: float,\n    labels: list[str] | None = None,\n    unit: list[str] | str | None = None,\n    frame_label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from a NumPy array.\n\n    This method is deprecated. Use from_numpy instead.\n\n    Args:\n        array: Signal data. Each row corresponds to a channel.\n        sampling_rate: Sampling rate (Hz).\n        labels: Labels for each channel.\n        unit: Unit of the signal.\n        frame_label: Label for the frame.\n        metadata: Optional metadata dictionary.\n\n    Returns:\n        A new ChannelFrame containing the data.\n    \"\"\"\n    # Redirect to from_numpy for compatibility\n    # However, from_ndarray is deprecated\n    logger.warning(\"from_ndarray is deprecated. Use from_numpy instead.\")\n    return cls.from_numpy(\n        data=array,\n        sampling_rate=sampling_rate,\n        label=frame_label,\n        metadata=metadata,\n        ch_labels=labels,\n        ch_units=unit,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.from_file","title":"<code>from_file(path, channel=None, start=None, end=None, chunk_size=None, ch_labels=None, time_column=0, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Create a ChannelFrame from an audio file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the audio file.</p> \u5fc5\u9808 <code>channel</code> <code>int | list[int] | None</code> <p>Channel(s) to load.</p> <code>None</code> <code>start</code> <code>float | None</code> <p>Start time in seconds.</p> <code>None</code> <code>end</code> <code>float | None</code> <p>End time in seconds.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Chunk size for processing. Specifies the splitting size for lazy processing.</p> <code>None</code> <code>ch_labels</code> <code>list[str] | None</code> <p>Labels for each channel.</p> <code>None</code> <code>time_column</code> <code>int | str</code> <p>For CSV files, index or name of the time column. Default is 0 (first column).</p> <code>0</code> <code>delimiter</code> <code>str</code> <p>For CSV files, delimiter character. Default is \",\".</p> <code>','</code> <code>header</code> <code>int | None</code> <p>For CSV files, row number to use as header. Default is 0 (first row). Set to None if no header.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the loaded audio data.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If channel specification is invalid.</p> <code>TypeError</code> <p>If channel parameter type is invalid.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist at the specified path. Error message includes absolute path, current directory, and troubleshooting suggestions.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; # Load WAV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n&gt;&gt;&gt; # Load specific channels\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n&gt;&gt;&gt; # Load CSV file\n&gt;&gt;&gt; cf = ChannelFrame.from_file(\n...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n... )\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    channel: int | list[int] | None = None,\n    start: float | None = None,\n    end: float | None = None,\n    chunk_size: int | None = None,\n    ch_labels: list[str] | None = None,\n    # CSV-specific parameters\n    time_column: int | str = 0,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Create a ChannelFrame from an audio file.\n\n    Args:\n        path: Path to the audio file.\n        channel: Channel(s) to load.\n        start: Start time in seconds.\n        end: End time in seconds.\n        chunk_size: Chunk size for processing.\n            Specifies the splitting size for lazy processing.\n        ch_labels: Labels for each channel.\n        time_column: For CSV files, index or name of the time column.\n            Default is 0 (first column).\n        delimiter: For CSV files, delimiter character. Default is \",\".\n        header: For CSV files, row number to use as header.\n            Default is 0 (first row). Set to None if no header.\n\n    Returns:\n        A new ChannelFrame containing the loaded audio data.\n\n    Raises:\n        ValueError: If channel specification is invalid.\n        TypeError: If channel parameter type is invalid.\n        FileNotFoundError: If the file doesn't exist at the specified path.\n            Error message includes absolute path, current directory, and\n            troubleshooting suggestions.\n\n    Examples:\n        &gt;&gt;&gt; # Load WAV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\")\n        &gt;&gt;&gt; # Load specific channels\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\"audio.wav\", channel=[0, 2])\n        &gt;&gt;&gt; # Load CSV file\n        &gt;&gt;&gt; cf = ChannelFrame.from_file(\n        ...     \"data.csv\", time_column=0, delimiter=\",\", header=0\n        ... )\n    \"\"\"\n    from .channel import ChannelFrame\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Audio file not found\\n\"\n            f\"  Path: {path.absolute()}\\n\"\n            f\"  Current directory: {Path.cwd()}\\n\"\n            f\"Please check:\\n\"\n            f\"  - File path is correct\\n\"\n            f\"  - File exists at the specified location\\n\"\n            f\"  - You have read permissions for the file\"\n        )\n\n    # Get file reader\n    reader = get_file_reader(path)\n\n    # Build kwargs for reader\n    reader_kwargs: dict[str, Any] = {}\n    if path.suffix.lower() == \".csv\":\n        reader_kwargs[\"time_column\"] = time_column\n        reader_kwargs[\"delimiter\"] = delimiter\n        if header is not None:\n            reader_kwargs[\"header\"] = header\n\n    # Get file info\n    info = reader.get_file_info(path, **reader_kwargs)\n    sr = info[\"samplerate\"]\n    n_channels = info[\"channels\"]\n    n_frames = info[\"frames\"]\n    ch_labels = ch_labels or info.get(\"ch_labels\", None)\n\n    logger.debug(f\"File info: sr={sr}, channels={n_channels}, frames={n_frames}\")\n\n    # Channel selection processing\n    all_channels = list(range(n_channels))\n\n    if channel is None:\n        channels_to_load = all_channels\n        logger.debug(f\"Will load all channels: {channels_to_load}\")\n    elif isinstance(channel, int):\n        if channel &lt; 0 or channel &gt;= n_channels:\n            raise ValueError(\n                f\"Channel specification is out of range: {channel} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n            )\n        channels_to_load = [channel]\n        logger.debug(f\"Will load single channel: {channel}\")\n    elif isinstance(channel, list | tuple):\n        for ch in channel:\n            if ch &lt; 0 or ch &gt;= n_channels:\n                raise ValueError(\n                    f\"Channel specification is out of range: {ch} (valid range: 0-{n_channels - 1})\"  # noqa: E501\n                )\n        channels_to_load = list(channel)\n        logger.debug(f\"Will load specific channels: {channels_to_load}\")\n    else:\n        raise TypeError(\"channel must be int, list, or None\")\n\n    # Index calculation\n    start_idx = 0 if start is None else max(0, int(start * sr))\n    end_idx = n_frames if end is None else min(n_frames, int(end * sr))\n    frames_to_read = end_idx - start_idx\n\n    logger.debug(\n        f\"Setting up lazy load from file={path}, frames={frames_to_read}, \"\n        f\"start_idx={start_idx}, end_idx={end_idx}\"\n    )\n\n    # Settings for lazy loading\n    expected_shape = (len(channels_to_load), frames_to_read)\n\n    # Define the loading function using the file reader\n    def _load_audio() -&gt; NDArrayReal:\n        logger.debug(\"&gt;&gt;&gt; EXECUTING DELAYED LOAD &lt;&lt;&lt;\")\n        # Use the reader to get audio data with parameters\n        out = reader.get_data(\n            path, channels_to_load, start_idx, frames_to_read, **reader_kwargs\n        )\n        if not isinstance(out, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n        return out\n\n    logger.debug(\n        f\"Creating delayed dask task with expected shape: {expected_shape}\"\n    )\n\n    # Create delayed operation\n    delayed_data = dask_delayed(_load_audio)()\n    logger.debug(\"Wrapping delayed function in dask array\")\n\n    # Create dask array from delayed computation\n    dask_array = da_from_delayed(\n        delayed_data, shape=expected_shape, dtype=np.float32\n    )\n\n    if chunk_size is not None:\n        if chunk_size &lt;= 0:\n            raise ValueError(\"Chunk size must be a positive integer\")\n        logger.debug(f\"Setting chunk size: {chunk_size} for sample axis\")\n        dask_array = dask_array.rechunk({0: -1, 1: chunk_size})\n\n    logger.debug(\n        \"ChannelFrame setup complete - actual file reading will occur on compute()\"  # noqa: E501\n    )\n\n    cf = ChannelFrame(\n        data=dask_array,\n        sampling_rate=sr,\n        label=path.stem,\n        metadata={\n            \"filename\": str(path),\n        },\n    )\n    if ch_labels is not None:\n        if len(ch_labels) != len(cf):\n            raise ValueError(\n                \"Number of channel labels does not match the number of specified channels\"  # noqa: E501\n            )\n        for i in range(len(ch_labels)):\n            cf._channel_metadata[i].label = ch_labels[i]\n    return cf\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.read_wav","title":"<code>read_wav(filename, labels=None)</code>  <code>classmethod</code>","text":"<p>Utility method to read a WAV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>filename</code> <code>str</code> <p>Path to the WAV file.</p> \u5fc5\u9808 <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_wav(cls, filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a WAV file.\n\n    Args:\n        filename: Path to the WAV file.\n        labels: Labels to set for each channel.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(filename, ch_labels=labels)\n    return cf\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.read_csv","title":"<code>read_csv(filename, time_column=0, labels=None, delimiter=',', header=0)</code>  <code>classmethod</code>","text":"<p>Utility method to read a CSV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> \u5fc5\u9808 <code>time_column</code> <code>int | str</code> <p>Index or name of the time column.</p> <code>0</code> <code>labels</code> <code>list[str] | None</code> <p>Labels to set for each channel.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>Delimiter character.</p> <code>','</code> <code>header</code> <code>int | None</code> <p>Row number to use as header.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame containing the data (lazy loading).</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; # Read CSV with default settings\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n&gt;&gt;&gt; # Read CSV with custom delimiter\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n&gt;&gt;&gt; # Read CSV without header\n&gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef read_csv(\n    cls,\n    filename: str,\n    time_column: int | str = 0,\n    labels: list[str] | None = None,\n    delimiter: str = \",\",\n    header: int | None = 0,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Utility method to read a CSV file.\n\n    Args:\n        filename: Path to the CSV file.\n        time_column: Index or name of the time column.\n        labels: Labels to set for each channel.\n        delimiter: Delimiter character.\n        header: Row number to use as header.\n\n    Returns:\n        A new ChannelFrame containing the data (lazy loading).\n\n    Examples:\n        &gt;&gt;&gt; # Read CSV with default settings\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\")\n        &gt;&gt;&gt; # Read CSV with custom delimiter\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", delimiter=\";\")\n        &gt;&gt;&gt; # Read CSV without header\n        &gt;&gt;&gt; cf = ChannelFrame.read_csv(\"data.csv\", header=None)\n    \"\"\"\n    from .channel import ChannelFrame\n\n    cf = ChannelFrame.from_file(\n        filename,\n        ch_labels=labels,\n        time_column=time_column,\n        delimiter=delimiter,\n        header=header,\n    )\n    return cf\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.to_wav","title":"<code>to_wav(path, format=None)</code>","text":"<p>Save the audio data to a WAV file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to save the file.</p> \u5fc5\u9808 <code>format</code> <code>str | None</code> <p>File format. If None, determined from file extension.</p> <code>None</code> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def to_wav(self, path: str | Path, format: str | None = None) -&gt; None:\n    \"\"\"Save the audio data to a WAV file.\n\n    Args:\n        path: Path to save the file.\n        format: File format. If None, determined from file extension.\n    \"\"\"\n    from wandas.io.wav_io import write_wav\n\n    write_wav(str(path), self, format=format)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.save","title":"<code>save(path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save the ChannelFrame to a WDF (Wandas Data File) format.</p> <p>This saves the complete frame including all channel data and metadata in a format that can be loaded back with full fidelity.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> Example <p>cf = ChannelFrame.read_wav(\"audio.wav\") cf.save(\"audio_analysis.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def save(\n    self,\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save the ChannelFrame to a WDF (Wandas Data File) format.\n\n    This saves the complete frame including all channel data and metadata\n    in a format that can be loaded back with full fidelity.\n\n    Args:\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; cf.save(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import save as wdf_save\n\n    wdf_save(\n        self,\n        path,\n        format=format,\n        compress=compress,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.load","title":"<code>load(path, *, format='hdf5')</code>  <code>classmethod</code>","text":"<p>Load a ChannelFrame from a WDF (Wandas Data File) file.</p> <p>This loads data saved with the save() method, preserving all channel data, metadata, labels, and units.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame with all data and metadata loaded</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>NotImplementedError</code> <p>For unsupported formats</p> Example <p>cf = ChannelFrame.load(\"audio_analysis.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>@classmethod\ndef load(cls, path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame from a WDF (Wandas Data File) file.\n\n    This loads data saved with the save() method, preserving all channel data,\n    metadata, labels, and units.\n\n    Args:\n        path: Path to the WDF file\n        format: Format of the file (currently only 'hdf5' is supported)\n\n    Returns:\n        A new ChannelFrame with all data and metadata loaded\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        NotImplementedError: For unsupported formats\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_analysis.wdf\")\n    \"\"\"\n    from ..io.wdf_io import load as wdf_load\n\n    return wdf_load(path, format=format)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.add_channel","title":"<code>add_channel(data, label=None, align='strict', suffix_on_dup=None, inplace=False)</code>","text":"<p>Add a new channel to the frame.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>ndarray[Any, Any] | Array | ChannelFrame</code> <p>Data to add as a new channel. Can be: - numpy array (1D or 2D) - dask array (1D or 2D) - ChannelFrame (channels will be added)</p> \u5fc5\u9808 <code>label</code> <code>str | None</code> <p>Label for the new channel. If None, generates a default label. Ignored when data is a ChannelFrame (uses its channel labels).</p> <code>None</code> <code>align</code> <code>str</code> <p>How to handle length mismatches: - \"strict\": Raise error if lengths don't match - \"pad\": Pad shorter data with zeros - \"truncate\": Truncate longer data to match</p> <code>'strict'</code> <code>suffix_on_dup</code> <code>str | None</code> <p>Suffix to add to duplicate labels. If None, raises error.</p> <code>None</code> <code>inplace</code> <code>bool</code> <p>If True, modifies the frame in place. Otherwise returns a new frame.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>Modified ChannelFrame (self if inplace=True, new frame otherwise).</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If data length doesn't match and align=\"strict\", or if label is duplicate and suffix_on_dup is None.</p> <code>TypeError</code> <p>If data type is not supported.</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Add a numpy array as a new channel\n&gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n&gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n&gt;&gt;&gt; # Add another ChannelFrame's channels\n&gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n&gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def add_channel(\n    self,\n    data: \"np.ndarray[Any, Any] | DaskArray | ChannelFrame\",\n    label: str | None = None,\n    align: str = \"strict\",\n    suffix_on_dup: str | None = None,\n    inplace: bool = False,\n) -&gt; \"ChannelFrame\":\n    \"\"\"Add a new channel to the frame.\n\n    Args:\n        data: Data to add as a new channel. Can be:\n            - numpy array (1D or 2D)\n            - dask array (1D or 2D)\n            - ChannelFrame (channels will be added)\n        label: Label for the new channel. If None, generates a default label.\n            Ignored when data is a ChannelFrame (uses its channel labels).\n        align: How to handle length mismatches:\n            - \"strict\": Raise error if lengths don't match\n            - \"pad\": Pad shorter data with zeros\n            - \"truncate\": Truncate longer data to match\n        suffix_on_dup: Suffix to add to duplicate labels. If None, raises error.\n        inplace: If True, modifies the frame in place.\n            Otherwise returns a new frame.\n\n    Returns:\n        Modified ChannelFrame (self if inplace=True, new frame otherwise).\n\n    Raises:\n        ValueError: If data length doesn't match and align=\"strict\",\n            or if label is duplicate and suffix_on_dup is None.\n        TypeError: If data type is not supported.\n\n    Examples:\n        &gt;&gt;&gt; cf = ChannelFrame.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Add a numpy array as a new channel\n        &gt;&gt;&gt; new_data = np.sin(2 * np.pi * 440 * cf.time)\n        &gt;&gt;&gt; cf_new = cf.add_channel(new_data, label=\"sine_440Hz\")\n        &gt;&gt;&gt; # Add another ChannelFrame's channels\n        &gt;&gt;&gt; cf2 = ChannelFrame.read_wav(\"audio2.wav\")\n        &gt;&gt;&gt; cf_combined = cf.add_channel(cf2)\n    \"\"\"\n    # ndarray/dask/\u540c\u578bFrame\u5bfe\u5fdc\n    if isinstance(data, ChannelFrame):\n        if self.sampling_rate != data.sampling_rate:\n            raise ValueError(\"sampling_rate\u4e0d\u4e00\u81f4\")\n        if data.n_samples != self.n_samples:\n            if align == \"pad\":\n                pad_len = self.n_samples - data.n_samples\n                arr = data._data\n                if pad_len &gt; 0:\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n                else:\n                    arr = arr[:, : self.n_samples]\n            elif align == \"truncate\":\n                arr = data._data[:, : self.n_samples]\n                if arr.shape[1] &lt; self.n_samples:\n                    pad_len = self.n_samples - arr.shape[1]\n                    arr = concatenate(\n                        [\n                            arr,\n                            from_array(\n                                np.zeros((arr.shape[0], pad_len), dtype=arr.dtype)\n                            ),\n                        ],\n                        axis=1,\n                    )\n            else:\n                raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n        else:\n            arr = data._data\n        labels = [ch.label for ch in self._channel_metadata]\n        new_labels = []\n        new_metadata_list = []\n        for chmeta in data._channel_metadata:\n            new_label = chmeta.label\n            if new_label in labels or new_label in new_labels:\n                if suffix_on_dup:\n                    new_label += suffix_on_dup\n                else:\n                    raise ValueError(f\"label\u91cd\u8907: {new_label}\")\n            new_labels.append(new_label)\n            # Copy the entire channel_metadata and update only the label\n            new_ch_meta = chmeta.model_copy(deep=True)\n            new_ch_meta.label = new_label\n            new_metadata_list.append(new_ch_meta)\n        new_data = concatenate([self._data, arr], axis=0)\n\n        new_chmeta = self._channel_metadata + new_metadata_list\n        if inplace:\n            self._data = new_data\n            self._channel_metadata = new_chmeta\n            return self\n        else:\n            return ChannelFrame(\n                data=new_data,\n                sampling_rate=self.sampling_rate,\n                label=self.label,\n                metadata=self.metadata,\n                operation_history=self.operation_history,\n                channel_metadata=new_chmeta,\n                previous=self,\n            )\n    if isinstance(data, np.ndarray):\n        arr = from_array(data.reshape(1, -1))\n    elif isinstance(data, DaskArray):\n        arr = data[None, ...] if data.ndim == 1 else data\n        if arr.shape[0] != 1:\n            arr = arr.reshape((1, -1))\n    else:\n        raise TypeError(\"add_channel: ndarray/dask/\u540c\u578bFrame\u306e\u307f\u5bfe\u5fdc\")\n    if arr.shape[1] != self.n_samples:\n        if align == \"pad\":\n            pad_len = self.n_samples - arr.shape[1]\n            if pad_len &gt; 0:\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n            else:\n                arr = arr[:, : self.n_samples]\n        elif align == \"truncate\":\n            arr = arr[:, : self.n_samples]\n            if arr.shape[1] &lt; self.n_samples:\n                pad_len = self.n_samples - arr.shape[1]\n                arr = concatenate(\n                    [arr, from_array(np.zeros((1, pad_len), dtype=arr.dtype))],\n                    axis=1,\n                )\n        else:\n            raise ValueError(\"\u30c7\u30fc\u30bf\u9577\u4e0d\u4e00\u81f4: align\u6307\u5b9a\u3092\u78ba\u8a8d\")\n    labels = [ch.label for ch in self._channel_metadata]\n    new_label = label or f\"ch{len(labels)}\"\n    if new_label in labels:\n        if suffix_on_dup:\n            new_label += suffix_on_dup\n        else:\n            raise ValueError(\"label\u91cd\u8907\")\n    new_data = concatenate([self._data, arr], axis=0)\n    from ..core.metadata import ChannelMetadata\n\n    new_chmeta = self._channel_metadata + [ChannelMetadata(label=new_label)]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.channel.ChannelFrame.remove_channel","title":"<code>remove_channel(key, inplace=False)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/channel.py</code> <pre><code>def remove_channel(self, key: int | str, inplace: bool = False) -&gt; \"ChannelFrame\":\n    if isinstance(key, int):\n        if not (0 &lt;= key &lt; self.n_channels):\n            raise IndexError(f\"index {key} out of range\")\n        idx = key\n    else:\n        labels = [ch.label for ch in self._channel_metadata]\n        if key not in labels:\n            raise KeyError(f\"label {key} not found\")\n        idx = labels.index(key)\n    new_data = self._data[[i for i in range(self.n_channels) if i != idx], :]\n    new_chmeta = [ch for i, ch in enumerate(self._channel_metadata) if i != idx]\n    if inplace:\n        self._data = new_data\n        self._channel_metadata = new_chmeta\n        return self\n    else:\n        return ChannelFrame(\n            data=new_data,\n            sampling_rate=self.sampling_rate,\n            label=self.label,\n            metadata=self.metadata,\n            operation_history=self.operation_history,\n            channel_metadata=new_chmeta,\n            previous=self,\n        )\n</code></pre>"},{"location":"en/api/frames/#spectralframe","title":"SpectralFrame","text":"<p>SpectralFrame is a frame for handling frequency-domain data.</p>"},{"location":"en/api/frames/#wandas.frames.spectral.SpectralFrame.__init__","title":"<code>__init__(data, sampling_rate, n_fft, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: BaseFrame[Any] | None = None,\n) -&gt; None:\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    elif data.ndim &gt; 2:\n        raise ValueError(\n            f\"Data must be 1-dimensional or 2-dimensional. Shape: {data.shape}\"\n        )\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectral.SpectralFrame.plot--examples","title":"Examples","text":"<p>spectrum = cf.fft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"frequency\",\n    ax: Axes | None = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot the spectral data using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"frequency\"\n        Type of plot to create. Options include:\n        - \"frequency\": Standard frequency plot\n        - \"matrix\": Matrix plot for comparing channels\n        - Other types as defined by available plot strategies\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; # Basic frequency plot\n    &gt;&gt;&gt; spectrum.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; spectrum.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; spectrum.plot(title=\"Frequency Spectrum\", color=\"red\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectral.SpectralFrame.ifft--returns","title":"Returns","text":"<p>ChannelFrame     A new ChannelFrame containing the time-domain signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def ifft(self) -&gt; ChannelFrame:\n    \"\"\"\n    Compute the Inverse Fast Fourier Transform (IFFT) to return to time domain.\n\n    This method transforms the frequency-domain data back to the time domain using\n    the inverse FFT operation. The window function used in the forward FFT is\n    taken into account to ensure proper reconstruction.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the time-domain signal.\n    \"\"\"\n    from ..processing import IFFT, create_operation\n    from .channel import ChannelFrame\n\n    params = {\"n_fft\": self.n_fft, \"window\": self.window}\n    operation_name = \"ifft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"IFFT\", operation)\n    # Apply processing to data\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Create new instance\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"ifft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectral.SpectralFrame.noct_synthesis--raises","title":"Raises","text":"<p>ValueError     If the sampling rate is not 48000 Hz, which is required for this operation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def noct_synthesis(\n    self,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; NOctFrame:\n    \"\"\"\n    Synthesize N-octave band spectrum.\n\n    This method combines frequency components into N-octave bands according to\n    standard acoustical band definitions. This is commonly used in noise and\n    vibration analysis.\n\n    Parameters\n    ----------\n    fmin : float\n        Lower frequency bound in Hz.\n    fmax : float\n        Upper frequency bound in Hz.\n    n : int, default=3\n        Number of bands per octave (e.g., 3 for third-octave bands).\n    G : int, default=10\n        Reference band number.\n    fr : int, default=1000\n        Reference frequency in Hz.\n\n    Returns\n    -------\n    NOctFrame\n        A new NOctFrame containing the N-octave band spectrum.\n\n    Raises\n    ------\n    ValueError\n        If the sampling rate is not 48000 Hz, which is required for this operation.\n    \"\"\"\n    if self.sampling_rate != 48000:\n        raise ValueError(\n            \"noct_synthesis can only be used with a sampling rate of 48000 Hz.\"\n        )\n    from ..processing import NOctSynthesis\n    from .noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_synthesis\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n    from ..processing import create_operation\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSynthesis\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_synthesis\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectral.SpectralFrame.plot_matrix--returns","title":"Returns","text":"<p>Union[Axes, Iterator[Axes]]     The matplotlib axes containing the plot.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def plot_matrix(\n    self,\n    plot_type: str = \"matrix\",\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"\n    Plot channel relationships in matrix format.\n\n    This method creates a matrix plot showing relationships between channels,\n    such as coherence, transfer functions, or cross-spectral density.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"matrix\"\n        Type of matrix plot to create.\n    **kwargs : dict\n        Additional plot parameters:\n        - vmin, vmax: Color scale limits\n        - cmap: Colormap name\n        - title: Plot title\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[SpectralFrame] = create_operation(plot_type)\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, **kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectral.SpectralFrame.info--examples","title":"Examples","text":"<p>spectrum = cf.fft() spectrum.info() SpectralFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectral.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectralFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Channel labels\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; spectrum = cf.fft()\n    &gt;&gt;&gt; spectrum.info()\n    SpectralFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F)\n    delta_f = self.sampling_rate / self.n_fft\n\n    print(\"SpectralFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {len(self.freqs)}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/frames/#spectrogramframe","title":"SpectrogramFrame","text":"<p>SpectrogramFrame is a frame for handling time-frequency domain (spectrogram) data.</p>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.__init__","title":"<code>__init__(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    if data.ndim == 2:\n        data = da.expand_dims(data, axis=0)  # type: ignore [unused-ignore]\n    elif data.ndim != 3:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306f2\u6b21\u5143\u307e\u305f\u306f3\u6b21\u5143\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u5f62\u72b6: {data.shape}\"\n        )\n    if not data.shape[-2] == n_fft // 2 + 1:\n        raise ValueError(\n            f\"\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u304c\u7121\u52b9\u3067\u3059\u3002\u5468\u6ce2\u6570\u30d3\u30f3\u6570\u306f {n_fft // 2 + 1} \u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"  # noqa: E501\n        )\n\n    self.n_fft = n_fft\n    self.hop_length = hop_length\n    self.win_length = win_length if win_length is not None else n_fft\n    self.window = window\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot--examples","title":"Examples","text":"<p>stft = cf.stft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    cmap: str = \"jet\",\n    vmin: float | None = None,\n    vmax: float | None = None,\n    fmin: float = 0,\n    fmax: float | None = None,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the spectrogram using various visualization strategies.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses the frame label.\n    cmap : str, default=\"jet\"\n        Colormap name for the spectrogram visualization.\n    vmin : float, optional\n        Minimum value for colormap scaling (dB). Auto-calculated if None.\n    vmax : float, optional\n        Maximum value for colormap scaling (dB). Auto-calculated if None.\n    fmin : float, default=0\n        Minimum frequency to display (Hz).\n    fmax : float, optional\n        Maximum frequency to display (Hz). If None, uses Nyquist frequency.\n    xlim : tuple[float, float], optional\n        Time axis limits as (start_time, end_time) in seconds.\n    ylim : tuple[float, float], optional\n        Frequency axis limits as (min_freq, max_freq) in Hz.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the spectrogram.\n    **kwargs : dict\n        Additional keyword arguments passed to librosa.display.specshow().\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # Basic spectrogram\n    &gt;&gt;&gt; stft.plot()\n    &gt;&gt;&gt; # Custom color scale and frequency range\n    &gt;&gt;&gt; stft.plot(vmin=-80, vmax=-20, fmin=100, fmax=5000)\n    &gt;&gt;&gt; # A-weighted spectrogram\n    &gt;&gt;&gt; stft.plot(Aw=True, cmap=\"viridis\")\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # \u30d7\u30ed\u30c3\u30c8\u6226\u7565\u3092\u53d6\u5f97\n    plot_strategy: PlotStrategy[SpectrogramFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"cmap\": cmap,\n        \"vmin\": vmin,\n        \"vmax\": vmax,\n        \"fmin\": fmin,\n        \"fmax\": fmax,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # \u30d7\u30ed\u30c3\u30c8\u5b9f\u884c\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.plot_Aw--examples","title":"Examples","text":"<p>stft = cf.stft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def plot_Aw(  # noqa: N802\n    self,\n    plot_type: str = \"spectrogram\",\n    ax: Optional[\"Axes\"] = None,\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the A-weighted spectrogram.\n\n    A convenience method that calls plot() with Aw=True, applying A-weighting\n    to the spectrogram before plotting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"spectrogram\"\n        Type of plot to create.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    **kwargs : dict\n        Additional keyword arguments passed to plot().\n        Accepts all parameters from plot() except Aw (which is set to True).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot.\n\n    Examples\n    --------\n    &gt;&gt;&gt; stft = cf.stft()\n    &gt;&gt;&gt; # A-weighted spectrogram with custom settings\n    &gt;&gt;&gt; stft.plot_Aw(vmin=-60, vmax=-10, cmap=\"magma\")\n    \"\"\"\n    return self.plot(plot_type=plot_type, ax=ax, Aw=True, **kwargs)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.abs--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) magnitude_spectrogram = spectrogram.abs()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def abs(self) -&gt; \"SpectrogramFrame\":\n    \"\"\"\n    Compute the absolute value (magnitude) of the complex spectrogram.\n\n    This method calculates the magnitude of each complex value in the\n    spectrogram, converting the complex-valued data to real-valued magnitude data.\n    The result is stored in a new SpectrogramFrame with complex dtype to maintain\n    compatibility with other spectrogram operations.\n\n    Returns\n    -------\n    SpectrogramFrame\n        A new SpectrogramFrame containing the magnitude values as complex numbers\n        (with zero imaginary parts).\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; magnitude_spectrogram = spectrogram.abs()\n    &gt;&gt;&gt; # The magnitude can be accessed via the magnitude property or data\n    &gt;&gt;&gt; print(magnitude_spectrogram.magnitude.shape)\n    \"\"\"\n    logger.debug(\"Computing absolute value (magnitude) of spectrogram\")\n\n    # Compute the absolute value using dask for lazy evaluation\n    magnitude_data = da.absolute(self._data)\n\n    # Update operation history\n    operation_metadata = {\"operation\": \"abs\", \"params\": {}}\n    new_history = self.operation_history.copy()\n    new_history.append(operation_metadata)\n    new_metadata = {**self.metadata}\n    new_metadata[\"abs\"] = {}\n\n    logger.debug(\"Created new SpectrogramFrame with abs operation added to graph\")\n\n    return SpectrogramFrame(\n        data=magnitude_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=self.window,\n        label=f\"abs({self.label})\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.get_frame_at--raises","title":"Raises","text":"<p>IndexError     If time_idx is out of range.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def get_frame_at(self, time_idx: int) -&gt; \"SpectralFrame\":\n    \"\"\"\n    Extract spectral data at a specific time frame.\n\n    Parameters\n    ----------\n    time_idx : int\n        Index of the time frame to extract.\n\n    Returns\n    -------\n    SpectralFrame\n        A new SpectralFrame containing the spectral data at the specified time.\n\n    Raises\n    ------\n    IndexError\n        If time_idx is out of range.\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n\n    if time_idx &lt; 0 or time_idx &gt;= self.n_frames:\n        raise IndexError(\n            f\"\u6642\u9593\u30a4\u30f3\u30c7\u30c3\u30af\u30b9 {time_idx} \u304c\u7bc4\u56f2\u5916\u3067\u3059\u3002\u6709\u52b9\u7bc4\u56f2: 0-{self.n_frames - 1}\"  # noqa: E501\n        )\n\n    frame_data = self._data[..., time_idx]\n\n    return SpectralFrame(\n        data=frame_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=self.n_fft,\n        window=self.window,\n        label=f\"{self.label} (Frame {time_idx}, Time {self.times[time_idx]:.3f}s)\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_channel_frame--see-also","title":"See Also","text":"<p>istft : Alias for this method with more intuitive naming.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def to_channel_frame(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This method performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    istft : Alias for this method with more intuitive naming.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n    from wandas.processing import ISTFT, create_operation\n\n    params = {\n        \"n_fft\": self.n_fft,\n        \"hop_length\": self.hop_length,\n        \"win_length\": self.win_length,\n        \"window\": self.window,\n    }\n    operation_name = \"istft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # \u64cd\u4f5c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"ISTFT\", operation)\n    # \u30c7\u30fc\u30bf\u306b\u51e6\u7406\u3092\u9069\u7528\n    time_series = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new ChannelFrame with operation {operation_name} added to graph\"\n    )\n\n    # \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n    return ChannelFrame(\n        data=time_series,\n        sampling_rate=self.sampling_rate,\n        label=f\"istft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.istft--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) reconstructed = spectrogram.istft()</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def istft(self) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Convert the spectrogram back to time domain using inverse STFT.\n\n    This is an alias for `to_channel_frame()` with a more intuitive name.\n    It performs an inverse Short-Time Fourier Transform (ISTFT) to\n    reconstruct the time-domain signal from the spectrogram.\n\n    Returns\n    -------\n    ChannelFrame\n        A new ChannelFrame containing the reconstructed time-domain signal.\n\n    See Also\n    --------\n    to_channel_frame : The underlying implementation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; reconstructed = spectrogram.istft()\n    \"\"\"\n    return self.to_channel_frame()\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.to_dataframe--raises","title":"Raises","text":"<p>NotImplementedError     Always raised as DataFrame conversion is not supported.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def to_dataframe(self) -&gt; \"pd.DataFrame\":\n    \"\"\"DataFrame conversion is not supported for SpectrogramFrame.\n\n    SpectrogramFrame contains 3D data (channels, frequency_bins, time_frames)\n    which cannot be directly converted to a 2D DataFrame. Consider using\n    get_frame_at() to extract a specific time frame as a SpectralFrame,\n    then convert that to a DataFrame.\n\n    Raises\n    ------\n    NotImplementedError\n        Always raised as DataFrame conversion is not supported.\n    \"\"\"\n    raise NotImplementedError(\n        \"DataFrame conversion is not supported for SpectrogramFrame. \"\n        \"Use get_frame_at() to extract a specific time frame as SpectralFrame, \"\n        \"then convert that to a DataFrame.\"\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.info--examples","title":"Examples","text":"<p>signal = ChannelFrame.from_wav(\"audio.wav\") spectrogram = signal.stft(n_fft=2048, hop_length=512) spectrogram.info() SpectrogramFrame Information:   Channels: 2   Sampling rate: 44100 Hz   FFT size: 2048   Hop length: 512 samples   Window length: 2048 samples   Window: hann   Frequency range: 0.0 - 22050.0 Hz   Frequency bins: 1025   Frequency resolution (\u0394F): 21.5 Hz   Time frames: 100   Time resolution (\u0394T): 11.6 ms   Total duration: 1.16 s   Channel labels: ['ch0', 'ch1']   Operations Applied: 1</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Display comprehensive information about the SpectrogramFrame.\n\n    This method prints a summary of the frame's properties including:\n    - Number of channels\n    - Sampling rate\n    - FFT size\n    - Hop length\n    - Window length\n    - Window function\n    - Frequency range\n    - Number of frequency bins\n    - Frequency resolution (\u0394F)\n    - Number of time frames\n    - Time resolution (\u0394T)\n    - Total duration\n    - Channel labels\n    - Number of operations applied\n\n    This is a convenience method to view all key properties at once,\n    similar to pandas DataFrame.info().\n\n    Examples\n    --------\n    &gt;&gt;&gt; signal = ChannelFrame.from_wav(\"audio.wav\")\n    &gt;&gt;&gt; spectrogram = signal.stft(n_fft=2048, hop_length=512)\n    &gt;&gt;&gt; spectrogram.info()\n    SpectrogramFrame Information:\n      Channels: 2\n      Sampling rate: 44100 Hz\n      FFT size: 2048\n      Hop length: 512 samples\n      Window length: 2048 samples\n      Window: hann\n      Frequency range: 0.0 - 22050.0 Hz\n      Frequency bins: 1025\n      Frequency resolution (\u0394F): 21.5 Hz\n      Time frames: 100\n      Time resolution (\u0394T): 11.6 ms\n      Total duration: 1.16 s\n      Channel labels: ['ch0', 'ch1']\n      Operations Applied: 1\n    \"\"\"\n    # Calculate frequency resolution (\u0394F) and time resolution (\u0394T)\n    delta_f = self.sampling_rate / self.n_fft\n    delta_t_ms = (self.hop_length / self.sampling_rate) * 1000\n    total_duration = (self.n_frames * self.hop_length) / self.sampling_rate\n\n    print(\"SpectrogramFrame Information:\")\n    print(f\"  Channels: {self.n_channels}\")\n    print(f\"  Sampling rate: {self.sampling_rate} Hz\")\n    print(f\"  FFT size: {self.n_fft}\")\n    print(f\"  Hop length: {self.hop_length} samples\")\n    print(f\"  Window length: {self.win_length} samples\")\n    print(f\"  Window: {self.window}\")\n    print(f\"  Frequency range: {self.freqs[0]:.1f} - {self.freqs[-1]:.1f} Hz\")\n    print(f\"  Frequency bins: {self.n_freq_bins}\")\n    print(f\"  Frequency resolution (\u0394F): {delta_f:.1f} Hz\")\n    print(f\"  Time frames: {self.n_frames}\")\n    print(f\"  Time resolution (\u0394T): {delta_t_ms:.1f} ms\")\n    print(f\"  Total duration: {total_duration:.2f} s\")\n    print(f\"  Channel labels: {self.labels}\")\n    self._print_operation_history()\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.spectrogram.SpectrogramFrame.from_numpy","title":"<code>from_numpy(data, sampling_rate, n_fft, hop_length, win_length=None, window='hann', label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>  <code>classmethod</code>","text":"<p>Create a SpectrogramFrame from a NumPy array.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>data</code> <code>NDArrayComplex</code> <p>NumPy array containing spectrogram data. Shape should be (n_channels, n_freq_bins, n_time_frames) or (n_freq_bins, n_time_frames) for single channel.</p> \u5fc5\u9808 <code>sampling_rate</code> <code>float</code> <p>The sampling rate in Hz.</p> \u5fc5\u9808 <code>n_fft</code> <code>int</code> <p>The FFT size used to generate this spectrogram.</p> \u5fc5\u9808 <code>hop_length</code> <code>int</code> <p>Number of samples between successive frames.</p> \u5fc5\u9808 <code>win_length</code> <code>int | None</code> <p>The window length in samples. If None, defaults to n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>The window function used (e.g., \"hann\", \"hamming\").</p> <code>'hann'</code> <code>label</code> <code>str | None</code> <p>A label for the frame.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata dictionary.</p> <code>None</code> <code>operation_history</code> <code>list[dict[str, Any]] | None</code> <p>History of operations applied to the frame.</p> <code>None</code> <code>channel_metadata</code> <code>list[ChannelMetadata] | list[dict[str, Any]] | None</code> <p>Metadata for each channel.</p> <code>None</code> <code>previous</code> <code>Optional[BaseFrame[Any]]</code> <p>Reference to the previous frame in the processing chain.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectrogramFrame</code> <p>A new SpectrogramFrame containing the NumPy data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/spectrogram.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    data: NDArrayComplex,\n    sampling_rate: float,\n    n_fft: int,\n    hop_length: int,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Create a SpectrogramFrame from a NumPy array.\n\n    Args:\n        data: NumPy array containing spectrogram data.\n            Shape should be (n_channels, n_freq_bins, n_time_frames) or\n            (n_freq_bins, n_time_frames) for single channel.\n        sampling_rate: The sampling rate in Hz.\n        n_fft: The FFT size used to generate this spectrogram.\n        hop_length: Number of samples between successive frames.\n        win_length: The window length in samples. If None, defaults to n_fft.\n        window: The window function used (e.g., \"hann\", \"hamming\").\n        label: A label for the frame.\n        metadata: Optional metadata dictionary.\n        operation_history: History of operations applied to the frame.\n        channel_metadata: Metadata for each channel.\n        previous: Reference to the previous frame in the processing chain.\n\n    Returns:\n        A new SpectrogramFrame containing the NumPy data.\n    \"\"\"\n\n    # Convert NumPy array to dask array\n    dask_data = da.from_array(data)\n    sf = cls(\n        data=dask_data,\n        sampling_rate=sampling_rate,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        label=label or \"numpy_spectrogram\",\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n    return sf\n</code></pre>"},{"location":"en/api/frames/#noctframe","title":"NOctFrame","text":"<p>NOctFrame is a frame class for octave-band analysis.</p>"},{"location":"en/api/frames/#wandas.frames.noct.NOctFrame.__init__","title":"<code>__init__(data, sampling_rate, fmin=0, fmax=0, n=3, G=10, fr=1000, label=None, metadata=None, operation_history=None, channel_metadata=None, previous=None)</code>","text":"<p>Initialize a NOctFrame instance.</p> <p>Sets up N-octave band analysis parameters and prepares the frame for storing band-filtered data. Data shape is validated to ensure compatibility with N-octave band analysis.</p> <p>See class docstring for parameter descriptions.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/noct.py</code> <pre><code>def __init__(\n    self,\n    data: DaArray,\n    sampling_rate: float,\n    fmin: float = 0,\n    fmax: float = 0,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n    label: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    operation_history: list[dict[str, Any]] | None = None,\n    channel_metadata: list[ChannelMetadata] | list[dict[str, Any]] | None = None,\n    previous: Optional[\"BaseFrame[Any]\"] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a NOctFrame instance.\n\n    Sets up N-octave band analysis parameters and prepares the frame for\n    storing band-filtered data. Data shape is validated to ensure compatibility\n    with N-octave band analysis.\n\n    See class docstring for parameter descriptions.\n    \"\"\"\n    self.n = n\n    self.G = G\n    self.fr = fr\n    self.fmin = fmin\n    self.fmax = fmax\n    super().__init__(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=label,\n        metadata=metadata,\n        operation_history=operation_history,\n        channel_metadata=channel_metadata,\n        previous=previous,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.noct.NOctFrame.plot--examples","title":"Examples","text":"<p>noct = spectrum.noct(n=3)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/noct.py</code> <pre><code>def plot(\n    self,\n    plot_type: str = \"noct\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    xlabel: str | None = None,\n    ylabel: str | None = None,\n    alpha: float = 1.0,\n    xlim: tuple[float, float] | None = None,\n    ylim: tuple[float, float] | None = None,\n    Aw: bool = False,  # noqa: N803\n    **kwargs: Any,\n) -&gt; Union[\"Axes\", Iterator[\"Axes\"]]:\n    \"\"\"\n    Plot the N-octave band data using various visualization strategies.\n\n    Supports standard plotting configurations for acoustic analysis,\n    including decibel scales and A-weighting.\n\n    Parameters\n    ----------\n    plot_type : str, default=\"noct\"\n        Type of plot to create. The default \"noct\" type creates a step plot\n        suitable for displaying N-octave band data.\n    ax : matplotlib.axes.Axes, optional\n        Axes to plot on. If None, creates new axes.\n    title : str, optional\n        Title for the plot. If None, uses a default title with band specification.\n    overlay : bool, default=False\n        Whether to overlay all channels on a single plot (True)\n        or create separate subplots for each channel (False).\n    xlabel : str, optional\n        Label for the x-axis. If None, uses default \"Center frequency [Hz]\".\n    ylabel : str, optional\n        Label for the y-axis. If None, uses default based on data type.\n    alpha : float, default=1.0\n        Transparency level for the plot lines (0.0 to 1.0).\n    xlim : tuple[float, float], optional\n        Limits for the x-axis as (min, max) tuple.\n    ylim : tuple[float, float], optional\n        Limits for the y-axis as (min, max) tuple.\n    Aw : bool, default=False\n        Whether to apply A-weighting to the data.\n    **kwargs : dict\n        Additional matplotlib Line2D parameters\n        (e.g., color, linewidth, linestyle).\n\n    Returns\n    -------\n    Union[Axes, Iterator[Axes]]\n        The matplotlib axes containing the plot, or an iterator of axes\n        for multi-plot outputs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; noct = spectrum.noct(n=3)\n    &gt;&gt;&gt; # Basic 1/3-octave plot\n    &gt;&gt;&gt; noct.plot()\n    &gt;&gt;&gt; # Overlay with A-weighting\n    &gt;&gt;&gt; noct.plot(overlay=True, Aw=True)\n    &gt;&gt;&gt; # Custom styling\n    &gt;&gt;&gt; noct.plot(title=\"1/3-Octave Spectrum\", color=\"blue\", linewidth=2)\n    \"\"\"\n    from wandas.visualization.plotting import create_operation\n\n    logger.debug(f\"Plotting audio with plot_type={plot_type} (will compute now)\")\n\n    # Get plot strategy\n    plot_strategy: PlotStrategy[NOctFrame] = create_operation(plot_type)\n\n    # Build kwargs for plot strategy\n    plot_kwargs = {\n        \"title\": title,\n        \"overlay\": overlay,\n        \"Aw\": Aw,\n        **kwargs,\n    }\n    if xlabel is not None:\n        plot_kwargs[\"xlabel\"] = xlabel\n    if ylabel is not None:\n        plot_kwargs[\"ylabel\"] = ylabel\n    if alpha != 1.0:\n        plot_kwargs[\"alpha\"] = alpha\n    if xlim is not None:\n        plot_kwargs[\"xlim\"] = xlim\n    if ylim is not None:\n        plot_kwargs[\"ylim\"] = ylim\n\n    # Execute plot\n    _ax = plot_strategy.plot(self, ax=ax, **plot_kwargs)\n\n    logger.debug(\"Plot rendering complete\")\n\n    return _ax\n</code></pre>"},{"location":"en/api/frames/#mixins","title":"Mixins","text":"<p>Mixins for extending frame functionality.</p>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.high_pass_filter","title":"<code>high_pass_filter(cutoff, order=4)</code>","text":"<p>Apply a high-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def high_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a high-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up highpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"highpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.low_pass_filter","title":"<code>low_pass_filter(cutoff, order=4)</code>","text":"<p>Apply a low-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>cutoff</code> <code>float</code> <p>Filter cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def low_pass_filter(\n    self: T_Processing, cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a low-pass filter to the signal.\n\n    Args:\n        cutoff: Filter cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up lowpass filter: cutoff={cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\"lowpass_filter\", cutoff=cutoff, order=order)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.band_pass_filter","title":"<code>band_pass_filter(low_cutoff, high_cutoff, order=4)</code>","text":"<p>Apply a band-pass filter to the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>low_cutoff</code> <code>float</code> <p>Lower cutoff frequency (Hz)</p> \u5fc5\u9808 <code>high_cutoff</code> <code>float</code> <p>Higher cutoff frequency (Hz)</p> \u5fc5\u9808 <code>order</code> <code>int</code> <p>Filter order. Default is 4.</p> <code>4</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame after filter application</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def band_pass_filter(\n    self: T_Processing, low_cutoff: float, high_cutoff: float, order: int = 4\n) -&gt; T_Processing:\n    \"\"\"Apply a band-pass filter to the signal.\n\n    Args:\n        low_cutoff: Lower cutoff frequency (Hz)\n        high_cutoff: Higher cutoff frequency (Hz)\n        order: Filter order. Default is 4.\n\n    Returns:\n        New ChannelFrame after filter application\n    \"\"\"\n    logger.debug(\n        f\"Setting up bandpass filter: low_cutoff={low_cutoff}, \"\n        f\"high_cutoff={high_cutoff}, order={order} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"bandpass_filter\",\n        low_cutoff=low_cutoff,\n        high_cutoff=high_cutoff,\n        order=order,\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.normalize","title":"<code>normalize(norm=float('inf'), axis=-1, threshold=None, fill=None)</code>","text":"<p>Normalize signal levels using librosa.util.normalize.</p> <p>This method normalizes the signal amplitude according to the specified norm.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>norm</code> <code>float | None</code> <p>Norm type. Default is np.inf (maximum absolute value normalization). Supported values: - np.inf: Maximum absolute value normalization - -np.inf: Minimum absolute value normalization - 0: Peak normalization - float: Lp norm - None: No normalization</p> <code>float('inf')</code> <code>axis</code> <code>int | None</code> <p>Axis along which to normalize. Default is -1 (time axis). - -1: Normalize along time axis (each channel independently) - None: Global normalization across all axes - int: Normalize along specified axis</p> <code>-1</code> <code>threshold</code> <code>float | None</code> <p>Threshold below which values are considered zero. If None, no threshold is applied.</p> <code>None</code> <code>fill</code> <code>bool | None</code> <p>Value to fill when the norm is zero. If None, the zero vector remains zero.</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the normalized signal</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n&gt;&gt;&gt; normalized = signal.normalize()\n&gt;&gt;&gt; # Global normalization across all channels\n&gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n&gt;&gt;&gt; # L2 normalization\n&gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n</code></pre> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def normalize(\n    self: T_Processing,\n    norm: float | None = float(\"inf\"),\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n) -&gt; T_Processing:\n    \"\"\"Normalize signal levels using librosa.util.normalize.\n\n    This method normalizes the signal amplitude according to the specified norm.\n\n    Args:\n        norm: Norm type. Default is np.inf (maximum absolute value normalization).\n            Supported values:\n            - np.inf: Maximum absolute value normalization\n            - -np.inf: Minimum absolute value normalization\n            - 0: Peak normalization\n            - float: Lp norm\n            - None: No normalization\n        axis: Axis along which to normalize. Default is -1 (time axis).\n            - -1: Normalize along time axis (each channel independently)\n            - None: Global normalization across all axes\n            - int: Normalize along specified axis\n        threshold: Threshold below which values are considered zero.\n            If None, no threshold is applied.\n        fill: Value to fill when the norm is zero.\n            If None, the zero vector remains zero.\n\n    Returns:\n        New ChannelFrame containing the normalized signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Normalize to maximum absolute value of 1.0 (per channel)\n        &gt;&gt;&gt; normalized = signal.normalize()\n        &gt;&gt;&gt; # Global normalization across all channels\n        &gt;&gt;&gt; normalized_global = signal.normalize(axis=None)\n        &gt;&gt;&gt; # L2 normalization\n        &gt;&gt;&gt; normalized_l2 = signal.normalize(norm=2)\n    \"\"\"\n    logger.debug(\n        f\"Setting up normalize: norm={norm}, axis={axis}, \"\n        f\"threshold={threshold}, fill={fill} (lazy)\"\n    )\n    result = self.apply_operation(\n        \"normalize\", norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.remove_dc","title":"<code>remove_dc()</code>","text":"<p>Remove DC component (DC offset) from the signal.</p> <p>This method removes the DC (direct current) component by subtracting the mean value from each channel. This is equivalent to centering the signal around zero.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame with DC component removed</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create signal with DC offset\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n&gt;&gt;&gt; # Remove DC offset\n&gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n&gt;&gt;&gt; # Verify DC removal\n&gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n</code></pre> Notes <ul> <li>This operation is performed per channel</li> <li>Equivalent to applying a high-pass filter with very low cutoff</li> <li>Useful for removing sensor drift or measurement offset</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def remove_dc(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Remove DC component (DC offset) from the signal.\n\n    This method removes the DC (direct current) component by subtracting\n    the mean value from each channel. This is equivalent to centering the\n    signal around zero.\n\n    Returns:\n        New ChannelFrame with DC component removed\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # Create signal with DC offset\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; signal_with_dc = signal + 2.0  # Add DC offset\n        &gt;&gt;&gt; # Remove DC offset\n        &gt;&gt;&gt; signal_clean = signal_with_dc.remove_dc()\n        &gt;&gt;&gt; # Verify DC removal\n        &gt;&gt;&gt; assert np.allclose(signal_clean.data.mean(axis=1), 0, atol=1e-10)\n\n    Notes:\n        - This operation is performed per channel\n        - Equivalent to applying a high-pass filter with very low cutoff\n        - Useful for removing sensor drift or measurement offset\n    \"\"\"\n    logger.debug(\"Setting up DC removal (lazy)\")\n    result = self.apply_operation(\"remove_dc\")\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.a_weighting","title":"<code>a_weighting()</code>","text":"<p>Apply A-weighting filter to the signal.</p> <p>A-weighting adjusts the frequency response to approximate human auditory perception, according to the IEC 61672-1:2013 standard.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the A-weighted signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def a_weighting(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Apply A-weighting filter to the signal.\n\n    A-weighting adjusts the frequency response to approximate human\n    auditory perception, according to the IEC 61672-1:2013 standard.\n\n    Returns:\n        New ChannelFrame containing the A-weighted signal\n    \"\"\"\n    result = self.apply_operation(\"a_weighting\")\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.abs","title":"<code>abs()</code>","text":"<p>Compute the absolute value of the signal.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the absolute values</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def abs(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Compute the absolute value of the signal.\n\n    Returns:\n        New ChannelFrame containing the absolute values\n    \"\"\"\n    result = self.apply_operation(\"abs\")\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.power","title":"<code>power(exponent=2.0)</code>","text":"<p>Compute the power of the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>exponent</code> <code>float</code> <p>Exponent to raise the signal to. Default is 2.0.</p> <code>2.0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the powered signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def power(self: T_Processing, exponent: float = 2.0) -&gt; T_Processing:\n    \"\"\"Compute the power of the signal.\n\n    Args:\n        exponent: Exponent to raise the signal to. Default is 2.0.\n\n    Returns:\n        New ChannelFrame containing the powered signal\n    \"\"\"\n    result = self.apply_operation(\"power\", exponent=exponent)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.sum","title":"<code>sum()</code>","text":"<p>Sum all channels.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame with summed signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def sum(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Sum all channels.\n\n    Returns:\n        A new ChannelFrame with summed signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"sum\"))\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.mean","title":"<code>mean()</code>","text":"<p>Average all channels.</p> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame with averaged signal.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def mean(self: T_Processing) -&gt; T_Processing:\n    \"\"\"Average all channels.\n\n    Returns:\n        A new ChannelFrame with averaged signal.\n    \"\"\"\n    return cast(T_Processing, cast(Any, self)._reduce_channels(\"mean\"))\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.trim","title":"<code>trim(start=0, end=None)</code>","text":"<p>Trim the signal to the specified time range.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>start</code> <code>float</code> <p>Start time (seconds)</p> <code>0</code> <code>end</code> <code>float | None</code> <p>End time (seconds)</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the trimmed signal</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If end time is earlier than start time</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def trim(\n    self: T_Processing,\n    start: float = 0,\n    end: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Trim the signal to the specified time range.\n\n    Args:\n        start: Start time (seconds)\n        end: End time (seconds)\n\n    Returns:\n        New ChannelFrame containing the trimmed signal\n\n    Raises:\n        ValueError: If end time is earlier than start time\n    \"\"\"\n    if end is None:\n        end = self.duration\n    if start &gt; end:\n        raise ValueError(\"start must be less than end\")\n    result = self.apply_operation(\"trim\", start=start, end=end)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.fix_length","title":"<code>fix_length(length=None, duration=None)</code>","text":"<p>Adjust the signal to the specified length.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>duration</code> <code>float | None</code> <p>Signal length in seconds</p> <code>None</code> <code>length</code> <code>int | None</code> <p>Signal length in samples</p> <code>None</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the adjusted signal</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fix_length(\n    self: T_Processing,\n    length: int | None = None,\n    duration: float | None = None,\n) -&gt; T_Processing:\n    \"\"\"Adjust the signal to the specified length.\n\n    Args:\n        duration: Signal length in seconds\n        length: Signal length in samples\n\n    Returns:\n        New ChannelFrame containing the adjusted signal\n    \"\"\"\n\n    result = self.apply_operation(\"fix_length\", length=length, duration=duration)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.rms_trend","title":"<code>rms_trend(frame_length=2048, hop_length=512, dB=False, Aw=False)</code>","text":"<p>Compute the RMS trend of the signal.</p> <p>This method calculates the root mean square value over a sliding window.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame_length</code> <code>int</code> <p>Size of the sliding window in samples. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int</code> <p>Hop length between windows in samples. Default is 512.</p> <code>512</code> <code>dB</code> <code>bool</code> <p>Whether to return RMS values in decibels. Default is False.</p> <code>False</code> <code>Aw</code> <code>bool</code> <p>Whether to apply A-weighting. Default is False.</p> <code>False</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the RMS trend</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def rms_trend(\n    self: T_Processing,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; T_Processing:\n    \"\"\"Compute the RMS trend of the signal.\n\n    This method calculates the root mean square value over a sliding window.\n\n    Args:\n        frame_length: Size of the sliding window in samples. Default is 2048.\n        hop_length: Hop length between windows in samples. Default is 512.\n        dB: Whether to return RMS values in decibels. Default is False.\n        Aw: Whether to apply A-weighting. Default is False.\n\n    Returns:\n        New ChannelFrame containing the RMS trend\n    \"\"\"\n    # Access _channel_metadata to retrieve reference values\n    frame = cast(ProcessingFrameProtocol, self)\n\n    # Ensure _channel_metadata exists before referencing\n    ref_values = []\n    if hasattr(frame, \"_channel_metadata\") and frame._channel_metadata:\n        ref_values = [ch.ref for ch in frame._channel_metadata]\n\n    result = self.apply_operation(\n        \"rms_trend\",\n        frame_length=frame_length,\n        hop_length=hop_length,\n        ref=ref_values,\n        dB=dB,\n        Aw=Aw,\n    )\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.channel_difference","title":"<code>channel_difference(other_channel=0)</code>","text":"<p>Compute the difference between channels.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>other_channel</code> <code>int | str</code> <p>Index or label of the reference channel. Default is 0.</p> <code>0</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the channel difference</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def channel_difference(\n    self: T_Processing, other_channel: int | str = 0\n) -&gt; T_Processing:\n    \"\"\"Compute the difference between channels.\n\n    Args:\n        other_channel: Index or label of the reference channel. Default is 0.\n\n    Returns:\n        New ChannelFrame containing the channel difference\n    \"\"\"\n    # label2index is a method of BaseFrame\n    if isinstance(other_channel, str):\n        if hasattr(self, \"label2index\"):\n            other_channel = self.label2index(other_channel)\n\n    result = self.apply_operation(\"channel_difference\", other_channel=other_channel)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.resampling","title":"<code>resampling(target_sr, **kwargs)</code>","text":"<p>Resample audio data.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>target_sr</code> <code>float</code> <p>Target sampling rate (Hz)</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional resampling parameters</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>Resampled ChannelFrame</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def resampling(\n    self: T_Processing,\n    target_sr: float,\n    **kwargs: Any,\n) -&gt; T_Processing:\n    \"\"\"Resample audio data.\n\n    Args:\n        target_sr: Target sampling rate (Hz)\n        **kwargs: Additional resampling parameters\n\n    Returns:\n        Resampled ChannelFrame\n    \"\"\"\n    return cast(\n        T_Processing,\n        self.apply_operation(\n            \"resampling\",\n            target_sr=target_sr,\n            **kwargs,\n        ),\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.hpss_harmonic","title":"<code>hpss_harmonic(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code>","text":"<p>Extract harmonic components using HPSS  (Harmonic-Percussive Source Separation).</p> <p>This method separates the harmonic (tonal) components from the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <code>n_fft</code> <code>int</code> <p>Size of FFT window.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Hop length for STFT.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length for STFT.</p> <code>None</code> <code>window</code> <code>_WindowSpec</code> <p>Window type for STFT.</p> <code>'hann'</code> <code>center</code> <code>bool</code> <p>If True, center the frames.</p> <code>True</code> <code>pad_mode</code> <code>_PadModeSTFT</code> <p>Padding mode for STFT.</p> <code>'constant'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_harmonic(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract harmonic components using HPSS\n     (Harmonic-Percussive Source Separation).\n\n    This method separates the harmonic (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n        n_fft: Size of FFT window.\n        hop_length: Hop length for STFT.\n        win_length: Window length for STFT.\n        window: Window type for STFT.\n        center: If True, center the frames.\n        pad_mode: Padding mode for STFT.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_harmonic\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.hpss_percussive","title":"<code>hpss_percussive(kernel_size=31, power=2, margin=1, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, pad_mode='constant')</code>","text":"<p>Extract percussive components using HPSS (Harmonic-Percussive Source Separation).</p> <p>This method separates the percussive (tonal) components from the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>kernel_size</code> <code>Union[_IntLike_co, tuple[_IntLike_co, _IntLike_co], list[_IntLike_co]]</code> <p>Median filter size for HPSS.</p> <code>31</code> <code>power</code> <code>float</code> <p>Exponent for the Weiner filter used in HPSS.</p> <code>2</code> <code>margin</code> <code>Union[_FloatLike_co, tuple[_FloatLike_co, _FloatLike_co], list[_FloatLike_co]]</code> <p>Margin size for the separation.</p> <code>1</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>A new ChannelFrame containing the harmonic components.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def hpss_percussive(\n    self: T_Processing,\n    kernel_size: Union[\n        \"_IntLike_co\", tuple[\"_IntLike_co\", \"_IntLike_co\"], list[\"_IntLike_co\"]\n    ] = 31,\n    power: float = 2,\n    margin: Union[\n        \"_FloatLike_co\",\n        tuple[\"_FloatLike_co\", \"_FloatLike_co\"],\n        list[\"_FloatLike_co\"],\n    ] = 1,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: \"_WindowSpec\" = \"hann\",\n    center: bool = True,\n    pad_mode: \"_PadModeSTFT\" = \"constant\",\n) -&gt; T_Processing:\n    \"\"\"\n    Extract percussive components using HPSS\n    (Harmonic-Percussive Source Separation).\n\n    This method separates the percussive (tonal) components from the signal.\n\n    Args:\n        kernel_size: Median filter size for HPSS.\n        power: Exponent for the Weiner filter used in HPSS.\n        margin: Margin size for the separation.\n\n    Returns:\n        A new ChannelFrame containing the harmonic components.\n    \"\"\"\n    result = self.apply_operation(\n        \"hpss_percussive\",\n        kernel_size=kernel_size,\n        power=power,\n        margin=margin,\n        n_fft=n_fft,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        center=center,\n        pad_mode=pad_mode,\n    )\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.loudness_zwtv","title":"<code>loudness_zwtv(field_type='free')</code>","text":"<p>Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of non-stationary signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing time-varying loudness values in sones.</p> <code>T_Processing</code> <p>Each channel is processed independently.</p> <code>T_Processing</code> <p>The output sampling rate is adjusted based on the loudness</p> <code>T_Processing</code> <p>calculation time resolution (typically ~500 Hz for 2ms steps).</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>\u4f8b\uff1a</p> <p>Calculate loudness for a signal:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre> Notes <ul> <li>The output contains time-varying loudness values in sones</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>The time resolution is approximately 2ms (determined by the algorithm)</li> <li>For multi-channel signals, loudness is calculated per channel</li> <li>The output sampling rate is updated to reflect the time resolution</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 2ms analysis step. This differs slightly from the MoSQITo library, which uses the center time of each step. For example:</p> <ul> <li>wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)</li> <li>MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)</li> </ul> <p>The difference is very small (~1ms) and does not affect the loudness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwtv(self: T_Processing, field_type: str = \"free\") -&gt; T_Processing:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of non-stationary signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        New ChannelFrame containing time-varying loudness values in sones.\n        Each channel is processed independently.\n        The output sampling rate is adjusted based on the loudness\n        calculation time resolution (typically ~500 Hz for 2ms steps).\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate loudness for a signal:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness.plot(title=\"Time-varying Loudness\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwtv(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n    Notes:\n        - The output contains time-varying loudness values in sones\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - The time resolution is approximately 2ms (determined by the algorithm)\n        - For multi-channel signals, loudness is calculated per channel\n        - The output sampling rate is updated to reflect the time resolution\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 2ms analysis step. This differs slightly from the MoSQITo\n        library, which uses the center time of each step. For example:\n\n        - wandas time: [0.000s, 0.002s, 0.004s, ...] (step start)\n        - MoSQITo time: [0.001s, 0.003s, 0.005s, ...] (step center)\n\n        The difference is very small (~1ms) and does not affect the loudness\n        values themselves. This design choice ensures consistency with\n        wandas's time axis convention across all frame types.\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    result = self.apply_operation(\"loudness_zwtv\", field_type=field_type)\n\n    # Sampling rate update is handled by the Operation class\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.loudness_zwst","title":"<code>loudness_zwst(field_type='free')</code>","text":"<p>Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).</p> <p>This method computes the loudness of stationary (steady) signals according to the Zwicker method, as specified in ISO 532-1:2017. The loudness is calculated in sones, where a doubling of sones corresponds to a doubling of perceived loudness.</p> <p>This method is suitable for analyzing steady sounds such as fan noise, constant machinery sounds, or other stationary signals.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>field_type</code> <code>str</code> <p>Type of sound field. Options: - 'free': Free field (sound from a specific direction) - 'diffuse': Diffuse field (sound from all directions) Default is 'free'.</p> <code>'free'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NDArrayReal</code> <p>Loudness values in sones, one per channel. Shape: (n_channels,)</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If field_type is not 'free' or 'diffuse'</p> <p>\u4f8b\uff1a</p> <p>Calculate steady-state loudness for a fan noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n&gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n</code></pre> <p>Compare free field and diffuse field:</p> <pre><code>&gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n&gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n&gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n&gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre> Notes <ul> <li>Returns a 1D array with one loudness value per channel</li> <li>Typical loudness: 1 sone \u2248 40 phon (loudness level)</li> <li>For multi-channel signals, loudness is calculated independently   per channel</li> <li>This method is designed for stationary signals (constant sounds)</li> <li>For time-varying signals, use loudness_zwtv() instead</li> <li>Similar to the rms property, returns NDArrayReal for consistency</li> </ul> References <p>ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def loudness_zwst(self: T_Processing, field_type: str = \"free\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method (ISO 532-1:2017).\n\n    This method computes the loudness of stationary (steady) signals according to\n    the Zwicker method, as specified in ISO 532-1:2017. The loudness is\n    calculated in sones, where a doubling of sones corresponds to a doubling\n    of perceived loudness.\n\n    This method is suitable for analyzing steady sounds such as fan noise,\n    constant machinery sounds, or other stationary signals.\n\n    Args:\n        field_type: Type of sound field. Options:\n            - 'free': Free field (sound from a specific direction)\n            - 'diffuse': Diffuse field (sound from all directions)\n            Default is 'free'.\n\n    Returns:\n        Loudness values in sones, one per channel. Shape: (n_channels,)\n\n    Raises:\n        ValueError: If field_type is not 'free' or 'diffuse'\n\n    Examples:\n        Calculate steady-state loudness for a fan noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"fan_noise.wav\")\n        &gt;&gt;&gt; loudness = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; print(f\"Channel 0 loudness: {loudness[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Mean loudness: {loudness.mean():.2f} sones\")\n\n        Compare free field and diffuse field:\n        &gt;&gt;&gt; loudness_free = signal.loudness_zwst(field_type=\"free\")\n        &gt;&gt;&gt; loudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n        &gt;&gt;&gt; print(f\"Free field: {loudness_free[0]:.2f} sones\")\n        &gt;&gt;&gt; print(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n\n    Notes:\n        - Returns a 1D array with one loudness value per channel\n        - Typical loudness: 1 sone \u2248 40 phon (loudness level)\n        - For multi-channel signals, loudness is calculated independently\n          per channel\n        - This method is designed for stationary signals (constant sounds)\n        - For time-varying signals, use loudness_zwtv() instead\n        - Similar to the rms property, returns NDArrayReal for consistency\n\n    References:\n        ISO 532-1:2017, \"Acoustics \u2014 Methods for calculating loudness \u2014\n        Part 1: Zwicker method\"\n    \"\"\"\n    # Treat self as a ProcessingFrameProtocol so mypy understands\n    # where sampling_rate and data come from.\n    from wandas.processing.psychoacoustic import LoudnessZwst\n    from wandas.utils.types import NDArrayReal\n\n    # Create operation instance\n    operation = LoudnessZwst(self.sampling_rate, field_type=field_type)\n\n    # Get data (triggers computation if lazy)\n    data = self.data\n\n    # Ensure data is 2D (n_channels, n_samples)\n    if data.ndim == 1:\n        data = data.reshape(1, -1)\n    # Process the array using the public API and materialize to NumPy\n    result = operation.process_array(data).compute()\n\n    # Squeeze to get 1D array (n_channels,)\n    loudness_values: NDArrayReal = result.squeeze()\n\n    # Ensure it's 1D even for single channel\n    if loudness_values.ndim == 0:\n        loudness_values = loudness_values.reshape(1)\n\n    return loudness_values\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.roughness_dw","title":"<code>roughness_dw(overlap=0.5)</code>","text":"<p>Calculate time-varying roughness using Daniel and Weber method.</p> <p>Roughness is a psychoacoustic metric that quantifies the perceived harshness or roughness of a sound, measured in asper. This method implements the Daniel &amp; Weber (1997) standard calculation.</p> <p>The calculation follows the standard formula: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing time-varying roughness values in asper.</p> <code>T_Processing</code> <p>The output sampling rate depends on the overlap parameter.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>\u4f8b\uff1a</p> <p>Calculate roughness for a motor noise:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n&gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n&gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n</code></pre> <p>Analyze roughness statistics:</p> <pre><code>&gt;&gt;&gt; mean_roughness = roughness.data.mean()\n&gt;&gt;&gt; max_roughness = roughness.data.max()\n&gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n&gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n</code></pre> <p>Compare before and after modification:</p> <pre><code>&gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n&gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n&gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n&gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n</code></pre> Notes <ul> <li>Returns a ChannelFrame with time-varying roughness values</li> <li>Typical roughness values: 0-2 asper for most sounds</li> <li>Higher values indicate rougher, harsher sounds</li> <li>For multi-channel signals, roughness is calculated independently   per channel</li> <li>This is the standard-compliant total roughness (R)</li> <li>For detailed Bark-band analysis, use roughness_dw_spec() instead</li> </ul> <p>Time axis convention: The time axis in the returned frame represents the start time of each 200ms analysis window. This differs from the MoSQITo library, which uses the center time of each window. For example:</p> <ul> <li>wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)</li> <li>MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)</li> </ul> <p>The difference is constant (half the window duration = 100ms) and does not affect the roughness values themselves. This design choice ensures consistency with wandas's time axis convention across all frame types.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw(self: T_Processing, overlap: float = 0.5) -&gt; T_Processing:\n    \"\"\"Calculate time-varying roughness using Daniel and Weber method.\n\n    Roughness is a psychoacoustic metric that quantifies the perceived\n    harshness or roughness of a sound, measured in asper. This method\n    implements the Daniel &amp; Weber (1997) standard calculation.\n\n    The calculation follows the standard formula:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        New ChannelFrame containing time-varying roughness values in asper.\n        The output sampling rate depends on the overlap parameter.\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Calculate roughness for a motor noise:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor_noise.wav\")\n        &gt;&gt;&gt; roughness = signal.roughness_dw(overlap=0.5)\n        &gt;&gt;&gt; roughness.plot(ylabel=\"Roughness [asper]\")\n\n        Analyze roughness statistics:\n        &gt;&gt;&gt; mean_roughness = roughness.data.mean()\n        &gt;&gt;&gt; max_roughness = roughness.data.max()\n        &gt;&gt;&gt; print(f\"Mean: {mean_roughness:.2f} asper\")\n        &gt;&gt;&gt; print(f\"Max: {max_roughness:.2f} asper\")\n\n        Compare before and after modification:\n        &gt;&gt;&gt; before = wd.read_wav(\"motor_before.wav\").roughness_dw()\n        &gt;&gt;&gt; after = wd.read_wav(\"motor_after.wav\").roughness_dw()\n        &gt;&gt;&gt; improvement = before.data.mean() - after.data.mean()\n        &gt;&gt;&gt; print(f\"Roughness reduction: {improvement:.2f} asper\")\n\n    Notes:\n        - Returns a ChannelFrame with time-varying roughness values\n        - Typical roughness values: 0-2 asper for most sounds\n        - Higher values indicate rougher, harsher sounds\n        - For multi-channel signals, roughness is calculated independently\n          per channel\n        - This is the standard-compliant total roughness (R)\n        - For detailed Bark-band analysis, use roughness_dw_spec() instead\n\n        **Time axis convention:**\n        The time axis in the returned frame represents the start time of\n        each 200ms analysis window. This differs from the MoSQITo library,\n        which uses the center time of each window. For example:\n\n        - wandas time: [0.0s, 0.1s, 0.2s, ...] (window start)\n        - MoSQITo time: [0.1s, 0.2s, 0.3s, ...] (window center)\n\n        The difference is constant (half the window duration = 100ms) and\n        does not affect the roughness values themselves. This design choice\n        ensures consistency with wandas's time axis convention across all\n        frame types.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n    logger.debug(f\"Applying roughness_dw operation with overlap={overlap} (lazy)\")\n    result = self.apply_operation(\"roughness_dw\", overlap=overlap)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.roughness_dw_spec","title":"<code>roughness_dw_spec(overlap=0.5)</code>","text":"<p>Calculate specific roughness with Bark-band frequency information.</p> <p>This method returns detailed roughness analysis data organized by Bark frequency bands over time, allowing for frequency-specific roughness analysis. It uses the Daniel &amp; Weber (1997) method.</p> <p>The relationship between total roughness and specific roughness: R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>overlap</code> <code>float</code> <p>Overlapping coefficient for 200ms analysis windows (0.0 to 1.0). - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate Default is 0.5.</p> <code>0.5</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>RoughnessFrame</code> <p>RoughnessFrame containing: - data: Specific roughness by Bark band, shape (47, n_time)         for mono or (n_channels, 47, n_time) for multi-channel - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5) - time: Time axis for each analysis frame - overlap: Overlap coefficient used - plot(): Method for Bark-Time heatmap visualization</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If overlap is not in the range [0.0, 1.0]</p> <p>\u4f8b\uff1a</p> <p>Analyze frequency-specific roughness:</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n&gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot Bark-Time heatmap\n&gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find dominant Bark band\n&gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n&gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n&gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Extract specific Bark band time series\n&gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n&gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify standard formula\n&gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n&gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n</code></pre> Notes <ul> <li>Returns a RoughnessFrame (not ChannelFrame)</li> <li>Contains 47 Bark bands from 0.5 to 23.5 Bark</li> <li>Each Bark band corresponds to a critical band of hearing</li> <li>Useful for identifying which frequencies contribute most to roughness</li> <li>The specific roughness can be integrated to obtain total roughness</li> <li>For simple time-series analysis, use roughness_dw() instead</li> </ul> <p>Time axis convention: The time axis represents the start time of each 200ms analysis window, consistent with roughness_dw() and other wandas methods.</p> References <p>Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness: Implementation of an optimized model.\" Acustica, 83, 113-123.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def roughness_dw_spec(self: T_Processing, overlap: float = 0.5) -&gt; \"RoughnessFrame\":\n    \"\"\"Calculate specific roughness with Bark-band frequency information.\n\n    This method returns detailed roughness analysis data organized by\n    Bark frequency bands over time, allowing for frequency-specific\n    roughness analysis. It uses the Daniel &amp; Weber (1997) method.\n\n    The relationship between total roughness and specific roughness:\n    R = 0.25 * sum(R'_i) for i=1 to 47 Bark bands\n\n    Args:\n        overlap: Overlapping coefficient for 200ms analysis windows (0.0 to 1.0).\n            - overlap=0.5: 100ms hop \u2192 ~10 Hz output sampling rate\n            - overlap=0.0: 200ms hop \u2192 ~5 Hz output sampling rate\n            Default is 0.5.\n\n    Returns:\n        RoughnessFrame containing:\n            - data: Specific roughness by Bark band, shape (47, n_time)\n                    for mono or (n_channels, 47, n_time) for multi-channel\n            - bark_axis: Frequency axis in Bark scale (47 values, 0.5-23.5)\n            - time: Time axis for each analysis frame\n            - overlap: Overlap coefficient used\n            - plot(): Method for Bark-Time heatmap visualization\n\n    Raises:\n        ValueError: If overlap is not in the range [0.0, 1.0]\n\n    Examples:\n        Analyze frequency-specific roughness:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; signal = wd.read_wav(\"motor.wav\")\n        &gt;&gt;&gt; roughness_spec = signal.roughness_dw_spec(overlap=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot Bark-Time heatmap\n        &gt;&gt;&gt; roughness_spec.plot(cmap=\"viridis\", title=\"Roughness Analysis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Find dominant Bark band\n        &gt;&gt;&gt; dominant_idx = roughness_spec.data.mean(axis=1).argmax()\n        &gt;&gt;&gt; dominant_bark = roughness_spec.bark_axis[dominant_idx]\n        &gt;&gt;&gt; print(f\"Most contributing band: {dominant_bark:.1f} Bark\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Extract specific Bark band time series\n        &gt;&gt;&gt; bark_10_idx = np.argmin(np.abs(roughness_spec.bark_axis - 10.0))\n        &gt;&gt;&gt; roughness_at_10bark = roughness_spec.data[bark_10_idx, :]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verify standard formula\n        &gt;&gt;&gt; total_roughness = 0.25 * roughness_spec.data.sum(axis=-2)\n        &gt;&gt;&gt; # This should match signal.roughness_dw(overlap=0.5).data\n\n    Notes:\n        - Returns a RoughnessFrame (not ChannelFrame)\n        - Contains 47 Bark bands from 0.5 to 23.5 Bark\n        - Each Bark band corresponds to a critical band of hearing\n        - Useful for identifying which frequencies contribute most to roughness\n        - The specific roughness can be integrated to obtain total roughness\n        - For simple time-series analysis, use roughness_dw() instead\n\n        **Time axis convention:**\n        The time axis represents the start time of each 200ms analysis\n        window, consistent with roughness_dw() and other wandas methods.\n\n    References:\n        Daniel, P., &amp; Weber, R. (1997). \"Psychoacoustical roughness:\n        Implementation of an optimized model.\" Acustica, 83, 113-123.\n    \"\"\"\n\n    params = {\"overlap\": overlap}\n    operation_name = \"roughness_dw_spec\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance via factory\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n\n    # Apply processing lazily to self._data (Dask)\n    r_spec_dask = operation.process(self._data)\n\n    # Get metadata updates (sampling rate, bark_axis)\n    metadata_updates = operation.get_metadata_updates()\n\n    # Build metadata and history\n    new_metadata = {**self.metadata, **params}\n    new_history = [\n        *self.operation_history,\n        {\"operation\": operation_name, \"params\": params},\n    ]\n\n    # Extract bark_axis with proper type handling\n    bark_axis_value = metadata_updates.get(\"bark_axis\")\n    if bark_axis_value is None:\n        raise ValueError(\"Operation did not provide bark_axis in metadata\")\n\n    # Create RoughnessFrame. operation.get_metadata_updates() should provide\n    # sampling_rate and bark_axis\n    roughness_frame = RoughnessFrame(\n        data=r_spec_dask,\n        sampling_rate=metadata_updates.get(\"sampling_rate\", self.sampling_rate),\n        bark_axis=bark_axis_value,\n        overlap=overlap,\n        label=f\"{self.label}_roughness_spec\" if self.label else \"roughness_spec\",\n        metadata=new_metadata,\n        operation_history=new_history,\n        channel_metadata=self._channel_metadata,\n        previous=cast(\"BaseFrame[NDArrayReal]\", self),\n    )\n\n    logger.debug(\n        \"Created RoughnessFrame via operation %s, shape=%s, sampling_rate=%.2f Hz\",\n        operation_name,\n        r_spec_dask.shape,\n        roughness_frame.sampling_rate,\n    )\n\n    return roughness_frame\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_processing_mixin.ChannelProcessingMixin.fade","title":"<code>fade(fade_ms=50)</code>","text":"<p>Apply symmetric fade-in and fade-out to the signal using Tukey window.</p> <p>This method applies a symmetric fade-in and fade-out envelope to the signal using a Tukey (tapered cosine) window. The fade duration is the same for both the beginning and end of the signal.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>fade_ms</code> <code>float</code> <p>Fade duration in milliseconds for each end of the signal. The total fade duration is 2 * fade_ms. Default is 50 ms. Must be positive and less than half the signal duration.</p> <code>50</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>T_Processing</code> <p>New ChannelFrame containing the faded signal</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ValueError</code> <p>If fade_ms is negative or too long for the signal</p> <p>\u4f8b\uff1a</p> <pre><code>&gt;&gt;&gt; import wandas as wd\n&gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n&gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n&gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n&gt;&gt;&gt; # Apply very short fade (almost no effect)\n&gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n</code></pre> Notes <ul> <li>Uses SciPy's Tukey window for smooth fade transitions</li> <li>Fade is applied symmetrically to both ends of the signal</li> <li>The Tukey window alpha parameter is computed automatically   based on the fade duration and signal length</li> <li>For multi-channel signals, the same fade envelope is applied   to all channels</li> <li>Lazy evaluation is preserved - computation occurs only when needed</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_processing_mixin.py</code> <pre><code>def fade(self: T_Processing, fade_ms: float = 50) -&gt; T_Processing:\n    \"\"\"Apply symmetric fade-in and fade-out to the signal using Tukey window.\n\n    This method applies a symmetric fade-in and fade-out envelope to the signal\n    using a Tukey (tapered cosine) window. The fade duration is the same for\n    both the beginning and end of the signal.\n\n    Args:\n        fade_ms: Fade duration in milliseconds for each end of the signal.\n            The total fade duration is 2 * fade_ms. Default is 50 ms.\n            Must be positive and less than half the signal duration.\n\n    Returns:\n        New ChannelFrame containing the faded signal\n\n    Raises:\n        ValueError: If fade_ms is negative or too long for the signal\n\n    Examples:\n        &gt;&gt;&gt; import wandas as wd\n        &gt;&gt;&gt; signal = wd.read_wav(\"audio.wav\")\n        &gt;&gt;&gt; # Apply 10ms fade-in and fade-out\n        &gt;&gt;&gt; faded = signal.fade(fade_ms=10.0)\n        &gt;&gt;&gt; # Apply very short fade (almost no effect)\n        &gt;&gt;&gt; faded_short = signal.fade(fade_ms=0.1)\n\n    Notes:\n        - Uses SciPy's Tukey window for smooth fade transitions\n        - Fade is applied symmetrically to both ends of the signal\n        - The Tukey window alpha parameter is computed automatically\n          based on the fade duration and signal length\n        - For multi-channel signals, the same fade envelope is applied\n          to all channels\n        - Lazy evaluation is preserved - computation occurs only when needed\n    \"\"\"\n    logger.debug(f\"Setting up fade: fade_ms={fade_ms} (lazy)\")\n    result = self.apply_operation(\"fade\", fade_ms=fade_ms)\n    return cast(T_Processing, result)\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.fft","title":"<code>fft(n_fft=None, window='hann')</code>","text":"<p>Calculate Fast Fourier Transform (FFT).</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is the next power of 2 of the data length.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing FFT results</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def fft(\n    self: T_Transform, n_fft: int | None = None, window: str = \"hann\"\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate Fast Fourier Transform (FFT).\n\n    Args:\n        n_fft: Number of FFT points. Default is the next power of 2 of the data\n            length.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectralFrame containing FFT results\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import FFT, create_operation\n\n    params = {\"n_fft\": n_fft, \"window\": window}\n    operation_name = \"fft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"FFT\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    if n_fft is None:\n        is_even = spectrum_data.shape[-1] % 2 == 0\n        _n_fft = (\n            spectrum_data.shape[-1] * 2 - 2\n            if is_even\n            else spectrum_data.shape[-1] * 2 - 1\n        )\n    else:\n        _n_fft = n_fft\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=_n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, \"window\": window, \"n_fft\": _n_fft},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"fft\", \"params\": {\"n_fft\": _n_fft, \"window\": window}},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.welch","title":"<code>welch(n_fft=None, hop_length=None, win_length=2048, window='hann', average='mean')</code>","text":"<p>Calculate power spectral density using Welch's method.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int | None</code> <p>Number of FFT points. Default is 2048.</p> <code>None</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int</code> <p>Window length. Default is n_fft.</p> <code>2048</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing power spectral density</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def welch(\n    self: T_Transform,\n    n_fft: int | None = None,\n    hop_length: int | None = None,\n    win_length: int = 2048,\n    window: str = \"hann\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate power spectral density using Welch's method.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing power spectral density\n    \"\"\"\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import Welch, create_operation\n\n    params = dict(\n        n_fft=n_fft or win_length,\n        hop_length=hop_length,\n        win_length=win_length,\n        window=window,\n        average=average,\n    )\n    operation_name = \"welch\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Welch\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return SpectralFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Spectrum of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": \"welch\", \"params\": params},\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.noct_spectrum","title":"<code>noct_spectrum(fmin=25, fmax=20000, n=3, G=10, fr=1000)</code>","text":"<p>Calculate N-octave band spectrum.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>fmin</code> <code>float</code> <p>Minimum center frequency (Hz). Default is 25 Hz.</p> <code>25</code> <code>fmax</code> <code>float</code> <p>Maximum center frequency (Hz). Default is 20000 Hz.</p> <code>20000</code> <code>n</code> <code>int</code> <p>Band division (1: octave, 3: 1/3 octave). Default is 3.</p> <code>3</code> <code>G</code> <code>int</code> <p>Reference gain (dB). Default is 10 dB.</p> <code>10</code> <code>fr</code> <code>int</code> <p>Reference frequency (Hz). Default is 1000 Hz.</p> <code>1000</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>NOctFrame</code> <p>NOctFrame containing N-octave band spectrum</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def noct_spectrum(\n    self: T_Transform,\n    fmin: float = 25,\n    fmax: float = 20000,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n) -&gt; \"NOctFrame\":\n    \"\"\"Calculate N-octave band spectrum.\n\n    Args:\n        fmin: Minimum center frequency (Hz). Default is 25 Hz.\n        fmax: Maximum center frequency (Hz). Default is 20000 Hz.\n        n: Band division (1: octave, 3: 1/3 octave). Default is 3.\n        G: Reference gain (dB). Default is 10 dB.\n        fr: Reference frequency (Hz). Default is 1000 Hz.\n\n    Returns:\n        NOctFrame containing N-octave band spectrum\n    \"\"\"\n    from wandas.processing import NOctSpectrum, create_operation\n\n    from ..noct import NOctFrame\n\n    params = {\"fmin\": fmin, \"fmax\": fmax, \"n\": n, \"G\": G, \"fr\": fr}\n    operation_name = \"noct_spectrum\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"NOctSpectrum\", operation)\n    # Apply processing to data\n    spectrum_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    return NOctFrame(\n        data=spectrum_data,\n        sampling_rate=self.sampling_rate,\n        fmin=fmin,\n        fmax=fmax,\n        n=n,\n        G=G,\n        fr=fr,\n        label=f\"1/{n}Oct of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\n                \"operation\": \"noct_spectrum\",\n                \"params\": params,\n            },\n        ],\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.stft","title":"<code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code>","text":"<p>Calculate Short-Time Fourier Transform.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectrogramFrame</code> <p>SpectrogramFrame containing STFT results</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def stft(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrame\":\n    \"\"\"Calculate Short-Time Fourier Transform.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n\n    Returns:\n        SpectrogramFrame containing STFT results\n    \"\"\"\n    from wandas.processing import STFT, create_operation\n\n    from ..spectrogram import SpectrogramFrame\n\n    # Set hop length and window length\n    _hop_length = hop_length if hop_length is not None else n_fft // 4\n    _win_length = win_length if win_length is not None else n_fft\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": _hop_length,\n        \"win_length\": _win_length,\n        \"window\": window,\n    }\n    operation_name = \"stft\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"STFT\", operation)\n\n    # Apply processing to data\n    spectrogram_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectrogramFrame with operation {operation_name} added to graph\"  # noqa: E501\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new instance\n    return SpectrogramFrame(\n        data=spectrogram_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=n_fft,\n        hop_length=_hop_length,\n        win_length=_win_length,\n        window=window,\n        label=f\"stft({self.label})\",\n        metadata=self.metadata,\n        operation_history=self.operation_history,\n        channel_metadata=self._channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.coherence","title":"<code>coherence(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant')</code>","text":"<p>Calculate magnitude squared coherence.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing magnitude squared coherence</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def coherence(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate magnitude squared coherence.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n\n    Returns:\n        SpectralFrame containing magnitude squared coherence\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.processing import Coherence, create_operation\n\n    from ..spectral import SpectralFrame\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n    }\n    operation_name = \"coherence\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"Coherence\", operation)\n\n    # Apply processing to data\n    coherence_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$\\\\gamma_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=coherence_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Coherence of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.csd","title":"<code>csd(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Calculate cross-spectral density matrix.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing cross-spectral density matrix</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def csd(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate cross-spectral density matrix.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing cross-spectral density matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import CSD, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"csd\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"CSD\", operation)\n\n    # Apply processing to data\n    csd_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"{operation_name}({in_ch.label}, {out_ch.label})\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=csd_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"$C_{{{in_ch.label}, {out_ch.label}}}$\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/frames/#wandas.frames.mixins.channel_transform_mixin.ChannelTransformMixin.transfer_function","title":"<code>transfer_function(n_fft=2048, hop_length=None, win_length=None, window='hann', detrend='constant', scaling='spectrum', average='mean')</code>","text":"<p>Calculate transfer function matrix.</p> <p>The transfer function represents the signal transfer characteristics between channels in the frequency domain and represents the input-output relationship of the system.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>n_fft</code> <code>int</code> <p>Number of FFT points. Default is 2048.</p> <code>2048</code> <code>hop_length</code> <code>int | None</code> <p>Number of samples between frames. Default is n_fft//4.</p> <code>None</code> <code>win_length</code> <code>int | None</code> <p>Window length. Default is n_fft.</p> <code>None</code> <code>window</code> <code>str</code> <p>Window type. Default is \"hann\".</p> <code>'hann'</code> <code>detrend</code> <code>str</code> <p>Detrend method. Options: \"constant\", \"linear\", None.</p> <code>'constant'</code> <code>scaling</code> <code>str</code> <p>Scaling method. Options: \"spectrum\", \"density\".</p> <code>'spectrum'</code> <code>average</code> <code>str</code> <p>Method for averaging segments. Default is \"mean\".</p> <code>'mean'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>SpectralFrame</code> <p>SpectralFrame containing transfer function matrix</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/frames/mixins/channel_transform_mixin.py</code> <pre><code>def transfer_function(\n    self: T_Transform,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n) -&gt; \"SpectralFrame\":\n    \"\"\"Calculate transfer function matrix.\n\n    The transfer function represents the signal transfer characteristics between\n    channels in the frequency domain and represents the input-output relationship\n    of the system.\n\n    Args:\n        n_fft: Number of FFT points. Default is 2048.\n        hop_length: Number of samples between frames.\n            Default is n_fft//4.\n        win_length: Window length. Default is n_fft.\n        window: Window type. Default is \"hann\".\n        detrend: Detrend method. Options: \"constant\", \"linear\", None.\n        scaling: Scaling method. Options: \"spectrum\", \"density\".\n        average: Method for averaging segments. Default is \"mean\".\n\n    Returns:\n        SpectralFrame containing transfer function matrix\n    \"\"\"\n    from wandas.core.metadata import ChannelMetadata\n    from wandas.frames.spectral import SpectralFrame\n    from wandas.processing import TransferFunction, create_operation\n\n    params = {\n        \"n_fft\": n_fft,\n        \"hop_length\": hop_length,\n        \"win_length\": win_length,\n        \"window\": window,\n        \"detrend\": detrend,\n        \"scaling\": scaling,\n        \"average\": average,\n    }\n    operation_name = \"transfer_function\"\n    logger.debug(f\"Applying operation={operation_name} with params={params} (lazy)\")\n\n    # Create operation instance\n    operation = create_operation(operation_name, self.sampling_rate, **params)\n    operation = cast(\"TransferFunction\", operation)\n\n    # Apply processing to data\n    tf_data = operation.process(self._data)\n\n    logger.debug(\n        f\"Created new SpectralFrame with operation {operation_name} added to graph\"\n    )\n\n    # Cast self as BaseFrame type\n    base_self = cast(BaseFrame[Any], self)\n\n    # Create new channel metadata\n    channel_metadata = []\n    for in_ch in self._channel_metadata:\n        for out_ch in self._channel_metadata:\n            meta = ChannelMetadata()\n            meta.label = f\"$H_{{{in_ch.label}, {out_ch.label}}}$\"\n            meta.unit = \"\"\n            meta.ref = 1\n            meta[\"metadata\"] = dict(\n                in_ch=in_ch[\"metadata\"], out_ch=out_ch[\"metadata\"]\n            )\n            channel_metadata.append(meta)\n\n    # Create new instance\n    return SpectralFrame(\n        data=tf_data,\n        sampling_rate=self.sampling_rate,\n        n_fft=operation.n_fft,\n        window=operation.window,\n        label=f\"Transfer function of {self.label}\",\n        metadata={**self.metadata, **params},\n        operation_history=[\n            *self.operation_history,\n            {\"operation\": operation_name, \"params\": params},\n        ],\n        channel_metadata=channel_metadata,\n        previous=base_self,\n    )\n</code></pre>"},{"location":"en/api/io/","title":"IO Module","text":"<p>The <code>wandas.io</code> module provides reading and writing capabilities for various file formats.</p>"},{"location":"en/api/io/#file-readers","title":"File Readers","text":"<p>Provides functionality to read data from various file formats.</p>"},{"location":"en/api/io/#wandas.io.readers.FileReader.get_file_info","title":"<code>get_file_info(path, **kwargs)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Get basic information about the audio file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the file.</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>dict[str, Any]</code> <p>Dictionary containing file information including:</p> <code>dict[str, Any]</code> <ul> <li>samplerate: Sampling rate in Hz</li> </ul> <code>dict[str, Any]</code> <ul> <li>channels: Number of channels</li> </ul> <code>dict[str, Any]</code> <ul> <li>frames: Total number of frames</li> </ul> <code>dict[str, Any]</code> <ul> <li>format: File format</li> </ul> <code>dict[str, Any]</code> <ul> <li>duration: Duration in seconds</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\n\n    Args:\n        path: Path to the file.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Dictionary containing file information including:\n        - samplerate: Sampling rate in Hz\n        - channels: Number of channels\n        - frames: Total number of frames\n        - format: File format\n        - duration: Duration in seconds\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.FileReader.get_data","title":"<code>get_data(path, channels, start_idx, frames, **kwargs)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Read audio data from the file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the file.</p> \u5fc5\u9808 <code>channels</code> <code>list[int]</code> <p>List of channel indices to read.</p> \u5fc5\u9808 <code>start_idx</code> <code>int</code> <p>Starting frame index.</p> \u5fc5\u9808 <code>frames</code> <code>int</code> <p>Number of frames to read.</p> \u5fc5\u9808 <code>**kwargs</code> <code>Any</code> <p>Additional parameters specific to the file reader.</p> <code>{}</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ArrayLike</code> <p>Array of shape (channels, frames) containing the audio data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\n@abstractmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\n\n    Args:\n        path: Path to the file.\n        channels: List of channel indices to read.\n        start_idx: Starting frame index.\n        frames: Number of frames to read.\n        **kwargs: Additional parameters specific to the file reader.\n\n    Returns:\n        Array of shape (channels, frames) containing the audio data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.FileReader.can_read","title":"<code>can_read(path)</code>  <code>classmethod</code>","text":"<p>Check if this reader can handle the file based on extension.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef can_read(cls, path: str | Path) -&gt; bool:\n    \"\"\"Check if this reader can handle the file based on extension.\"\"\"\n    ext = Path(path).suffix.lower()\n    return ext in cls.supported_extensions\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.SoundFileReader.get_file_info","title":"<code>get_file_info(path, **kwargs)</code>  <code>classmethod</code>","text":"<p>Get basic information about the audio file.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(cls, path: str | Path, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the audio file.\"\"\"\n    info = sf.info(str(path))\n    return {\n        \"samplerate\": info.samplerate,\n        \"channels\": info.channels,\n        \"frames\": info.frames,\n        \"format\": info.format,\n        \"subtype\": info.subtype,\n        \"duration\": info.frames / info.samplerate,\n    }\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.SoundFileReader.get_data","title":"<code>get_data(path, channels, start_idx, frames, **kwargs)</code>  <code>classmethod</code>","text":"<p>Read audio data from the file.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read audio data from the file.\"\"\"\n    logger.debug(f\"Reading {frames} frames from {path} starting at {start_idx}\")\n\n    with sf.SoundFile(str(path)) as f:\n        if start_idx &gt; 0:\n            f.seek(start_idx)\n        data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n\n        # Select requested channels\n        if len(channels) &lt; f.channels:\n            data = data[:, channels]\n\n        # Transpose to get (channels, samples) format\n        result: ArrayLike = data.T\n        if not isinstance(result, np.ndarray):\n            raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"File read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.CSVFileReader.get_file_info--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVFileInfoParams for supported parameter types.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_file_info(\n    cls,\n    path: str | Path,\n    **kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Get basic information about the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header. Set to None if no header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing file information including:\n        - samplerate: Estimated sampling rate in Hz\n        - channels: Number of data channels (excluding time column)\n        - frames: Total number of frames\n        - format: \"CSV\"\n        - duration: Duration in seconds (or None if cannot be calculated)\n        - ch_labels: List of channel labels\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVFileInfoParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n\n    # Read first few lines to determine structure\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Estimate sampling rate from first column (assuming it's time)\n    try:\n        # Get time column as Series\n        if isinstance(time_column, str):\n            time_series = df[time_column]\n        else:\n            time_series = df.iloc[:, time_column]\n        time_values = np.array(time_series.values)\n        if len(time_values) &gt; 1:\n            # Use round() instead of int() to handle floating-point precision issues\n            estimated_sr = round(1 / np.mean(np.diff(time_values)))\n        else:\n            estimated_sr = 0  # Cannot determine from single row\n    except Exception:\n        estimated_sr = 0  # Default if can't calculate\n\n    frames = df.shape[0]\n    duration = frames / estimated_sr if estimated_sr &gt; 0 else None\n\n    # Return file info\n    return {\n        \"samplerate\": estimated_sr,\n        \"channels\": df.shape[1] - 1,  # Assuming first column is time\n        \"frames\": frames,\n        \"format\": \"CSV\",\n        \"duration\": duration,\n        \"ch_labels\": df.columns[1:].tolist(),  # Assuming first column is time\n    }\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.CSVFileReader.get_data--notes","title":"Notes","text":"<p>This method accepts CSV-specific parameters through kwargs. See CSVGetDataParams for supported parameter types.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>@classmethod\ndef get_data(\n    cls,\n    path: str | Path,\n    channels: list[int],\n    start_idx: int,\n    frames: int,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Read data from the CSV file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the CSV file.\n    channels : list[int]\n        List of channel indices to read.\n    start_idx : int\n        Starting frame index.\n    frames : int\n        Number of frames to read.\n    **kwargs : Any\n        Additional parameters for CSV reading. Supported parameters:\n\n        - delimiter : str, default=\",\"\n            Delimiter character.\n        - header : Optional[int], default=0\n            Row number to use as header.\n        - time_column : Union[int, str], default=0\n            Index or name of the time column.\n\n    Returns\n    -------\n    ArrayLike\n        Array of shape (channels, frames) containing the data.\n\n    Notes\n    -----\n    This method accepts CSV-specific parameters through kwargs.\n    See CSVGetDataParams for supported parameter types.\n    \"\"\"\n    # Extract parameters with defaults\n    time_column: int | str = kwargs.get(\"time_column\", 0)\n    delimiter: str = kwargs.get(\"delimiter\", \",\")\n    header: int | None = kwargs.get(\"header\", 0)\n\n    logger.debug(f\"Reading CSV data from {path} starting at {start_idx}\")\n\n    # Read the CSV file\n    df = pd.read_csv(path, delimiter=delimiter, header=header)\n\n    # Remove time column\n    df = df.drop(\n        columns=[time_column]\n        if isinstance(time_column, str)\n        else df.columns[time_column]\n    )\n\n    # Select requested channels - adjust indices to account for time column removal\n    if channels:\n        try:\n            data_df = df.iloc[:, channels]\n        except IndexError:\n            raise ValueError(f\"Requested channels {channels} out of range\")\n    else:\n        data_df = df\n\n    # Handle start_idx and frames for partial reading\n    end_idx = start_idx + frames if frames &gt; 0 else None\n    data_df = data_df.iloc[start_idx:end_idx]\n\n    # Convert to numpy array and transpose to (channels, samples) format\n    result = data_df.values.T\n\n    if not isinstance(result, np.ndarray):\n        raise ValueError(\"Unexpected data type after reading file\")\n\n    _shape = result.shape\n    logger.debug(f\"CSV read complete, returning data with shape {_shape}\")\n    return result\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.get_file_reader","title":"<code>get_file_reader(path)</code>","text":"<p>Get an appropriate file reader for the given path.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>def get_file_reader(path: str | Path) -&gt; FileReader:\n    \"\"\"Get an appropriate file reader for the given path.\"\"\"\n    path_str = str(path)\n    ext = Path(path).suffix.lower()\n\n    # Try each reader in order\n    for reader in _file_readers:\n        if ext in reader.__class__.supported_extensions:\n            logger.debug(f\"Using {reader.__class__.__name__} for {path_str}\")\n            return reader\n\n    # If no reader found, raise error\n    raise ValueError(f\"No suitable file reader found for {path_str}\")\n</code></pre>"},{"location":"en/api/io/#wandas.io.readers.register_file_reader","title":"<code>register_file_reader(reader_class)</code>","text":"<p>Register a new file reader.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/readers.py</code> <pre><code>def register_file_reader(reader_class: type) -&gt; None:\n    \"\"\"Register a new file reader.\"\"\"\n    reader = reader_class()\n    _file_readers.append(reader)\n    logger.debug(f\"Registered new file reader: {reader_class.__name__}\")\n</code></pre>"},{"location":"en/api/io/#wav-file-io","title":"WAV File IO","text":"<p>Provides functions for reading and writing WAV files.</p>"},{"location":"en/api/io/#wandas.io.wav_io.read_wav--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the audio data.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wav_io.py</code> <pre><code>def read_wav(filename: str, labels: list[str] | None = None) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Read a WAV file and create a ChannelFrame object.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file or URL to the WAV file.\n    labels : list of str, optional\n        Labels for each channel.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the audio data.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304cURL\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\n    if filename.startswith(\"http://\") or filename.startswith(\"https://\"):\n        # URL\u306e\u5834\u5408\u3001requests\u3092\u4f7f\u7528\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n        response = requests.get(filename)\n        file_obj = io.BytesIO(response.content)\n        file_label = os.path.basename(filename)\n        # \u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u306f\u4f7f\u7528\u305b\u305a\u306b\u8aad\u307f\u8fbc\u3080\n        sampling_rate, data = wavfile.read(file_obj)\n    else:\n        # \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u5834\u5408\n        file_label = os.path.basename(filename)\n        # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\uff08\u30e1\u30e2\u30ea\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4f7f\u7528\uff09\n        sampling_rate, data = wavfile.read(filename, mmap=True)\n\n    # \u30c7\u30fc\u30bf\u3092(num_channels, num_samples)\u5f62\u72b6\u306eNumPy\u914d\u5217\u306b\u5909\u63db\n    if data.ndim == 1:\n        # \u30e2\u30ce\u30e9\u30eb\uff1a(samples,) -&gt; (1, samples)\n        data = np.expand_dims(data, axis=0)\n    else:\n        # \u30b9\u30c6\u30ec\u30aa\uff1a(samples, channels) -&gt; (channels, samples)\n        data = data.T\n\n    # NumPy\u914d\u5217\u304b\u3089ChannelFrame\u3092\u4f5c\u6210\n    channel_frame = ChannelFrame.from_numpy(\n        data=data,\n        sampling_rate=sampling_rate,\n        label=file_label,\n        ch_labels=labels,\n    )\n\n    return channel_frame\n</code></pre>"},{"location":"en/api/io/#wandas.io.wav_io.write_wav--raises","title":"Raises","text":"<p>ValueError     If target is not a ChannelFrame object.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wav_io.py</code> <pre><code>def write_wav(filename: str, target: \"ChannelFrame\", format: str | None = None) -&gt; None:\n    \"\"\"\n    Write a ChannelFrame object to a WAV file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to the WAV file.\n    target : ChannelFrame\n        ChannelFrame object containing the data to write.\n    format : str, optional\n        File format. If None, determined from file extension.\n\n    Raises\n    ------\n    ValueError\n        If target is not a ChannelFrame object.\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    if not isinstance(target, ChannelFrame):\n        raise ValueError(\"target must be a ChannelFrame object.\")\n\n    logger.debug(f\"Saving audio data to file: {filename} (will compute now)\")\n    data = target.compute()\n    data = data.T\n    if data.shape[1] == 1:\n        data = data.squeeze(axis=1)\n    if data.dtype == float and max([np.abs(data.max()), np.abs(data.min())]) &lt; 1:\n        sf.write(\n            str(filename),\n            data,\n            int(target.sampling_rate),\n            subtype=\"FLOAT\",\n            format=format,\n        )\n    else:\n        sf.write(str(filename), data, int(target.sampling_rate), format=format)\n    logger.debug(f\"Save complete: {filename}\")\n</code></pre>"},{"location":"en/api/io/#wdf-file-io","title":"WDF File IO","text":"<p>Provides functions for reading and writing WDF (Wandas Data File) format, which enables complete preservation including metadata.</p>"},{"location":"en/api/io/#wandas.io.wdf_io.save","title":"<code>save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> \u5fc5\u9808 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"en/api/io/#wandas.io.wdf_io.load","title":"<code>load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"en/api/processing/","title":"Processing Module","text":"<p>The <code>wandas.processing</code> module provides various processing capabilities for audio data.</p>"},{"location":"en/api/processing/#base-processing","title":"Base Processing","text":"<p>Provides basic processing operations.</p>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) pure : bool, default=True     Whether the operation is pure (deterministic with no side effects).     When True, Dask can cache results for identical inputs.     Set to False only if the operation has side effects or is non-deterministic. **params : Any     Operation-specific parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def __init__(self, sampling_rate: float, *, pure: bool = True, **params: Any):\n    \"\"\"\n    Initialize AudioOperation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    pure : bool, default=True\n        Whether the operation is pure (deterministic with no side effects).\n        When True, Dask can cache results for identical inputs.\n        Set to False only if the operation has side effects or is non-deterministic.\n    **params : Any\n        Operation-specific parameters\n    \"\"\"\n    self.sampling_rate = sampling_rate\n    self.pure = pure\n    self.params = params\n\n    # Validate parameters during initialization\n    self.validate_params()\n\n    # Create processor function (lazy initialization possible)\n    self._setup_processor()\n\n    logger.debug(\n        f\"Initialized {self.__class__.__name__} operation with params: {params}\"\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters (raises exception if invalid)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters (raises exception if invalid)\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.get_metadata_updates--notes","title":"Notes","text":"<p>This method is called by the framework after processing to update the frame metadata. Subclasses should override this method if they need to update metadata (e.g., changing sampling rate).</p> <p>Design principle: Operations should use parameters provided at initialization (via init). All necessary information should be available as instance variables.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Get metadata updates to apply after processing.\n\n    This method allows operations to specify how metadata should be\n    updated after processing. By default, no metadata is updated.\n\n    Returns\n    -------\n    dict\n        Dictionary of metadata updates. Can include:\n        - 'sampling_rate': New sampling rate (float)\n        - Other metadata keys as needed\n\n    Examples\n    --------\n    Return empty dict for operations that don't change metadata:\n\n    &gt;&gt;&gt; return {}\n\n    Return new sampling rate for operations that resample:\n\n    &gt;&gt;&gt; return {\"sampling_rate\": self.target_sr}\n\n    Notes\n    -----\n    This method is called by the framework after processing to update\n    the frame metadata. Subclasses should override this method if they\n    need to update metadata (e.g., changing sampling rate).\n\n    Design principle: Operations should use parameters provided at\n    initialization (via __init__). All necessary information should be\n    available as instance variables.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.get_display_name--notes","title":"Notes","text":"<p>Subclasses can override this method to provide operation-specific display names that include parameter information, making labels more informative.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_display_name(self) -&gt; str | None:\n    \"\"\"\n    Get display name for the operation for use in channel labels.\n\n    This method allows operations to customize how they appear in\n    channel labels. By default, returns None, which means the\n    operation name will be used.\n\n    Returns\n    -------\n    str or None\n        Display name for the operation. If None, the operation name\n        (from the `name` class variable) is used.\n\n    Examples\n    --------\n    Default behavior (returns None, uses operation name):\n\n    &gt;&gt;&gt; class NormalizeOp(AudioOperation):\n    ...     name = \"normalize\"\n    &gt;&gt;&gt; op = NormalizeOp(44100)\n    &gt;&gt;&gt; op.get_display_name()  # Returns None\n    &gt;&gt;&gt; # Channel label: \"normalize(ch0)\"\n\n    Custom display name:\n\n    &gt;&gt;&gt; class LowPassFilter(AudioOperation):\n    ...     name = \"lowpass_filter\"\n    ...\n    ...     def __init__(self, sr, cutoff):\n    ...         self.cutoff = cutoff\n    ...         super().__init__(sr, cutoff=cutoff)\n    ...\n    ...     def get_display_name(self):\n    ...         return f\"lpf_{self.cutoff}Hz\"\n    &gt;&gt;&gt; op = LowPassFilter(44100, cutoff=1000)\n    &gt;&gt;&gt; op.get_display_name()  # Returns \"lpf_1000Hz\"\n    &gt;&gt;&gt; # Channel label: \"lpf_1000Hz(ch0)\"\n\n    Notes\n    -----\n    Subclasses can override this method to provide operation-specific\n    display names that include parameter information, making labels\n    more informative.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.process_array--returns","title":"Returns","text":"<p>dask.delayed.Delayed     A Delayed object representing the computation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def process_array(self, x: InputArrayType) -&gt; Any:\n    \"\"\"\n    Processing function wrapped with @dask.delayed.\n\n    This method returns a Delayed object that can be computed later.\n    The operation name is used in the Dask task graph for better visualization.\n\n    Parameters\n    ----------\n    x : InputArrayType\n        Input array to process.\n\n    Returns\n    -------\n    dask.delayed.Delayed\n        A Delayed object representing the computation.\n    \"\"\"\n    logger.debug(f\"Creating delayed operation on data with shape: {x.shape}\")\n    # Create wrapper with operation name and wrap it with dask.delayed\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    return delayed_func(x)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.calculate_output_shape--notes","title":"Notes","text":"<p>The default implementation creates a minimal test array and processes it to determine output shape. For performance-critical code, subclasses should override this method with a direct calculation.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation.\n\n    This method can be overridden by subclasses for efficiency.\n    If not overridden, it will execute _process_array on a small test array\n    to determine the output shape.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n\n    Notes\n    -----\n    The default implementation creates a minimal test array and processes it\n    to determine output shape. For performance-critical code, subclasses should\n    override this method with a direct calculation.\n    \"\"\"\n    # Try to infer shape by executing _process_array on test data\n    import numpy as np\n\n    try:\n        # Create minimal test array with input shape\n        if len(input_shape) == 0:\n            return input_shape\n\n        # Create test input with correct dtype\n        # Try complex first, fall back to float if needed\n        test_input: Any = np.zeros(input_shape, dtype=np.complex128)\n\n        # Process test input\n        test_output: Any = self._process_array(test_input)\n\n        # Return the shape of the output\n        if isinstance(test_output, np.ndarray):\n            return tuple(int(s) for s in test_output.shape)\n        return input_shape\n    except Exception as e:\n        logger.warning(\n            f\"Failed to infer output shape for {self.__class__.__name__}: {e}. \"\n            \"Please implement calculate_output_shape method.\"\n        )\n        raise NotImplementedError(\n            f\"Subclass {self.__class__.__name__} must implement \"\n            f\"calculate_output_shape or ensure _process_array can be \"\n            f\"called with test data.\"\n        ) from e\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.AudioOperation.process","title":"<code>process(data)</code>","text":"<p>Execute operation and return result data shape is (channels, samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    \"\"\"\n    Execute operation and return result\n    data shape is (channels, samples)\n    \"\"\"\n    # Add task as delayed processing with custom name for visualization\n    logger.debug(\"Adding delayed operation to computation graph\")\n\n    # Create a wrapper function with the operation name\n    # This allows Dask to use the operation name in the task graph\n    wrapper = self._create_named_wrapper()\n    delayed_func = delayed(wrapper, pure=self.pure)\n    delayed_result = delayed_func(data)\n\n    # Convert delayed result to dask array and return\n    output_shape = self.calculate_output_shape(data.shape)\n    return _da_from_delayed(delayed_result, shape=output_shape, dtype=data.dtype)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.register_operation","title":"<code>register_operation(operation_class)</code>","text":"<p>Register a new operation type</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def register_operation(operation_class: type) -&gt; None:\n    \"\"\"Register a new operation type\"\"\"\n\n    if not issubclass(operation_class, AudioOperation):\n        raise TypeError(\"Strategy class must inherit from AudioOperation.\")\n    if inspect.isabstract(operation_class):\n        raise TypeError(\"Cannot register abstract AudioOperation class.\")\n\n    _OPERATION_REGISTRY[operation_class.name] = operation_class\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.get_operation","title":"<code>get_operation(name)</code>","text":"<p>Get operation class by name</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def get_operation(name: str) -&gt; type[AudioOperation[Any, Any]]:\n    \"\"\"Get operation class by name\"\"\"\n    if name not in _OPERATION_REGISTRY:\n        raise ValueError(f\"Unknown operation type: {name}\")\n    return _OPERATION_REGISTRY[name]\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.base.create_operation","title":"<code>create_operation(name, sampling_rate, **params)</code>","text":"<p>Create operation instance from name and parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/base.py</code> <pre><code>def create_operation(\n    name: str, sampling_rate: float, **params: Any\n) -&gt; AudioOperation[Any, Any]:\n    \"\"\"Create operation instance from name and parameters\"\"\"\n    operation_class = get_operation(name)\n    return operation_class(sampling_rate, **params)\n</code></pre>"},{"location":"en/api/processing/#effects","title":"Effects","text":"<p>Provides audio effect processing.</p>"},{"location":"en/api/processing/#wandas.processing.effects.HpssHarmonic.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Harmonic\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.HpssHarmonic.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.HpssHarmonic.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Hrm\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.HpssPercussive.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    **kwargs: Any,\n):\n    \"\"\"\n    Initialize HPSS Percussive\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    self.kwargs = kwargs\n    super().__init__(sampling_rate, **kwargs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.HpssPercussive.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.HpssPercussive.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Prc\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Normalize.__init__--raises","title":"Raises","text":"<p>ValueError     If norm parameter is invalid or threshold is negative</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    norm: float | None = np.inf,\n    axis: int | None = -1,\n    threshold: float | None = None,\n    fill: bool | None = None,\n):\n    \"\"\"\n    Initialize normalization operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    norm : float or np.inf, default=np.inf\n        Norm type. Supported values:\n        - np.inf: Maximum absolute value normalization\n        - -np.inf: Minimum absolute value normalization\n        - 0: Pseudo L0 normalization (divide by number of non-zero elements)\n        - float: Lp norm\n        - None: No normalization\n    axis : int or None, default=-1\n        Axis along which to normalize.\n        - -1: Normalize along time axis (each channel independently)\n        - None: Global normalization across all axes\n        - int: Normalize along specified axis\n    threshold : float or None, optional\n        Threshold below which values are considered zero.\n        If None, no threshold is applied.\n    fill : bool or None, optional\n        Value to fill when the norm is zero.\n        If None, the zero vector remains zero.\n\n    Raises\n    ------\n    ValueError\n        If norm parameter is invalid or threshold is negative\n    \"\"\"\n    # Validate norm parameter\n    if norm is not None and not isinstance(norm, int | float):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {type(norm).__name__} ({norm})\\n\"\n            f\"  Expected: float, int, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be a numeric value or None.\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate that norm is non-negative (except for -np.inf which is valid)\n    if norm is not None and norm &lt; 0 and not np.isneginf(norm):\n        raise ValueError(\n            f\"Invalid normalization method\\n\"\n            f\"  Got: {norm}\\n\"\n            f\"  Expected: Non-negative value, np.inf, -np.inf, or None\\n\"\n            f\"Norm parameter must be non-negative (except -np.inf for min norm).\\n\"\n            f\"Common values: np.inf (max norm), 2 (L2 norm),\\n\"\n            f\"1 (L1 norm), 0 (pseudo L0)\"\n        )\n\n    # Validate threshold\n    if threshold is not None and threshold &lt; 0:\n        raise ValueError(\n            f\"Invalid threshold for normalization\\n\"\n            f\"  Got: {threshold}\\n\"\n            f\"  Expected: Non-negative value or None\\n\"\n            f\"Threshold must be non-negative.\\n\"\n            f\"Typical values: 0.0 (no threshold), 1e-10 (small threshold)\"\n        )\n\n    super().__init__(\n        sampling_rate, norm=norm, axis=axis, threshold=threshold, fill=fill\n    )\n    self.norm = norm\n    self.axis = axis\n    self.threshold = threshold\n    self.fill = fill\n    logger.debug(\n        f\"Initialized Normalize operation with norm={norm}, \"\n        f\"axis={axis}, threshold={threshold}, fill={fill}\"\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Normalize.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Normalize.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"norm\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.RemoveDC.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"Initialize DC removal operation.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n    logger.debug(\"Initialized RemoveDC operation\")\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.RemoveDC.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"Calculate output data shape after operation.\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.RemoveDC.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"dcRM\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.AddWithSNR.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other : DaArray     Noise signal to add (channel-frame format) snr : float     Signal-to-noise ratio (dB)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, other: DaArray, snr: float = 1.0):\n    \"\"\"\n    Initialize addition operation considering SNR\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other : DaArray\n        Noise signal to add (channel-frame format)\n    snr : float\n        Signal-to-noise ratio (dB)\n    \"\"\"\n    super().__init__(sampling_rate, other=other, snr=snr)\n\n    self.other = other\n    self.snr = snr\n    logger.debug(f\"Initialized AddWithSNR operation with SNR: {snr} dB\")\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.AddWithSNR.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (same as input)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape (same as input)\n    \"\"\"\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.AddWithSNR.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"+SNR\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Fade.__init__","title":"<code>__init__(sampling_rate, fade_ms=50)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def __init__(self, sampling_rate: float, fade_ms: float = 50) -&gt; None:\n    self.fade_ms = float(fade_ms)\n    # Precompute fade length in samples at construction time\n    self.fade_len = int(round(self.fade_ms * float(sampling_rate) / 1000.0))\n    super().__init__(sampling_rate, fade_ms=fade_ms)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Fade.validate_params","title":"<code>validate_params()</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def validate_params(self) -&gt; None:\n    if self.fade_ms &lt; 0:\n        raise ValueError(\"fade_ms must be non-negative\")\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Fade.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Fade.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fade\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.effects.Fade.calculate_tukey_alpha--examples","title":"Examples","text":"<p>Fade.calculate_tukey_alpha(fade_len=20, n_samples=200) 0.2 Fade.calculate_tukey_alpha(fade_len=100, n_samples=100) 1.0</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/effects.py</code> <pre><code>@staticmethod\ndef calculate_tukey_alpha(fade_len: int, n_samples: int) -&gt; float:\n    \"\"\"Calculate Tukey window alpha parameter from fade length.\n\n    The alpha parameter determines what fraction of the window is tapered.\n    For symmetric fade-in/fade-out, alpha = 2 * fade_len / n_samples ensures\n    that each side's taper has exactly fade_len samples.\n\n    Parameters\n    ----------\n    fade_len : int\n        Desired fade length in samples for each end (in and out).\n    n_samples : int\n        Total number of samples in the signal.\n\n    Returns\n    -------\n    float\n        Alpha parameter for scipy.signal.windows.tukey, clamped to [0, 1].\n\n    Examples\n    --------\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=20, n_samples=200)\n    0.2\n    &gt;&gt;&gt; Fade.calculate_tukey_alpha(fade_len=100, n_samples=100)\n    1.0\n    \"\"\"\n    alpha = float(2 * fade_len) / float(n_samples)\n    return min(1.0, alpha)\n</code></pre>"},{"location":"en/api/processing/#filters","title":"Filters","text":"<p>Provides various audio filter processing.</p>"},{"location":"en/api/processing/#wandas.processing.filters.HighPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize high-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.HighPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.HighPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.HighPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"hpf\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.LowPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float, cutoff: float, order: int = 4):\n    \"\"\"\n    Initialize low-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    cutoff : float\n        Cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        (sampling_rate / 2).\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist)\n    \"\"\"\n    self.cutoff = cutoff\n    self.order = order\n    super().__init__(sampling_rate, cutoff=cutoff, order=order)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.LowPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.cutoff &lt;= 0 or self.cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Solutions:\\n\"\n            f\"  - Use a cutoff frequency below {nyquist} Hz\\n\"\n            f\"  - Or increase sampling rate above {self.cutoff * 2} Hz\\n\"\n            f\"    using resample()\"\n        )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.LowPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.LowPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"lpf\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.BandPassFilter.__init__--raises","title":"Raises","text":"<p>ValueError     If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),     or if low_cutoff &gt;= high_cutoff</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    low_cutoff: float,\n    high_cutoff: float,\n    order: int = 4,\n):\n    \"\"\"\n    Initialize band-pass filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    low_cutoff : float\n        Lower cutoff frequency (Hz). Must be between 0 and Nyquist frequency.\n    high_cutoff : float\n        Higher cutoff frequency (Hz). Must be between 0 and Nyquist frequency\n        and greater than low_cutoff.\n    order : int, optional\n        Filter order, default is 4\n\n    Raises\n    ------\n    ValueError\n        If either cutoff frequency is not within valid range (0 &lt; cutoff &lt; Nyquist),\n        or if low_cutoff &gt;= high_cutoff\n    \"\"\"\n    self.low_cutoff = low_cutoff\n    self.high_cutoff = high_cutoff\n    self.order = order\n    super().__init__(\n        sampling_rate, low_cutoff=low_cutoff, high_cutoff=high_cutoff, order=order\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.BandPassFilter.validate_params","title":"<code>validate_params()</code>","text":"<p>Validate parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def validate_params(self) -&gt; None:\n    \"\"\"Validate parameters\"\"\"\n    nyquist = self.sampling_rate / 2\n    if self.low_cutoff &lt;= 0 or self.low_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Lower cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.low_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a lower cutoff frequency below {nyquist} Hz\"\n        )\n    if self.high_cutoff &lt;= 0 or self.high_cutoff &gt;= nyquist:\n        raise ValueError(\n            f\"Higher cutoff frequency out of valid range\\n\"\n            f\"  Got: {self.high_cutoff} Hz\\n\"\n            f\"  Valid range: 0 &lt; cutoff &lt; {nyquist} Hz (Nyquist frequency)\\n\"\n            f\"The Nyquist frequency is half the sampling rate\\n\"\n            f\"  ({self.sampling_rate} Hz).\\n\"\n            f\"Filters cannot work above this limit due to aliasing.\\n\"\n            f\"Use a cutoff frequency below {nyquist} Hz\"\n        )\n    if self.low_cutoff &gt;= self.high_cutoff:\n        raise ValueError(\n            f\"Invalid bandpass filter cutoff frequencies\\n\"\n            f\"  Lower cutoff: {self.low_cutoff} Hz\\n\"\n            f\"  Higher cutoff: {self.high_cutoff} Hz\\n\"\n            f\"  Problem: Lower cutoff must be less than higher cutoff\\n\"\n            f\"A bandpass filter passes frequencies between low and high\\n\"\n            f\"  cutoffs.\\n\"\n            f\"Ensure low_cutoff &lt; high_cutoff\\n\"\n            f\"  (e.g., low_cutoff=100, high_cutoff=1000)\"\n        )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.BandPassFilter.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.BandPassFilter.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"bpf\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.AWeighting.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize A-weighting filter\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.AWeighting.calculate_output_shape","title":"<code>calculate_output_shape(input_shape)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    return input_shape\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.filters.AWeighting.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/filters.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Aw\"\n</code></pre>"},{"location":"en/api/processing/#spectral-processing","title":"Spectral Processing","text":"<p>Provides spectral analysis and processing capabilities.</p>"},{"location":"en/api/processing/#wandas.processing.spectral.FFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not a positive integer</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize FFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is None (determined by input size)\n    window : str, optional\n        Window function type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not a positive integer\n    \"\"\"\n    # Validate n_fft parameter\n    if n_fft is not None and n_fft &lt;= 0:\n        raise ValueError(\n            f\"Invalid FFT size\\n\"\n            f\"  Got: {n_fft}\\n\"\n            f\"  Expected: Positive integer &gt; 0\\n\"\n            f\"FFT size must be a positive integer.\\n\"\n            f\"Common values: 512, 1024, 2048, 4096,\\n\"\n            f\"8192 (powers of 2 are most efficient)\"\n        )\n\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.FFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    \u64cd\u4f5c\u5f8c\u306e\u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6\u3092\u8a08\u7b97\u3057\u307e\u3059\n\n    Parameters\n    ----------\n    input_shape : tuple\n        \u5165\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, samples)\n\n    Returns\n    -------\n    tuple\n        \u51fa\u529b\u30c7\u30fc\u30bf\u306e\u5f62\u72b6 (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1 if self.n_fft else input_shape[-1] // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.FFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"FFT\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.IFFT.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) n_fft : Optional[int], optional     IFFT size, default is None (determined based on input size) window : str, optional     Window function type, default is 'hann'</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self, sampling_rate: float, n_fft: int | None = None, window: str = \"hann\"\n):\n    \"\"\"\n    Initialize IFFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : Optional[int], optional\n        IFFT size, default is None (determined based on input size)\n    window : str, optional\n        Window function type, default is 'hann'\n    \"\"\"\n    self.n_fft = n_fft\n    self.window = window\n    super().__init__(sampling_rate, n_fft=n_fft, window=window)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.IFFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, samples)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, freqs)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, samples)\n    \"\"\"\n    n_samples = 2 * (input_shape[-1] - 1) if self.n_fft is None else self.n_fft\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.IFFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iFFT\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.STFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n):\n    \"\"\"\n    Initialize STFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"STFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",\n    )\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.STFT.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    n_samples = input_shape[-1]\n    n_f = len(self.SFT.f)\n    n_t = len(self.SFT.t(n_samples))\n    return (input_shape[0], n_f, n_t)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.STFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"STFT\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.ISTFT.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    length: int | None = None,\n):\n    \"\"\"\n    Initialize ISTFT operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window type, default is 'hann'\n    length : int, optional\n        Length of output signal. Default is None (determined from input)\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"ISTFT\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.length = length\n\n    # Instantiate ShortTimeFFT for ISTFT calculation\n    self.SFT = ShortTimeFFT(\n        win=get_window(window, self.win_length),\n        hop=self.hop_length,\n        fs=sampling_rate,\n        mfft=self.n_fft,\n        scale_to=\"magnitude\",  # Consistent scaling with STFT\n    )\n\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        length=length,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.ISTFT.calculate_output_shape--references","title":"References","text":"<ul> <li>SciPy ShortTimeFFT.istft:   https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html</li> <li>SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after ISTFT operation.\n\n    Uses the SciPy ShortTimeFFT calculation formula to compute the expected\n    output length based on the input spectrogram dimensions and output range\n    parameters (k0, k1).\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input spectrogram shape (channels, n_freqs, n_frames)\n        where n_freqs = n_fft // 2 + 1 and n_frames is the number of time frames.\n\n    Returns\n    -------\n    tuple\n        Output shape (channels, output_samples) where output_samples is the\n        reconstructed signal length determined by the output range [k0, k1).\n\n    Notes\n    -----\n    The calculation follows SciPy's ShortTimeFFT.istft() implementation.\n    When k1 is None (default), the maximum reconstructible signal length is\n    computed as:\n\n    .. math::\n\n        q_{max} = n_{frames} + p_{min}\n\n        k_{max} = (q_{max} - 1) \\\\cdot hop + m_{num} - m_{num\\\\_mid}\n\n    The output length is then:\n\n    .. math::\n\n        output\\\\_samples = k_1 - k_0\n\n    where k0 defaults to 0 and k1 defaults to k_max.\n\n    Parameters that affect the calculation:\n    - n_frames: number of time frames in the STFT\n    - p_min: minimum frame index (ShortTimeFFT property)\n    - hop: hop length (samples between frames)\n    - m_num: window length\n    - m_num_mid: window midpoint position\n    - self.length: optional length override (if set, limits output)\n\n    References\n    ----------\n    - SciPy ShortTimeFFT.istft:\n      https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ShortTimeFFT.istft.html\n    - SciPy Source: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    \"\"\"\n    n_channels = input_shape[0]\n    n_frames = input_shape[-1]  # time_frames\n\n    # SciPy ShortTimeFFT \u306e\u8a08\u7b97\u5f0f\u306b\u5f93\u3046\n    # See: https://github.com/scipy/scipy/blob/main/scipy/signal/_short_time_fft.py\n    q_max = n_frames + self.SFT.p_min\n    k_max = (q_max - 1) * self.SFT.hop + self.SFT.m_num - self.SFT.m_num_mid\n\n    # Default parameters: k0=0, k1=None (which becomes k_max)\n    # The output length is k1 - k0 = k_max - 0 = k_max\n    k0 = 0\n    k1 = k_max\n\n    # If self.length is specified, it acts as an override to limit the output\n    if self.length is not None:\n        k1 = min(self.length, k1)\n\n    output_samples = k1 - k0\n\n    return (n_channels, output_samples)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.ISTFT.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"iSTFT\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.Welch.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft, win_length, or hop_length are invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    average: str = \"mean\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize Welch operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int, optional\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str, optional\n        Window function type, default is 'hann'\n    average : str, optional\n        Averaging method, default is 'mean'\n    detrend : str, optional\n        Detrend method, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft, win_length, or hop_length are invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Welch method\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.noverlap = (\n        self.win_length - self.hop_length if hop_length is not None else None\n    )\n    self.window = window\n    self.average = average\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        win_length=self.win_length,\n        hop_length=self.hop_length,\n        window=window,\n        average=average,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.Welch.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, freqs)\n    \"\"\"\n    n_freqs = self.n_fft // 2 + 1\n    return (*input_shape[:-1], n_freqs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.Welch.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"PS\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.NOctSpectrum.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize N-octave spectrum\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.NOctSpectrum.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.NOctSpectrum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Oct\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.NOctSynthesis.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) fmin : float     Minimum frequency (Hz) fmax : float     Maximum frequency (Hz) n : int, optional     Number of octave divisions, default is 3 G : int, optional     Reference level, default is 10 fr : int, optional     Reference frequency, default is 1000</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    fmin: float,\n    fmax: float,\n    n: int = 3,\n    G: int = 10,  # noqa: N803\n    fr: int = 1000,\n):\n    \"\"\"\n    Initialize octave synthesis\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    fmin : float\n        Minimum frequency (Hz)\n    fmax : float\n        Maximum frequency (Hz)\n    n : int, optional\n        Number of octave divisions, default is 3\n    G : int, optional\n        Reference level, default is 10\n    fr : int, optional\n        Reference frequency, default is 1000\n    \"\"\"\n    super().__init__(sampling_rate, fmin=fmin, fmax=fmax, n=n, G=G, fr=fr)\n\n    self.fmin = fmin\n    self.fmax = fmax\n    self.n = n\n    self.G = G\n    self.fr = fr\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.NOctSynthesis.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate output shape for octave spectrum\n    _, fpref = _center_freq(\n        fmin=self.fmin, fmax=self.fmax, n=self.n, G=self.G, fr=self.fr\n    )\n    return (input_shape[0], fpref.shape[0])\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.NOctSynthesis.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Octs\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.Coherence.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n):\n    \"\"\"\n    Initialize coherence estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Coherence\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.Coherence.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.Coherence.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"Coh\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.CSD.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize cross-spectral density estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"CSD\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.CSD.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.CSD.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"CSD\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.TransferFunction.__init__--raises","title":"Raises","text":"<p>ValueError     If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n    detrend: str = \"constant\",\n    scaling: str = \"spectrum\",\n    average: str = \"mean\",\n):\n    \"\"\"\n    Initialize transfer function estimation operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    n_fft : int\n        FFT size, default is 2048\n    hop_length : int, optional\n        Number of samples between frames. Default is win_length // 4\n    win_length : int, optional\n        Window length. Default is n_fft\n    window : str\n        Window function, default is 'hann'\n    detrend : str\n        Type of detrend, default is 'constant'\n    scaling : str\n        Type of scaling, default is 'spectrum'\n    average : str\n        Method of averaging, default is 'mean'\n\n    Raises\n    ------\n    ValueError\n        If n_fft is not positive, win_length &gt; n_fft, or hop_length is invalid\n    \"\"\"\n    # Validate and compute parameters\n    actual_win_length, actual_hop_length = _validate_spectral_params(\n        n_fft, win_length, hop_length, \"Transfer function\"\n    )\n\n    self.n_fft = n_fft\n    self.win_length = actual_win_length\n    self.hop_length = actual_hop_length\n    self.window = window\n    self.detrend = detrend\n    self.scaling = scaling\n    self.average = average\n    super().__init__(\n        sampling_rate,\n        n_fft=n_fft,\n        hop_length=self.hop_length,\n        win_length=self.win_length,\n        window=window,\n        detrend=detrend,\n        scaling=scaling,\n        average=average,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.TransferFunction.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels * channels, freqs)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels * channels, freqs)\n    \"\"\"\n    n_channels = input_shape[0]\n    n_freqs = self.n_fft // 2 + 1\n    return (n_channels * n_channels, n_freqs)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.spectral.TransferFunction.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/spectral.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"H\"\n</code></pre>"},{"location":"en/api/processing/#statistical-processing","title":"Statistical Processing","text":"<p>Provides statistical analysis functions for audio data.</p>"},{"location":"en/api/processing/#wandas.processing.stats.ABS.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float):\n    \"\"\"\n    Initialize absolute value operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    \"\"\"\n    super().__init__(sampling_rate)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.ABS.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"abs\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.ABS.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.abs(data)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Power.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) exponent : float     Power exponent</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, exponent: float):\n    \"\"\"\n    Initialize power operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    exponent : float\n        Power exponent\n    \"\"\"\n    super().__init__(sampling_rate)\n    self.exp = exponent\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Power.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"pow\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Power.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    return da.power(data, self.exp)  # type: ignore [unused-ignore]\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Sum.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"sum\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Sum.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.sum(axis=0, keepdims=True)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Mean.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"mean\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.Mean.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # Use Dask's aggregate function directly without map_blocks\n    return data.mean(axis=0, keepdims=True)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.ChannelDifference.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) other_channel : int     Channel to calculate difference with, default is 0</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def __init__(self, sampling_rate: float, other_channel: int = 0):\n    \"\"\"\n    Initialize channel difference calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    other_channel : int\n        Channel to calculate difference with, default is 0\n    \"\"\"\n    self.other_channel = other_channel\n    super().__init__(sampling_rate, other_channel=other_channel)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.ChannelDifference.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"diff\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.stats.ChannelDifference.process","title":"<code>process(data)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/stats.py</code> <pre><code>def process(self, data: DaArray) -&gt; DaArray:\n    # map_blocks\u3092\u4f7f\u308f\u305a\u3001\u76f4\u63a5Dask\u306e\u96c6\u7d04\u95a2\u6570\u3092\u4f7f\u7528\n    result = data - data[self.other_channel]\n    return result\n</code></pre>"},{"location":"en/api/processing/#temporal-processing","title":"Temporal Processing","text":"<p>Provides time-domain processing capabilities.</p>"},{"location":"en/api/processing/#wandas.processing.temporal.ReSampling.__init__--raises","title":"Raises","text":"<p>ValueError     If sampling_rate or target_sr is not positive</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(self, sampling_rate: float, target_sr: float):\n    \"\"\"\n    Initialize resampling operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    target_sampling_rate : float\n        Target sampling rate (Hz)\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate or target_sr is not positive\n    \"\"\"\n    validate_sampling_rate(sampling_rate, \"source sampling rate\")\n    validate_sampling_rate(target_sr, \"target sampling rate\")\n    super().__init__(sampling_rate, target_sr=target_sr)\n    self.target_sr = target_sr\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.ReSampling.get_metadata_updates--notes","title":"Notes","text":"<p>Resampling always produces output at target_sr, regardless of input sampling rate. All necessary parameters are provided at initialization.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate to target sampling rate.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate\n\n    Notes\n    -----\n    Resampling always produces output at target_sr, regardless of input\n    sampling rate. All necessary parameters are provided at initialization.\n    \"\"\"\n    return {\"sampling_rate\": self.target_sr}\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.ReSampling.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after resampling\n    ratio = float(self.target_sr) / float(self.sampling_rate)\n    n_samples = int(np.ceil(input_shape[-1] * ratio))\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.ReSampling.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"rs\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.Trim.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) start : float     Start time for trimming (seconds) end : float     End time for trimming (seconds)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    start: float,\n    end: float,\n):\n    \"\"\"\n    Initialize trimming operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    start : float\n        Start time for trimming (seconds)\n    end : float\n        End time for trimming (seconds)\n    \"\"\"\n    super().__init__(sampling_rate, start=start, end=end)\n    self.start = start\n    self.end = end\n    self.start_sample = int(start * sampling_rate)\n    self.end_sample = int(end * sampling_rate)\n    logger.debug(\n        f\"Initialized Trim operation with start: {self.start}, end: {self.end}\"\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.Trim.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    # Calculate length after trimming\n    # Exclude parts where there is no signal\n    end_sample = min(self.end_sample, input_shape[-1])\n    n_samples = end_sample - self.start_sample\n    return (*input_shape[:-1], n_samples)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.Trim.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"trim\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.FixLength.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) length : Optional[int]     Target length for fixing duration : Optional[float]     Target length for fixing</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    length: int | None = None,\n    duration: float | None = None,\n):\n    \"\"\"\n    Initialize fix length operation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    length : Optional[int]\n        Target length for fixing\n    duration : Optional[float]\n        Target length for fixing\n    \"\"\"\n    if length is None:\n        if duration is None:\n            raise ValueError(\"Either length or duration must be provided.\")\n        else:\n            length = int(duration * sampling_rate)\n    self.target_length = length\n\n    super().__init__(sampling_rate, target_length=self.target_length)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.FixLength.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape\n\n    Returns\n    -------\n    tuple\n        Output data shape\n    \"\"\"\n    return (*input_shape[:-1], self.target_length)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.FixLength.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"fix\"\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.RmsTrend.__init__--parameters","title":"Parameters","text":"<p>sampling_rate : float     Sampling rate (Hz) frame_length : int     Frame length, default is 2048 hop_length : int     Hop length, default is 512 ref : Union[list[float], float]     Reference value(s) for dB calculation dB : bool     Whether to convert to decibels Aw : bool     Whether to apply A-weighting before RMS calculation</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def __init__(\n    self,\n    sampling_rate: float,\n    frame_length: int = 2048,\n    hop_length: int = 512,\n    ref: list[float] | float = 1.0,\n    dB: bool = False,  # noqa: N803\n    Aw: bool = False,  # noqa: N803\n) -&gt; None:\n    \"\"\"\n    Initialize RMS calculation\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate (Hz)\n    frame_length : int\n        Frame length, default is 2048\n    hop_length : int\n        Hop length, default is 512\n    ref : Union[list[float], float]\n        Reference value(s) for dB calculation\n    dB : bool\n        Whether to convert to decibels\n    Aw : bool\n        Whether to apply A-weighting before RMS calculation\n    \"\"\"\n    self.frame_length = frame_length\n    self.hop_length = hop_length\n    self.dB = dB\n    self.Aw = Aw\n    self.ref = np.array(ref if isinstance(ref, list) else [ref])\n    super().__init__(\n        sampling_rate,\n        frame_length=frame_length,\n        hop_length=hop_length,\n        dB=dB,\n        Aw=Aw,\n        ref=self.ref,\n    )\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.RmsTrend.get_metadata_updates--notes","title":"Notes","text":"<p>The output sampling rate is determined by downsampling the input by hop_length. All necessary parameters are provided at initialization.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_metadata_updates(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Update sampling rate based on hop length.\n\n    Returns\n    -------\n    dict\n        Metadata updates with new sampling rate based on hop length\n\n    Notes\n    -----\n    The output sampling rate is determined by downsampling the input\n    by hop_length. All necessary parameters are provided at initialization.\n    \"\"\"\n    new_sr = self.sampling_rate / self.hop_length\n    return {\"sampling_rate\": new_sr}\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.RmsTrend.calculate_output_shape--returns","title":"Returns","text":"<p>tuple     Output data shape (channels, frames)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def calculate_output_shape(self, input_shape: tuple[int, ...]) -&gt; tuple[int, ...]:\n    \"\"\"\n    Calculate output data shape after operation\n\n    Parameters\n    ----------\n    input_shape : tuple\n        Input data shape (channels, samples)\n\n    Returns\n    -------\n    tuple\n        Output data shape (channels, frames)\n    \"\"\"\n    n_frames = librosa.feature.rms(\n        y=np.ones((1, input_shape[-1])),\n        frame_length=self.frame_length,\n        hop_length=self.hop_length,\n    ).shape[-1]\n    return (*input_shape[:-1], n_frames)\n</code></pre>"},{"location":"en/api/processing/#wandas.processing.temporal.RmsTrend.get_display_name","title":"<code>get_display_name()</code>","text":"<p>Get display name for the operation for use in channel labels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/processing/temporal.py</code> <pre><code>def get_display_name(self) -&gt; str:\n    \"\"\"Get display name for the operation for use in channel labels.\"\"\"\n    return \"RMS\"\n</code></pre>"},{"location":"en/api/utils/","title":"Utilities Module","text":"<p>The <code>wandas.utils</code> module provides various utility functions used in the Wandas library.</p>"},{"location":"en/api/utils/#frame-dataset","title":"Frame Dataset","text":"<p>Provides dataset utilities for managing multiple data frames.</p>"},{"location":"en/api/utils/#overview","title":"Overview","text":"<p>The <code>FrameDataset</code> classes enable efficient batch processing of audio files in a folder. Key features include:</p> <ul> <li>Lazy Loading: Load files only when accessed, reducing memory usage</li> <li>Transformation Chaining: Apply multiple processing operations efficiently</li> <li>Sampling: Extract random subsets for testing or analysis</li> <li>Metadata Tracking: Keep track of dataset properties and processing history</li> </ul>"},{"location":"en/api/utils/#main-classes","title":"Main Classes","text":"<ul> <li><code>ChannelFrameDataset</code>: For time-domain audio data (WAV, MP3, FLAC, CSV files)</li> <li><code>SpectrogramFrameDataset</code>: For time-frequency domain data (typically created from STFT)</li> </ul>"},{"location":"en/api/utils/#basic-usage","title":"Basic Usage","text":"<pre><code>from wandas.utils.frame_dataset import ChannelFrameDataset\n\n# Create a dataset from a folder\ndataset = ChannelFrameDataset.from_folder(\n    folder_path=\"path/to/audio/files\",\n    sampling_rate=16000,  # Optional: resample all files to this rate\n    file_extensions=[\".wav\", \".mp3\"],  # File types to include\n    recursive=True,  # Search subdirectories\n    lazy_loading=True  # Load files on demand (recommended)\n)\n\n# Access individual files\nfirst_file = dataset[0]\nprint(f\"File: {first_file.label}\")\nprint(f\"Duration: {first_file.duration}s\")\n\n# Get dataset information\nmetadata = dataset.get_metadata()\nprint(f\"Total files: {metadata['file_count']}\")\nprint(f\"Loaded files: {metadata['loaded_count']}\")\n</code></pre>"},{"location":"en/api/utils/#sampling","title":"Sampling","text":"<p>Extract random subsets of the dataset for testing or analysis:</p> <pre><code># Sample by number of files\nsampled = dataset.sample(n=10, seed=42)\n\n# Sample by ratio\nsampled = dataset.sample(ratio=0.1, seed=42)\n\n# Default: 10% or minimum 1 file\nsampled = dataset.sample(seed=42)\n</code></pre>"},{"location":"en/api/utils/#transformations","title":"Transformations","text":"<p>Apply processing operations to all files in the dataset:</p> <pre><code># Built-in transformations\nresampled = dataset.resample(target_sr=8000)\ntrimmed = dataset.trim(start=0.5, end=2.0)\n\n# Chain multiple transformations\nprocessed = (\n    dataset\n    .resample(target_sr=8000)\n    .trim(start=0.5, end=2.0)\n)\n\n# Custom transformation\ndef custom_filter(frame):\n    return frame.low_pass_filter(cutoff=1000)\n\nfiltered = dataset.apply(custom_filter)\n</code></pre>"},{"location":"en/api/utils/#stft-spectrogram-generation","title":"STFT - Spectrogram Generation","text":"<p>Convert time-domain data to spectrograms:</p> <pre><code># Create spectrogram dataset\nspec_dataset = dataset.stft(\n    n_fft=2048,\n    hop_length=512,\n    window=\"hann\"\n)\n\n# Access a spectrogram\nspec_frame = spec_dataset[0]\nspec_frame.plot()\n</code></pre>"},{"location":"en/api/utils/#iteration","title":"Iteration","text":"<p>Process all files in the dataset:</p> <pre><code>for i in range(len(dataset)):\n    frame = dataset[i]\n    if frame is not None:\n        # Process the frame\n        print(f\"Processing {frame.label}...\")\n</code></pre>"},{"location":"en/api/utils/#key-parameters","title":"Key Parameters","text":"<p>folder_path (str): Path to the folder containing audio files</p> <p>sampling_rate (Optional[int]): Target sampling rate. Files will be resampled if different from this rate</p> <p>file_extensions (Optional[list[str]]): List of file extensions to include. Default: <code>[\".wav\", \".mp3\", \".flac\", \".csv\"]</code></p> <p>lazy_loading (bool): If True, files are loaded only when accessed. Default: True</p> <p>recursive (bool): If True, search subdirectories recursively. Default: False</p>"},{"location":"en/api/utils/#examples","title":"Examples","text":"<p>For detailed examples, see the FrameDataset Usage Guide notebook.</p>"},{"location":"en/api/utils/#api-reference","title":"API Reference","text":""},{"location":"en/api/utils/#wandas.utils.frame_dataset.LazyFrame","title":"<code>LazyFrame</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[F]</code></p> <p>A class that encapsulates a frame and its loading state.</p> <p>\u5c5e\u6027\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>file_path</code> <code>Path</code> <p>File path associated with the frame</p> <code>frame</code> <code>F | None</code> <p>Loaded frame object (None if not loaded)</p> <code>is_loaded</code> <code>bool</code> <p>Flag indicating if the frame is loaded</p> <code>load_attempted</code> <code>bool</code> <p>Flag indicating if loading was attempted (for error detection)</p> Source code in <code>wandas/utils/frame_dataset.py</code> <pre><code>@dataclass\nclass LazyFrame(Generic[F]):\n    \"\"\"\n    A class that encapsulates a frame and its loading state.\n\n    Attributes:\n        file_path: File path associated with the frame\n        frame: Loaded frame object (None if not loaded)\n        is_loaded: Flag indicating if the frame is loaded\n        load_attempted: Flag indicating if loading was attempted (for error detection)\n    \"\"\"\n\n    file_path: Path\n    frame: F | None = None\n    is_loaded: bool = False\n    load_attempted: bool = False\n\n    def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n        \"\"\"\n        Ensures the frame is loaded, loading it if necessary.\n\n        Args:\n            loader: Function to load a frame from a file path\n\n        Returns:\n            The loaded frame, or None if loading failed\n        \"\"\"\n        # Return the current frame if already loaded\n        if self.is_loaded:\n            return self.frame\n\n        # Attempt to load if not loaded yet\n        try:\n            self.load_attempted = True\n            self.frame = loader(self.file_path)\n            self.is_loaded = True\n            return self.frame\n        except Exception as e:\n            logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n            self.is_loaded = True  # Loading was attempted\n            self.frame = None\n            return None\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the frame state.\n        \"\"\"\n        self.frame = None\n        self.is_loaded = False\n        self.load_attempted = False\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.LazyFrame.ensure_loaded","title":"<code>ensure_loaded(loader)</code>","text":"<p>Ensures the frame is loaded, loading it if necessary.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>loader</code> <code>Callable[[Path], F | None]</code> <p>Function to load a frame from a file path</p> \u5fc5\u9808 <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>F | None</code> <p>The loaded frame, or None if loading failed</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def ensure_loaded(self, loader: Callable[[Path], F | None]) -&gt; F | None:\n    \"\"\"\n    Ensures the frame is loaded, loading it if necessary.\n\n    Args:\n        loader: Function to load a frame from a file path\n\n    Returns:\n        The loaded frame, or None if loading failed\n    \"\"\"\n    # Return the current frame if already loaded\n    if self.is_loaded:\n        return self.frame\n\n    # Attempt to load if not loaded yet\n    try:\n        self.load_attempted = True\n        self.frame = loader(self.file_path)\n        self.is_loaded = True\n        return self.frame\n    except Exception as e:\n        logger.error(f\"Failed to load file {self.file_path}: {str(e)}\")\n        self.is_loaded = True  # Loading was attempted\n        self.frame = None\n        return None\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.LazyFrame.reset","title":"<code>reset()</code>","text":"<p>Reset the frame state.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the frame state.\n    \"\"\"\n    self.frame = None\n    self.is_loaded = False\n    self.load_attempted = False\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.__init__","title":"<code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], F | None] | None = None,\n):\n    self.folder_path = Path(folder_path)\n    if source_dataset is None and not self.folder_path.exists():\n        raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n\n    self.sampling_rate = sampling_rate\n    self.signal_length = signal_length\n    self.file_extensions = file_extensions or [\".wav\"]\n    self._recursive = recursive\n    self._lazy_loading = lazy_loading\n\n    # Changed to a list of LazyFrame\n    self._lazy_frames: list[LazyFrame[F]] = []\n\n    self._source_dataset = source_dataset\n    self._transform = transform\n\n    if self._source_dataset:\n        self._initialize_from_source()\n    else:\n        self._initialize_from_folder()\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of files in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of files in the dataset.\"\"\"\n    return len(self._lazy_frames)\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.get_by_label--examples","title":"Examples","text":"<p>frame = dataset.get_by_label(\"sample_1.wav\") if frame: ...     print(frame.label)</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_by_label(self, label: str) -&gt; F | None:\n    \"\"\"\n    Get a frame by its label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    Optional[F]\n        The frame if found, otherwise None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset.get_by_label(\"sample_1.wav\")\n    &gt;&gt;&gt; if frame:\n    ...     print(frame.label)\n    \"\"\"\n    # Keep for backward compatibility: return the first match but emit\n    # a DeprecationWarning recommending `get_all_by_label`.\n    all_matches = self.get_all_by_label(label)\n    if len(all_matches) &gt; 0:\n        warnings.warn(\n            \"get_by_label() returns the first matching frame and is deprecated; \"\n            \"use get_all_by_label() to obtain all matches.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return all_matches[0]\n    return None\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.get_all_by_label--notes","title":"Notes","text":"<ul> <li>Search is performed against the filename portion only (i.e. Path.name).</li> <li>Each matched frame will be loaded (triggering lazy load) via <code>_ensure_loaded</code>.</li> </ul> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_all_by_label(self, label: str) -&gt; list[F]:\n    \"\"\"\n    Get all frames matching the given label (filename).\n\n    Parameters\n    ----------\n    label : str\n        The filename (label) to search for (e.g., 'sample_1.wav').\n\n    Returns\n    -------\n    list[F]\n        A list of frames matching the label.\n        If none are found, returns an empty list.\n\n    Notes\n    -----\n    - Search is performed against the filename portion only (i.e. Path.name).\n    - Each matched frame will be loaded (triggering lazy load) via `_ensure_loaded`.\n    \"\"\"\n    matches: list[F] = []\n    for i, lazy_frame in enumerate(self._lazy_frames):\n        if lazy_frame.file_path.name == label:\n            loaded = self._ensure_loaded(i)\n            if loaded is not None:\n                matches.append(loaded)\n    return matches\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.__getitem__--examples","title":"Examples","text":"<p>frame = dataset[0]  # by index frames = dataset[\"sample_1.wav\"]  # list of matches by filename</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __getitem__(self, key: int | str) -&gt; F | None | list[F]:\n    \"\"\"\n    Get the frame by index (int) or label (str).\n\n    Parameters\n    ----------\n    key : int or str\n        Index (int) or filename/label (str).\n\n    Returns\n    -------\n    Optional[F] or list[F]\n        If `key` is an int, returns the frame or None. If `key` is a str,\n        returns a list of matching frames (may be empty).\n\n    Examples\n    --------\n    &gt;&gt;&gt; frame = dataset[0]  # by index\n    &gt;&gt;&gt; frames = dataset[\"sample_1.wav\"]  # list of matches by filename\n    \"\"\"\n    if isinstance(key, int):\n        return self._ensure_loaded(key)\n    if isinstance(key, str):\n        # pandas-like behaviour: return all matches for the label as a list\n        return self.get_all_by_label(key)\n    raise TypeError(f\"Invalid key type: {type(key)}. Must be int or str.\")\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.apply","title":"<code>apply(func)</code>","text":"<pre><code>apply(func: Callable[[F], F_out | None]) -&gt; FrameDataset[F_out]\n</code></pre><pre><code>apply(func: Callable[[F], Any | None]) -&gt; FrameDataset[Any]\n</code></pre> <p>Apply a function to the entire dataset to create a new dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def apply(self, func: Callable[[F], Any | None]) -&gt; \"FrameDataset[Any]\":\n    \"\"\"Apply a function to the entire dataset to create a new dataset.\"\"\"\n    new_dataset = type(self)(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=func,\n        sampling_rate=self.sampling_rate,\n        signal_length=self.signal_length,\n        file_extensions=self.file_extensions,\n        recursive=self._recursive,\n    )\n    return cast(\"FrameDataset[Any]\", new_dataset)\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.save","title":"<code>save(output_folder, filename_prefix='')</code>","text":"<p>Save processed frames to files.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def save(self, output_folder: str, filename_prefix: str = \"\") -&gt; None:\n    \"\"\"Save processed frames to files.\"\"\"\n    raise NotImplementedError(\"The save method is not currently implemented.\")\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.sample","title":"<code>sample(n=None, ratio=None, seed=None)</code>","text":"<p>Get a sample from the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def sample(\n    self,\n    n: int | None = None,\n    ratio: float | None = None,\n    seed: int | None = None,\n) -&gt; \"FrameDataset[F]\":\n    \"\"\"Get a sample from the dataset.\"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    total = len(self._lazy_frames)\n    if total == 0:\n        return type(self)(\n            str(self.folder_path),\n            sampling_rate=self.sampling_rate,\n            signal_length=self.signal_length,\n            file_extensions=self.file_extensions,\n            lazy_loading=self._lazy_loading,\n            recursive=self._recursive,\n        )\n\n    # Determine sample size\n    if n is None and ratio is None:\n        n = max(1, min(10, int(total * 0.1)))\n    elif n is None and ratio is not None:\n        n = max(1, int(total * ratio))\n    elif n is not None:\n        n = max(1, n)\n    else:\n        n = 1\n\n    n = min(n, total)\n\n    # Randomly select indices\n    sampled_indices = sorted(random.sample(range(total), n))\n\n    return _SampledFrameDataset(self, sampled_indices)\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.FrameDataset.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Get metadata for the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def get_metadata(self) -&gt; dict[str, Any]:\n    \"\"\"Get metadata for the dataset.\"\"\"\n    actual_sr: int | float | None = self.sampling_rate\n    frame_type_name = \"Unknown\"\n\n    # Count loaded frames\n    loaded_count = sum(\n        1 for lazy_frame in self._lazy_frames if lazy_frame.is_loaded\n    )\n\n    # Get metadata from the first frame (if possible)\n    first_frame: F | None = None\n    if len(self._lazy_frames) &gt; 0:\n        try:\n            if self._lazy_frames[0].is_loaded:\n                first_frame = self._lazy_frames[0].frame\n\n            if first_frame:\n                actual_sr = getattr(\n                    first_frame, \"sampling_rate\", self.sampling_rate\n                )\n                frame_type_name = type(first_frame).__name__\n        except Exception as e:\n            logger.warning(\n                f\"Error accessing the first frame during metadata retrieval: {e}\"\n            )\n\n    return {\n        \"folder_path\": str(self.folder_path),\n        \"file_count\": len(self._lazy_frames),\n        \"loaded_count\": loaded_count,\n        \"target_sampling_rate\": self.sampling_rate,\n        \"actual_sampling_rate\": actual_sr,\n        \"signal_length\": self.signal_length,\n        \"file_extensions\": self.file_extensions,\n        \"lazy_loading\": self._lazy_loading,\n        \"recursive\": self._recursive,\n        \"frame_type\": frame_type_name,\n        \"has_transform\": self._transform is not None,\n        \"is_sampled\": isinstance(self, _SampledFrameDataset),\n    }\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.__init__","title":"<code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], ChannelFrame | None] | None = None,\n):\n    _file_extensions = file_extensions or [\n        \".wav\",\n        \".mp3\",\n        \".flac\",\n        \".csv\",\n    ]\n\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=_file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.resample","title":"<code>resample(target_sr)</code>","text":"<p>Resample all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def resample(self, target_sr: int) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Resample all frames in the dataset.\"\"\"\n\n    def _resample_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.resampling(target_sr=target_sr)\n        except Exception as e:\n            logger.warning(f\"Resampling error (target_sr={target_sr}): {e}\")\n            return None\n\n    new_dataset = self.apply(_resample_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.trim","title":"<code>trim(start, end)</code>","text":"<p>Trim all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def trim(self, start: float, end: float) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Trim all frames in the dataset.\"\"\"\n\n    def _trim_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.trim(start=start, end=end)\n        except Exception as e:\n            logger.warning(f\"Trimming error (start={start}, end={end}): {e}\")\n            return None\n\n    new_dataset = self.apply(_trim_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.normalize","title":"<code>normalize(**kwargs)</code>","text":"<p>Normalize all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def normalize(self, **kwargs: Any) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Normalize all frames in the dataset.\"\"\"\n\n    def _normalize_func(frame: ChannelFrame) -&gt; ChannelFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.normalize(**kwargs)\n        except Exception as e:\n            logger.warning(f\"Normalization error ({kwargs}): {e}\")\n            return None\n\n    new_dataset = self.apply(_normalize_func)\n    return cast(ChannelFrameDataset, new_dataset)\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.stft","title":"<code>stft(n_fft=2048, hop_length=None, win_length=None, window='hann')</code>","text":"<p>Apply STFT to all frames in the dataset.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def stft(\n    self,\n    n_fft: int = 2048,\n    hop_length: int | None = None,\n    win_length: int | None = None,\n    window: str = \"hann\",\n) -&gt; \"SpectrogramFrameDataset\":\n    \"\"\"Apply STFT to all frames in the dataset.\"\"\"\n    _hop = hop_length or n_fft // 4\n\n    def _stft_func(frame: ChannelFrame) -&gt; SpectrogramFrame | None:\n        if frame is None:\n            return None\n        try:\n            return frame.stft(\n                n_fft=n_fft,\n                hop_length=_hop,\n                win_length=win_length,\n                window=window,\n            )\n        except Exception as e:\n            logger.warning(f\"STFT error (n_fft={n_fft}, hop={_hop}): {e}\")\n            return None\n\n    new_dataset = SpectrogramFrameDataset(\n        folder_path=str(self.folder_path),\n        lazy_loading=True,\n        source_dataset=self,\n        transform=_stft_func,\n        sampling_rate=self.sampling_rate,\n    )\n    return new_dataset\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.ChannelFrameDataset.from_folder","title":"<code>from_folder(folder_path, sampling_rate=None, file_extensions=None, recursive=False, lazy_loading=True)</code>  <code>classmethod</code>","text":"<p>Class method to create a ChannelFrameDataset from a folder.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>@classmethod\ndef from_folder(\n    cls,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    file_extensions: list[str] | None = None,\n    recursive: bool = False,\n    lazy_loading: bool = True,\n) -&gt; \"ChannelFrameDataset\":\n    \"\"\"Class method to create a ChannelFrameDataset from a folder.\"\"\"\n    extensions = (\n        file_extensions\n        if file_extensions is not None\n        else [\".wav\", \".mp3\", \".flac\", \".csv\"]\n    )\n\n    return cls(\n        folder_path,\n        sampling_rate=sampling_rate,\n        file_extensions=extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n    )\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.SpectrogramFrameDataset.__init__","title":"<code>__init__(folder_path, sampling_rate=None, signal_length=None, file_extensions=None, lazy_loading=True, recursive=False, source_dataset=None, transform=None)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def __init__(\n    self,\n    folder_path: str,\n    sampling_rate: int | None = None,\n    signal_length: int | None = None,\n    file_extensions: list[str] | None = None,\n    lazy_loading: bool = True,\n    recursive: bool = False,\n    source_dataset: Optional[\"FrameDataset[Any]\"] = None,\n    transform: Callable[[Any], SpectrogramFrame | None] | None = None,\n):\n    super().__init__(\n        folder_path=folder_path,\n        sampling_rate=sampling_rate,\n        signal_length=signal_length,\n        file_extensions=file_extensions,\n        lazy_loading=lazy_loading,\n        recursive=recursive,\n        source_dataset=source_dataset,\n        transform=transform,\n    )\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.frame_dataset.SpectrogramFrameDataset.plot","title":"<code>plot(index, **kwargs)</code>","text":"<p>Plot the spectrogram at the specified index.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/frame_dataset.py</code> <pre><code>def plot(self, index: int, **kwargs: Any) -&gt; None:\n    \"\"\"Plot the spectrogram at the specified index.\"\"\"\n    try:\n        frame = self._ensure_loaded(index)\n\n        if frame is None:\n            logger.warning(\n                f\"Cannot plot index {index} as it failed to load/transform.\"\n            )\n            return\n\n        plot_method = getattr(frame, \"plot\", None)\n        if callable(plot_method):\n            plot_method(**kwargs)\n        else:\n            logger.warning(\n                f\"Frame (index {index}, type {type(frame).__name__}) does not \"\n                f\"have a plot method implemented.\"\n            )\n    except Exception as e:\n        logger.error(f\"An error occurred while plotting index {index}: {e}\")\n</code></pre>"},{"location":"en/api/utils/#sample-generation","title":"Sample Generation","text":"<p>Provides functions for generating sample data for testing.</p>"},{"location":"en/api/utils/#wandas.utils.generate_sample.generate_sin--returns","title":"Returns","text":"<p>ChannelFrame     ChannelFrame object containing the sine wave(s).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    # \u76f4\u63a5\u3001generate_sin_lazy\u95a2\u6570\u3092\u547c\u3073\u51fa\u3059\n    return generate_sin_lazy(\n        freqs=freqs, sampling_rate=sampling_rate, duration=duration, label=label\n    )\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.generate_sample.generate_sin_lazy--returns","title":"Returns","text":"<p>ChannelFrame     Lazy ChannelFrame object containing the sine wave(s).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/generate_sample.py</code> <pre><code>def generate_sin_lazy(\n    freqs: float | list[float] = 1000,\n    sampling_rate: int = 16000,\n    duration: float = 1.0,\n    label: str | None = None,\n) -&gt; \"ChannelFrame\":\n    \"\"\"\n    Generate sample sine wave signals using lazy computation.\n\n    Parameters\n    ----------\n    freqs : float or list of float, default=1000\n        Frequency of the sine wave(s) in Hz.\n        If multiple frequencies are specified, multiple channels will be created.\n    sampling_rate : int, default=16000\n        Sampling rate in Hz.\n    duration : float, default=1.0\n        Duration of the signal in seconds.\n    label : str, optional\n        Label for the entire signal.\n\n    Returns\n    -------\n    ChannelFrame\n        Lazy ChannelFrame object containing the sine wave(s).\n    \"\"\"\n    from wandas.frames.channel import ChannelFrame\n\n    label = label or \"Generated Sin\"\n    t = np.linspace(0, duration, int(sampling_rate * duration), endpoint=False)\n\n    _freqs: list[float]\n    if isinstance(freqs, float):\n        _freqs = [freqs]\n    elif isinstance(freqs, list):\n        _freqs = freqs\n    else:\n        raise ValueError(\"freqs must be a float or a list of floats.\")\n\n    channels = []\n    labels = []\n    for idx, freq in enumerate(_freqs):\n        data = np.sin(2 * np.pi * freq * t)\n        labels.append(f\"Channel {idx + 1}\")\n        channels.append(data)\n    return ChannelFrame.from_numpy(\n        data=np.array(channels),\n        label=label,\n        sampling_rate=sampling_rate,\n        ch_labels=labels,\n    )\n</code></pre>"},{"location":"en/api/utils/#type-definitions","title":"Type Definitions","text":"<p>Provides type definitions used in Wandas.</p>"},{"location":"en/api/utils/#general-utilities","title":"General Utilities","text":"<p>Provides other general utility functions.</p>"},{"location":"en/api/utils/#wandas.utils.util.validate_sampling_rate--examples","title":"Examples","text":"<p>validate_sampling_rate(44100)  # No error validate_sampling_rate(0)  # Raises ValueError validate_sampling_rate(-100)  # Raises ValueError</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def validate_sampling_rate(\n    sampling_rate: float, param_name: str = \"sampling_rate\"\n) -&gt; None:\n    \"\"\"\n    Validate that sampling rate is positive.\n\n    Parameters\n    ----------\n    sampling_rate : float\n        Sampling rate in Hz to validate.\n    param_name : str, default=\"sampling_rate\"\n        Name of the parameter being validated (for error messages).\n\n    Raises\n    ------\n    ValueError\n        If sampling_rate is not positive (i.e., &lt;= 0).\n\n    Examples\n    --------\n    &gt;&gt;&gt; validate_sampling_rate(44100)  # No error\n    &gt;&gt;&gt; validate_sampling_rate(0)  # Raises ValueError\n    &gt;&gt;&gt; validate_sampling_rate(-100)  # Raises ValueError\n    \"\"\"\n    if sampling_rate &lt;= 0:\n        raise ValueError(\n            f\"Invalid {param_name}\\n\"\n            f\"  Got: {sampling_rate} Hz\\n\"\n            f\"  Expected: Positive value &gt; 0\\n\"\n            f\"Sampling rate represents samples per second and must be positive.\\n\"\n            f\"Common values: 8000, 16000, 22050, 44100, 48000 Hz\"\n        )\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.util.unit_to_ref--returns","title":"Returns","text":"<p>float     Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).     For other units, returns 1.0.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def unit_to_ref(unit: str) -&gt; float:\n    \"\"\"\n    Convert unit to reference value.\n\n    Parameters\n    ----------\n    unit : str\n        Unit string.\n\n    Returns\n    -------\n    float\n        Reference value for the unit. For 'Pa', returns 2e-5 (20 \u03bcPa).\n        For other units, returns 1.0.\n    \"\"\"\n    if unit == \"Pa\":\n        return 2e-5\n\n    else:\n        return 1.0\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.util.calculate_rms--returns","title":"Returns","text":"<p>Union[float, NDArray[np.float64]]     RMS value(s). For multi-channel input, returns an array of RMS values,     one per channel. For single-channel input, returns a single RMS value.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def calculate_rms(wave: \"NDArrayReal\") -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the root mean square of the wave.\n\n    Parameters\n    ----------\n    wave : NDArrayReal\n        Input waveform data. Can be multi-channel (shape: [channels, samples])\n        or single channel (shape: [samples]).\n\n    Returns\n    -------\n    Union[float, NDArray[np.float64]]\n        RMS value(s). For multi-channel input, returns an array of RMS values,\n        one per channel. For single-channel input, returns a single RMS value.\n    \"\"\"\n    # Calculate RMS considering axis (over the last dimension)\n    axis_to_use = -1 if wave.ndim &gt; 1 else None\n    rms_values: NDArrayReal = np.sqrt(\n        np.mean(np.square(wave), axis=axis_to_use, keepdims=True)\n    )\n    return rms_values\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.util.calculate_desired_noise_rms--returns","title":"Returns","text":"<p>\"NDArrayReal\"     Desired noise RMS value(s) to achieve the target SNR.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def calculate_desired_noise_rms(clean_rms: \"NDArrayReal\", snr: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Calculate the desired noise RMS based on clean signal RMS and target SNR.\n\n    Parameters\n    ----------\n    clean_rms : \"NDArrayReal\"\n        RMS value(s) of the clean signal.\n        Can be a single value or an array for multi-channel.\n    snr : float\n        Target Signal-to-Noise Ratio in dB.\n\n    Returns\n    -------\n    \"NDArrayReal\"\n        Desired noise RMS value(s) to achieve the target SNR.\n    \"\"\"\n    a = snr / 20\n    noise_rms = clean_rms / (10**a)\n    return noise_rms\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.util.amplitude_to_db--returns","title":"Returns","text":"<p>NDArrayReal     Amplitude data converted to decibels.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def amplitude_to_db(amplitude: \"NDArrayReal\", ref: float) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Convert amplitude to decibel.\n\n    Parameters\n    ----------\n    amplitude : NDArrayReal\n        Input amplitude data.\n    ref : float\n        Reference value for conversion.\n\n    Returns\n    -------\n    NDArrayReal\n        Amplitude data converted to decibels.\n    \"\"\"\n    db: NDArrayReal = librosa.amplitude_to_db(\n        np.abs(amplitude), ref=ref, amin=1e-15, top_db=None\n    )\n    return db\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.util.level_trigger--returns","title":"Returns","text":"<p>list of int     List of sample indices where the signal crosses the level.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def level_trigger(\n    data: \"NDArrayReal\", level: float, offset: int = 0, hold: int = 1\n) -&gt; list[int]:\n    \"\"\"\n    Find points where the signal crosses the specified level from below.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    level : float\n        Threshold level for triggering.\n    offset : int, default=0\n        Offset to add to trigger points.\n    hold : int, default=1\n        Minimum number of samples between successive trigger points.\n\n    Returns\n    -------\n    list of int\n        List of sample indices where the signal crosses the level.\n    \"\"\"\n    trig_point: list[int] = []\n\n    sig_len = len(data)\n    diff = np.diff(np.sign(data - level))\n    level_point = np.where(diff &gt; 0)[0]\n    level_point = level_point[(level_point + hold) &lt; sig_len]\n\n    if len(level_point) == 0:\n        return list()\n\n    last_point = level_point[0]\n    trig_point.append(last_point + offset)\n    for i in level_point:\n        if (last_point + hold) &lt; i:\n            trig_point.append(i + offset)\n            last_point = i\n\n    return trig_point\n</code></pre>"},{"location":"en/api/utils/#wandas.utils.util.cut_sig--returns","title":"Returns","text":"<p>NDArrayReal     Array containing cut segments with shape (n_segments, cut_len).</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/utils/util.py</code> <pre><code>def cut_sig(\n    data: \"NDArrayReal\",\n    point_list: list[int],\n    cut_len: int,\n    taper_rate: float = 0,\n    dc_cut: bool = False,\n) -&gt; \"NDArrayReal\":\n    \"\"\"\n    Cut segments from signal at specified points.\n\n    Parameters\n    ----------\n    data : NDArrayReal\n        Input signal data.\n    point_list : list of int\n        List of starting points for cutting.\n    cut_len : int\n        Length of each segment to cut.\n    taper_rate : float, default=0\n        Taper rate for Tukey window applied to segments.\n        A value of 0 means no tapering, 1 means full tapering.\n    dc_cut : bool, default=False\n        Whether to remove DC component (mean) from segments.\n\n    Returns\n    -------\n    NDArrayReal\n        Array containing cut segments with shape (n_segments, cut_len).\n    \"\"\"\n    length = len(data)\n    point_list_ = [p for p in point_list if p &gt;= 0 and p + cut_len &lt;= length]\n    trial: NDArrayReal = np.zeros((len(point_list_), cut_len))\n\n    for i, v in enumerate(point_list_):\n        trial[i] = data[v : v + cut_len]\n        if dc_cut:\n            trial[i] = trial[i] - trial[i].mean()\n\n    win: NDArrayReal = tukey(cut_len, taper_rate).astype(trial.dtype)[np.newaxis, :]\n    trial = trial * win\n    return trial\n</code></pre>"},{"location":"en/api/visualization/","title":"Visualization Module","text":"<p>The <code>wandas.visualization</code> module provides functionality for visually representing audio data.</p>"},{"location":"en/api/visualization/#plotting","title":"Plotting","text":"<p>Provides plotting functions for visualizing audio data.</p>"},{"location":"en/api/visualization/#wandas.visualization.plotting.PlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax)</code>  <code>abstractmethod</code>","text":"<p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef channel_plot(self, x: Any, y: Any, ax: \"Axes\") -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.PlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Implementation of plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>@abc.abstractmethod\ndef plot(\n    self,\n    bf: TFrame,\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of plotting\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.set_ylabel(\"Amplitude\")\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.WaveformPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Waveform plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Waveform plotting\"\"\"\n    kwargs = kwargs or {}\n    ylabel = kwargs.pop(\"ylabel\", \"Amplitude\")\n    xlabel = kwargs.pop(\"xlabel\", \"Time [s]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(\n        Line2D,\n        kwargs,\n        strict_mode=True,\n    )\n    ax_set = filter_kwargs(\n        Axes.set,\n        kwargs,\n        strict_mode=True,\n    )\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    data = bf.data\n    data = _reshape_to_2d(data)\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(10, 4))\n\n        self.channel_plot(\n            bf.time, data.T, ax, label=bf.labels, alpha=alpha, **plot_kwargs\n        )\n        ax.set(\n            ylabel=ylabel,\n            title=title or bf.label or \"Channel Data\",\n            xlabel=xlabel,\n            **ax_set,\n        )\n        if ax is None:\n            fig.suptitle(title or bf.label or None)\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.time, channel_data, ax_i, alpha=alpha, **plot_kwargs\n            )\n            ax_i.set(\n                ylabel=ylabel + f\" [{ch_meta.unit}]\",\n                title=ch_meta.label,\n                **ax_set,\n            )\n\n        axes_list[-1].set(\n            xlabel=\"Time [s]\",\n        )\n        fig.suptitle(title or bf.label or \"Channel Data\")\n\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.FrequencyPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Frequency domain plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Frequency domain plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    data = _reshape_to_2d(data)\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=title or bf.label or \"Channel Data\",\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or \"Channel Data\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.NOctPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    ax.step(x, y, **kwargs)\n    ax.grid(True)\n    if \"label\" in kwargs:\n        ax.legend()\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.NOctPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>N-octave band analysis plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"NOctFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"N-octave band analysis plotting\"\"\"\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n\n    if is_aw:\n        unit = \"dBrA\"\n        data = bf.dBA\n    else:\n        unit = \"dBr\"\n        data = bf.dB\n    data = _reshape_to_2d(data)\n    ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n    xlabel = kwargs.pop(\"xlabel\", \"Center frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            _, ax = plt.subplots(figsize=(10, 4))\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,\n            label=bf.labels,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        default_title = f\"1/{str(bf.n)}-Octave Spectrum\"\n        actual_title = title if title else (bf.label or default_title)\n        ax.set(\n            ylabel=ylabel,\n            xlabel=xlabel,\n            title=actual_title,\n            **ax_set,\n        )\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 4 * num_channels), sharex=True\n        )\n        # Convert axs to list if it is a single Axes object\n        if not isinstance(axs, list | np.ndarray):\n            axs = [axs]\n\n        axes_list = list(axs)\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                label=ch_meta.label,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(\n                ylabel=ylabel,\n                title=ch_meta.label,\n                xlabel=xlabel,\n                **ax_set,\n            )\n        axes_list[-1].set(ylabel=ylabel, xlabel=xlabel)\n        fig.suptitle(title or bf.label or f\"1/{str(bf.n)}-Octave Spectrum\")\n        if ax is None:\n            plt.tight_layout()\n            plt.show()\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.SpectrogramPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Spectrogram plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectrogramFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Spectrogram plotting\"\"\"\n    # Explicit overlay mode is not supported for spectrograms\n    if overlay:\n        raise ValueError(\"Overlay is not supported for SpectrogramPlotStrategy.\")\n\n    # If an Axes is provided, allow drawing into it only for single-channel frames\n    if ax is not None and bf.n_channels &gt; 1:\n        raise ValueError(\"ax must be None when n_channels &gt; 1.\")\n\n    kwargs = kwargs or {}\n\n    is_aw = kwargs.pop(\"Aw\", False)\n    if is_aw:\n        unit = \"dBA\"\n        data = bf.dBA\n    else:\n        unit = \"dB\"\n        data = bf.dB\n    data = _reshape_spectrogram_data(data)\n    specshow_kwargs = filter_kwargs(display.specshow, kwargs, strict_mode=True)\n    ax_set_kwargs = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n\n    if ax is not None:\n        img = display.specshow(\n            data=data[0],\n            sr=bf.sampling_rate,\n            hop_length=bf.hop_length,\n            n_fft=bf.n_fft,\n            win_length=bf.win_length,\n            x_axis=\"time\",\n            y_axis=\"linear\",\n            cmap=cmap,\n            ax=ax,\n            vmin=vmin,\n            vmax=vmax,\n            **specshow_kwargs,\n        )\n        ax.set(\n            title=title or bf.label or \"Spectrogram\",\n            ylabel=\"Frequency [Hz]\",\n            xlabel=\"Time [s]\",\n            **ax_set_kwargs,\n        )\n\n        fig = ax.figure\n        if fig is not None:\n            try:\n                cbar = fig.colorbar(img, ax=ax)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n        return ax\n\n    else:\n        # Create a new figure if ax is None\n        num_channels = bf.n_channels\n        fig, axs = plt.subplots(\n            num_channels, 1, figsize=(10, 5 * num_channels), sharex=True\n        )\n        if not isinstance(fig, Figure):\n            raise ValueError(\"fig must be a matplotlib Figure object.\")\n        # Convert axs to array if it is a single Axes object\n        if not isinstance(axs, np.ndarray):\n            axs = np.array([axs])\n\n        for ax_i, channel_data, ch_meta in zip(axs.flatten(), data, bf.channels):\n            img = display.specshow(\n                data=channel_data,\n                sr=bf.sampling_rate,\n                hop_length=bf.hop_length,\n                n_fft=bf.n_fft,\n                win_length=bf.win_length,\n                x_axis=\"time\",\n                y_axis=\"linear\",\n                ax=ax_i,\n                cmap=cmap,\n                vmin=vmin,\n                vmax=vmax,\n                **specshow_kwargs,\n            )\n            ax_i.set(\n                title=ch_meta.label,\n                ylabel=\"Frequency [Hz]\",\n                xlabel=\"Time [s]\",\n                **ax_set_kwargs,\n            )\n            try:\n                cbar = ax_i.figure.colorbar(img, ax=ax_i)\n                cbar.set_label(f\"Spectrum level [{unit}]\")\n            except (ValueError, AttributeError) as e:\n                # Handle case where img doesn't have proper colorbar properties\n                logger.warning(\n                    f\"Failed to create colorbar for spectrogram: \"\n                    f\"{type(e).__name__}: {e}\"\n                )\n            fig.suptitle(title or \"Spectrogram Data\")\n        plt.tight_layout()\n        plt.show()\n\n        return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.DescribePlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, **kwargs)</code>","text":"<p>Implementation of channel plotting</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(self, x: Any, y: Any, ax: \"Axes\", **kwargs: Any) -&gt; None:\n    \"\"\"Implementation of channel plotting\"\"\"\n    pass  # This method is not used for describe plot\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.DescribePlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"<p>Implementation of describe method for visualizing ChannelFrame data</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"ChannelFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    \"\"\"Implementation of describe method for visualizing ChannelFrame data\"\"\"\n\n    fmin = kwargs.pop(\"fmin\", 0)\n    fmax = kwargs.pop(\"fmax\", None)\n    cmap = kwargs.pop(\"cmap\", \"jet\")\n    vmin = kwargs.pop(\"vmin\", None)\n    vmax = kwargs.pop(\"vmax\", None)\n    xlim = kwargs.pop(\"xlim\", None)\n    ylim = kwargs.pop(\"ylim\", None)\n    is_aw = kwargs.pop(\"Aw\", False)\n    waveform = kwargs.pop(\"waveform\", {})\n    spectral = kwargs.pop(\"spectral\", dict(xlim=(vmin, vmax)))\n\n    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 3], width_ratios=[3, 1, 0.1])\n    gs.update(wspace=0.2)\n\n    fig = plt.figure(figsize=(12, 6))\n    fig.subplots_adjust(wspace=0.0001)\n\n    # First subplot (Time Plot)\n    ax_1 = fig.add_subplot(gs[0])\n    bf.plot(plot_type=\"waveform\", ax=ax_1, overlay=True)\n    ax_1.set(**waveform)\n    ax_1.legend().set_visible(False)\n    ax_1.set(xlabel=\"\", title=\"\")\n\n    # Second subplot (STFT Plot)\n    ax_2 = fig.add_subplot(gs[3], sharex=ax_1)\n    stft_ch = bf.stft()\n    if is_aw:\n        unit = \"dBA\"\n        channel_data = stft_ch.dBA\n    else:\n        unit = \"dB\"\n        channel_data = stft_ch.dB\n    if channel_data.ndim == 3:\n        channel_data = channel_data[0]\n    # Get the maximum value of the data and round it to a convenient value\n    if vmax is None:\n        data_max = np.nanmax(channel_data)\n        # Round to a convenient number with increments of 10, 5, or 2\n        for step in [10, 5, 2]:\n            rounded_max = np.ceil(data_max / step) * step\n            if rounded_max &gt;= data_max:\n                vmax = rounded_max\n                vmin = vmax - 180\n                break\n    img = display.specshow(\n        data=channel_data,\n        sr=bf.sampling_rate,\n        hop_length=stft_ch.hop_length,\n        n_fft=stft_ch.n_fft,\n        win_length=stft_ch.win_length,\n        x_axis=\"time\",\n        y_axis=\"linear\",\n        ax=ax_2,\n        fmin=fmin,\n        fmax=fmax,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n    ax_2.set(xlim=xlim, ylim=ylim)\n\n    # Third subplot\n    ax_3 = fig.add_subplot(gs[1])\n    ax_3.axis(\"off\")\n\n    # Fourth subplot (Welch Plot)\n    ax_4 = fig.add_subplot(gs[4], sharey=ax_2)\n    welch_ch = bf.welch()\n    if is_aw:\n        unit = \"dBA\"\n        data_db = welch_ch.dBA\n    else:\n        unit = \"dB\"\n        data_db = welch_ch.dB\n    ax_4.plot(data_db.T, welch_ch.freqs.T)\n    ax_4.grid(True)\n    ax_4.set(xlabel=f\"Spectrum level [{unit}]\", **spectral)\n\n    cbar = fig.colorbar(img, ax=ax_4, format=\"%+2.0f\")\n    cbar.set_label(unit)\n    fig.suptitle(title or bf.label or \"Channel Data\")\n\n    return _return_axes_iterator(fig.axes)\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy.channel_plot","title":"<code>channel_plot(x, y, ax, title=None, ylabel='', xlabel='Frequency [Hz]', alpha=0, **kwargs)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def channel_plot(\n    self,\n    x: Any,\n    y: Any,\n    ax: \"Axes\",\n    title: str | None = None,\n    ylabel: str = \"\",\n    xlabel: str = \"Frequency [Hz]\",\n    alpha: float = 0,\n    **kwargs: Any,\n) -&gt; None:\n    ax.plot(x, y, **kwargs)\n    ax.grid(True)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_title(title or \"\")\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.MatrixPlotStrategy.plot","title":"<code>plot(bf, ax=None, title=None, overlay=False, **kwargs)</code>","text":"\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def plot(\n    self,\n    bf: \"SpectralFrame\",\n    ax: Optional[\"Axes\"] = None,\n    title: str | None = None,\n    overlay: bool = False,\n    **kwargs: Any,\n) -&gt; Axes | Iterator[Axes]:\n    kwargs = kwargs or {}\n    is_aw = kwargs.pop(\"Aw\", False)\n    if (\n        len(bf.operation_history) &gt; 0\n        and bf.operation_history[-1][\"operation\"] == \"coherence\"\n    ):\n        unit = \"\"\n        data = bf.magnitude\n        ylabel = kwargs.pop(\"ylabel\", \"coherence\")\n    else:\n        if is_aw:\n            unit = \"dBA\"\n            data = bf.dBA\n        else:\n            unit = \"dB\"\n            data = bf.dB\n        ylabel = kwargs.pop(\"ylabel\", f\"Spectrum level [{unit}]\")\n\n    data = _reshape_to_2d(data)\n\n    xlabel = kwargs.pop(\"xlabel\", \"Frequency [Hz]\")\n    alpha = kwargs.pop(\"alpha\", 1)\n    plot_kwargs = filter_kwargs(Line2D, kwargs, strict_mode=True)\n    ax_set = filter_kwargs(Axes.set, kwargs, strict_mode=True)\n    num_channels = bf.n_channels\n    # If an Axes is provided, prefer drawing into it (treat as overlay)\n    if ax is not None:\n        overlay = True\n    if overlay:\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n        else:\n            fig = ax.figure\n        self.channel_plot(\n            bf.freqs,\n            data.T,\n            ax,  # \u3053\u3053\u3067\u5fc5\u305aAxes\u578b\n            title=title or bf.label or \"Spectral Data\",\n            ylabel=ylabel,\n            xlabel=xlabel,\n            alpha=alpha,\n            **plot_kwargs,\n        )\n        ax.set(**ax_set)\n        if fig is not None:\n            fig.suptitle(title or bf.label or \"Spectral Data\")\n        if ax.figure != fig:  # Only show if we created the figure\n            plt.tight_layout()\n            plt.show()\n        return ax\n    else:\n        num_rows = int(np.ceil(np.sqrt(num_channels)))\n        fig, axs = plt.subplots(\n            num_rows,\n            num_rows,\n            figsize=(3 * num_rows, 3 * num_rows),\n            sharex=True,\n            sharey=True,\n        )\n        if isinstance(axs, np.ndarray):\n            axes_list = axs.flatten().tolist()\n        elif isinstance(axs, list):\n            import itertools\n\n            axes_list = list(itertools.chain.from_iterable(axs))\n        else:\n            axes_list = [axs]\n        for ax_i, channel_data, ch_meta in zip(axes_list, data, bf.channels):\n            self.channel_plot(\n                bf.freqs,\n                channel_data,\n                ax_i,\n                title=ch_meta.label,\n                ylabel=ylabel,\n                xlabel=xlabel,\n                alpha=alpha,\n                **plot_kwargs,\n            )\n            ax_i.set(**ax_set)\n        fig.suptitle(title or bf.label or \"Spectral Data\")\n        plt.tight_layout()\n        plt.show()\n        return _return_axes_iterator(fig.axes)\n\n    raise NotImplementedError()\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.register_plot_strategy","title":"<code>register_plot_strategy(strategy_cls)</code>","text":"<p>Register a new plot strategy from a class</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def register_plot_strategy(strategy_cls: type) -&gt; None:\n    \"\"\"Register a new plot strategy from a class\"\"\"\n    if not issubclass(strategy_cls, PlotStrategy):\n        raise TypeError(\"Strategy class must inherit from PlotStrategy.\")\n    if inspect.isabstract(strategy_cls):\n        raise TypeError(\"Cannot register abstract PlotStrategy class.\")\n    _plot_strategies[strategy_cls.name] = strategy_cls\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.get_plot_strategy","title":"<code>get_plot_strategy(name)</code>","text":"<p>Get plot strategy by name</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def get_plot_strategy(name: str) -&gt; type[PlotStrategy[Any]]:\n    \"\"\"Get plot strategy by name\"\"\"\n    if name not in _plot_strategies:\n        raise ValueError(f\"Unknown plot type: {name}\")\n    return _plot_strategies[name]\n</code></pre>"},{"location":"en/api/visualization/#wandas.visualization.plotting.create_operation","title":"<code>create_operation(name, **params)</code>","text":"<p>Create operation instance from operation name and parameters</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/visualization/plotting.py</code> <pre><code>def create_operation(name: str, **params: Any) -&gt; PlotStrategy[Any]:\n    \"\"\"Create operation instance from operation name and parameters\"\"\"\n    operation_class = get_plot_strategy(name)\n    return operation_class(**params)\n</code></pre>"},{"location":"en/api/wdf_io/","title":"WDF File I/O","text":"<p>The <code>wandas.io.wdf_io</code> module provides functionality for saving and loading <code>ChannelFrame</code> objects in the WDF (Wandas Data File) format. The WDF format is based on HDF5 and preserves not only the data but also all metadata such as sampling rate, units, and channel labels.</p>"},{"location":"en/api/wdf_io/#wdf-format-overview","title":"WDF Format Overview","text":"<p>The WDF format has the following features:</p> <ul> <li>HDF5-based hierarchical data structure</li> <li>Complete preservation of channel data and metadata</li> <li>Size optimization through data compression and chunking</li> <li>Version management for future extensions</li> </ul> <p>File structure:</p> <pre><code>/meta           : Frame-level metadata (JSON format)\n/channels/{i}   : Individual channel data and metadata\n    \u251c\u2500 data           : Waveform data (numpy array)\n    \u2514\u2500 attrs          : Channel attributes (labels, units, etc.)\n</code></pre>"},{"location":"en/api/wdf_io/#saving-wdf-files","title":"Saving WDF Files","text":""},{"location":"en/api/wdf_io/#wandas.io.wdf_io.save","title":"<code>wandas.io.wdf_io.save(frame, path, *, format='hdf5', compress='gzip', overwrite=False, dtype=None)</code>","text":"<p>Save a frame to a file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>frame</code> <code>BaseFrame[Any]</code> <p>The frame to save.</p> \u5fc5\u9808 <code>path</code> <code>str | Path</code> <p>Path to save the file. '.wdf' extension will be added if not present.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format to use (currently only 'hdf5' is supported)</p> <code>'hdf5'</code> <code>compress</code> <code>str | None</code> <p>Compression method ('gzip' by default, None for no compression)</p> <code>'gzip'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing file</p> <code>False</code> <code>dtype</code> <code>str | dtype[Any] | None</code> <p>Optional data type conversion before saving (e.g. 'float32')</p> <code>None</code> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileExistsError</code> <p>If the file exists and overwrite=False.</p> <code>NotImplementedError</code> <p>For unsupported formats.</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def save(\n    frame: BaseFrame[Any],\n    path: str | Path,\n    *,\n    format: str = \"hdf5\",\n    compress: str | None = \"gzip\",\n    overwrite: bool = False,\n    dtype: str | np.dtype[Any] | None = None,\n) -&gt; None:\n    \"\"\"Save a frame to a file.\n\n    Args:\n        frame: The frame to save.\n        path: Path to save the file. '.wdf' extension will be added if not present.\n        format: Format to use (currently only 'hdf5' is supported)\n        compress: Compression method ('gzip' by default, None for no compression)\n        overwrite: Whether to overwrite existing file\n        dtype: Optional data type conversion before saving (e.g. 'float32')\n\n    Raises:\n        FileExistsError: If the file exists and overwrite=False.\n        NotImplementedError: For unsupported formats.\n    \"\"\"\n    # Handle path\n    path = Path(path)\n    if path.suffix != \".wdf\":\n        path = path.with_suffix(\".wdf\")\n\n    # Check if file exists\n    if path.exists() and not overwrite:\n        raise FileExistsError(\n            f\"File {path} already exists. Set overwrite=True to overwrite.\"\n        )\n\n    # Currently only HDF5 is supported\n    if format.lower() != \"hdf5\":\n        raise NotImplementedError(\n            f\"Format {format} not supported. Only 'hdf5' is currently implemented.\"\n        )\n\n    # Compute data arrays (this triggers actual computation)\n    logger.info(\"Computing data arrays for saving...\")\n    computed_data = frame.compute()\n    if dtype is not None:\n        computed_data = computed_data.astype(dtype)\n\n    # Create file\n    logger.info(f\"Creating HDF5 file at {path}...\")\n    with h5py.File(path, \"w\") as f:\n        # Set file version\n        f.attrs[\"version\"] = WDF_FORMAT_VERSION\n\n        # Store frame metadata\n        f.attrs[\"sampling_rate\"] = frame.sampling_rate\n        f.attrs[\"label\"] = frame.label or \"\"\n        f.attrs[\"frame_type\"] = type(frame).__name__\n\n        # Create channels group\n        channels_grp = f.create_group(\"channels\")\n\n        # Store each channel\n        for i, (channel_data, ch_meta) in enumerate(\n            zip(computed_data, frame._channel_metadata)\n        ):\n            ch_grp = channels_grp.create_group(f\"{i}\")\n\n            # Store channel data\n            if compress:\n                ch_grp.create_dataset(\"data\", data=channel_data, compression=compress)\n            else:\n                ch_grp.create_dataset(\"data\", data=channel_data)\n\n            # Store metadata\n            ch_grp.attrs[\"label\"] = ch_meta.label\n            ch_grp.attrs[\"unit\"] = ch_meta.unit\n\n            # Store extra metadata as JSON\n            if ch_meta.extra:\n                ch_grp.attrs[\"metadata_json\"] = json.dumps(ch_meta.extra)\n\n        # Store operation history\n        if frame.operation_history:\n            op_grp = f.create_group(\"operation_history\")\n            for i, op in enumerate(frame.operation_history):\n                op_sub_grp = op_grp.create_group(f\"operation_{i}\")\n                for k, v in op.items():\n                    # Store simple attributes directly\n                    if isinstance(v, str | int | float | bool | np.number):\n                        op_sub_grp.attrs[k] = v\n                    else:\n                        # For complex types, serialize to JSON\n                        try:\n                            op_sub_grp.attrs[k] = json.dumps(v)\n                        except (TypeError, OverflowError) as e:\n                            logger.warning(\n                                f\"Could not serialize operation key '{k}': {e}\"\n                            )\n                            op_sub_grp.attrs[k] = str(v)\n\n        # Store frame metadata\n        if frame.metadata:\n            meta_grp = f.create_group(\"meta\")\n            # Store metadata as JSON\n            meta_grp.attrs[\"json\"] = json.dumps(frame.metadata)\n\n            # Also store individual metadata items as attributes for compatibility\n            for k, v in frame.metadata.items():\n                if isinstance(v, str | int | float | bool | np.number):\n                    meta_grp.attrs[k] = v\n\n    logger.info(f\"Frame saved to {path}\")\n</code></pre>"},{"location":"en/api/wdf_io/#loading-wdf-files","title":"Loading WDF Files","text":""},{"location":"en/api/wdf_io/#wandas.io.wdf_io.load","title":"<code>wandas.io.wdf_io.load(path, *, format='hdf5')</code>","text":"<p>Load a ChannelFrame object from a WDF (Wandas Data File) file.</p> <p>\u5f15\u6570\uff1a</p> \u540d\u524d \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 <code>path</code> <code>str | Path</code> <p>Path to the WDF file to load.</p> \u5fc5\u9808 <code>format</code> <code>str</code> <p>Format of the file. Currently only \"hdf5\" is supported.</p> <code>'hdf5'</code> <p>\u623b\u308a\u5024\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>ChannelFrame</code> <p>A new ChannelFrame object with data and metadata loaded from the file.</p> <p>\u767a\u751f\uff1a</p> \u30bf\u30a4\u30d7 \u30c7\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3 <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> <code>NotImplementedError</code> <p>If format is not \"hdf5\".</p> <code>ValueError</code> <p>If the file format is invalid or incompatible.</p> Example <p>cf = ChannelFrame.load(\"audio_data.wdf\")</p> \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u4f4d\u7f6e\uff1a <code>wandas/io/wdf_io.py</code> <pre><code>def load(path: str | Path, *, format: str = \"hdf5\") -&gt; \"ChannelFrame\":\n    \"\"\"Load a ChannelFrame object from a WDF (Wandas Data File) file.\n\n    Args:\n        path: Path to the WDF file to load.\n        format: Format of the file. Currently only \"hdf5\" is supported.\n\n    Returns:\n        A new ChannelFrame object with data and metadata loaded from the file.\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist.\n        NotImplementedError: If format is not \"hdf5\".\n        ValueError: If the file format is invalid or incompatible.\n\n    Example:\n        &gt;&gt;&gt; cf = ChannelFrame.load(\"audio_data.wdf\")\n    \"\"\"\n    # Ensure ChannelFrame is imported here to avoid circular imports\n    from ..core.metadata import ChannelMetadata\n    from ..frames.channel import ChannelFrame\n\n    if format != \"hdf5\":\n        raise NotImplementedError(f\"Format '{format}' is not supported\")\n\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    logger.debug(f\"Loading ChannelFrame from {path}\")\n\n    with h5py.File(path, \"r\") as f:\n        # Check format version for compatibility\n        version = f.attrs.get(\"version\", \"unknown\")\n        if version != WDF_FORMAT_VERSION:\n            logger.warning(\n                f\"File format version mismatch: file={version}, current={WDF_FORMAT_VERSION}\"  # noqa: E501\n            )\n\n        # Get global attributes\n        sampling_rate = float(f.attrs[\"sampling_rate\"])\n        frame_label = f.attrs.get(\"label\", \"\")\n\n        # Get frame metadata\n        frame_metadata = {}\n        if \"meta\" in f:\n            meta_json = f[\"meta\"].attrs.get(\"json\", \"{}\")\n            frame_metadata = json.loads(meta_json)\n\n        # Load operation history\n        operation_history = []\n        if \"operation_history\" in f:\n            op_grp = f[\"operation_history\"]\n            # Sort operation indices numerically\n            op_indices = sorted([int(key.split(\"_\")[1]) for key in op_grp.keys()])\n\n            for idx in op_indices:\n                op_sub_grp = op_grp[f\"operation_{idx}\"]\n                op_dict = {}\n                for attr_name in op_sub_grp.attrs:\n                    attr_value = op_sub_grp.attrs[attr_name]\n                    # Try to deserialize JSON, fallback to string\n                    try:\n                        op_dict[attr_name] = json.loads(attr_value)\n                    except (json.JSONDecodeError, TypeError):\n                        op_dict[attr_name] = attr_value\n                operation_history.append(op_dict)\n\n        # Load channel data and metadata\n        all_channel_data = []\n        channel_metadata_list = []\n\n        if \"channels\" in f:\n            channels_group = f[\"channels\"]\n            # Sort channel indices numerically\n            channel_indices = sorted([int(key) for key in channels_group.keys()])\n\n            for idx in channel_indices:\n                ch_group = channels_group[f\"{idx}\"]\n\n                # Load channel data\n                channel_data = ch_group[\"data\"][()]\n\n                # Append to combined array\n                all_channel_data.append(channel_data)\n\n                # Load channel metadata\n                label = ch_group.attrs.get(\"label\", f\"Ch{idx}\")\n                unit = ch_group.attrs.get(\"unit\", \"\")\n\n                # Load additional metadata if present\n                ch_extra = {}\n                if \"metadata_json\" in ch_group.attrs:\n                    ch_extra = json.loads(ch_group.attrs[\"metadata_json\"])\n\n                # Create ChannelMetadata object\n                channel_metadata = ChannelMetadata(\n                    label=label, unit=unit, extra=ch_extra\n                )\n                channel_metadata_list.append(channel_metadata)\n\n        # Stack channel data into a single array\n        if all_channel_data:\n            combined_data = np.stack(all_channel_data, axis=0)\n        else:\n            raise ValueError(\"No channel data found in the file\")\n\n        # Create a new ChannelFrame\n        dask_data = da_from_array(combined_data)\n\n        cf = ChannelFrame(\n            data=dask_data,\n            sampling_rate=sampling_rate,\n            label=frame_label if frame_label else None,\n            metadata=frame_metadata,\n            operation_history=operation_history,\n            channel_metadata=channel_metadata_list,\n        )\n\n        logger.debug(\n            f\"ChannelFrame loaded from {path}: {len(cf)} channels, {cf.n_samples} samples\"  # noqa: E501\n        )\n        return cf\n</code></pre>"},{"location":"en/api/wdf_io/#usage-examples","title":"Usage Examples","text":"<pre><code># Save a ChannelFrame in WDF format\ncf = wd.read_wav(\"audio.wav\")\ncf.save(\"audio_data.wdf\")\n\n# Specifying options when saving\ncf.save(\n    \"high_quality.wdf\",\n    compress=\"gzip\",  # Compression method\n    dtype=\"float64\",  # Data type\n    overwrite=True    # Allow overwriting\n)\n\n# Load a ChannelFrame from a WDF file\ncf2 = wd.ChannelFrame.load(\"audio_data.wdf\")\n</code></pre> <p>For detailed usage examples, see the File I/O Guide.</p>"},{"location":"en/explanation/","title":"Theory Background and Architecture","text":"<p>This section explains the design philosophy, internal architecture, and theoretical background used in the Wandas library.</p>"},{"location":"en/explanation/#design-philosophy","title":"Design Philosophy","text":"<p>Wandas is developed based on the following design principles:</p> <ol> <li>Intuitive API Design - Consistent interface that users can easily use</li> <li>Efficient Memory Usage - Memory-efficient implementation suitable for processing large-scale data</li> <li>Extensibility - Expandable architecture that makes it easy to add new features and algorithms</li> <li>Scientific Accuracy - Accurate implementation based on acoustic signal processing theory</li> </ol>"},{"location":"en/explanation/#core-architecture","title":"Core Architecture","text":""},{"location":"en/explanation/#data-model","title":"Data Model","text":"<p>The central data model of the Wandas library is hierarchically structured:</p> <pre><code>BaseChannel (base class)\n \u251c\u2500\u2500 Channel (time-domain signal)\n \u2502    \u2514\u2500\u2500 FrequencyChannel (frequency-domain signal)\n \u2502         \u2514\u2500\u2500 TimeFrequencyChannel (time-frequency domain signal)\n \u2514\u2500\u2500 ChannelFrame (container for multiple channels)\n      \u251c\u2500\u2500 FileFrame (file-based multiple channels)\n      \u2514\u2500\u2500 FrequencyChannelFrame (multiple channels in frequency domain)\n</code></pre> <p>Responsibilities of each class:</p> <ul> <li>BaseChannel: Base class for all channels. Provides basic functionality for data access and metadata management</li> <li>Channel: Implements time-domain signal data and processing methods</li> <li>FrequencyChannel: Implements FFT-based frequency-domain data and processing</li> <li>TimeFrequencyChannel: Implements time-frequency domain representations such as Short-Time Fourier Transform (STFT)</li> <li>ChannelFrame: Manages multiple channels and enables batch processing</li> </ul>"},{"location":"en/explanation/#data-processing-flow","title":"Data Processing Flow","text":"<ol> <li>Input Stage: Generate <code>Channel</code> or <code>ChannelFrame</code> objects from files such as WAV and CSV</li> <li>Processing Stage: Apply processing such as filtering and resampling</li> <li>Analysis Stage: Analyze signal characteristics (spectrum, level, etc.)</li> <li>Output Stage: Save processing results to files or visualize as graphs</li> </ol>"},{"location":"en/explanation/#implementation-details","title":"Implementation Details","text":""},{"location":"en/explanation/#memory-efficiency","title":"Memory Efficiency","text":"<p>Wandas ensures memory efficiency for handling large audio data through the following methods:</p> <ul> <li>Lazy Evaluation: A mechanism that delays calculations until needed</li> <li>Memory Mapping: Access to large files without loading them entirely into memory</li> <li>Dask and H5PY: Utilizing libraries suitable for large-scale data processing</li> </ul>"},{"location":"en/explanation/#signal-processing-algorithms","title":"Signal Processing Algorithms","text":"<p>Wandas implements signal processing algorithms such as:</p> <ul> <li>Digital Filters: IIR/FIR filters such as Butterworth filters</li> <li>Spectral Analysis: Frequency analysis based on Fast Fourier Transform (FFT)</li> <li>Time-Frequency Analysis: Short-Time Fourier Transform (STFT), spectrograms</li> <li>Statistical Analysis: Calculation of signal characteristics such as RMS, peak values, crest factor</li> </ul>"},{"location":"en/explanation/#performance-considerations","title":"Performance Considerations","text":"<p>Performance considerations when using Wandas:</p> <ul> <li>When processing large amounts of data, consider processing in chunks</li> <li>When building complex processing chains, improve performance by caching intermediate results</li> <li>Multi-channel processing efficiently utilizes multi-core processors</li> </ul>"},{"location":"en/explanation/#psychoacoustic-metrics","title":"Psychoacoustic Metrics","text":"<p>Wandas provides psychoacoustic metrics for analyzing audio signals based on human perception:</p> <ul> <li>Loudness Calculation: Time-varying loudness calculation using Zwicker method according to ISO 532-1:2017</li> </ul>"},{"location":"en/explanation/#references","title":"References","text":"<ol> <li>Smith, J. O. (2011). Spectral Audio Signal Processing. W3K Publishing.</li> <li>M\u00fcller, M. (2015). Fundamentals of Music Processing: Audio, Analysis, Algorithms, Applications. Springer.</li> <li>Z\u00f6lzer, U. (2008). Digital Audio Signal Processing. Wiley.</li> </ol>"},{"location":"en/explanation/psychoacoustic_metrics/","title":"Psychoacoustic Metrics","text":"<p>Wandas provides psychoacoustic metrics for analyzing audio signals based on human perception. These metrics are calculated using standardized methods and the MoSQITo library.</p>"},{"location":"en/explanation/psychoacoustic_metrics/#loudness-non-stationary-signals","title":"Loudness (Non-Stationary Signals)","text":""},{"location":"en/explanation/psychoacoustic_metrics/#overview","title":"Overview","text":"<p>The <code>loudness_zwtv()</code> method calculates time-varying loudness for non-stationary signals using the Zwicker method according to ISO 532-1:2017. This method provides a measure of perceived loudness that correlates well with human perception.</p>"},{"location":"en/explanation/psychoacoustic_metrics/#what-is-loudness","title":"What is Loudness?","text":"<p>Loudness is measured in sones, a perceptual unit where:</p> <ul> <li>1 sone corresponds to a loudness level of 40 phon (approximately the loudness of a 1 kHz tone at 40 dB SPL)</li> <li>Doubling the sones corresponds to doubling the perceived loudness</li> <li>The relationship is: if sound A has twice the loudness in sones as sound B, it will sound twice as loud</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#typical-loudness-values","title":"Typical Loudness Values","text":"Environment/Sound Approximate Loudness Quiet library ~0.5-1 sone Quiet conversation ~2-4 sones Normal conversation ~4-8 sones Busy office ~8-16 sones Loud music ~32+ sones Very loud noise ~100+ sones"},{"location":"en/explanation/psychoacoustic_metrics/#usage","title":"Usage","text":""},{"location":"en/explanation/psychoacoustic_metrics/#basic-usage","title":"Basic Usage","text":"<pre><code>import wandas as wd\n\n# Load audio file\nsignal = wd.read_wav(\"audio.wav\")\n\n# Calculate loudness (free field)\nloudness = signal.loudness_zwtv()\n\n# Plot loudness over time\nloudness.plot(title=\"Time-varying Loudness\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#field-type-selection","title":"Field Type Selection","text":"<p>The method supports two types of sound fields:</p> <ul> <li>Free field (<code>field_type=\"free\"</code>): Sound arriving from a specific direction (e.g., loudspeaker in front of listener)</li> <li>Diffuse field (<code>field_type=\"diffuse\"</code>): Sound arriving uniformly from all directions (e.g., reverberant room)</li> </ul> <pre><code># Free field (default)\nloudness_free = signal.loudness_zwtv(field_type=\"free\")\n\n# Diffuse field\nloudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#method-signature","title":"Method Signature","text":"<pre><code>def loudness_zwtv(self, field_type: str = \"free\") -&gt; ChannelFrame:\n    \"\"\"\n    Calculate time-varying loudness using Zwicker method.\n\n    Parameters\n    ----------\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n\n    Returns\n    -------\n    ChannelFrame\n        Time-varying loudness values in sones\n    \"\"\"\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#output","title":"Output","text":"<p>The method returns a <code>ChannelFrame</code> containing:</p> <ul> <li>Time-varying loudness values in sones</li> <li>Time resolution: Approximately 2ms (0.002 seconds)</li> <li>Multi-channel handling: Each channel is processed independently</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#examples","title":"Examples","text":""},{"location":"en/explanation/psychoacoustic_metrics/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<pre><code>import wandas as wd\nimport numpy as np\n\n# Load an audio file\nsignal = wd.read_wav(\"audio.wav\")\n\n# Calculate loudness (free field by default)\nloudness = signal.loudness_zwtv()\n\n# Plot the loudness over time\nloudness.plot(title=\"Time-varying Loudness (sones)\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-2-creating-a-test-signal","title":"Example 2: Creating a Test Signal","text":"<pre><code>import wandas as wd\nimport numpy as np\n\n# Generate a 1 kHz sine wave at moderate level\nsignal = wd.generate_sin(freqs=[1000], duration=2.0, sampling_rate=48000)\n\n# Scale to approximately 70 dB SPL\nsignal = signal * 0.063\n\n# Calculate loudness\nloudness = signal.loudness_zwtv()\n\n# Print statistics\nprint(f\"Mean loudness: {loudness.mean():.2f} sones\")\nprint(f\"Max loudness: {loudness.max():.2f} sones\")\nprint(f\"Min loudness: {loudness.min():.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-3-comparing-free-vs-diffuse-field","title":"Example 3: Comparing Free vs Diffuse Field","text":"<pre><code>import wandas as wd\nimport numpy as np\n\n# Generate 1 kHz sine wave at moderate level\nsignal = wd.generate_sin(freqs=[1000], duration=2.0, sampling_rate=48000)\nsignal = signal * 0.063  # Scale to ~70 dB SPL\n\n# Calculate loudness\nloudness = signal.loudness_zwtv()\n\n# Get statistics\nprint(f\"Mean loudness: {loudness.mean():.2f} sones\")\nprint(f\"Max loudness: {loudness.max():.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-3-comparing-free-vs-diffuse-field_1","title":"Example 3: Comparing Free vs Diffuse Field","text":"<pre><code>import wandas as wd\nimport matplotlib.pyplot as plt\n\n# Load signal\nsignal = wd.read_wav(\"audio.wav\")\n\n# Calculate for both field types\nloudness_free = signal.loudness_zwtv(field_type=\"free\")\nloudness_diffuse = signal.loudness_zwtv(field_type=\"diffuse\")\n\n# Plot comparison\nfig, axes = plt.subplots(2, 1, figsize=(12, 8))\nloudness_free.plot(ax=axes[0], title=\"Free Field Loudness\")\nloudness_diffuse.plot(ax=axes[1], title=\"Diffuse Field Loudness\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-4-multi-channel-processing","title":"Example 4: Multi-Channel Processing","text":"<pre><code>import wandas as wd\n\n# Load stereo audio\nstereo_signal = wd.read_wav(\"stereo_audio.wav\")\n\n# Calculate loudness (each channel processed independently)\nloudness = stereo_signal.loudness_zwtv()\n\n# Access individual channels\nleft_loudness = loudness[0]\nright_loudness = loudness[1]\n\n# Plot both channels\nloudness.plot(overlay=True, title=\"Stereo Loudness Comparison\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-5-accessing-mosqito-directly","title":"Example 5: Accessing MoSQITo Directly","text":"<p>If you need more detailed output (specific loudness, bark axis, etc.), you can use MoSQITo directly:</p> <pre><code>from mosqito.sq_metrics.loudness.loudness_zwtv import loudness_zwtv\nimport wandas as wd\n\nsignal = wd.read_wav(\"audio.wav\")\ndata = signal.data[0]  # Get first channel\n\n# Call MoSQITo directly\nN, N_spec, bark_axis, time_axis = loudness_zwtv(\n    data, signal.sampling_rate, field_type=\"free\"\n)\n\nprint(f\"Loudness shape: {N.shape}\")\nprint(f\"Specific loudness shape: {N_spec.shape}\")\nprint(f\"Time axis: {time_axis[:10]}...\")  # First 10 time points\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#technical-details","title":"Technical Details","text":""},{"location":"en/explanation/psychoacoustic_metrics/#algorithm","title":"Algorithm","text":"<p>The implementation uses MoSQITo's <code>loudness_zwtv</code> function, which implements:</p> <ol> <li>Outer ear transfer function: Simulates the filtering effect of the outer ear</li> <li>Middle ear transfer function: Models middle ear transmission</li> <li>Excitation patterns: Calculates excitation along the basilar membrane</li> <li>Specific loudness: Determines loudness in each critical band</li> <li>Total loudness: Integrates specific loudness over all critical bands</li> </ol>"},{"location":"en/explanation/psychoacoustic_metrics/#time-resolution","title":"Time Resolution","text":"<p>The loudness calculation produces values with approximately 2ms time resolution. For a 1-second signal, you can expect around 500 loudness values.</p>"},{"location":"en/explanation/psychoacoustic_metrics/#computational-complexity","title":"Computational Complexity","text":"<ul> <li>The algorithm processes signals in blocks for efficiency</li> <li>Processing time scales linearly with signal duration</li> <li>Memory usage is moderate (stores time-varying loudness values)</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#limitations","title":"Limitations","text":"<ol> <li>Sampling rate: Best results with sampling rates \u2265 44.1 kHz</li> <li>Signal level: Accurate for signals in the range of audibility (typically 20-100 dB SPL)</li> <li>Stationary assumption: While designed for non-stationary signals, extremely rapid transients may not be fully captured</li> <li>Calibration: Assumes proper signal calibration to physical units (Pa)</li> </ol>"},{"location":"en/explanation/psychoacoustic_metrics/#standards-and-references","title":"Standards and References","text":"<ul> <li>ISO 532-1:2017: \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</li> <li>Zwicker, E., &amp; Fastl, H. (1999): Psychoacoustics: Facts and models (2nd ed.). Springer.</li> <li>MoSQITo library: https://mosqito.readthedocs.io/en/latest/</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#loudness-steady-signals","title":"Loudness (Steady Signals)","text":""},{"location":"en/explanation/psychoacoustic_metrics/#overview_1","title":"Overview","text":"<p>The <code>loudness_zwst()</code> method calculates steady-state loudness for stationary (steady) signals using the Zwicker method according to ISO 532-1:2017. This method is suitable for evaluating continuous sounds such as fan noise, steady machinery sounds, and other stationary signals.</p>"},{"location":"en/explanation/psychoacoustic_metrics/#differences-from-time-varying-loudness","title":"Differences from Time-Varying Loudness","text":"Feature Time-varying (<code>loudness_zwtv</code>) Steady-state (<code>loudness_zwst</code>) Signal type Non-stationary (time-varying) Stationary (steady) Use cases Speech, music, transient sounds Fan noise, constant machinery Output Time series of loudness values Single loudness value Output shape (channels, time_samples) (n_channels,) Sampling rate Updated to ~500 Hz Not changed (single value)"},{"location":"en/explanation/psychoacoustic_metrics/#usage_1","title":"Usage","text":""},{"location":"en/explanation/psychoacoustic_metrics/#basic-usage_1","title":"Basic Usage","text":"<pre><code>import wandas as wd\n\n# Load steady signal (e.g., fan noise)\nsignal = wd.read_wav(\"fan_noise.wav\")\n\n# Calculate steady-state loudness (free field)\nloudness = signal.loudness_zwst()\n\n# Display result\nprint(f\"Steady-state loudness: {loudness[0]:.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#field-type-selection_1","title":"Field Type Selection","text":"<p>Like time-varying loudness, this method supports two types of sound fields:</p> <pre><code># Free field (default)\nloudness_free = signal.loudness_zwst(field_type=\"free\")\n\n# Diffuse field\nloudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n\nprint(f\"Free field: {loudness_free[0]:.2f} sones\")\nprint(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#method-signature_1","title":"Method Signature","text":"<pre><code>def loudness_zwst(self, field_type: str = \"free\") -&gt; NDArrayReal:\n    \"\"\"\n    Calculate steady-state loudness using Zwicker method\n\n    Parameters\n    ----------\n    field_type : str, default=\"free\"\n        Type of sound field ('free' or 'diffuse')\n\n    Returns\n    -------\n    NDArrayReal\n        Steady-state loudness values in sones (one value per channel)\n        Shape: (n_channels,)\n    \"\"\"\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#output_1","title":"Output","text":"<p>The method returns <code>NDArrayReal</code> containing:</p> <ul> <li>Single loudness value in sones for each channel</li> <li>Output shape: (n_channels,) - 1D array</li> <li>Multi-channel handling: Each channel is processed independently</li> <li>NumPy compatible: Direct NumPy operations possible (<code>loudness[0]</code>, <code>loudness.mean()</code>, etc.)</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#examples_1","title":"Examples","text":""},{"location":"en/explanation/psychoacoustic_metrics/#example-1-fan-noise-evaluation","title":"Example 1: Fan Noise Evaluation","text":"<pre><code>import wandas as wd\n\n# Load fan noise\nfan_signal = wd.read_wav(\"fan_noise.wav\")\n\n# Calculate steady-state loudness\nloudness = fan_signal.loudness_zwst(field_type=\"free\")\n\n# Display result\nprint(f\"Fan noise loudness: {loudness[0]:.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-2-comparing-multiple-steady-sound-sources","title":"Example 2: Comparing Multiple Steady Sound Sources","text":"<pre><code>import wandas as wd\n\n# Load different steady sound sources\nfan1 = wd.read_wav(\"fan1.wav\")\nfan2 = wd.read_wav(\"fan2.wav\")\n\n# Calculate steady-state loudness\nloudness1 = fan1.loudness_zwst()\nloudness2 = fan2.loudness_zwst()\n\n# Compare\nprint(f\"Fan 1: {loudness1[0]:.2f} sones\")\nprint(f\"Fan 2: {loudness2[0]:.2f} sones\")\n\nif loudness1[0] &gt; loudness2[0]:\n    print(\"Fan 1 is louder\")\nelse:\n    print(\"Fan 2 is louder\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-3-stereo-steady-sound-processing","title":"Example 3: Stereo Steady Sound Processing","text":"<pre><code>import wandas as wd\n\n# Load stereo steady sound source\nstereo_signal = wd.read_wav(\"stereo_steady_noise.wav\")\n\n# Calculate steady-state loudness (each channel independently)\nloudness = stereo_signal.loudness_zwst()\n\n# Display results for each channel\nprint(f\"Left channel: {loudness[0]:.2f} sones\")\nprint(f\"Right channel: {loudness[1]:.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-4-comparing-free-field-and-diffuse-field","title":"Example 4: Comparing Free Field and Diffuse Field","text":"<pre><code>import wandas as wd\n\n# Load steady signal\nsignal = wd.read_wav(\"steady_noise.wav\")\n\n# Calculate for both field types\nloudness_free = signal.loudness_zwst(field_type=\"free\")\nloudness_diffuse = signal.loudness_zwst(field_type=\"diffuse\")\n\n# Compare\nprint(f\"Free field: {loudness_free[0]:.2f} sones\")\nprint(f\"Diffuse field: {loudness_diffuse[0]:.2f} sones\")\nprint(f\"Difference: {abs(loudness_free[0] - loudness_diffuse[0]):.2f} sones\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#example-5-accessing-mosqito-directly_1","title":"Example 5: Accessing MoSQITo Directly","text":"<p>If you need more detailed output (specific loudness, bark axis, etc.), you can use MoSQITo directly:</p> <pre><code>from mosqito.sq_metrics.loudness.loudness_zwst import loudness_zwst\nimport wandas as wd\n\nsignal = wd.read_wav(\"steady_noise.wav\")\ndata = signal.data[0]  # Get first channel\n\n# Call MoSQITo directly\nN, N_spec, bark_axis = loudness_zwst(\n    data, signal.sampling_rate, field_type=\"free\"\n)\n\nprint(f\"Loudness: {N:.2f} sones\")\nprint(f\"Specific loudness shape: {N_spec.shape}\")\nprint(f\"Bark axis: {bark_axis}\")\n</code></pre>"},{"location":"en/explanation/psychoacoustic_metrics/#technical-details_1","title":"Technical Details","text":""},{"location":"en/explanation/psychoacoustic_metrics/#algorithm_1","title":"Algorithm","text":"<p>Steady-state loudness calculation is based on the same Zwicker method as time-varying loudness, but outputs a single representative value:</p> <ol> <li>Outer ear transfer function: Simulates the filtering effect of the outer ear</li> <li>Middle ear transfer function: Models middle ear transmission</li> <li>Excitation patterns: Calculates excitation along the basilar membrane</li> <li>Specific loudness: Determines loudness in each critical band</li> <li>Total loudness: Integrates specific loudness over all critical bands</li> </ol>"},{"location":"en/explanation/psychoacoustic_metrics/#computational-complexity_1","title":"Computational Complexity","text":"<ul> <li>Calculation is simplified compared to time-varying loudness since steady signals are assumed</li> <li>Processing time depends on signal length, but only a single value is output</li> <li>Memory usage is small (stores only a single loudness value)</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#limitations_1","title":"Limitations","text":"<ol> <li>Sampling rate: Best results with sampling rates \u2265 44.1 kHz</li> <li>Signal level: Accurate for signals in the range of audibility (typically 20-100 dB SPL)</li> <li>Stationarity assumption: This method is designed for stationary signals. For time-varying signals, use <code>loudness_zwtv()</code> instead</li> <li>Calibration: Assumes proper signal calibration to physical units (Pa)</li> </ol>"},{"location":"en/explanation/psychoacoustic_metrics/#standards-and-references_1","title":"Standards and References","text":"<ul> <li>ISO 532-1:2017: \"Acoustics \u2014 Methods for calculating loudness \u2014 Part 1: Zwicker method\"</li> <li>Zwicker, E., &amp; Fastl, H. (1999): Psychoacoustics: Facts and models (2nd ed.). Springer.</li> <li>MoSQITo library: https://mosqito.readthedocs.io/en/latest/</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#related-operations","title":"Related Operations","text":"<ul> <li><code>loudness_zwtv()</code>: Calculate time-varying loudness (for non-stationary signals)</li> <li><code>loudness_zwst()</code>: Calculate steady-state loudness (for stationary signals)</li> <li><code>a_weighting()</code>: Apply A-weighting filter (frequency weighting approximating human hearing)</li> <li><code>noct_spectrum()</code>: Calculate N-octave band spectrum</li> <li><code>rms_trend()</code>: Calculate RMS trend over time</li> </ul>"},{"location":"en/explanation/psychoacoustic_metrics/#see-also","title":"See Also","text":"<ul> <li>MoSQITo Documentation</li> <li>ISO 532-1:2017 Standard</li> <li>Psychoacoustics Fundamentals</li> </ul>"},{"location":"en/tutorial/","title":"Tutorial","text":"<p>This tutorial will teach you the basics of the Wandas library in 5 minutes.</p>"},{"location":"en/tutorial/#installation","title":"Installation","text":"<pre><code>pip install git+https://github.com/endolith/waveform-analysis.git@master\npip install wandas\n</code></pre>"},{"location":"en/tutorial/#basic-usage","title":"Basic Usage","text":""},{"location":"en/tutorial/#1-import-the-library","title":"1. Import the Library","text":"<pre><code>import wandas as wd\n</code></pre>"},{"location":"en/tutorial/#2-load-audio-files","title":"2. Load Audio Files","text":"<pre><code># Load a WAV file\nurl = \"https://github.com/kasahart/wandas/raw/main/examples/data/summer_streets1.wav\"\n\naudio = wd.read_wav(url)\nprint(f\"Sampling rate: {audio.sampling_rate} Hz\")\nprint(f\"Number of channels: {len(audio)}\")\nprint(f\"Duration: {audio.duration} s\")\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: session wd_demo; n8&gt;\", line 3, in &lt;module&gt;\n    audio = wd.read_wav(url)\n  File \"/home/runner/work/wandas/wandas/wandas/io/wav_io.py\", line 44, in read_wav\n    sampling_rate, data = wavfile.read(file_obj)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/scipy/io/wavfile.py\", line 677, in read\n    file_size, is_big_endian, is_rf64 = _read_riff_chunk(fid)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/scipy/io/wavfile.py\", line 536, in _read_riff_chunk\n    raise ValueError(f\"File format {repr(str1)} not understood. Only \"\nValueError: File format b'\\n\\n\\n\\n' not understood. Only 'RIFF', 'RIFX', and 'RF64' supported.\n</code></pre>"},{"location":"en/tutorial/#3-visualize-signals","title":"3. Visualize Signals","text":"<pre><code># Display waveform\naudio.describe()\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: session wd_demo; n9&gt;\", line 1, in &lt;module&gt;\n    audio.describe(is_close=False)\nNameError: name 'audio' is not defined\n</code></pre>"},{"location":"en/tutorial/#4-basic-signal-processing","title":"4. Basic Signal Processing","text":"<pre><code># Apply a low-pass filter (passing frequencies below 1kHz)\nfiltered = audio.low_pass_filter(cutoff=1000)\n\n# Visualize and compare results\nfiltered.previous.plot(title=\"Original\")\nfiltered.plot(title=\"filtered\")\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"/home/runner/work/wandas/wandas/.venv/lib/python3.10/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: session wd_demo; n10&gt;\", line 1, in &lt;module&gt;\n    filtered = audio.low_pass_filter(cutoff=1000)\nNameError: name 'audio' is not defined\n</code></pre>"},{"location":"en/tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>Check out various applications in the Cookbook</li> <li>Look up detailed functions in the API Reference</li> <li>Understand the library's design philosophy in the Theory Background</li> </ul>"},{"location":"en/tutorial/#recipes-by-use-case","title":"Recipes by Use Case","text":"<p>This section provides links to tutorial notebooks that demonstrate more detailed features and application examples of the Wandas library.</p> <ul> <li>00_setup.ipynb: Setup and basic configuration</li> <li>01_io_basics.ipynb: File reading/writing and basic operations</li> <li>02_signal_processing_basics.ipynb: Basic signal processing</li> <li>03_visualization.ipynb: Data visualization</li> <li>04_time_frequency.ipynb: Time-frequency analysis</li> <li>05_lazy_and_dask.ipynb: Lazy evaluation and large-scale data processing with Dask</li> <li>06_metadata_history.ipynb: Utilizing metadata and processing history</li> <li>07_batch_processing.ipynb: Batch processing for multiple files</li> <li>08_frame_dataset_usage.ipynb: FrameDataset Usage Guide - Efficient processing of multiple audio files in a folder</li> <li>09_extending_api.ipynb: Adding custom functions and extending the API</li> <li>10_interoperability.ipynb: Integration with other libraries</li> <li>11_case_studies.ipynb: Practical use case studies</li> </ul> <p>Hint</p> <p>Each notebook focuses on a specific topic. Refer to them sequentially or as needed based on your interests. For basic usage of Wandas, please also see the \"Basic Usage\" section at the beginning of this document.</p>"}]}