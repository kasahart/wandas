{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrameDataset Usage Guide\n",
    "# FrameDataset 使用ガイド\n",
    "\n",
    "This notebook demonstrates how to use the `FrameDataset` class for efficient batch processing of audio files.\n",
    "\n",
    "このノートブックでは、`FrameDataset` クラスを使用して音声ファイルのバッチ処理を効率的に行う方法を示します。\n",
    "\n",
    "## Overview / 概要\n",
    "\n",
    "`FrameDataset` is an abstract base class for handling multiple audio files in a folder. The main concrete implementations are:\n",
    "- `ChannelFrameDataset`: For time-domain audio data\n",
    "- `SpectrogramFrameDataset`: For time-frequency domain data (typically created from `ChannelFrameDataset.stft()`)\n",
    "\n",
    "`FrameDataset` は、フォルダ内の複数の音声ファイルを扱うための抽象基底クラスです。主な具象実装は以下の通りです：\n",
    "- `ChannelFrameDataset`: 時間領域の音声データ用\n",
    "- `SpectrogramFrameDataset`: 時間周波数領域データ用（通常は `ChannelFrameDataset.stft()` から作成）\n",
    "\n",
    "## Key Features / 主な機能\n",
    "\n",
    "- **Lazy Loading**: Efficient memory usage by loading files only when needed\n",
    "- **Transformation Chaining**: Apply multiple transformations efficiently\n",
    "- **Sampling**: Extract subsets of data for testing or analysis\n",
    "- **Metadata Tracking**: Keep track of dataset properties and processing history\n",
    "\n",
    "- **遅延読み込み**: 必要なときだけファイルを読み込むことでメモリ効率を向上\n",
    "- **変換のチェーン**: 複数の変換を効率的に適用\n",
    "- **サンプリング**: テストや分析のためにデータのサブセットを抽出\n",
    "- **メタデータ追跡**: データセットのプロパティと処理履歴を追跡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup / セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandas as wd\n",
    "from wandas.utils.frame_dataset import ChannelFrameDataset, SpectrogramFrameDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For this example, we'll create some sample audio files\n",
    "# この例では、サンプル音声ファイルを作成します\n",
    "import tempfile\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory with sample audio files\n",
    "# サンプル音声ファイルを含む一時ディレクトリを作成\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Created temporary directory: {temp_dir}\")\n",
    "\n",
    "# Generate and save sample audio files\n",
    "# サンプル音声ファイルを生成して保存\n",
    "sampling_rate = 16000\n",
    "duration = 2.0  # seconds\n",
    "\n",
    "for i in range(5):\n",
    "    # Generate a sine wave with different frequencies\n",
    "    # 異なる周波数の正弦波を生成\n",
    "    freq = 440 * (i + 1)  # A4, A5, etc.\n",
    "    signal = wd.generate_sin(freqs=[freq], duration=duration, sampling_rate=sampling_rate)\n",
    "    \n",
    "    # Save as WAV file\n",
    "    # WAVファイルとして保存\n",
    "    filename = os.path.join(temp_dir, f\"sample_{i+1}.wav\")\n",
    "    signal.to_wav(filename)\n",
    "    print(f\"Created: {filename}\")\n",
    "\n",
    "# Create a subdirectory for testing recursive loading\n",
    "# 再帰的読み込みテスト用のサブディレクトリを作成\n",
    "sub_dir = os.path.join(temp_dir, \"subdir\")\n",
    "os.makedirs(sub_dir)\n",
    "\n",
    "for i in range(2):\n",
    "    freq = 880 * (i + 1)\n",
    "    signal = wd.generate_sin(freqs=[freq], duration=duration, sampling_rate=sampling_rate)\n",
    "    filename = os.path.join(sub_dir, f\"sub_sample_{i+1}.wav\")\n",
    "    signal.to_wav(filename)\n",
    "    print(f\"Created: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Initialization / 基本的な初期化\n",
    "\n",
    "### 1.1 Creating a ChannelFrameDataset\n",
    "\n",
    "The most common way to create a dataset is using the `from_folder` class method or direct initialization.\n",
    "\n",
    "データセットを作成する最も一般的な方法は、`from_folder` クラスメソッドまたは直接初期化です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using from_folder (recommended)\n",
    "# 方法1: from_folder を使用（推奨）\n",
    "dataset = ChannelFrameDataset.from_folder(\n",
    "    folder_path=temp_dir,\n",
    "    sampling_rate=None,  # Keep original sampling rate / 元のサンプリングレートを維持\n",
    "    file_extensions=[\".wav\"],  # File types to load / 読み込むファイルタイプ\n",
    "    recursive=False,  # Don't search subdirectories / サブディレクトリを検索しない\n",
    "    lazy_loading=True  # Load files on demand / 必要に応じてファイルを読み込む\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} files\")\n",
    "print(f\"データセットが {len(dataset)} ファイルで作成されました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Direct initialization\n",
    "# 方法2: 直接初期化\n",
    "dataset_direct = ChannelFrameDataset(\n",
    "    folder_path=temp_dir,\n",
    "    file_extensions=[\".wav\"],\n",
    "    lazy_loading=True,\n",
    "    recursive=False\n",
    ")\n",
    "\n",
    "print(f\"Direct initialization: {len(dataset_direct)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Important Parameters / 重要なパラメータ\n",
    "\n",
    "**folder_path**: Path to the folder containing audio files  \n",
    "音声ファイルを含むフォルダへのパス\n",
    "\n",
    "**sampling_rate**: Target sampling rate (files will be resampled if different)  \n",
    "目標サンプリングレート（異なる場合はリサンプリングされます）\n",
    "\n",
    "**file_extensions**: List of file extensions to include (default: `[\".wav\", \".mp3\", \".flac\", \".csv\"]`)  \n",
    "含めるファイル拡張子のリスト（デフォルト: `[\".wav\", \".mp3\", \".flac\", \".csv\"]`）\n",
    "\n",
    "**lazy_loading**: If True, files are loaded only when accessed (default: True)  \n",
    "True の場合、アクセス時のみファイルを読み込む（デフォルト: True）\n",
    "\n",
    "**recursive**: If True, search subdirectories recursively  \n",
    "True の場合、サブディレクトリを再帰的に検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Recursive loading\n",
    "# 例: 再帰的読み込み\n",
    "dataset_recursive = ChannelFrameDataset.from_folder(\n",
    "    folder_path=temp_dir,\n",
    "    recursive=True  # Include files in subdirectories / サブディレクトリのファイルも含める\n",
    ")\n",
    "\n",
    "print(f\"Non-recursive dataset: {len(dataset)} files\")\n",
    "print(f\"Recursive dataset: {len(dataset_recursive)} files\")\n",
    "print(f\"非再帰的データセット: {len(dataset)} ファイル\")\n",
    "print(f\"再帰的データセット: {len(dataset_recursive)} ファイル\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accessing Files / ファイルへのアクセス\n",
    "\n",
    "### 2.1 Getting Individual Frames / 個別のフレームを取得\n",
    "\n",
    "Use the `__getitem__` method (indexing) to access individual frames.\n",
    "\n",
    "`__getitem__` メソッド（インデックス）を使用して個別のフレームにアクセスします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first file\n",
    "# 最初のファイルにアクセス\n",
    "first_frame = dataset[0]\n",
    "\n",
    "if first_frame is not None:\n",
    "    print(f\"Label: {first_frame.label}\")\n",
    "    print(f\"Sampling rate: {first_frame.sampling_rate} Hz\")\n",
    "    print(f\"Duration: {first_frame.duration:.2f} seconds\")\n",
    "    print(f\"Channels: {first_frame.n_channels}\")\n",
    "    \n",
    "    # Plot the waveform\n",
    "    # 波形をプロット\n",
    "    first_frame.plot()\n",
    "    plt.title(f\"Waveform: {first_frame.label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lazy Loading Demonstration / 遅延読み込みのデモンストレーション\n",
    "\n",
    "With lazy loading, files are only loaded when accessed. This is efficient for large datasets.\n",
    "\n",
    "遅延読み込みでは、アクセス時にのみファイルが読み込まれます。大規模データセットに効率的です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata before accessing any files\n",
    "# ファイルにアクセスする前にメタデータを取得\n",
    "metadata_before = dataset.get_metadata()\n",
    "print(\"Before accessing files:\")\n",
    "print(f\"  Loaded count: {metadata_before['loaded_count']} / {metadata_before['file_count']}\")\n",
    "\n",
    "# Access a file\n",
    "# ファイルにアクセス\n",
    "_ = dataset[0]\n",
    "\n",
    "# Get metadata after accessing one file\n",
    "# 1つのファイルにアクセスした後のメタデータを取得\n",
    "metadata_after = dataset.get_metadata()\n",
    "print(\"\\nAfter accessing one file:\")\n",
    "print(f\"  Loaded count: {metadata_after['loaded_count']} / {metadata_after['file_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Iterating Over the Dataset / データセットの反復処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all files in the dataset\n",
    "# データセット内のすべてのファイルを反復処理\n",
    "print(\"Files in dataset:\")\n",
    "for i in range(len(dataset)):\n",
    "    frame = dataset[i]\n",
    "    if frame is not None:\n",
    "        print(f\"  [{i}] {frame.label} - {frame.duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling / サンプリング\n",
    "\n",
    "### 3.1 Random Sampling / ランダムサンプリング\n",
    "\n",
    "The `sample` method allows you to extract a random subset of the dataset.\n",
    "\n",
    "`sample` メソッドを使用すると、データセットのランダムなサブセットを抽出できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample by number of files\n",
    "# ファイル数でサンプリング\n",
    "sampled_dataset = dataset.sample(n=3, seed=42)\n",
    "\n",
    "print(f\"Original dataset: {len(dataset)} files\")\n",
    "print(f\"Sampled dataset: {len(sampled_dataset)} files\")\n",
    "print(f\"元のデータセット: {len(dataset)} ファイル\")\n",
    "print(f\"サンプリングされたデータセット: {len(sampled_dataset)} ファイル\")\n",
    "\n",
    "# Show sampled files\n",
    "# サンプリングされたファイルを表示\n",
    "print(\"\\nSampled files:\")\n",
    "for i in range(len(sampled_dataset)):\n",
    "    frame = sampled_dataset[i]\n",
    "    if frame is not None:\n",
    "        print(f\"  {frame.label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample by ratio\n",
    "# 比率でサンプリング\n",
    "sampled_by_ratio = dataset.sample(ratio=0.5, seed=123)\n",
    "\n",
    "print(f\"Sampling 50% of {len(dataset)} files: {len(sampled_by_ratio)} files\")\n",
    "print(f\"{len(dataset)} ファイルの50%をサンプリング: {len(sampled_by_ratio)} ファイル\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default sampling (10% or minimum 1 file)\n",
    "# デフォルトサンプリング（10%または最小1ファイル）\n",
    "default_sample = dataset.sample(seed=999)\n",
    "\n",
    "print(f\"Default sample: {len(default_sample)} files\")\n",
    "print(f\"デフォルトサンプル: {len(default_sample)} ファイル\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Reproducible Sampling / 再現可能なサンプリング\n",
    "\n",
    "Use the `seed` parameter for reproducible random sampling.\n",
    "\n",
    "再現可能なランダムサンプリングには `seed` パラメータを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample with same seed produces same results\n",
    "# 同じシードでサンプリングすると同じ結果が得られる\n",
    "sample1 = dataset.sample(n=2, seed=42)\n",
    "sample2 = dataset.sample(n=2, seed=42)\n",
    "\n",
    "print(\"Sample 1:\")\n",
    "for i in range(len(sample1)):\n",
    "    frame = sample1[i]\n",
    "    if frame:\n",
    "        print(f\"  {frame.label}\")\n",
    "\n",
    "print(\"\\nSample 2 (same seed):\")\n",
    "for i in range(len(sample2)):\n",
    "    frame = sample2[i]\n",
    "    if frame:\n",
    "        print(f\"  {frame.label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Applying Transformations / 変換の適用\n",
    "\n",
    "### 4.1 Basic Transformations / 基本的な変換\n",
    "\n",
    "The `apply` method allows you to apply a function to all frames in the dataset.\n",
    "\n",
    "`apply` メソッドを使用すると、データセット内のすべてのフレームに関数を適用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a custom transformation\n",
    "# カスタム変換を適用\n",
    "def amplify(frame):\n",
    "    \"\"\"Amplify the signal by a factor of 2.\"\"\"\n",
    "    return frame * 2.0\n",
    "\n",
    "# Apply the transformation (lazy evaluation)\n",
    "# 変換を適用（遅延評価）\n",
    "amplified_dataset = dataset.apply(amplify)\n",
    "\n",
    "print(f\"Transformation applied (not yet computed)\")\n",
    "print(f\"変換が適用されました（まだ計算されていません）\")\n",
    "\n",
    "# Access a frame to trigger computation\n",
    "# フレームにアクセスして計算をトリガー\n",
    "original_frame = dataset[0]\n",
    "amplified_frame = amplified_dataset[0]\n",
    "\n",
    "if original_frame and amplified_frame:\n",
    "    print(f\"\\nOriginal max amplitude: {np.max(np.abs(original_frame.compute())):.4f}\")\n",
    "    print(f\"Amplified max amplitude: {np.max(np.abs(amplified_frame.compute())):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Built-in Transformations / 組み込み変換\n",
    "\n",
    "`ChannelFrameDataset` provides several built-in transformation methods.\n",
    "\n",
    "`ChannelFrameDataset` はいくつかの組み込み変換メソッドを提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to a different sampling rate\n",
    "# 異なるサンプリングレートにリサンプリング\n",
    "resampled_dataset = dataset.resample(target_sr=8000)\n",
    "\n",
    "original_sr = dataset[0].sampling_rate if dataset[0] else None\n",
    "resampled_sr = resampled_dataset[0].sampling_rate if resampled_dataset[0] else None\n",
    "\n",
    "print(f\"Original sampling rate: {original_sr} Hz\")\n",
    "print(f\"Resampled sampling rate: {resampled_sr} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim audio files\n",
    "# 音声ファイルをトリミング\n",
    "trimmed_dataset = dataset.trim(start=0.2, end=1.5)\n",
    "\n",
    "original_duration = dataset[0].duration if dataset[0] else None\n",
    "trimmed_duration = trimmed_dataset[0].duration if trimmed_dataset[0] else None\n",
    "\n",
    "print(f\"Original duration: {original_duration:.2f}s\")\n",
    "print(f\"Trimmed duration: {trimmed_duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize audio files\n",
    "# 音声ファイルを正規化\n",
    "normalized_dataset = dataset.normalize()\n",
    "\n",
    "normalized_frame = normalized_dataset[0]\n",
    "if normalized_frame:\n",
    "    max_amplitude = np.max(np.abs(normalized_frame.compute()))\n",
    "    print(f\"Max amplitude after normalization: {max_amplitude:.4f}\")\n",
    "    print(f\"正規化後の最大振幅: {max_amplitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Chaining Transformations / 変換のチェーン\n",
    "\n",
    "Multiple transformations can be chained together efficiently.\n",
    "\n",
    "複数の変換を効率的にチェーンできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain multiple transformations\n",
    "# 複数の変換をチェーン\n",
    "processed_dataset = (\n",
    "    dataset\n",
    "    .resample(target_sr=8000)  # Resample to 8 kHz\n",
    "    .trim(start=0.5, end=1.5)   # Keep 1 second from 0.5s to 1.5s\n",
    "    .normalize()                 # Normalize amplitude\n",
    ")\n",
    "\n",
    "# Access a processed frame\n",
    "# 処理されたフレームにアクセス\n",
    "processed_frame = processed_dataset[0]\n",
    "\n",
    "if processed_frame:\n",
    "    print(f\"Processed frame:\")\n",
    "    print(f\"  Sampling rate: {processed_frame.sampling_rate} Hz\")\n",
    "    print(f\"  Duration: {processed_frame.duration:.2f}s\")\n",
    "    print(f\"  Max amplitude: {np.max(np.abs(processed_frame.compute())):.4f}\")\n",
    "    \n",
    "    processed_frame.plot()\n",
    "    plt.title(f\"Processed: {processed_frame.label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 STFT - Converting to Spectrogram / STFT - スペクトログラムへの変換\n",
    "\n",
    "The `stft` method creates a `SpectrogramFrameDataset` from the time-domain data.\n",
    "\n",
    "`stft` メソッドは、時間領域データから `SpectrogramFrameDataset` を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply STFT to create spectrograms\n",
    "# STFTを適用してスペクトログラムを作成\n",
    "spectrogram_dataset = dataset.stft(\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    window=\"hann\"\n",
    ")\n",
    "\n",
    "print(f\"Type: {type(spectrogram_dataset).__name__}\")\n",
    "print(f\"Number of files: {len(spectrogram_dataset)}\")\n",
    "\n",
    "# Access and plot a spectrogram\n",
    "# スペクトログラムにアクセスしてプロット\n",
    "spec_frame = spectrogram_dataset[0]\n",
    "\n",
    "if spec_frame:\n",
    "    print(f\"\\nSpectrogram shape: {spec_frame.shape}\")\n",
    "    print(f\"FFT size: {spec_frame.n_fft}\")\n",
    "    print(f\"Hop length: {spec_frame.hop_length}\")\n",
    "    \n",
    "    spec_frame.plot()\n",
    "    plt.title(f\"Spectrogram: {spec_frame.label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metadata and Dataset Information / メタデータとデータセット情報\n",
    "\n",
    "### 5.1 Getting Dataset Metadata / データセットのメタデータを取得\n",
    "\n",
    "The `get_metadata` method provides comprehensive information about the dataset.\n",
    "\n",
    "`get_metadata` メソッドは、データセットに関する包括的な情報を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata for the original dataset\n",
    "# 元のデータセットのメタデータを取得\n",
    "metadata = dataset.get_metadata()\n",
    "\n",
    "print(\"Dataset Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata for a transformed dataset\n",
    "# 変換されたデータセットのメタデータを取得\n",
    "transformed_metadata = processed_dataset.get_metadata()\n",
    "\n",
    "print(\"\\nTransformed Dataset Metadata:\")\n",
    "for key, value in transformed_metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Usage / 高度な使用法\n",
    "\n",
    "### 6.1 Combining Sampling and Transformation / サンプリングと変換の組み合わせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset and apply transformations\n",
    "# サブセットをサンプリングして変換を適用\n",
    "sampled_and_processed = (\n",
    "    dataset\n",
    "    .sample(n=3, seed=42)       # Sample 3 files\n",
    "    .resample(target_sr=8000)   # Resample to 8 kHz\n",
    "    .normalize()                 # Normalize\n",
    ")\n",
    "\n",
    "print(f\"Sampled and processed dataset: {len(sampled_and_processed)} files\")\n",
    "\n",
    "# Process all sampled files\n",
    "# すべてのサンプリングされたファイルを処理\n",
    "for i in range(len(sampled_and_processed)):\n",
    "    frame = sampled_and_processed[i]\n",
    "    if frame:\n",
    "        print(f\"  {frame.label}: {frame.sampling_rate}Hz, {frame.duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Custom Processing Function / カスタム処理関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom processing function\n",
    "# カスタム処理関数を定義\n",
    "def custom_processing(frame):\n",
    "    \"\"\"\n",
    "    Custom processing: apply low-pass filter and normalize.\n",
    "    \n",
    "    カスタム処理: ローパスフィルタを適用して正規化します。\n",
    "    \"\"\"\n",
    "    # Apply low-pass filter at 1000 Hz\n",
    "    # 1000 Hz でローパスフィルタを適用\n",
    "    filtered = frame.low_pass_filter(cutoff=1000)\n",
    "    \n",
    "    # Normalize\n",
    "    # 正規化\n",
    "    normalized = filtered.normalize()\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# Apply custom processing\n",
    "# カスタム処理を適用\n",
    "custom_dataset = dataset.apply(custom_processing)\n",
    "\n",
    "# Access a processed frame\n",
    "# 処理されたフレームにアクセス\n",
    "custom_frame = custom_dataset[0]\n",
    "\n",
    "if custom_frame:\n",
    "    print(f\"Custom processed frame: {custom_frame.label}\")\n",
    "    custom_frame.plot()\n",
    "    plt.title(f\"Custom Processing: {custom_frame.label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Working with SpectrogramFrameDataset / SpectrogramFrameDataset の操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to spectrogram dataset\n",
    "# スペクトログラムデータセットに変換を適用\n",
    "def enhance_spectrogram(spec_frame):\n",
    "    \"\"\"\n",
    "    Enhance spectrogram by adding a small constant.\n",
    "    \n",
    "    小さな定数を追加してスペクトログラムを強調します。\n",
    "    \"\"\"\n",
    "    return spec_frame + 1e-10  # Add small constant to avoid log(0)\n",
    "\n",
    "# Apply to spectrogram dataset\n",
    "# スペクトログラムデータセットに適用\n",
    "enhanced_spec_dataset = spectrogram_dataset.apply(enhance_spectrogram)\n",
    "\n",
    "# Access and visualize\n",
    "# アクセスして可視化\n",
    "enhanced_spec = enhanced_spec_dataset[0]\n",
    "\n",
    "if enhanced_spec:\n",
    "    enhanced_spec.plot()\n",
    "    plt.title(f\"Enhanced Spectrogram: {enhanced_spec.label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices / ベストプラクティス\n",
    "\n",
    "### 7.1 Memory Efficiency / メモリ効率\n",
    "\n",
    "- Always use `lazy_loading=True` for large datasets\n",
    "- Access only the files you need\n",
    "- Use sampling to test processing pipelines before applying to the full dataset\n",
    "\n",
    "- 大規模データセットには常に `lazy_loading=True` を使用する\n",
    "- 必要なファイルのみにアクセスする\n",
    "- 完全なデータセットに適用する前に、サンプリングを使用して処理パイプラインをテストする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test processing on a small sample first\n",
    "# 例: 最初に小さなサンプルで処理をテスト\n",
    "test_sample = dataset.sample(n=2, seed=42)\n",
    "test_processed = test_sample.resample(target_sr=8000).normalize()\n",
    "\n",
    "# Verify the processing works as expected\n",
    "# 処理が期待通りに動作することを確認\n",
    "test_frame = test_processed[0]\n",
    "if test_frame:\n",
    "    print(f\"Test processing successful: {test_frame.label}\")\n",
    "    print(f\"  Sampling rate: {test_frame.sampling_rate}\")\n",
    "    print(f\"  Max amplitude: {np.max(np.abs(test_frame.compute())):.4f}\")\n",
    "\n",
    "# If satisfied, apply to full dataset\n",
    "# 満足できる場合は、完全なデータセットに適用\n",
    "full_processed = dataset.resample(target_sr=8000).normalize()\n",
    "print(f\"\\nProcessing pipeline ready for {len(full_processed)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Error Handling / エラーハンドリング\n",
    "\n",
    "Always check if frames are `None` before processing, as file loading can fail.\n",
    "\n",
    "ファイルの読み込みに失敗する可能性があるため、処理前にフレームが `None` でないか常に確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe way to process frames\n",
    "# フレームを安全に処理する方法\n",
    "for i in range(len(dataset)):\n",
    "    frame = dataset[i]\n",
    "    \n",
    "    if frame is None:\n",
    "        print(f\"Warning: Failed to load frame at index {i}\")\n",
    "        continue\n",
    "    \n",
    "    # Process the frame\n",
    "    # フレームを処理\n",
    "    print(f\"Processing {frame.label}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup / クリーンアップ\n",
    "\n",
    "Clean up temporary files created for this example.\n",
    "\n",
    "この例で作成した一時ファイルをクリーンアップします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary directory\n",
    "# 一時ディレクトリをクリーンアップ\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f\"Cleaned up temporary directory: {temp_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to clean up: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary / まとめ\n",
    "\n",
    "This notebook demonstrated the key features of `FrameDataset`:\n",
    "\n",
    "1. **Initialization**: Creating datasets from folders with various options\n",
    "2. **Accessing Data**: Using indexing and iteration to access frames\n",
    "3. **Sampling**: Extracting random subsets for testing or analysis\n",
    "4. **Transformations**: Applying processing operations lazily and efficiently\n",
    "5. **Metadata**: Tracking dataset properties and processing history\n",
    "6. **Advanced Usage**: Combining operations for complex workflows\n",
    "\n",
    "このノートブックでは、`FrameDataset` の主な機能を実演しました：\n",
    "\n",
    "1. **初期化**: さまざまなオプションでフォルダからデータセットを作成\n",
    "2. **データへのアクセス**: インデックスと反復処理を使用してフレームにアクセス\n",
    "3. **サンプリング**: テストや分析のためにランダムなサブセットを抽出\n",
    "4. **変換**: 処理操作を遅延的かつ効率的に適用\n",
    "5. **メタデータ**: データセットのプロパティと処理履歴を追跡\n",
    "6. **高度な使用法**: 複雑なワークフローのために操作を組み合わせる\n",
    "\n",
    "For more information, refer to the [API documentation](https://kasahart.github.io/wandas/).\n",
    "\n",
    "詳細については、[APIドキュメント](https://kasahart.github.io/wandas/)を参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
